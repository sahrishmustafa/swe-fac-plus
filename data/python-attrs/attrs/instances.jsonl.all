{"repo": "python-attrs/attrs", "pull_number": 1417, "instance_id": "python-attrs__attrs-1417", "issue_numbers": ["1416"], "base_commit": "19943b775d40c018e844f2cb1728442f58112a3b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -448,7 +448,7 @@ def _transform_attrs(\n     attrs = base_attrs + own_attrs\n \n     if field_transformer is not None:\n-        attrs = field_transformer(cls, attrs)\n+        attrs = tuple(field_transformer(cls, attrs))\n \n     # Check attr order after executing the field_transformer.\n     # Mandatory vs non-mandatory attr order only matters when they are part of\n", "test_patch": "diff --git a/tests/test_hooks.py b/tests/test_hooks.py\n--- a/tests/test_hooks.py\n+++ b/tests/test_hooks.py\n@@ -217,6 +217,22 @@ class C:\n         assert \"CAttributes\" == fields_type.__name__\n         assert issubclass(fields_type, tuple)\n \n+    def test_hook_generator(self):\n+        \"\"\"\n+        Ensure that `attrs.fields` are correctly recorded when field_transformer is a generator\n+\n+        Regression test for #1417\n+        \"\"\"\n+\n+        def hook(cls, attribs):\n+            yield from attribs\n+\n+        @attr.s(auto_attribs=True, field_transformer=hook)\n+        class Base:\n+            x: int\n+\n+        assert [\"x\"] == [a.name for a in attr.fields(Base)]\n+\n \n class TestAsDictHook:\n     def test_asdict(self):\n", "problem_statement": "Creating a Subclassed instance now errors with `got an unexpected keyword argument`\nWe just noticed this in Airflow CI on upgrading to 25.2.0.\n\nThe error is\n\n```\nERROR    airflow.models.dagbag.DagBag:dagbag.py:394 Failed to import: /opt/airflow/airflow/example_dags/example_dynamic_task_mapping.py\nTraceback (most recent call last):\n  File \"/opt/airflow/airflow/models/dagbag.py\", line 384, in parse\n    loader.exec_module(new_module)\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/opt/airflow/airflow/example_dags/example_dynamic_task_mapping.py\", line 27, in <module>\n    with DAG(dag_id=\"example_dynamic_task_mapping\", schedule=None, start_date=datetime(2022, 3, 4)) as dag:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: DAG.__init__() got an unexpected keyword argument 'dag_id'\n```\n\n(Yes, I know your view on subclassing. I don't disagree either)\n\nMinimal repro case:\n\n```python\nimport attrs\n\ndef _all_after_dag_id_to_kw_only(cls, fields: list[attrs.Attribute]):\n    i = iter(fields)\n    f = next(i)\n    if f.name != \"dag_id\":\n        raise RuntimeError(\"dag_id was not the first field\")\n    yield f\n\n    for f in i:\n        yield f.evolve(kw_only=True)\n\n\n@attrs.define(field_transformer=_all_after_dag_id_to_kw_only)\nclass Base:\n    dag_id: str\n    has_default: str = \"default\"\n\n\n@attrs.define()\nclass Subclass(Base):\n    other: bool\n\n\nx = Subclass(dag_id=\"foo\", other=False)\n\nprint(repr(x))\nprint(attrs.__version__)\n```\n", "hints_text": "https://github.com/python-attrs/attrs/pull/1401 might have caused it\nMight do, yes, but the minimal example is not failing, so it's some quirk of what we are doing in Airflow\ncc @jamesmurphy-mc \npls provide a repro and I'll see if I can do anything before leaving for my vacation tomorrow afternoon\nI updated the example to include `help(Subclass.__init__)`;\n\nOn 25.1.0 we see this:\n```\n__init__(self, dag_id: str, other: bool, *, has_default: str = 'default') -> None\n    Method generated by attrs for class Subclass.\n```\n\nOn 25.2.0 we see this:\n```\n__init__(self, other: bool) -> None\n    Method generated by attrs for class Subclass.\n```\n@hynek No rush at all!, we are happy to pin to !latest for now\nI have got a simple reproducer. Let me try that.\ncc @sscherfke for good measure\n@tirkarthi I've got a reproducer now. Top post has been updated.\n@ashb Thanks, I got the same one but didn't to subclass.\n\n```python\nimport attrs\n\ndef _all_after_dag_id_to_kw_only(cls, fields: list[attrs.Attribute]):\n    i = iter(fields)\n    f = next(i)\n    if f.name != \"dag_id\":\n        raise RuntimeError(\"dag_id was not the first field\")\n    yield f\n\n    for f in i:\n        yield f.evolve(kw_only=True)\n\n\n@attrs.define(repr=False, field_transformer=_all_after_dag_id_to_kw_only, slots=False)\nclass DAG:\n    dag_id: str = attrs.field(kw_only=False, validator=attrs.validators.instance_of(str))\n\n\ndag = DAG(dag_id=\"test\")\nprint(dag)\n```\n\n```\n(.venv) \u279c  airflow git:(main) \u2717 python /tmp/attrs_repro.py\n<__main__.DAG object at 0x7f69c5305bd0>\n(.venv) \u279c  airflow git:(main) \u2717 pip install attrs==25.2.0\nCollecting attrs==25.2.0\n  Downloading attrs-25.2.0-py3-none-any.whl.metadata (11 kB)\nDownloading attrs-25.2.0-py3-none-any.whl (64 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.0/64.0 kB 1.5 MB/s eta 0:00:00\nInstalling collected packages: attrs\n  Attempting uninstall: attrs\n    Found existing installation: attrs 25.1.0\n    Uninstalling attrs-25.1.0:\n      Successfully uninstalled attrs-25.1.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydb 3.18.15 requires protobuf<5.0.0,>=3.13.0, but you have protobuf 5.29.3 which is incompatible.\nSuccessfully installed attrs-25.2.0\n\n[notice] A new release of pip is available: 24.0 -> 25.0.1\n[notice] To update, run: pip install --upgrade pip\n(.venv) \u279c  airflow git:(main) \u2717 python /tmp/attrs_repro.py \nTraceback (most recent call last):\n  File \"/tmp/attrs_repro.py\", line 19, in <module>\n    dag = DAG(dag_id=\"test\")\n          ^^^^^^^^^^^^^^^^^^\nTypeError: DAG.__init__() got an unexpected keyword argument 'dag_id'\n```\nWalking up the stack to where the field transformer is called, I notice that base_attrs is an empty list, even though collect_mro is true. \nDebugging continues!\n`print(inspect.signature(DAG))`\n\nOn 24.2.0 : `(dag_id: str) -> None`\nOn 25.2.0 : `() -> None`\n\n\nOh, this might be part of the problem, Base.__attrs_attrs__ is empty when a field transformer is used:\n\n```python\n\nimport attrs\n\nprint(f\"{attrs.__version__=}\")\ndef _all_after_dag_id_to_kw_only(cls, fields: list[attrs.Attribute]):\n    i = iter(fields)\n    f = next(i)\n    if f.name != \"dag_id\":\n        raise RuntimeError(\"dag_id was not the first field\")\n    yield f\n\n    for f in i:\n        yield f.evolve(kw_only=True)\n\n\n@attrs.define(field_transformer=_all_after_dag_id_to_kw_only)\nclass Base:\n    dag_id: str\n    has_default: str = \"default\"\n\nprint(attrs.fields(Base))\n```\n\nPrints:\n\n```\nattrs.__version__='25.2.0'\n()\n```\nAhhh, got it.\n\nThe issue is that the field transformer is defined as a generator, so it's exhausted once looking for the `a.init` and `a.kw_only` args, then it's empty in the uses elsewhere in `_transform_attr` \n> Ahhh, got it.\n\n\ud83c\udf89\n\n> The issue is that the field transformer is defined as a generator, so it's exhausted once looking for the `a.init` and `a.kw_only` args, then it's empty in the uses elsewhere in `_transform_attr`\n\nWithout being able to look at the code: sounds like we should be able to convert it to a tuple on first use? Quick PRs with tests welcome. ;)\nYup, that was exactly my plan, `inspect.isgenerator()` + tuple.", "created_at": "2025-03-12T16:48:42Z"}
{"repo": "python-attrs/attrs", "pull_number": 1410, "instance_id": "python-attrs__attrs-1410", "issue_numbers": ["1354"], "base_commit": "6bde3618237cdae312e4e7fb006690be2a3ee0f6", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -2491,7 +2491,7 @@ def from_counting_attr(cls, name: str, ca: _CountingAttr, type=None):\n         if type is None:\n             type = ca.type\n         elif ca.type is not None:\n-            msg = \"Type annotation and type argument cannot both be present\"\n+            msg = f\"Type annotation and type argument cannot both be present for '{name}'.\"\n             raise ValueError(msg)\n         return cls(\n             name,\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -62,7 +62,7 @@ class C:\n                 x: int = attr.ib(type=int)\n \n         assert (\n-            \"Type annotation and type argument cannot both be present\",\n+            \"Type annotation and type argument cannot both be present for 'x'.\",\n         ) == e.value.args\n \n     def test_typing_annotations(self):\n", "problem_statement": "unhelpful message \"ValueError: Type annotation and type argument cannot both be present\"\nGetting this message because I both have the type annotation and type defined on a custom attribute class which is reasonable considering the ambiguity.\r\n\r\nHowever I think the message itself could be more helpful by displaying the name of the attribute to eliminate the variable hunt.\r\n\r\nMy suggested change is:\r\n\r\nhttps://github.com/python-attrs/attrs/blob/2afd663bf40e4a8209986accdfb1e2d53afc15e2/src/attr/_make.py#L2354\r\n```python\r\n    @classmethod\r\n    def from_counting_attr(cls, name, ca, type=None):\r\n        # type holds the annotated value. deal with conflicts:\r\n        if type is None:\r\n            type = ca.type\r\n        elif ca.type is not None:\r\n            raise ValueError(\r\n                f\"Type annotation and type argument for {name} cannot both be present\"\r\n            )\r\n        inst_dict = {\r\n            k: getattr(ca, k)\r\n            for k\r\n            in Attribute.__slots__\r\n            if k not in (\r\n                \"name\", \"validator\", \"default\", \"type\", \"convert\",\r\n            )  # exclude methods and deprecated alias\r\n        }\r\n        return cls(\r\n            name=name, validator=ca._validator, default=ca._default, type=type,\r\n            **inst_dict\r\n        )\r\n ```\n", "hints_text": "", "created_at": "2025-02-22T10:44:17Z"}
{"repo": "python-attrs/attrs", "pull_number": 1383, "instance_id": "python-attrs__attrs-1383", "issue_numbers": ["1313"], "base_commit": "103d51f6efa36efcc7be4adecfd571da3f63291c", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -10,7 +10,7 @@\n from . import converters, exceptions, filters, setters, validators\n from ._cmp import cmp_using\n from ._config import get_run_validators, set_run_validators\n-from ._funcs import asdict, assoc, astuple, evolve, has, resolve_types\n+from ._funcs import asdict, assoc, astuple, has, resolve_types\n from ._make import (\n     NOTHING,\n     Attribute,\n@@ -19,6 +19,7 @@\n     _Nothing,\n     attrib,\n     attrs,\n+    evolve,\n     fields,\n     fields_dict,\n     make_class,\ndiff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -394,60 +394,6 @@ def assoc(inst, **changes):\n     return new\n \n \n-def evolve(*args, **changes):\n-    \"\"\"\n-    Create a new instance, based on the first positional argument with\n-    *changes* applied.\n-\n-    Args:\n-\n-        inst:\n-            Instance of a class with *attrs* attributes. *inst* must be passed\n-            as a positional argument.\n-\n-        changes:\n-            Keyword changes in the new copy.\n-\n-    Returns:\n-        A copy of inst with *changes* incorporated.\n-\n-    Raises:\n-        TypeError:\n-            If *attr_name* couldn't be found in the class ``__init__``.\n-\n-        attrs.exceptions.NotAnAttrsClassError:\n-            If *cls* is not an *attrs* class.\n-\n-    .. versionadded:: 17.1.0\n-    .. deprecated:: 23.1.0\n-       It is now deprecated to pass the instance using the keyword argument\n-       *inst*. It will raise a warning until at least April 2024, after which\n-       it will become an error. Always pass the instance as a positional\n-       argument.\n-    .. versionchanged:: 24.1.0\n-       *inst* can't be passed as a keyword argument anymore.\n-    \"\"\"\n-    try:\n-        (inst,) = args\n-    except ValueError:\n-        msg = (\n-            f\"evolve() takes 1 positional argument, but {len(args)} were given\"\n-        )\n-        raise TypeError(msg) from None\n-\n-    cls = inst.__class__\n-    attrs = fields(cls)\n-    for a in attrs:\n-        if not a.init:\n-            continue\n-        attr_name = a.name  # To deal with private attributes.\n-        init_name = a.alias\n-        if init_name not in changes:\n-            changes[init_name] = getattr(inst, attr_name)\n-\n-    return cls(**changes)\n-\n-\n def resolve_types(\n     cls, globalns=None, localns=None, attribs=None, include_extras=True\n ):\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -22,6 +22,7 @@\n from ._compat import (\n     PY_3_10_PLUS,\n     PY_3_11_PLUS,\n+    PY_3_13_PLUS,\n     _AnnotationExtractor,\n     _get_annotations,\n     get_generic_base,\n@@ -565,6 +566,64 @@ def _frozen_delattrs(self, name):\n     raise FrozenInstanceError\n \n \n+def evolve(*args, **changes):\n+    \"\"\"\n+    Create a new instance, based on the first positional argument with\n+    *changes* applied.\n+\n+    .. tip::\n+\n+       On Python 3.13 and later, you can also use `copy.replace` instead.\n+\n+    Args:\n+\n+        inst:\n+            Instance of a class with *attrs* attributes. *inst* must be passed\n+            as a positional argument.\n+\n+        changes:\n+            Keyword changes in the new copy.\n+\n+    Returns:\n+        A copy of inst with *changes* incorporated.\n+\n+    Raises:\n+        TypeError:\n+            If *attr_name* couldn't be found in the class ``__init__``.\n+\n+        attrs.exceptions.NotAnAttrsClassError:\n+            If *cls* is not an *attrs* class.\n+\n+    .. versionadded:: 17.1.0\n+    .. deprecated:: 23.1.0\n+       It is now deprecated to pass the instance using the keyword argument\n+       *inst*. It will raise a warning until at least April 2024, after which\n+       it will become an error. Always pass the instance as a positional\n+       argument.\n+    .. versionchanged:: 24.1.0\n+       *inst* can't be passed as a keyword argument anymore.\n+    \"\"\"\n+    try:\n+        (inst,) = args\n+    except ValueError:\n+        msg = (\n+            f\"evolve() takes 1 positional argument, but {len(args)} were given\"\n+        )\n+        raise TypeError(msg) from None\n+\n+    cls = inst.__class__\n+    attrs = fields(cls)\n+    for a in attrs:\n+        if not a.init:\n+            continue\n+        attr_name = a.name  # To deal with private attributes.\n+        init_name = a.alias\n+        if init_name not in changes:\n+            changes[init_name] = getattr(inst, attr_name)\n+\n+    return cls(**changes)\n+\n+\n class _ClassBuilder:\n     \"\"\"\n     Iteratively build *one* class.\n@@ -979,6 +1038,12 @@ def add_init(self):\n \n         return self\n \n+    def add_replace(self):\n+        self._cls_dict[\"__replace__\"] = self._add_method_dunders(\n+            lambda self, **changes: evolve(self, **changes)\n+        )\n+        return self\n+\n     def add_match_args(self):\n         self._cls_dict[\"__match_args__\"] = tuple(\n             field.name\n@@ -1381,6 +1446,9 @@ def wrap(cls):\n                 msg = \"Invalid value for cache_hash.  To use hash caching, init must be True.\"\n                 raise TypeError(msg)\n \n+        if PY_3_13_PLUS and not _has_own_attribute(cls, \"__replace__\"):\n+            builder.add_replace()\n+\n         if (\n             PY_3_10_PLUS\n             and match_args\n@@ -2394,7 +2462,7 @@ def evolve(self, **changes):\n         Copy *self* and apply *changes*.\n \n         This works similarly to `attrs.evolve` but that function does not work\n-        with {class}`Attribute`.\n+        with :class:`attrs.Attribute`.\n \n         It is mainly meant to be used for `transform-fields`.\n \ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -316,6 +316,9 @@ def define(\n        If a class has an *inherited* classmethod called\n        ``__attrs_init_subclass__``, it is executed after the class is created.\n     .. deprecated:: 24.1.0 *hash* is deprecated in favor of *unsafe_hash*.\n+    .. versionadded:: 24.3.0\n+       Unless already present, a ``__replace__`` method is automatically\n+       created for `copy.replace` (Python 3.13+ only).\n \n     .. note::\n \n", "test_patch": "diff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -4,6 +4,7 @@\n End-to-end tests.\n \"\"\"\n \n+import copy\n import inspect\n import pickle\n \n@@ -16,6 +17,7 @@\n \n import attr\n \n+from attr._compat import PY_3_13_PLUS\n from attr._make import NOTHING, Attribute\n from attr.exceptions import FrozenInstanceError\n \n@@ -766,3 +768,40 @@ class ToRegister(Base):\n             pass\n \n         assert [ToRegister] == REGISTRY\n+\n+\n+@pytest.mark.skipif(not PY_3_13_PLUS, reason=\"requires Python 3.13+\")\n+class TestReplace:\n+    def test_replaces(self):\n+        \"\"\"\n+        copy.replace() is added by default and works like `attrs.evolve`.\n+        \"\"\"\n+        inst = C1(1, 2)\n+\n+        assert C1(1, 42) == copy.replace(inst, y=42)\n+        assert C1(42, 2) == copy.replace(inst, x=42)\n+\n+    def test_already_has_one(self):\n+        \"\"\"\n+        If the object already has a __replace__, it's left alone.\n+        \"\"\"\n+        sentinel = object()\n+\n+        @attr.s\n+        class C:\n+            x = attr.ib()\n+\n+            __replace__ = sentinel\n+\n+        assert sentinel == C.__replace__\n+\n+    def test_invalid_field_name(self):\n+        \"\"\"\n+        Invalid field names raise a TypeError.\n+\n+        This is consistent with dataclasses.\n+        \"\"\"\n+        inst = C1(1, 2)\n+\n+        with pytest.raises(TypeError):\n+            copy.replace(inst, z=42)\n", "problem_statement": "`copy.replace` support\nPython 3.13 introduced the `__replace__` dunder, exposed via [`copy.replace`](https://docs.python.org/3.13/library/copy.html#copy.replace), as a [generalised method](https://discuss.python.org/t/generalize-replace-function/28511) through which to replace fields in immutable dataclass-likes.  Would you be interested in supporting it in addition to attrs' own `evolve`?\n", "hints_text": "Yeah, that sounds super cool!", "created_at": "2024-12-14T12:23:52Z"}
{"repo": "python-attrs/attrs", "pull_number": 1372, "instance_id": "python-attrs__attrs-1372", "issue_numbers": ["1348"], "base_commit": "ee0f19b696c60064c58cdc08b3265aef56d49ff8", "patch": "diff --git a/src/attr/converters.py b/src/attr/converters.py\n--- a/src/attr/converters.py\n+++ b/src/attr/converters.py\n@@ -7,7 +7,7 @@\n import typing\n \n from ._compat import _AnnotationExtractor\n-from ._make import NOTHING, Factory, pipe\n+from ._make import NOTHING, Converter, Factory, pipe\n \n \n __all__ = [\n@@ -33,10 +33,19 @@ def optional(converter):\n     .. versionadded:: 17.1.0\n     \"\"\"\n \n-    def optional_converter(val):\n-        if val is None:\n-            return None\n-        return converter(val)\n+    if isinstance(converter, Converter):\n+\n+        def optional_converter(val, inst, field):\n+            if val is None:\n+                return None\n+            return converter(val, inst, field)\n+\n+    else:\n+\n+        def optional_converter(val):\n+            if val is None:\n+                return None\n+            return converter(val)\n \n     xtr = _AnnotationExtractor(converter)\n \n@@ -48,6 +57,9 @@ def optional_converter(val):\n     if rt:\n         optional_converter.__annotations__[\"return\"] = typing.Optional[rt]\n \n+    if isinstance(converter, Converter):\n+        return Converter(optional_converter, takes_self=True, takes_field=True)\n+\n     return optional_converter\n \n \n", "test_patch": "diff --git a/tests/test_converters.py b/tests/test_converters.py\n--- a/tests/test_converters.py\n+++ b/tests/test_converters.py\n@@ -143,6 +143,14 @@ def test_fail(self):\n         with pytest.raises(ValueError):\n             c(\"not_an_int\")\n \n+    def test_converter_instance(self):\n+        \"\"\"\n+        Works when passed a Converter instance as argument.\n+        \"\"\"\n+        c = optional(Converter(to_bool))\n+\n+        assert True is c(\"yes\", None, None)\n+\n \n class TestDefaultIfNone:\n     def test_missing_default(self):\n@@ -272,6 +280,48 @@ class C:\n         )\n \n \n+class TestOptionalPipe:\n+    def test_optional(self):\n+        \"\"\"\n+        Nothing happens if None.\n+        \"\"\"\n+        c = optional(pipe(str, Converter(to_bool), bool))\n+\n+        assert None is c.converter(None, None, None)\n+\n+    def test_pipe(self):\n+        \"\"\"\n+        A value is given, run it through all wrapped converters.\n+        \"\"\"\n+        c = optional(pipe(str, Converter(to_bool), bool))\n+\n+        assert (\n+            True\n+            is c.converter(\"True\", None, None)\n+            is c.converter(True, None, None)\n+        )\n+\n+    def test_instance(self):\n+        \"\"\"\n+        Should work when set as an attrib.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            x = attrib(\n+                converter=optional(pipe(str, Converter(to_bool), bool)),\n+                default=None,\n+            )\n+\n+        c1 = C()\n+\n+        assert None is c1.x\n+\n+        c2 = C(\"True\")\n+\n+        assert True is c2.x\n+\n+\n class TestToBool:\n     def test_unhashable(self):\n         \"\"\"\n", "problem_statement": "Error occurs when using converters.optional and converters.pipe together\n23.2.0 is OK.\r\n```Python\r\nPython 3.10.13 (main, Dec  6 2023, 12:01:00) [GCC 13.2.1 20230801] on linux\r\n>>> import attr\r\n>>> attr.__version__\r\n'23.2.0'\r\n>>> @attr.define\r\n... class A:\r\n...     abc: int | None = attr.field(converter=attr.converters.optional(attr.converters.pipe(str, int)), default=None)\r\n...     \r\n>>> A()\r\nA(abc=None)\r\n>>> A('1')\r\nA(abc=1)\r\n```\r\n\r\nafter 24.1.0, error occurs:\r\n```Python\r\nPython 3.10.13 (main, Dec  6 2023, 12:01:00) [GCC 13.2.1 20230801] on linux\r\n>>> import attr\r\n>>> attr.__version__\r\n'24.2.0'\r\n>>> @attr.define\r\n... class A:\r\n...     abc: int | None = attr.field(converter=attr.converters.optional(attr.converters.pipe(str, int)), default=None)\r\n...     \r\n>>> A()\r\nA(abc=None)\r\n>>> A('1')\r\nTraceback (most recent call last):\r\n  File \"/opt/pycharm-professional/plugins/python-ce/helpers/pydev/pydevconsole.py\", line 364, in runcode\r\n    coro = func()\r\n  File \"<input>\", line 1, in <module>\r\n  File \"<attrs generated init __main__.A>\", line 3, in __init__\r\n  File \"/home/mio/Work/venv/calliper310N/lib/python3.10/site-packages/attr/converters.py\", line 40, in optional_converter\r\n    return converter(val)\r\nTypeError: Converter.__init__.<locals>.<lambda>() missing 2 required positional arguments: 'instance' and 'field'\r\n\r\n```\n", "hints_text": "Also seeing this issue as I'm trying to upgrade to attrs 24, is there a fix or workaround for it?", "created_at": "2024-11-13T14:54:26Z"}
{"repo": "python-attrs/attrs", "pull_number": 1329, "instance_id": "python-attrs__attrs-1329", "issue_numbers": ["1326"], "base_commit": "f520d9a89f1fde6fdc5310ffe6c5d4c7467fb10b", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -15,6 +15,7 @@\n PY_3_10_PLUS = sys.version_info[:2] >= (3, 10)\n PY_3_12_PLUS = sys.version_info[:2] >= (3, 12)\n PY_3_13_PLUS = sys.version_info[:2] >= (3, 13)\n+PY_3_14_PLUS = sys.version_info[:2] >= (3, 14)\n \n \n if sys.version_info < (3, 8):\n@@ -25,6 +26,19 @@\n else:\n     from typing import Protocol  # noqa: F401\n \n+if PY_3_14_PLUS:  # pragma: no cover\n+    import annotationlib\n+\n+    _get_annotations = annotationlib.get_annotations\n+\n+else:\n+\n+    def _get_annotations(cls):\n+        \"\"\"\n+        Get annotations for *cls*.\n+        \"\"\"\n+        return cls.__dict__.get(\"__annotations__\", {})\n+\n \n class _AnnotationExtractor:\n     \"\"\"\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -23,6 +23,7 @@\n     PY_3_8_PLUS,\n     PY_3_10_PLUS,\n     _AnnotationExtractor,\n+    _get_annotations,\n     get_generic_base,\n )\n from .exceptions import (\n@@ -308,13 +309,6 @@ def _has_own_attribute(cls, attrib_name):\n     return attrib_name in cls.__dict__\n \n \n-def _get_annotations(cls):\n-    \"\"\"\n-    Get annotations for *cls*.\n-    \"\"\"\n-    return cls.__dict__.get(\"__annotations__\", {})\n-\n-\n def _collect_base_attrs(cls, taken_attr_names):\n     \"\"\"\n     Collect attr.ibs from base classes of *cls*, except *taken_attr_names*.\n", "test_patch": "diff --git a/tests/test_3rd_party.py b/tests/test_3rd_party.py\n--- a/tests/test_3rd_party.py\n+++ b/tests/test_3rd_party.py\n@@ -8,12 +8,17 @@\n \n from hypothesis import given\n \n+from attr._compat import PY_3_14_PLUS\n+\n from .strategies import simple_classes\n \n \n cloudpickle = pytest.importorskip(\"cloudpickle\")\n \n \n+@pytest.mark.xfail(\n+    PY_3_14_PLUS, reason=\"cloudpickle is currently broken on 3.14.\"\n+)\n class TestCloudpickleCompat:\n     \"\"\"\n     Tests for compatibility with ``cloudpickle``.\ndiff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -12,6 +12,7 @@\n \n import attr\n \n+from attr._compat import PY_3_14_PLUS\n from attr._make import _is_class_var\n from attr.exceptions import UnannotatedAttributeError\n \n@@ -588,6 +589,8 @@ def test_self_reference(self, slots):\n         \"\"\"\n         References to self class using quotes can be resolved.\n         \"\"\"\n+        if PY_3_14_PLUS and not slots:\n+            pytest.xfail(\"References are changing a lot in 3.14.\")\n \n         @attr.s(slots=slots, auto_attribs=True)\n         class A:\n@@ -603,6 +606,8 @@ def test_forward_reference(self, slots):\n         \"\"\"\n         Forward references can be resolved.\n         \"\"\"\n+        if PY_3_14_PLUS and not slots:\n+            pytest.xfail(\"Forward references are changing a lot in 3.14.\")\n \n         @attr.s(slots=slots, auto_attribs=True)\n         class A:\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -21,7 +21,7 @@\n import attr\n \n from attr import _config\n-from attr._compat import PY_3_8_PLUS, PY_3_10_PLUS\n+from attr._compat import PY_3_8_PLUS, PY_3_10_PLUS, PY_3_14_PLUS\n from attr._make import (\n     Attribute,\n     Factory,\n@@ -1838,9 +1838,11 @@ class C2(C):\n         assert [C2] == C.__subclasses__()\n \n     @pytest.mark.skipif(not PY_3_8_PLUS, reason=\"cached_property is 3.8+\")\n+    @pytest.mark.xfail(PY_3_14_PLUS, reason=\"Currently broken on nightly.\")\n     def test_no_references_to_original_when_using_cached_property(self):\n         \"\"\"\n-        When subclassing a slotted class and using cached property, there are no stray references to the original class.\n+        When subclassing a slotted class and using cached property, there are\n+        no stray references to the original class.\n         \"\"\"\n \n         @attr.s(slots=True)\ndiff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -3,6 +3,7 @@\n \"\"\"\n Unit tests for slots-related functionality.\n \"\"\"\n+\n import functools\n import pickle\n import weakref\n@@ -14,7 +15,7 @@\n import attr\n import attrs\n \n-from attr._compat import PY_3_8_PLUS, PYPY\n+from attr._compat import PY_3_8_PLUS, PY_3_14_PLUS, PYPY\n \n \n # Pympler doesn't work on PyPy.\n@@ -774,6 +775,9 @@ def f(self) -> int:\n \n \n @pytest.mark.skipif(not PY_3_8_PLUS, reason=\"cached_property is 3.8+\")\n+@pytest.mark.xfail(\n+    PY_3_14_PLUS, reason=\"3.14 returns weird annotation for cached_properies\"\n+)\n def test_slots_cached_property_infers_type():\n     \"\"\"\n     Infers type of cached property.\n", "problem_statement": "Latest release breaks hypothesis tests in CPython main branch\nSee https://github.com/python/cpython/issues/122686.  Pinning to \"attrs<=23.2.0\" - a workaround.\n", "hints_text": "I\u2019m afk, can I have a \r\n[_Short, Self Contained, Correct, Example_](http://sscce.org) please?\nSorry, I didn't deep debugging (yet).  If that helps, tracebacks from above job looks like:\r\n```\r\n[...]\r\n  File \"/home/runner/work/cpython/cpython-builddir/hypovenv/lib/python3.14/site-packages/hypothesis/internal/conjecture/data.py\", line 2466, in stop_example\r\n    self.tags.update([structural_coverage(l) for l in labels_for_structure])\r\n                      ~~~~~~~~~~~~~~~~~~~^^^\r\n  File \"/home/runner/work/cpython/cpython-builddir/hypovenv/lib/python3.14/site-packages/hypothesis/internal/conjecture/data.py\", line 170, in structural_coverage\r\n    return STRUCTURAL_COVERAGE_CACHE.setdefault(label, StructuralCoverageTag(label))\r\n                                                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^\r\nTypeError: StructuralCoverageTag.__init__() takes 1 positional argument but 2 were given\r\n```\r\n\r\nIt's this class in Hypothesis:\r\nhttps://github.com/HypothesisWorks/hypothesis/blob/3c15b34ece30825ed153a0b350f5847efb30dd79/hypothesis-python/src/hypothesis/internal/conjecture/data.py#L157-L160\r\n\r\nMaybe hypothesis package should add pinning, but it's not clear for me from release notes that was broken here.\nFrom looking on my phone it looks like the breakage is that we now use the official dataclass transform decorator and they\u2019re applying is a second time. I _think_ that\u2019s something they have to fix, this is just the price of the typing bleeding edge. Has someone opened a ticket over there?\nhttps://github.com/HypothesisWorks/hypothesis/issues/4067\nSo it looks like *attrs* can't find annotation-only fields **Python 3.14 only** anymore.\r\n\r\n\r\nIt's caused by 689a0e6 and my wild guess is that it's related to [PEP 649](https://peps.python.org/pep-0649/) / [PEP 749](https://peps.python.org/pep-0749/).", "created_at": "2024-08-06T10:03:58Z"}
{"repo": "python-attrs/attrs", "pull_number": 1321, "instance_id": "python-attrs__attrs-1321", "issue_numbers": ["595"], "base_commit": "fd7538f0e23a49ec34b636484de2d1b4b690c7fb", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -2,6 +2,7 @@\n \n from __future__ import annotations\n \n+import abc\n import contextlib\n import copy\n import enum\n@@ -683,34 +684,28 @@ def __init__(\n     def __repr__(self):\n         return f\"<_ClassBuilder(cls={self._cls.__name__})>\"\n \n-    if PY_3_10_PLUS:\n-        import abc\n-\n-        def build_class(self):\n-            \"\"\"\n-            Finalize class based on the accumulated configuration.\n-\n-            Builder cannot be used after calling this method.\n-            \"\"\"\n-            if self._slots is True:\n-                return self._create_slots_class()\n-\n-            return self.abc.update_abstractmethods(\n-                self._patch_original_class()\n-            )\n-\n-    else:\n+    def build_class(self):\n+        \"\"\"\n+        Finalize class based on the accumulated configuration.\n \n-        def build_class(self):\n-            \"\"\"\n-            Finalize class based on the accumulated configuration.\n+        Builder cannot be used after calling this method.\n+        \"\"\"\n+        if self._slots is True:\n+            cls = self._create_slots_class()\n+        else:\n+            cls = self._patch_original_class()\n+            if PY_3_10_PLUS:\n+                cls = abc.update_abstractmethods(cls)\n \n-            Builder cannot be used after calling this method.\n-            \"\"\"\n-            if self._slots is True:\n-                return self._create_slots_class()\n+        # The method gets only called if it's not inherited from a base class.\n+        # _has_own_attribute does NOT work properly for classmethods.\n+        if (\n+            getattr(cls, \"__attrs_init_subclass__\", None)\n+            and \"__attrs_init_subclass__\" not in cls.__dict__\n+        ):\n+            cls.__attrs_init_subclass__()\n \n-            return self._patch_original_class()\n+        return cls\n \n     def _patch_original_class(self):\n         \"\"\"\n@@ -1269,10 +1264,12 @@ def attrs(\n        *unsafe_hash* as an alias for *hash* (for :pep:`681` compliance).\n     .. deprecated:: 24.1.0 *repr_ns*\n     .. versionchanged:: 24.1.0\n-\n        Instances are not compared as tuples of attributes anymore, but using a\n        big ``and`` condition. This is faster and has more correct behavior for\n        uncomparable values like `math.nan`.\n+    .. versionadded:: 24.1.0\n+       If a class has an *inherited* classmethod called\n+       ``__attrs_init_subclass__``, it is executed after the class is created.\n     \"\"\"\n     if repr_ns is not None:\n         import warnings\ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -50,6 +50,12 @@ def define(\n     :term:`fields <field>` specified using :doc:`type annotations <types>`,\n     `field()` calls, or the *these* argument.\n \n+    Since *attrs* patches or replaces an existing class, you cannot use\n+    `object.__init_subclass__` with *attrs* classes, because it runs too early.\n+    As a replacement, you can define ``__attrs_init_subclass__`` on your class.\n+    It will be called by *attrs* classes that subclass it after they're\n+    created. See also :ref:`init-subclass`.\n+\n     Args:\n         slots (bool):\n             Create a :term:`slotted class <slotted classes>` that's more\n@@ -308,10 +314,12 @@ def define(\n     .. versionadded:: 22.2.0\n        *unsafe_hash* as an alias for *hash* (for :pep:`681` compliance).\n     .. versionchanged:: 24.1.0\n-\n        Instances are not compared as tuples of attributes anymore, but using a\n        big ``and`` condition. This is faster and has more correct behavior for\n        uncomparable values like `math.nan`.\n+    .. versionadded:: 24.1.0\n+       If a class has an *inherited* classmethod called\n+       ``__attrs_init_subclass__``, it is executed after the class is created.\n \n     .. note::\n \n", "test_patch": "diff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -4,7 +4,6 @@\n End-to-end tests.\n \"\"\"\n \n-\n import inspect\n import pickle\n \n@@ -744,3 +743,21 @@ class Hashable:\n             pass\n \n         assert hash(Hashable())\n+\n+    def test_init_subclass(self, slots):\n+        \"\"\"\n+        __attrs_init_subclass__ is called on subclasses.\n+        \"\"\"\n+        REGISTRY = []\n+\n+        @attr.s(slots=slots)\n+        class Base:\n+            @classmethod\n+            def __attrs_init_subclass__(cls):\n+                REGISTRY.append(cls)\n+\n+        @attr.s(slots=slots)\n+        class ToRegister(Base):\n+            pass\n+\n+        assert [ToRegister] == REGISTRY\n", "problem_statement": "Attr-compatible __init_subclass__ variant: __attr_init_subclass__\nSay I have a base class Foo, where for every derived class I want to compute some class fields. This can easily be done with `__init_subclass__` in python. However, it's not possible to use the class's attribute data in `__init_subclass__`, since they will only get initialized by the decorator after the class is created. \r\n\r\nWhat I'd like to see is a  `__attrs_init_subclass__` method, that is called just before the decorator returns. In that method, `attr.fields(cls)` could then return the correct value. This method could obviously not take the `kwargs` like `__init_subclass__`. What might be useful is to pass a list of attributes declared in that class; there is currently no way to get those otherwise.\r\n\r\nThe only current alternative is to have the base class _and_ a custom decorator after the attrib decorator, that means every user of the class needs two separate declarations to get it working correctly.\n", "hints_text": "I also hit this one. For me, one classic use-case of `__init_subclass__` is for registering sub-classes in some kind of registry, e.g. for deserialisation given some kind of type-key. However, with `attrs`, that obviously doesn't work because `__init_subclas__` will be called on a temporary type only - `attrs` is going to create a new type from scratch that happens to share most of it's `__dict__` contents.", "created_at": "2024-08-02T08:35:52Z"}
{"repo": "python-attrs/attrs", "pull_number": 1320, "instance_id": "python-attrs__attrs-1320", "issue_numbers": ["1295"], "base_commit": "09161fc9181bf94aa3bbc5509c663d736a9553dc", "patch": "diff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -234,6 +234,7 @@ def optional(validator):\n @attrs(repr=False, slots=True, hash=True)\n class _InValidator:\n     options = attrib()\n+    _original_options = attrib(hash=False)\n \n     def __call__(self, inst, attr, value):\n         try:\n@@ -242,23 +243,28 @@ def __call__(self, inst, attr, value):\n             in_options = False\n \n         if not in_options:\n-            msg = f\"'{attr.name}' must be in {self.options!r} (got {value!r})\"\n+            msg = f\"'{attr.name}' must be in {self._original_options!r} (got {value!r})\"\n             raise ValueError(\n                 msg,\n                 attr,\n-                self.options,\n+                self._original_options,\n                 value,\n             )\n \n     def __repr__(self):\n-        return f\"<in_ validator with options {self.options!r}>\"\n+        return f\"<in_ validator with options {self._original_options!r}>\"\n \n \n def in_(options):\n     \"\"\"\n     A validator that raises a `ValueError` if the initializer is called with a\n-    value that does not belong in the options provided.  The check is performed\n-    using ``value in options``, so *options* has to support that operation.\n+    value that does not belong in the *options* provided.\n+\n+    The check is performed using ``value in options``, so *options* has to\n+    support that operation.\n+\n+    To keep the validator hashable, dicts, lists, and sets are transparently\n+    transformed into a `tuple`.\n \n     Args:\n         options: Allowed options.\n@@ -273,8 +279,15 @@ def in_(options):\n        The ValueError was incomplete until now and only contained the human\n        readable error message. Now it contains all the information that has\n        been promised since 17.1.0.\n+    .. versionchanged:: 24.1.0\n+       *options* that are a list, dict, or a set are now transformed into a\n+       tuple to keep the validator hashable.\n     \"\"\"\n-    return _InValidator(options)\n+    repr_options = options\n+    if isinstance(options, (list, dict, set)):\n+        options = tuple(options)\n+\n+    return _InValidator(options, repr_options)\n \n \n @attrs(repr=False, slots=False, hash=True)\n", "test_patch": "diff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -391,6 +391,7 @@ def test_success_with_value(self):\n         \"\"\"\n         v = in_([1, 2, 3])\n         a = simple_attr(\"test\")\n+\n         v(1, a, 3)\n \n     def test_fail(self):\n@@ -433,6 +434,21 @@ def test_repr(self):\n         v = in_([3, 4, 5])\n         assert (\"<in_ validator with options [3, 4, 5]>\") == repr(v)\n \n+    def test_is_hashable(self):\n+        \"\"\"\n+        `in_` is hashable, so fields using it can be used with the include and\n+        exclude filters.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            x: int = attr.ib(validator=attr.validators.in_({1, 2}))\n+\n+        i = C(2)\n+\n+        attr.asdict(i, filter=attr.filters.include(lambda val: True))\n+        attr.asdict(i, filter=attr.filters.exclude(lambda val: True))\n+\n \n @pytest.fixture(\n     name=\"member_validator\",\n", "problem_statement": "`attr.filters.exclude` or `include` not simultaneously usable with `validators.in_` set.\nWhen using one of the mentioned filter functions in `attrs.as_dict` or `as_tuple` on frozen nodes that have attributes with `attrs.validators.in_`  set as their validator, the following TypeError is thrown: \r\n\r\n```pytb\r\n  File \"<>/venv/lib/python3.11/site-packages/attr/filters.py\", line 63, in exclude_\r\n    or attribute in attrs\r\n       ^^^^^^^^^^^^^^^^^^\r\n  File \"<>/venv/lib/python3.11/site-packages/attr/_funcs.py\", line 57, in asdict\r\n    if filter is not None and not filter(a, v):\r\n                                  ^^^^^^^^^^^^\r\n  File \"<>/venv/lib/python3.11/site-packages/attr/_next_gen.py\", line 211, in asdict\r\n    return _asdict(\r\n           ^^^^^^^^\r\n  [...]\r\nTypeError: unhashable type: 'set'\r\n``` \r\n\r\nTrying to execute line 63, in exclude_ (top of traceback) resulted in the following error:\r\n\r\n```pytb\r\nTraceback (most recent call last):\r\n [...]\r\n  File \"<attrs generated hash attr._make.Attribute>\", line 2, in __hash__\r\n    return hash((\r\n           ^^^^^^\r\n  File \"<attrs generated hash attr.validators._InValidator>\", line 2, in __hash__\r\n    return hash((\r\n           ^^^^^^\r\nTypeError: unhashable type: 'set'\r\n```\r\n\r\nTherefore I suspect, that the issue lies in hashing of `attrs.validators.in_`. \r\n\n", "hints_text": "Looking further into it, I noticed that this issue occurs if the options passed to to the `in_` function are not of a hashable type (in my case list objects), what made the corresponding attribute unhashable. \r\n\r\nCasting the options into a hashable type such as `tuple` or `frozenset` might resolve this issue. \r\n\nFor posterity, this is what breaks:\r\n\r\n```python\r\nimport attrs\r\n\r\n\r\n@attrs.define\r\nclass C:\r\n    x: int = attrs.field(validator=attrs.validators.in_({1, 2}))\r\n\r\n\r\ni = C(2)\r\n\r\nattrs.asdict(i, filter=attrs.filters.exclude(lambda val: True))\r\n```", "created_at": "2024-08-02T07:53:19Z"}
{"repo": "python-attrs/attrs", "pull_number": 1319, "instance_id": "python-attrs__attrs-1319", "issue_numbers": ["1284"], "base_commit": "689a0e64012d1e576ebd99e786a254bc537582c6", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -2207,15 +2207,17 @@ def _attrs_to_init_script(\n         # leading comma & kw_only args\n         args += f\"{', ' if args else ''}*, {', '.join(kw_only_args)}\"\n         pre_init_kw_only_args = \", \".join(\n-            [f\"{kw_arg}={kw_arg}\" for kw_arg in kw_only_args]\n+            [\n+                f\"{kw_arg_name}={kw_arg_name}\"\n+                # We need to remove the defaults from the kw_only_args.\n+                for kw_arg_name in (kwa.split(\"=\")[0] for kwa in kw_only_args)\n+            ]\n         )\n-        pre_init_args += (\n-            \", \" if pre_init_args else \"\"\n-        )  # handle only kwargs and no regular args\n+        pre_init_args += \", \" if pre_init_args else \"\"\n         pre_init_args += pre_init_kw_only_args\n \n     if call_pre_init and pre_init_has_args:\n-        # If pre init method has arguments, pass same arguments as `__init__`\n+        # If pre init method has arguments, pass same arguments as `__init__`.\n         lines[0] = f\"self.__attrs_pre_init__({pre_init_args})\"\n \n     # Python 3.7 doesn't allow backslashes in f strings.\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -694,6 +694,25 @@ def __attrs_pre_init__(self2, y):\n \n         assert 12 == getattr(c, \"z\", None)\n \n+    @pytest.mark.usefixtures(\"with_and_without_validation\")\n+    def test_pre_init_kw_only_work_with_defaults(self):\n+        \"\"\"\n+        Default values together with kw_only don't break __attrs__pre_init__.\n+        \"\"\"\n+        val = None\n+\n+        @attr.define\n+        class KWOnlyAndDefault:\n+            kw_and_default: int = attr.field(kw_only=True, default=3)\n+\n+            def __attrs_pre_init__(self, *, kw_and_default):\n+                nonlocal val\n+                val = kw_and_default\n+\n+        inst = KWOnlyAndDefault()\n+\n+        assert 3 == val == inst.kw_and_default\n+\n     @pytest.mark.usefixtures(\"with_and_without_validation\")\n     def test_post_init(self):\n         \"\"\"\n", "problem_statement": "`kw_only` with `default` breaks `__attrs_pre_init__` call\nThe following code raises SyntaxError\r\n```python\r\nfrom attrs import define, field\r\n\r\n@define\r\nclass A:\r\n    a: int = field(kw_only=True, default=3)\r\n\r\n    def __attrs_pre_init__(self, _):\r\n        pass\r\n```\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/user/attrs_pre_init.py\", line 4, in <module>\r\n    @define\r\n     ^^^^^^\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_next_gen.py\", line 153, in define\r\n    return wrap(maybe_cls)\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_next_gen.py\", line 144, in wrap\r\n    return do_it(cls, True)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_next_gen.py\", line 90, in do_it\r\n    return attrs(\r\n           ^^^^^^\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_make.py\", line 1715, in attrs\r\n    return wrap(maybe_cls)\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_make.py\", line 1694, in wrap\r\n    builder.add_init()\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_make.py\", line 1090, in add_init\r\n    _make_init(\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_make.py\", line 2181, in _make_init\r\n    init = _make_method(\r\n           ^^^^^^^^^^^^^\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_make.py\", line 345, in _make_method\r\n    _compile_and_eval(script, globs, locs, filename)\r\n  File \"/home/user/.venv/lib/python3.12/site-packages/attr/_make.py\", line 317, in _compile_and_eval\r\n    bytecode = compile(script, filename, \"exec\")\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<attrs generated init __main__.A>\", line 2\r\n    self.__attrs_pre_init__(a=attr_dict['a'].default=a=attr_dict['a'].default)\r\n                                                    ^\r\nSyntaxError: invalid syntax\r\n```\r\n\n", "hints_text": "", "created_at": "2024-08-02T07:12:18Z"}
{"repo": "python-attrs/attrs", "pull_number": 1303, "instance_id": "python-attrs__attrs-1303", "issue_numbers": ["1214"], "base_commit": "37ac3ef0888bbd9235d17cbc6d284856f5276b44", "patch": "diff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -35,6 +35,7 @@\n     \"min_len\",\n     \"not_\",\n     \"optional\",\n+    \"or_\",\n     \"set_disabled\",\n ]\n \n@@ -614,3 +615,46 @@ def not_(validator, *, msg=None, exc_types=(ValueError, TypeError)):\n     except TypeError:\n         exc_types = (exc_types,)\n     return _NotValidator(validator, msg, exc_types)\n+\n+\n+@attrs(repr=False, slots=True, hash=True)\n+class _OrValidator:\n+    validators = attrib()\n+\n+    def __call__(self, inst, attr, value):\n+        for v in self.validators:\n+            try:\n+                v(inst, attr, value)\n+            except Exception:  # noqa: BLE001, PERF203, S112\n+                continue\n+            else:\n+                return\n+\n+        msg = f\"None of {self.validators!r} satisfied for value {value!r}\"\n+        raise ValueError(msg)\n+\n+    def __repr__(self):\n+        return f\"<or validator wrapping {self.validators!r}>\"\n+\n+\n+def or_(*validators):\n+    \"\"\"\n+    A validator that composes multiple validators into one.\n+\n+    When called on a value, it runs all wrapped validators until one of them\n+    is satisfied.\n+\n+    :param ~collections.abc.Iterable[typing.Callable] validators: Arbitrary\n+        number of validators.\n+\n+    :raises ValueError: If no validator is satisfied. Raised with a\n+        human-readable error message listing all the wrapped validators and\n+        the value that failed all of them.\n+\n+    .. versionadded:: 24.1.0\n+    \"\"\"\n+    vals = []\n+    for v in validators:\n+        vals.extend(v.validators if isinstance(v, _OrValidator) else [v])\n+\n+    return _OrValidator(tuple(vals))\n", "test_patch": "diff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -30,6 +30,7 @@\n     min_len,\n     not_,\n     optional,\n+    or_,\n )\n \n from .utils import simple_attr\n@@ -1261,3 +1262,38 @@ def test_bad_exception_args(self):\n             \"'exc_types' must be a subclass of <class 'Exception'> \"\n             \"(got <class 'str'>).\"\n         ) == e.value.args[0]\n+\n+\n+class TestOr:\n+    def test_in_all(self):\n+        \"\"\"\n+        Verify that this validator is in ``__all__``.\n+        \"\"\"\n+        assert or_.__name__ in validator_module.__all__\n+\n+    def test_success(self):\n+        \"\"\"\n+        Succeeds if at least one of wrapped validators succeed.\n+        \"\"\"\n+        v = or_(instance_of(str), always_pass)\n+\n+        v(None, simple_attr(\"test\"), 42)\n+\n+    def test_fail(self):\n+        \"\"\"\n+        Fails if all wrapped validators fail.\n+        \"\"\"\n+        v = or_(instance_of(str), always_fail)\n+\n+        with pytest.raises(ValueError):\n+            v(None, simple_attr(\"test\"), 42)\n+\n+    def test_repr(self):\n+        \"\"\"\n+        Returned validator has a useful `__repr__`.\n+        \"\"\"\n+        v = or_(instance_of(int), instance_of(str))\n+        assert (\n+            \"<or validator wrapping (<instance_of validator for type \"\n+            \"<class 'int'>>, <instance_of validator for type <class 'str'>>)>\"\n+        ) == repr(v)\n", "problem_statement": "Multiple alternatives validator\nI'd like to validate that a field can be of several types, one of which is an iterator.\r\n\r\n```py\r\nfrom attrs.validator import instance_of\r\n\r\n@define\r\nclass C:\r\n  x: A | B | tuple[int, ...] = field(validator=instance_of((A, B, tuple)))\r\n```\r\n\r\nI can use `instance_of` to check the outer type `tuple`, but I can't use `deep_iterable` to validate that they are indeed the element type `int`.\r\n\r\nSince we already have validators `and_` and `not_`, it may make sense to also add `or_`, so that I can represent this with\r\n\r\n```py\r\nfrom attrs.validator import instance_of, deep_iterable, or_\r\n\r\n@define\r\nclass C:\r\n  x: A | B | tuple[int, ...] = field(\r\n    validator=or_(\r\n      instance_of((A, B)),\r\n      deep_iterable(instance_of(int))))\r\n```\r\n\r\nFor comparison, this is how I'm writing a custom validator\r\n\r\n\r\n```py\r\nfrom attrs.validator import instance_of, deep_iterable\r\n\r\n@define\r\nclass C:\r\n  x: A | B | tuple[int, ...] = field()\r\n\r\n  @x.validator\r\n  def _validate_x(self, attr, value):\r\n    v1 = instance_of((A, B))\r\n    v2 = deep_iterable(instance_of(int))\r\n    try:\r\n      v1(self, attr, value)\r\n    except TypeError:\r\n      v2(self, attr, value)\r\n```\r\n\n", "hints_text": "FTR, it's already possible to do that using only `and_` and `not_`, thanks to [De Morgan's laws](https://en.wikipedia.org/wiki/De_Morgan%27s_laws):\r\n\r\n```py\r\nfrom attrs.validator import instance_of, deep_iterable, and_, not_\r\n\r\n@define\r\nclass C:\r\n  x: A | B | tuple[int, ...] = field(\r\n    validator= not_(and_(\r\n      not_(instance_of((A, B))),\r\n      not_(deep_iterable(instance_of(int))))))\r\n```\r\n\r\nBut the error message is not very informative:\r\n\r\n```py\r\n>>> @define\r\n... class C:\r\n...   x = field(validator=not_( and_( not_( instance_of((A, B)) ), not_( deep_iterable(instance_of(int))  ) ) ))\r\n... \r\n>>> C(A())\r\nC(x=A())\r\n>>> C(B())\r\nC(x=B())\r\n>>> C(())\r\nC(x=())\r\n>>> C((1, 2, 3))\r\nC(x=(1, 2, 3))\r\n>>> C((1, 2, 3, '4'))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"<attrs generated init __main__.C>\", line 5, in __init__\r\n  File \"<REDACTED>/lib/python3.12/site-packages/attr/validators.py\", line 670, in __call__\r\n    raise ValueError(\r\nValueError: (\"not_ validator child '_AndValidator(_validators=(<not_ validator wrapping <instance_of validator for type (<class '__main__.A'>, <class '__main__.B'>)>, capturing (<class 'ValueError'>, <class 'TypeError'>)>, <not_ validator wrapping <deep_iterable validator for iterables of <instance_of validator for type <class 'int'>>>, capturing (<class 'ValueError'>, <class 'TypeError'>)>))' did not raise a captured error\", Attribute(name='x', default=NOTHING, validator=<not_ validator wrapping _AndValidator(_validators=(<not_ validator wrapping <instance_of validator for type (<class '__main__.A'>, <class '__main__.B'>)>, capturing (<class 'ValueError'>, <class 'TypeError'>)>, <not_ validator wrapping <deep_iterable validator for iterables of <instance_of validator for type <class 'int'>>>, capturing (<class 'ValueError'>, <class 'TypeError'>)>)), capturing (<class 'ValueError'>, <class 'TypeError'>)>, repr=True, eq=True, eq_key=None, order=True, order_key=None, hash=None, init=True, metadata=mappingproxy({}), type=None, converter=None, kw_only=False, inherited=False, on_setattr=None, alias='x'), _AndValidator(_validators=(<not_ validator wrapping <instance_of validator for type (<class '__main__.A'>, <class '__main__.B'>)>, capturing (<class 'ValueError'>, <class 'TypeError'>)>, <not_ validator wrapping <deep_iterable validator for iterables of <instance_of validator for type <class 'int'>>>, capturing (<class 'ValueError'>, <class 'TypeError'>)>)), (1, 2, 3, '4'), (<class 'ValueError'>, <class 'TypeError'>))\r\n```", "created_at": "2024-07-14T15:03:00Z"}
{"repo": "python-attrs/attrs", "pull_number": 1267, "instance_id": "python-attrs__attrs-1267", "issue_numbers": ["709"], "base_commit": "0f045cd231f01716c9c81ac78fa2c237c0dd1933", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -15,6 +15,7 @@\n from ._make import (\n     NOTHING,\n     Attribute,\n+    Converter,\n     Factory,\n     attrib,\n     attrs,\n@@ -39,6 +40,7 @@ class AttrsInstance(Protocol):\n __all__ = [\n     \"Attribute\",\n     \"AttrsInstance\",\n+    \"Converter\",\n     \"Factory\",\n     \"NOTHING\",\n     \"asdict\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1,5 +1,7 @@\n # SPDX-License-Identifier: MIT\n \n+from __future__ import annotations\n+\n import contextlib\n import copy\n import enum\n@@ -32,7 +34,6 @@\n \n # This is used at least twice, so cache it here.\n _OBJ_SETATTR = object.__setattr__\n-_INIT_CONVERTER_PAT = \"__attr_converter_%s\"\n _INIT_FACTORY_PAT = \"__attr_factory_%s\"\n _CLASSVAR_PREFIXES = (\n     \"typing.ClassVar\",\n@@ -213,11 +214,17 @@ def attrib(\n \n             .. seealso:: `init`\n \n-        converter (typing.Callable(): `callable` that is called by\n-            *attrs*-generated ``__init__`` methods to convert attribute's value\n-            to the desired format.  It is given the passed-in value, and the\n-            returned value will be used as the new value of the attribute.  The\n-            value is converted before being passed to the validator, if any.\n+        converter (typing.Callable | Converter):\n+            `callable` that is called by *attrs*-generated ``__init__`` methods\n+            to convert attribute's value to the desired format.\n+\n+            If a vanilla callable is passed, it is given the passed-in value as\n+            the only positional argument. It is possible to receive additional\n+            arguments by wrapping the callable in a `Converter`.\n+\n+            Either way, the returned value will be used as the new value of the\n+            attribute.  The value is converted before being passed to the\n+            validator, if any.\n \n             .. seealso:: :ref:`converters`\n \n@@ -2239,7 +2246,7 @@ def _make_init(\n         is_exc,\n         needs_cached_setattr,\n         has_cls_on_setattr,\n-        attrs_init,\n+        \"__attrs_init__\" if attrs_init else \"__init__\",\n     )\n     if cls.__module__ in sys.modules:\n         # This makes typing.get_type_hints(CLS.__init__) resolve string types.\n@@ -2263,26 +2270,24 @@ def _make_init(\n     return init\n \n \n-def _setattr(attr_name, value_var, has_on_setattr):\n+def _setattr(attr_name: str, value_var: str, has_on_setattr: bool) -> str:\n     \"\"\"\n     Use the cached object.setattr to set *attr_name* to *value_var*.\n     \"\"\"\n     return f\"_setattr('{attr_name}', {value_var})\"\n \n \n-def _setattr_with_converter(attr_name, value_var, has_on_setattr):\n+def _setattr_with_converter(\n+    attr_name: str, value_var: str, has_on_setattr: bool, converter: Converter\n+) -> str:\n     \"\"\"\n     Use the cached object.setattr to set *attr_name* to *value_var*, but run\n     its converter first.\n     \"\"\"\n-    return \"_setattr('%s', %s(%s))\" % (\n-        attr_name,\n-        _INIT_CONVERTER_PAT % (attr_name,),\n-        value_var,\n-    )\n+    return f\"_setattr('{attr_name}', {converter._fmt_converter_call(attr_name, value_var)})\"\n \n \n-def _assign(attr_name, value, has_on_setattr):\n+def _assign(attr_name: str, value: str, has_on_setattr: bool) -> str:\n     \"\"\"\n     Unless *attr_name* has an on_setattr hook, use normal assignment. Otherwise\n     relegate to _setattr.\n@@ -2293,22 +2298,22 @@ def _assign(attr_name, value, has_on_setattr):\n     return f\"self.{attr_name} = {value}\"\n \n \n-def _assign_with_converter(attr_name, value_var, has_on_setattr):\n+def _assign_with_converter(\n+    attr_name: str, value_var: str, has_on_setattr: bool, converter: Converter\n+) -> str:\n     \"\"\"\n     Unless *attr_name* has an on_setattr hook, use normal assignment after\n     conversion. Otherwise relegate to _setattr_with_converter.\n     \"\"\"\n     if has_on_setattr:\n-        return _setattr_with_converter(attr_name, value_var, True)\n+        return _setattr_with_converter(attr_name, value_var, True, converter)\n \n-    return \"self.%s = %s(%s)\" % (\n-        attr_name,\n-        _INIT_CONVERTER_PAT % (attr_name,),\n-        value_var,\n-    )\n+    return f\"self.{attr_name} = {converter._fmt_converter_call(attr_name, value_var)}\"\n \n \n-def _determine_setters(frozen, slots, base_attr_map):\n+def _determine_setters(\n+    frozen: bool, slots: bool, base_attr_map: dict[str, type]\n+):\n     \"\"\"\n     Determine the correct setter functions based on whether a class is frozen\n     and/or slotted.\n@@ -2322,23 +2327,26 @@ def _determine_setters(frozen, slots, base_attr_map):\n         # class.\n         # Note _inst_dict will be used again below if cache_hash is True\n \n-        def fmt_setter(attr_name, value_var, has_on_setattr):\n+        def fmt_setter(\n+            attr_name: str, value_var: str, has_on_setattr: bool\n+        ) -> str:\n             if _is_slot_attr(attr_name, base_attr_map):\n                 return _setattr(attr_name, value_var, has_on_setattr)\n \n             return f\"_inst_dict['{attr_name}'] = {value_var}\"\n \n-        def fmt_setter_with_converter(attr_name, value_var, has_on_setattr):\n+        def fmt_setter_with_converter(\n+            attr_name: str,\n+            value_var: str,\n+            has_on_setattr: bool,\n+            converter: Converter,\n+        ) -> str:\n             if has_on_setattr or _is_slot_attr(attr_name, base_attr_map):\n                 return _setattr_with_converter(\n-                    attr_name, value_var, has_on_setattr\n+                    attr_name, value_var, has_on_setattr, converter\n                 )\n \n-            return \"_inst_dict['%s'] = %s(%s)\" % (\n-                attr_name,\n-                _INIT_CONVERTER_PAT % (attr_name,),\n-                value_var,\n-            )\n+            return f\"_inst_dict['{attr_name}'] = {converter._fmt_converter_call(attr_name, value_var)}\"\n \n         return (\n             (\"_inst_dict = self.__dict__\",),\n@@ -2351,39 +2359,37 @@ def fmt_setter_with_converter(attr_name, value_var, has_on_setattr):\n \n \n def _attrs_to_init_script(\n-    attrs,\n-    frozen,\n-    slots,\n-    pre_init,\n-    pre_init_has_args,\n-    post_init,\n-    cache_hash,\n-    base_attr_map,\n-    is_exc,\n-    needs_cached_setattr,\n-    has_cls_on_setattr,\n-    attrs_init,\n-):\n-    \"\"\"\n-    Return a script of an initializer for *attrs* and a dict of globals.\n-\n-    The globals are expected by the generated script.\n-\n-    If *frozen* is True, we cannot set the attributes directly so we use\n-    a cached ``object.__setattr__``.\n-    \"\"\"\n-    lines = [\"self.__attrs_pre_init__()\"] if pre_init else []\n+    attrs: list[Attribute],\n+    is_frozen: bool,\n+    is_slotted: bool,\n+    call_pre_init: bool,\n+    pre_init_has_args: bool,\n+    call_post_init: bool,\n+    does_cache_hash: bool,\n+    base_attr_map: dict[str, type],\n+    is_exc: bool,\n+    needs_cached_setattr: bool,\n+    has_cls_on_setattr: bool,\n+    method_name: str,\n+) -> tuple[str, dict, dict]:\n+    \"\"\"\n+    Return a script of an initializer for *attrs*, a dict of globals, and\n+    annotations for the initializer.\n+\n+    The globals are required by the generated script.\n+    \"\"\"\n+    lines = [\"self.__attrs_pre_init__()\"] if call_pre_init else []\n \n     if needs_cached_setattr:\n         lines.append(\n             # Circumvent the __setattr__ descriptor to save one lookup per\n-            # assignment.\n-            # Note _setattr will be used again below if cache_hash is True\n+            # assignment. Note _setattr will be used again below if\n+            # does_cache_hash is True.\n             \"_setattr = _cached_setattr_get(self)\"\n         )\n \n     extra_lines, fmt_setter, fmt_setter_with_converter = _determine_setters(\n-        frozen, slots, base_attr_map\n+        is_frozen, is_slotted, base_attr_map\n     )\n     lines.extend(extra_lines)\n \n@@ -2411,19 +2417,25 @@ def _attrs_to_init_script(\n         has_factory = isinstance(a.default, Factory)\n         maybe_self = \"self\" if has_factory and a.default.takes_self else \"\"\n \n+        if a.converter and not isinstance(a.converter, Converter):\n+            converter = Converter(a.converter)\n+        else:\n+            converter = a.converter\n+\n         if a.init is False:\n             if has_factory:\n                 init_factory_name = _INIT_FACTORY_PAT % (a.name,)\n-                if a.converter is not None:\n+                if converter is not None:\n                     lines.append(\n                         fmt_setter_with_converter(\n                             attr_name,\n                             init_factory_name + f\"({maybe_self})\",\n                             has_on_setattr,\n+                            converter,\n                         )\n                     )\n-                    names_for_globals[_INIT_CONVERTER_PAT % (a.name,)] = (\n-                        a.converter\n+                    names_for_globals[converter._get_global_name(a.name)] = (\n+                        converter.converter\n                     )\n                 else:\n                     lines.append(\n@@ -2434,16 +2446,17 @@ def _attrs_to_init_script(\n                         )\n                     )\n                 names_for_globals[init_factory_name] = a.default.factory\n-            elif a.converter is not None:\n+            elif converter is not None:\n                 lines.append(\n                     fmt_setter_with_converter(\n                         attr_name,\n                         f\"attr_dict['{attr_name}'].default\",\n                         has_on_setattr,\n+                        converter,\n                     )\n                 )\n-                names_for_globals[_INIT_CONVERTER_PAT % (a.name,)] = (\n-                    a.converter\n+                names_for_globals[converter._get_global_name(a.name)] = (\n+                    converter.converter\n                 )\n             else:\n                 lines.append(\n@@ -2460,14 +2473,14 @@ def _attrs_to_init_script(\n             else:\n                 args.append(arg)\n \n-            if a.converter is not None:\n+            if converter is not None:\n                 lines.append(\n                     fmt_setter_with_converter(\n-                        attr_name, arg_name, has_on_setattr\n+                        attr_name, arg_name, has_on_setattr, converter\n                     )\n                 )\n-                names_for_globals[_INIT_CONVERTER_PAT % (a.name,)] = (\n-                    a.converter\n+                names_for_globals[converter._get_global_name(a.name)] = (\n+                    converter.converter\n                 )\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name, has_on_setattr))\n@@ -2481,11 +2494,11 @@ def _attrs_to_init_script(\n             lines.append(f\"if {arg_name} is not NOTHING:\")\n \n             init_factory_name = _INIT_FACTORY_PAT % (a.name,)\n-            if a.converter is not None:\n+            if converter is not None:\n                 lines.append(\n                     \"    \"\n                     + fmt_setter_with_converter(\n-                        attr_name, arg_name, has_on_setattr\n+                        attr_name, arg_name, has_on_setattr, converter\n                     )\n                 )\n                 lines.append(\"else:\")\n@@ -2495,10 +2508,11 @@ def _attrs_to_init_script(\n                         attr_name,\n                         init_factory_name + \"(\" + maybe_self + \")\",\n                         has_on_setattr,\n+                        converter,\n                     )\n                 )\n-                names_for_globals[_INIT_CONVERTER_PAT % (a.name,)] = (\n-                    a.converter\n+                names_for_globals[converter._get_global_name(a.name)] = (\n+                    converter.converter\n                 )\n             else:\n                 lines.append(\n@@ -2520,26 +2534,24 @@ def _attrs_to_init_script(\n             else:\n                 args.append(arg_name)\n \n-            if a.converter is not None:\n+            if converter is not None:\n                 lines.append(\n                     fmt_setter_with_converter(\n-                        attr_name, arg_name, has_on_setattr\n+                        attr_name, arg_name, has_on_setattr, converter\n                     )\n                 )\n-                names_for_globals[_INIT_CONVERTER_PAT % (a.name,)] = (\n-                    a.converter\n+                names_for_globals[converter._get_global_name(a.name)] = (\n+                    converter.converter\n                 )\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name, has_on_setattr))\n \n         if a.init is True:\n-            if a.type is not None and a.converter is None:\n+            if a.type is not None and converter is None:\n                 annotations[arg_name] = a.type\n-            elif a.converter is not None:\n-                # Try to get the type from the converter.\n-                t = _AnnotationExtractor(a.converter).get_first_param_type()\n-                if t:\n-                    annotations[arg_name] = t\n+            elif converter is not None and converter._first_param_type:\n+                # Use the type from the converter if present.\n+                annotations[arg_name] = converter._first_param_type\n \n     if attrs_to_validate:  # we can skip this if there are no validators.\n         names_for_globals[\"_config\"] = _config\n@@ -2551,25 +2563,23 @@ def _attrs_to_init_script(\n             names_for_globals[val_name] = a.validator\n             names_for_globals[attr_name] = a\n \n-    if post_init:\n+    if call_post_init:\n         lines.append(\"self.__attrs_post_init__()\")\n \n-    # because this is set only after __attrs_post_init__ is called, a crash\n+    # Because this is set only after __attrs_post_init__ is called, a crash\n     # will result if post-init tries to access the hash code.  This seemed\n-    # preferable to setting this beforehand, in which case alteration to\n-    # field values during post-init combined with post-init accessing the\n-    # hash code would result in silent bugs.\n-    if cache_hash:\n-        if frozen:\n-            if slots:  # noqa: SIM108\n-                # if frozen and slots, then _setattr defined above\n-                init_hash_cache = \"_setattr('%s', %s)\"\n+    # preferable to setting this beforehand, in which case alteration to field\n+    # values during post-init combined with post-init accessing the hash code\n+    # would result in silent bugs.\n+    if does_cache_hash:\n+        if is_frozen:\n+            if is_slotted:\n+                init_hash_cache = f\"_setattr('{_HASH_CACHE_FIELD}', None)\"\n             else:\n-                # if frozen and not slots, then _inst_dict defined above\n-                init_hash_cache = \"_inst_dict['%s'] = %s\"\n+                init_hash_cache = f\"_inst_dict['{_HASH_CACHE_FIELD}'] = None\"\n         else:\n-            init_hash_cache = \"self.%s = %s\"\n-        lines.append(init_hash_cache % (_HASH_CACHE_FIELD, \"None\"))\n+            init_hash_cache = f\"self.{_HASH_CACHE_FIELD} = None\"\n+        lines.append(init_hash_cache)\n \n     # For exceptions we rely on BaseException.__init__ for proper\n     # initialization.\n@@ -2593,14 +2603,13 @@ def _attrs_to_init_script(\n         )  # handle only kwargs and no regular args\n         pre_init_args += pre_init_kw_only_args\n \n-    if pre_init and pre_init_has_args:\n+    if call_pre_init and pre_init_has_args:\n         # If pre init method has arguments, pass same arguments as `__init__`\n-        lines[0] = \"self.__attrs_pre_init__(%s)\" % pre_init_args\n+        lines[0] = f\"self.__attrs_pre_init__({pre_init_args})\"\n \n     return (\n-        \"def %s(self, %s):\\n    %s\\n\"\n+        f\"def {method_name}(self, %s):\\n    %s\\n\"\n         % (\n-            (\"__attrs_init__\" if attrs_init else \"__init__\"),\n             args,\n             \"\\n    \".join(lines) if lines else \"pass\",\n         ),\n@@ -3056,6 +3065,109 @@ def __setstate__(self, state):\n Factory = _add_hash(_add_eq(_add_repr(Factory, attrs=_f), attrs=_f), attrs=_f)\n \n \n+class Converter:\n+    \"\"\"\n+    Stores a converter callable.\n+\n+    Allows for the wrapped converter to take additional arguments. The\n+    arguments are passed in the order they are documented.\n+\n+    Args:\n+        converter (Callable): A callable that converts the passed value.\n+\n+        takes_self (bool):\n+            Pass the partially initialized instance that is being initialized\n+            as a positional argument. (default: `False`)\n+\n+        takes_field (bool):\n+            Pass the field definition (an `Attribute`) into the converter as a\n+            positional argument. (default: `False`)\n+\n+    .. versionadded:: 24.1.0\n+    \"\"\"\n+\n+    __slots__ = (\n+        \"converter\",\n+        \"takes_self\",\n+        \"takes_field\",\n+        \"_first_param_type\",\n+        \"_global_name\",\n+        \"__call__\",\n+    )\n+\n+    def __init__(self, converter, *, takes_self=False, takes_field=False):\n+        self.converter = converter\n+        self.takes_self = takes_self\n+        self.takes_field = takes_field\n+\n+        self._first_param_type = _AnnotationExtractor(\n+            converter\n+        ).get_first_param_type()\n+\n+    @staticmethod\n+    def _get_global_name(attr_name: str) -> str:\n+        \"\"\"\n+        Return the name that a converter for an attribute name *attr_name*\n+        would have.\n+        \"\"\"\n+        return f\"__attr_converter_{attr_name}\"\n+\n+    def _fmt_converter_call(self, attr_name: str, value_var: str) -> str:\n+        \"\"\"\n+        Return a string that calls the converter for an attribute name\n+        *attr_name* and the value in variable named *value_var* according to\n+        `self.takes_self` and `self.takes_field`.\n+        \"\"\"\n+        if not (self.takes_self or self.takes_field):\n+            return f\"{self._get_global_name(attr_name)}({value_var})\"\n+\n+        if self.takes_self and self.takes_field:\n+            return f\"{self._get_global_name(attr_name)}({value_var}, self, attr_dict['{attr_name}'])\"\n+\n+        if self.takes_self:\n+            return f\"{self._get_global_name(attr_name)}({value_var}, self)\"\n+\n+        return f\"{self._get_global_name(attr_name)}({value_var}, attr_dict['{attr_name}'])\"\n+\n+    def __getstate__(self):\n+        \"\"\"\n+        Return a dict containing only converter and takes_self -- the rest gets\n+        computed when loading.\n+        \"\"\"\n+        return {\n+            \"converter\": self.converter,\n+            \"takes_self\": self.takes_self,\n+            \"takes_field\": self.takes_field,\n+        }\n+\n+    def __setstate__(self, state):\n+        \"\"\"\n+        Load instance from state.\n+        \"\"\"\n+        self.__init__(**state)\n+\n+\n+_f = [\n+    Attribute(\n+        name=name,\n+        default=NOTHING,\n+        validator=None,\n+        repr=True,\n+        cmp=None,\n+        eq=True,\n+        order=False,\n+        hash=True,\n+        init=True,\n+        inherited=False,\n+    )\n+    for name in (\"converter\", \"takes_self\", \"takes_field\")\n+]\n+\n+Converter = _add_hash(\n+    _add_eq(_add_repr(Converter, attrs=_f), attrs=_f), attrs=_f\n+)\n+\n+\n def make_class(\n     name, attrs, bases=(object,), class_body=None, **attributes_arguments\n ):\n@@ -3196,16 +3308,27 @@ def pipe(*converters):\n     .. versionadded:: 20.1.0\n     \"\"\"\n \n-    def pipe_converter(val):\n-        for converter in converters:\n-            val = converter(val)\n+    def pipe_converter(val, inst, field):\n+        for c in converters:\n+            if isinstance(c, Converter):\n+                val = c.converter(\n+                    val,\n+                    *{\n+                        (False, False): (),\n+                        (True, False): (c.takes_self,),\n+                        (False, True): (c.takes_field,),\n+                        (True, True): (c.takes_self, c.takes_field),\n+                    }[c.takes_self, c.takes_field],\n+                )\n+            else:\n+                val = c(val)\n \n         return val\n \n     if not converters:\n         # If the converter list is empty, pipe_converter is the identity.\n         A = typing.TypeVar(\"A\")\n-        pipe_converter.__annotations__ = {\"val\": A, \"return\": A}\n+        pipe_converter.__annotations__.update({\"val\": A, \"return\": A})\n     else:\n         # Get parameter type from first converter.\n         t = _AnnotationExtractor(converters[0]).get_first_param_type()\n@@ -3217,4 +3340,4 @@ def pipe_converter(val):\n         if rt:\n             pipe_converter.__annotations__[\"return\"] = rt\n \n-    return pipe_converter\n+    return Converter(pipe_converter, takes_self=True, takes_field=True)\ndiff --git a/src/attrs/__init__.py b/src/attrs/__init__.py\n--- a/src/attrs/__init__.py\n+++ b/src/attrs/__init__.py\n@@ -4,6 +4,7 @@\n     NOTHING,\n     Attribute,\n     AttrsInstance,\n+    Converter,\n     Factory,\n     _make_getattr,\n     assoc,\n@@ -42,6 +43,7 @@\n     \"Attribute\",\n     \"AttrsInstance\",\n     \"cmp_using\",\n+    \"Converter\",\n     \"converters\",\n     \"define\",\n     \"evolve\",\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -277,25 +277,27 @@ def strlen(y: str) -> int:\n         def identity(z):\n             return z\n \n-        assert attr.converters.pipe(int2str).__annotations__ == {\n+        assert attr.converters.pipe(int2str).converter.__annotations__ == {\n             \"val\": int,\n             \"return\": str,\n         }\n-        assert attr.converters.pipe(int2str, strlen).__annotations__ == {\n+        assert attr.converters.pipe(\n+            int2str, strlen\n+        ).converter.__annotations__ == {\n             \"val\": int,\n             \"return\": int,\n         }\n-        assert attr.converters.pipe(identity, strlen).__annotations__ == {\n-            \"return\": int\n-        }\n-        assert attr.converters.pipe(int2str, identity).__annotations__ == {\n-            \"val\": int\n-        }\n+        assert attr.converters.pipe(\n+            identity, strlen\n+        ).converter.__annotations__ == {\"return\": int}\n+        assert attr.converters.pipe(\n+            int2str, identity\n+        ).converter.__annotations__ == {\"val\": int}\n \n         def int2str_(x: int, y: int = 0) -> str:\n             return str(x)\n \n-        assert attr.converters.pipe(int2str_).__annotations__ == {\n+        assert attr.converters.pipe(int2str_).converter.__annotations__ == {\n             \"val\": int,\n             \"return\": str,\n         }\n@@ -306,17 +308,20 @@ def test_pipe_empty(self):\n         \"\"\"\n \n         p = attr.converters.pipe()\n-        assert \"val\" in p.__annotations__\n-        t = p.__annotations__[\"val\"]\n+\n+        assert \"val\" in p.converter.__annotations__\n+\n+        t = p.converter.__annotations__[\"val\"]\n+\n         assert isinstance(t, typing.TypeVar)\n-        assert p.__annotations__ == {\"val\": t, \"return\": t}\n+        assert p.converter.__annotations__ == {\"val\": t, \"return\": t}\n \n     def test_pipe_non_introspectable(self):\n         \"\"\"\n         pipe() doesn't crash when passed a non-introspectable converter.\n         \"\"\"\n \n-        assert attr.converters.pipe(print).__annotations__ == {}\n+        assert attr.converters.pipe(print).converter.__annotations__ == {}\n \n     def test_pipe_nullary(self):\n         \"\"\"\n@@ -326,7 +331,7 @@ def test_pipe_nullary(self):\n         def noop():\n             pass\n \n-        assert attr.converters.pipe(noop).__annotations__ == {}\n+        assert attr.converters.pipe(noop).converter.__annotations__ == {}\n \n     def test_optional(self):\n         \"\"\"\ndiff --git a/tests/test_converters.py b/tests/test_converters.py\n--- a/tests/test_converters.py\n+++ b/tests/test_converters.py\n@@ -4,15 +4,61 @@\n Tests for `attr.converters`.\n \"\"\"\n \n+import pickle\n \n import pytest\n \n import attr\n \n-from attr import Factory, attrib\n+from attr import Converter, Factory, attrib\n from attr.converters import default_if_none, optional, pipe, to_bool\n \n \n+class TestConverter:\n+    @pytest.mark.parametrize(\"takes_self\", [True, False])\n+    @pytest.mark.parametrize(\"takes_field\", [True, False])\n+    def test_pickle(self, takes_self, takes_field):\n+        \"\"\"\n+        Wrapped converters can be pickled.\n+        \"\"\"\n+        c = Converter(int, takes_self=takes_self, takes_field=takes_field)\n+\n+        new_c = pickle.loads(pickle.dumps(c))\n+\n+        assert c == new_c\n+        assert takes_self == new_c.takes_self\n+        assert takes_field == new_c.takes_field\n+\n+    @pytest.mark.parametrize(\n+        \"scenario\",\n+        [\n+            ((False, False), \"__attr_converter_le_name(le_value)\"),\n+            (\n+                (True, True),\n+                \"__attr_converter_le_name(le_value, self, attr_dict['le_name'])\",\n+            ),\n+            (\n+                (True, False),\n+                \"__attr_converter_le_name(le_value, self)\",\n+            ),\n+            (\n+                (False, True),\n+                \"__attr_converter_le_name(le_value, attr_dict['le_name'])\",\n+            ),\n+        ],\n+    )\n+    def test_fmt_converter_call(self, scenario):\n+        \"\"\"\n+        _fmt_converter_call determines the arguments to the wrapped converter\n+        according to `takes_self` and `takes_field`.\n+        \"\"\"\n+        (takes_self, takes_field), expect = scenario\n+\n+        c = Converter(None, takes_self=takes_self, takes_field=takes_field)\n+\n+        assert expect == c._fmt_converter_call(\"le_name\", \"le_value\")\n+\n+\n class TestOptional:\n     \"\"\"\n     Tests for `optional`.\n@@ -105,9 +151,13 @@ def test_success(self):\n         \"\"\"\n         Succeeds if all wrapped converters succeed.\n         \"\"\"\n-        c = pipe(str, to_bool, bool)\n+        c = pipe(str, Converter(to_bool), bool)\n \n-        assert True is c(\"True\") is c(True)\n+        assert (\n+            True\n+            is c.converter(\"True\", None, None)\n+            is c.converter(True, None, None)\n+        )\n \n     def test_fail(self):\n         \"\"\"\n@@ -117,11 +167,11 @@ def test_fail(self):\n \n         # First wrapped converter fails:\n         with pytest.raises(ValueError):\n-            c(33)\n+            c.converter(33, None, None)\n \n         # Last wrapped converter fails:\n         with pytest.raises(ValueError):\n-            c(\"33\")\n+            c.converter(\"33\", None, None)\n \n     def test_sugar(self):\n         \"\"\"\n@@ -142,7 +192,7 @@ def test_empty(self):\n         \"\"\"\n         o = object()\n \n-        assert o is pipe()(o)\n+        assert o is pipe().converter(o, None, None)\n \n \n class TestToBool:\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1312,7 +1312,7 @@ class TestConverter:\n     Tests for attribute conversion.\n     \"\"\"\n \n-    def test_convert(self):\n+    def test_converter(self):\n         \"\"\"\n         Return value of converter is used as the attribute's value.\n         \"\"\"\n@@ -1324,6 +1324,46 @@ def test_convert(self):\n         assert c.x == 2\n         assert c.y == 2\n \n+    def test_converter_wrapped_takes_self(self):\n+        \"\"\"\n+        When wrapped and passed `takes_self`, the converter receives the\n+        instance that's being initializes -- and the return value is used as\n+        the field's value.\n+        \"\"\"\n+\n+        def converter_with_self(v, self_):\n+            return v * self_.y\n+\n+        @attr.define\n+        class C:\n+            x: int = attr.field(\n+                converter=attr.Converter(converter_with_self, takes_self=True)\n+            )\n+            y = 42\n+\n+        assert 84 == C(2).x\n+\n+    def test_converter_wrapped_takes_field(self):\n+        \"\"\"\n+        When wrapped and passed `takes_field`, the converter receives the field\n+        definition -- and the return value is used as the field's value.\n+        \"\"\"\n+\n+        def converter_with_field(v, field):\n+            assert isinstance(field, attr.Attribute)\n+            return v * field.metadata[\"x\"]\n+\n+        @attr.define\n+        class C:\n+            x: int = attr.field(\n+                converter=attr.Converter(\n+                    converter_with_field, takes_field=True\n+                ),\n+                metadata={\"x\": 42},\n+            )\n+\n+        assert 84 == C(2).x\n+\n     @given(integers(), booleans())\n     def test_convert_property(self, val, init):\n         \"\"\"\ndiff --git a/tests/test_mypy.yml b/tests/test_mypy.yml\n--- a/tests/test_mypy.yml\n+++ b/tests/test_mypy.yml\n@@ -767,7 +767,7 @@\n             return 'hello'\n \n - case: testAttrsUsingBadConverter\n-  regex: true\n+  skip: sys.version_info[:2] < (3, 10)\n   main: |\n     import attr\n     from typing import overload\n@@ -787,14 +787,14 @@\n         bad_overloaded: int = attr.ib(converter=bad_overloaded_converter)\n     reveal_type(A)\n   out: |\n-    main:15: error: Cannot determine __init__ type from converter  \\[misc\\]\n-    main:15: error: Argument \"converter\" has incompatible type \\\"Callable\\[\\[\\], str\\]\\\"; expected (\\\"Callable\\[\\[Any\\], Any\\] \\| None\\\"|\\\"Optional\\[Callable\\[\\[Any\\], Any\\]\\]\\\")  \\[arg-type\\]\n-    main:16: error: Cannot determine __init__ type from converter  \\[misc\\]\n-    main:16: error: Argument \"converter\" has incompatible type overloaded function; expected (\\\"Callable\\[\\[Any\\], Any\\] \\| None\\\"|\\\"Optional\\[Callable\\[\\[Any\\], Any\\]\\]\\\")  \\[arg-type\\]\n-    main:17: note: Revealed type is \"def (bad: Any, bad_overloaded: Any\\) -> main.A\"\n+    main:15: error: Cannot determine __init__ type from converter  [misc]\n+    main:15: error: Argument \"converter\" has incompatible type \"Callable[[], str]\"; expected \"Callable[[Any], Any] | Converter[Any, Never] | None\"  [arg-type]\n+    main:16: error: Cannot determine __init__ type from converter  [misc]\n+    main:16: error: Argument \"converter\" has incompatible type overloaded function; expected \"Callable[[Any], Any] | Converter[Any, Never] | None\"  [arg-type]\n+    main:17: note: Revealed type is \"def (bad: Any, bad_overloaded: Any) -> main.A\"\n \n - case: testAttrsUsingBadConverterReprocess\n-  regex: true\n+  skip: sys.version_info[:2] < (3, 10)\n   main: |\n     import attr\n     from typing import overload\n@@ -815,11 +815,11 @@\n         bad_overloaded: int = attr.ib(converter=bad_overloaded_converter)\n     reveal_type(A)\n   out: |\n-    main:16: error: Cannot determine __init__ type from converter  \\[misc\\]\n-    main:16: error: Argument \\\"converter\\\" has incompatible type \\\"Callable\\[\\[\\], str\\]\\\"; expected (\\\"Callable\\[\\[Any\\], Any\\] \\| None\\\"|\\\"Optional\\[Callable\\[\\[Any\\], Any\\]\\]\\\")  \\[arg-type\\]\n-    main:17: error: Cannot determine __init__ type from converter  \\[misc\\]\n-    main:17: error: Argument \"converter\" has incompatible type overloaded function; expected (\\\"Callable\\[\\[Any\\], Any\\] \\| None\\\"|\\\"Optional\\[Callable\\[\\[Any\\], Any\\]\\]\\\")  \\[arg-type\\]\n-    main:18: note: Revealed type is \"def (bad: Any, bad_overloaded: Any\\) -> main.A\"\n+    main:16: error: Cannot determine __init__ type from converter  [misc]\n+    main:16: error: Argument \"converter\" has incompatible type \"Callable[[], str]\"; expected \"Callable[[Any], Any] | Converter[Any, Never] | None\"  [arg-type]\n+    main:17: error: Cannot determine __init__ type from converter  [misc]\n+    main:17: error: Argument \"converter\" has incompatible type overloaded function; expected \"Callable[[Any], Any] | Converter[Any, Never] | None\"  [arg-type]\n+    main:18: note: Revealed type is \"def (bad: Any, bad_overloaded: Any) -> main.A\"\n \n - case: testAttrsUsingUnsupportedConverter\n   main: |\n@@ -874,6 +874,66 @@\n     o = C(\"1\", \"2\", \"3\")\n     o = C(1, 2, \"3\")\n \n+- case: testThreeArgConverterTypes\n+  main: |\n+    from typing import Any\n+    from attrs import AttrsInstance, Attribute, Converter\n+\n+    def my_converter(value: Any) -> str:\n+        \"\"\"A converter that only takes the value.\"\"\"\n+        return str(value)\n+\n+    def my_converter_with_self(value: Any, self: AttrsInstance) -> str:\n+        \"\"\"This converter takes the value and the self.\"\"\"\n+        return str(value)\n+\n+\n+    def my_converter_with_field(value: Any, field: Attribute) -> str:\n+        \"\"\"This converter takes the value and the field.\"\"\"\n+        return str(value)\n+\n+    reveal_type(Converter(my_converter))\n+    Converter(my_converter_with_self)\n+    Converter(my_converter_with_field)\n+\n+    reveal_type(Converter(my_converter_with_self, takes_self=True))\n+    Converter(my_converter, takes_self=True)\n+    Converter(my_converter_with_field, takes_self=True)\n+\n+    reveal_type(Converter(my_converter_with_field, takes_field=True))\n+    Converter(my_converter, takes_field=True)\n+    Converter(my_converter_with_self, takes_field=True)\n+  out: |\n+    main:17: note: Revealed type is \"attr.Converter[Any, builtins.str]\"\n+    main:18: error: Argument 1 to \"Converter\" has incompatible type \"Callable[[Any, AttrsInstance], str]\"; expected \"Callable[[Any], str]\"  [arg-type]\n+    main:19: error: Argument 1 to \"Converter\" has incompatible type \"Callable[[Any, Attribute[Any]], str]\"; expected \"Callable[[Any], str]\"  [arg-type]\n+    main:21: note: Revealed type is \"attr.Converter[Any, builtins.str]\"\n+    main:22: error: No overload variant of \"Converter\" matches argument types \"Callable[[Any], str]\", \"bool\"  [call-overload]\n+    main:22: note: Possible overload variants:\n+    main:22: note:     def [In, Out] Converter(self, converter: Callable[[In], Out]) -> Converter[In, Out]\n+    main:22: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance, Attribute[Any]], Out], *, takes_self: Literal[True], takes_field: Literal[True]) -> Converter[In, Out]\n+    main:22: note:     def [In, Out] Converter(self, converter: Callable[[In, Attribute[Any]], Out], *, takes_field: Literal[True]) -> Converter[In, Out]\n+    main:22: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance], Out], *, takes_self: Literal[True]) -> Converter[In, Out]\n+    main:23: error: No overload variant of \"Converter\" matches argument types \"Callable[[Any, Attribute[Any]], str]\", \"bool\"  [call-overload]\n+    main:23: note: Possible overload variants:\n+    main:23: note:     def [In, Out] Converter(self, converter: Callable[[In], Out]) -> Converter[In, Out]\n+    main:23: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance, Attribute[Any]], Out], *, takes_self: Literal[True], takes_field: Literal[True]) -> Converter[In, Out]\n+    main:23: note:     def [In, Out] Converter(self, converter: Callable[[In, Attribute[Any]], Out], *, takes_field: Literal[True]) -> Converter[In, Out]\n+    main:23: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance], Out], *, takes_self: Literal[True]) -> Converter[In, Out]\n+    main:25: note: Revealed type is \"attr.Converter[Any, builtins.str]\"\n+    main:26: error: No overload variant of \"Converter\" matches argument types \"Callable[[Any], str]\", \"bool\"  [call-overload]\n+    main:26: note: Possible overload variants:\n+    main:26: note:     def [In, Out] Converter(self, converter: Callable[[In], Out]) -> Converter[In, Out]\n+    main:26: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance, Attribute[Any]], Out], *, takes_self: Literal[True], takes_field: Literal[True]) -> Converter[In, Out]\n+    main:26: note:     def [In, Out] Converter(self, converter: Callable[[In, Attribute[Any]], Out], *, takes_field: Literal[True]) -> Converter[In, Out]\n+    main:26: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance], Out], *, takes_self: Literal[True]) -> Converter[In, Out]\n+    main:27: error: No overload variant of \"Converter\" matches argument types \"Callable[[Any, AttrsInstance], str]\", \"bool\"  [call-overload]\n+    main:27: note: Possible overload variants:\n+    main:27: note:     def [In, Out] Converter(self, converter: Callable[[In], Out]) -> Converter[In, Out]\n+    main:27: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance, Attribute[Any]], Out], *, takes_self: Literal[True], takes_field: Literal[True]) -> Converter[In, Out]\n+    main:27: note:     def [In, Out] Converter(self, converter: Callable[[In, Attribute[Any]], Out], *, takes_field: Literal[True]) -> Converter[In, Out]\n+    main:27: note:     def [In, Out] Converter(self, converter: Callable[[In, AttrsInstance], Out], *, takes_self: Literal[True]) -> Converter[In, Out]\n+\n - case: testAttrsCmpWithSubclasses\n   regex: true\n   main: |\n", "problem_statement": "Allow three-argument converters (like validators/on_setattr)\nI'd like to move the discussion from [converter decorator PR](https://github.com/python-attrs/attrs/pull/404) to this issue.\r\n\r\nI think converters are semantically closer to `on_setattr` and `validator` than `default`. E.g. `attr.ib(converter=...)` allows you to pass a list of callables and pipes them automatically - exactly like `attr.ib(validator=...)` and `attr.ib(on_setattr=...)` and there is `attr.converters` module, like `attr.setters` and `attr.validators`. \r\n\r\nIf we allow passing half-initialized self to converter, why don't allow full-form converters, `converter(self, attr, value)` to make them the same as `on_setattr`, but for initialization? \r\n\r\nTo support one, two and three-argument converters there should be either inspect-magic (in py2 - getargspec, in py3 - signature) or mandatory `Converter` wrapper for two and three-argument converters. \n", "hints_text": "Maybe, converters and validators can (or event should) be merged (similarly to [click callbacks](https://click.palletsprojects.com/en/7.x/options/#callbacks-for-validation))?\r\n\r\n```python\r\ndef int_validator(self, attrib, value):\r\n    return int(value)  # Validates and converts at the same time :-)\r\n```\r\n\r\nI guess that would be very backwards incompatible, but maybe this can (still) be added to the new `attrs` API?\n> To support one, two and three-argument converters there should be either inspect-magic (in py2 - getargspec, in py3 - signature) or mandatory `Converter` wrapper for two and three-argument converters.\r\n\r\nThis is something I've been thinking about in the past days. I _think_ a marker-wrapper for three-argument converters would be most solid and in line with our other APIs?\nThere's also #146  which still bothers me that it's unresolved but to which I still don't have a good answer, 3.5 years later. :(\nThank you for the discussion! \r\n\r\n@sscherfke I think this is kind of thing that happened to `on_setattr` already. The only big difference here is that converters should work with half-initialized self, but `@default` shows that it can be tackled by users (and #404 shows that some of them are actually craving that possibility in a converter). \r\n\r\nPersonally I like separate validators, as they are running after all the conversions (hence - guaranteed to work with fully-initialized self!) and imply that the field value doesn't change (unless some reckless guy will do  `object.__setattr__(self, attr.name, new_value)` inside, but it seems like a dirty hack and wouldn't pass any code-review. Or at least I hope so...)\r\n\r\n@hynek #146 is pretty informative, thank you for mentioning it! :) I actually missed the stacktrace point when I was thinking about it (and maybe some performance issues, as there is a level of indirection here...). Though, I think that having `on_setattr` on board actually introduces some `common` API for a pipeline here. \r\n\r\nI do like the marker-wrapper idea (e.g. `Converter(fun, takes_self=True, takes_attr=True)`), though it may be a bit unexpected for a newcomer that `attr.ib(converter=c)` expects one-argument function or wrapper, while `attr.ib(validator=v, on_seattr=s)` expect three-argument function (and no wrappers provided). But - considering possible issues with half-initialized `self` - it may be a good practice, actually. \r\n\r\nUPD: Just saw the comment in the PR. Actually, if `converter` is kind of shortcut to something like `on_init` - it sounds like a great way to get away from this unexpected behavior :)\nAny update to this issue ? ", "created_at": "2024-03-17T12:19:06Z"}
{"repo": "python-attrs/attrs", "pull_number": 1187, "instance_id": "python-attrs__attrs-1187", "issue_numbers": ["1102"], "base_commit": "46a03dcef6d2698aa5934a1ee00d9523564dcd8c", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -3,6 +3,7 @@\n import contextlib\n import copy\n import enum\n+import inspect\n import linecache\n import sys\n import types\n@@ -624,6 +625,7 @@ class _ClassBuilder:\n         \"_delete_attribs\",\n         \"_frozen\",\n         \"_has_pre_init\",\n+        \"_pre_init_has_args\",\n         \"_has_post_init\",\n         \"_is_exc\",\n         \"_on_setattr\",\n@@ -670,6 +672,13 @@ def __init__(\n         self._weakref_slot = weakref_slot\n         self._cache_hash = cache_hash\n         self._has_pre_init = bool(getattr(cls, \"__attrs_pre_init__\", False))\n+        self._pre_init_has_args = False\n+        if self._has_pre_init:\n+            # Check if the pre init method has more arguments than just `self`\n+            # We want to pass arguments if pre init expects arguments\n+            pre_init_func = cls.__attrs_pre_init__\n+            pre_init_signature = inspect.signature(pre_init_func)\n+            self._pre_init_has_args = len(pre_init_signature.parameters) > 1\n         self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\n         self._delete_attribs = not bool(these)\n         self._is_exc = is_exc\n@@ -974,6 +983,7 @@ def add_init(self):\n                 self._cls,\n                 self._attrs,\n                 self._has_pre_init,\n+                self._pre_init_has_args,\n                 self._has_post_init,\n                 self._frozen,\n                 self._slots,\n@@ -1000,6 +1010,7 @@ def add_attrs_init(self):\n                 self._cls,\n                 self._attrs,\n                 self._has_pre_init,\n+                self._pre_init_has_args,\n                 self._has_post_init,\n                 self._frozen,\n                 self._slots,\n@@ -1984,6 +1995,7 @@ def _make_init(\n     cls,\n     attrs,\n     pre_init,\n+    pre_init_has_args,\n     post_init,\n     frozen,\n     slots,\n@@ -2027,6 +2039,7 @@ def _make_init(\n         frozen,\n         slots,\n         pre_init,\n+        pre_init_has_args,\n         post_init,\n         cache_hash,\n         base_attr_map,\n@@ -2107,6 +2120,7 @@ def _attrs_to_init_script(\n     frozen,\n     slots,\n     pre_init,\n+    pre_init_has_args,\n     post_init,\n     cache_hash,\n     base_attr_map,\n@@ -2361,11 +2375,23 @@ def fmt_setter_with_converter(\n         lines.append(f\"BaseException.__init__(self, {vals})\")\n \n     args = \", \".join(args)\n+    pre_init_args = args\n     if kw_only_args:\n         args += \"%s*, %s\" % (\n             \", \" if args else \"\",  # leading comma\n             \", \".join(kw_only_args),  # kw_only args\n         )\n+        pre_init_kw_only_args = \", \".join(\n+            [\"%s=%s\" % (kw_arg, kw_arg) for kw_arg in kw_only_args]\n+        )\n+        pre_init_args += (\n+            \", \" if pre_init_args else \"\"\n+        )  # handle only kwargs and no regular args\n+        pre_init_args += pre_init_kw_only_args\n+\n+    if pre_init and pre_init_has_args:\n+        # If pre init method has arguments, pass same arguments as `__init__`\n+        lines[0] = \"self.__attrs_pre_init__(%s)\" % pre_init_args\n \n     return (\n         \"def %s(self, %s):\\n    %s\\n\"\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -6,6 +6,7 @@\n \n \n import copy\n+import inspect\n import pickle\n \n import pytest\n@@ -84,10 +85,15 @@ def _add_init(cls, frozen):\n     This function used to be part of _make.  It wasn't used anymore however\n     the tests for it are still useful to test the behavior of _make_init.\n     \"\"\"\n+    has_pre_init = bool(getattr(cls, \"__attrs_pre_init__\", False))\n+\n     cls.__init__ = _make_init(\n         cls,\n         cls.__attrs_attrs__,\n-        getattr(cls, \"__attrs_pre_init__\", False),\n+        has_pre_init,\n+        len(inspect.signature(cls.__attrs_pre_init__).parameters) > 1\n+        if has_pre_init\n+        else False,\n         getattr(cls, \"__attrs_post_init__\", False),\n         frozen,\n         _is_slot_cls(cls),\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -613,21 +613,89 @@ class D:\n         assert C.D.__qualname__ == C.__qualname__ + \".D\"\n \n     @pytest.mark.parametrize(\"with_validation\", [True, False])\n-    def test_pre_init(self, with_validation, monkeypatch):\n+    def test_pre_init(self, with_validation):\n         \"\"\"\n         Verify that __attrs_pre_init__ gets called if defined.\n         \"\"\"\n-        monkeypatch.setattr(_config, \"_run_validators\", with_validation)\n \n         @attr.s\n         class C:\n             def __attrs_pre_init__(self2):\n                 self2.z = 30\n \n-        c = C()\n+        try:\n+            attr.validators.set_disabled(not with_validation)\n+            c = C()\n+        finally:\n+            attr.validators.set_disabled(False)\n \n         assert 30 == getattr(c, \"z\", None)\n \n+    @pytest.mark.parametrize(\"with_validation\", [True, False])\n+    def test_pre_init_args(self, with_validation):\n+        \"\"\"\n+        Verify that __attrs_pre_init__ gets called with extra args if defined.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            x = attr.ib()\n+\n+            def __attrs_pre_init__(self2, x):\n+                self2.z = x + 1\n+\n+        try:\n+            attr.validators.set_disabled(not with_validation)\n+            c = C(x=10)\n+        finally:\n+            attr.validators.set_disabled(False)\n+\n+        assert 11 == getattr(c, \"z\", None)\n+\n+    @pytest.mark.parametrize(\"with_validation\", [True, False])\n+    def test_pre_init_kwargs(self, with_validation):\n+        \"\"\"\n+        Verify that __attrs_pre_init__ gets called with extra args and kwargs if defined.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            x = attr.ib()\n+            y = attr.field(kw_only=True)\n+\n+            def __attrs_pre_init__(self2, x, y):\n+                self2.z = x + y + 1\n+\n+        try:\n+            attr.validators.set_disabled(not with_validation)\n+            c = C(10, y=11)\n+        finally:\n+            attr.validators.set_disabled(False)\n+\n+        assert 22 == getattr(c, \"z\", None)\n+\n+    @pytest.mark.parametrize(\"with_validation\", [True, False])\n+    def test_pre_init_kwargs_only(self, with_validation):\n+        \"\"\"\n+        Verify that __attrs_pre_init__ gets called with extra kwargs only if\n+        defined.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            y = attr.field(kw_only=True)\n+\n+            def __attrs_pre_init__(self2, y):\n+                self2.z = y + 1\n+\n+        try:\n+            attr.validators.set_disabled(not with_validation)\n+            c = C(y=11)\n+        finally:\n+            attr.validators.set_disabled(False)\n+\n+        assert 12 == getattr(c, \"z\", None)\n+\n     @pytest.mark.parametrize(\"with_validation\", [True, False])\n     def test_post_init(self, with_validation, monkeypatch):\n         \"\"\"\n", "problem_statement": "Pass all args to `__attrs_pre_init__()`\nI am subclassing a class that I have no control over, which is written in standard Python.  The base class A has a number of arguments that I want to set.  Infact there are 3 classes.  C (attrs class) is a sublcass of B (attrs class) which is a subclass of A (non-attrs class).\r\n\r\nWhen I instantiate C, I want to pass arguments to B and A.\r\n\r\nI implemented class based factory functions (vai `@classmethod`), which works well for a single level inheritance, but I'm not sure how to use the classmethod of B from the classmethod of A.  I figured I'm stuck with duplicating of the B initialisation within the C classmethod and the instantiating class C by passing all the necessary arguments.\r\n\r\nAll this involves defining a custom `__init__()` method (https://www.attrs.org/en/stable/init.html#custom-init), but it seems to me that could be avoided by using `__attrs_pre_init__()`, but unfortunately it seems no arguments are passed to that (i.e. no `*args` or `**kwargs`).\r\n\r\nIs there a reason why arguments are not passed to `attrs_pre_init__()`, and only passed to `__init__()`?\r\n\r\nI think it makes sense to pass all arguments to `__attrs_pre_init__()` so the user can have the flexibility to do what is required (or nothing at all).\r\n\r\n```python\r\n\r\n    def __attrs_pre_init__(self, *args, **kwargs):\r\n        ...\r\n        super().__init__(*args, **kwargs)\r\n        ...\r\n```\r\n\r\nI can see why it is less relevant for `__attrs_post_init__()`, but I'm sure someone can think of a use-case where the arguments could be useful (e.g. for arguments that aren't stored as instanace attributes).\n", "hints_text": "Yeah in hindsight that seems an odd omission. I think the expectation was that you're gonna use a custom init for anything more complicated.\nI'm interested in implementing this feature but I'm not sure where to start. I see where the call to `__atrs_pre_init__` is being added in [`src/attr/_make.py`](https://github.com/python-attrs/attrs/blob/06b1bb414121bd21dd0781016a035ed1388aa136/src/attr/_make.py#L2105). Would I change this call to include the arguments being passed into the `__init__` method being generated?\nWithout looking closer, I suspect you\u2019ll have to inspect the `__attrs_pre_init__` method and call with with or without based on its arguments. For all I care: do nothing if it\u2019s only one argument (presumably self), pass them if it has more than one.", "created_at": "2023-09-21T18:22:53Z"}
{"repo": "python-attrs/attrs", "pull_number": 1172, "instance_id": "python-attrs__attrs-1172", "issue_numbers": ["1133"], "base_commit": "8f4e7e921bbe68e938989385a563a9af28b71f38", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -9,6 +9,7 @@\n \n from . import converters, exceptions, filters, setters, validators\n from ._cmp import cmp_using\n+from ._compat import Protocol\n from ._config import get_run_validators, set_run_validators\n from ._funcs import asdict, assoc, astuple, evolve, has, resolve_types\n from ._make import (\n@@ -31,7 +32,7 @@\n dataclass = partial(attrs, auto_attribs=True)  # happy Easter ;)\n \n \n-class AttrsInstance:\n+class AttrsInstance(Protocol):\n     pass\n \n \ndiff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -18,6 +18,15 @@\n PY_3_12_PLUS = sys.version_info[:2] >= (3, 12)\n \n \n+if sys.version_info < (3, 8):\n+    try:\n+        from typing_extensions import Protocol\n+    except ImportError:  # pragma: no cover\n+        Protocol = object\n+else:\n+    from typing import Protocol  # noqa: F401\n+\n+\n def just_warn(*args, **kw):\n     warnings.warn(\n         \"Running interpreter doesn't sufficiently support code object \"\n", "test_patch": "diff --git a/tests/test_compat.py b/tests/test_compat.py\n--- a/tests/test_compat.py\n+++ b/tests/test_compat.py\n@@ -4,6 +4,8 @@\n \n import pytest\n \n+import attr\n+\n \n @pytest.fixture(name=\"mp\")\n def _mp():\n@@ -50,3 +52,13 @@ def test_immutable(self, mp):\n \n         with pytest.raises(AttributeError, match=\"no attribute 'setdefault'\"):\n             mp.setdefault(\"x\")\n+\n+\n+def test_attrsinstance_subclass_protocol():\n+    \"\"\"\n+    It's possible to subclass AttrsInstance and Protocol at once.\n+    \"\"\"\n+\n+    class Foo(attr.AttrsInstance, attr._compat.Protocol):\n+        def attribute(self) -> int:\n+            ...\n", "problem_statement": "AttrsInstance is only a Protocol in mypy\n`__init__.pyi` defines AttrsInstance as follows:\r\n```\r\nclass AttrsInstance(AttrsInstance_, Protocol):\r\n    pass\r\n```\r\n\r\nSo the following typechecks correctly:\r\n```\r\nimport attr\r\nfrom typing import Protocol\r\n\r\nclass Foo(attr.AttrsInstance, Protocol):\r\n    def attribute(self) -> int:\r\n        ...\r\n\r\n\r\ndef bar(foo: Foo) -> int:\r\n    return foo.attribute()\r\n\r\n@attr.define\r\nclass CFoo:\r\n    a: int\r\n\r\n    def attribute(self) -> int:\r\n        return self.a\r\n\r\nbar(CFoo(15))\r\n```\r\n\r\nBut if you run it you get:\r\n\r\n`TypeError: Protocols can only inherit from other protocols, got <class 'attr.AttrsInstance'>`\r\n\r\nBecause in `__init__.py` it's defined as:\r\n```\r\nclass AttrsInstance:\r\n    pass\r\n```\r\n\r\ninstead of \r\n```\r\nclass AttrsInstance(Protocol):\r\n    pass\r\n```\n", "hints_text": "Ah. Looks like a workaround is to do:\r\n\r\n```\r\nclass Foo(Protocol):\r\n    __attrs_attrs__: ClassVar[Any]\r\n   def attribute(self) -> int:\r\n        ...\r\n```\nIs this anything we can fix in attrs?\nI think just the small change I said, I can make a PR. But probably not until next week.\r\n\r\nIt should just be:\r\n```\r\nfrom typing import Protocol\r\n\r\nclass AttrsInstance(Protocol):\r\n    pass\r\n```\r\n", "created_at": "2023-08-04T15:22:28Z"}
{"repo": "python-attrs/attrs", "pull_number": 1165, "instance_id": "python-attrs__attrs-1165", "issue_numbers": ["1164"], "base_commit": "a37b556f7d762b7a6229b1fbf985965539571cd2", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -72,19 +72,25 @@ def asdict(\n                 )\n             elif isinstance(v, (tuple, list, set, frozenset)):\n                 cf = v.__class__ if retain_collection_types is True else list\n-                rv[a.name] = cf(\n-                    [\n-                        _asdict_anything(\n-                            i,\n-                            is_key=False,\n-                            filter=filter,\n-                            dict_factory=dict_factory,\n-                            retain_collection_types=retain_collection_types,\n-                            value_serializer=value_serializer,\n-                        )\n-                        for i in v\n-                    ]\n-                )\n+                items = [\n+                    _asdict_anything(\n+                        i,\n+                        is_key=False,\n+                        filter=filter,\n+                        dict_factory=dict_factory,\n+                        retain_collection_types=retain_collection_types,\n+                        value_serializer=value_serializer,\n+                    )\n+                    for i in v\n+                ]\n+                try:\n+                    rv[a.name] = cf(items)\n+                except TypeError:\n+                    if not issubclass(cf, tuple):\n+                        raise\n+                    # Workaround for TypeError: cf.__new__() missing 1 required\n+                    # positional argument (which appears, for a namedturle)\n+                    rv[a.name] = cf(*items)\n             elif isinstance(v, dict):\n                 df = dict_factory\n                 rv[a.name] = df(\n@@ -241,22 +247,26 @@ def astuple(\n                 )\n             elif isinstance(v, (tuple, list, set, frozenset)):\n                 cf = v.__class__ if retain is True else list\n-                rv.append(\n-                    cf(\n-                        [\n-                            astuple(\n-                                j,\n-                                recurse=True,\n-                                filter=filter,\n-                                tuple_factory=tuple_factory,\n-                                retain_collection_types=retain,\n-                            )\n-                            if has(j.__class__)\n-                            else j\n-                            for j in v\n-                        ]\n+                items = [\n+                    astuple(\n+                        j,\n+                        recurse=True,\n+                        filter=filter,\n+                        tuple_factory=tuple_factory,\n+                        retain_collection_types=retain,\n                     )\n-                )\n+                    if has(j.__class__)\n+                    else j\n+                    for j in v\n+                ]\n+                try:\n+                    rv.append(cf(items))\n+                except TypeError:\n+                    if not issubclass(cf, tuple):\n+                        raise\n+                    # Workaround for TypeError: cf.__new__() missing 1 required\n+                    # positional argument (which appears, for a namedturle)\n+                    rv.append(cf(*items))\n             elif isinstance(v, dict):\n                 df = v.__class__ if retain is True else dict\n                 rv.append(\n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -4,9 +4,10 @@\n Tests for `attr._funcs`.\n \"\"\"\n \n+import re\n \n from collections import OrderedDict\n-from typing import Generic, TypeVar\n+from typing import Generic, NamedTuple, TypeVar\n \n import pytest\n \n@@ -232,6 +233,52 @@ class A:\n \n         assert {\"a\": {(1,): 1}} == attr.asdict(instance)\n \n+    def test_named_tuple_retain_type(self):\n+        \"\"\"\n+        Namedtuples can be serialized if retain_collection_types is True.\n+\n+        See #1164\n+        \"\"\"\n+\n+        class Coordinates(NamedTuple):\n+            lat: float\n+            lon: float\n+\n+        @attr.s\n+        class A:\n+            coords: Coordinates = attr.ib()\n+\n+        instance = A(Coordinates(50.419019, 30.516225))\n+\n+        assert {\"coords\": Coordinates(50.419019, 30.516225)} == attr.asdict(\n+            instance, retain_collection_types=True\n+        )\n+\n+    def test_type_error_with_retain_type(self):\n+        \"\"\"\n+        Serialization that fails with TypeError leaves the error through if\n+        they're not tuples.\n+\n+        See #1164\n+        \"\"\"\n+\n+        message = \"__new__() missing 1 required positional argument (asdict)\"\n+\n+        class Coordinates(list):\n+            def __init__(self, first, *rest):\n+                if isinstance(first, list):\n+                    raise TypeError(message)\n+                super().__init__([first, *rest])\n+\n+        @attr.s\n+        class A:\n+            coords: Coordinates = attr.ib()\n+\n+        instance = A(Coordinates(50.419019, 30.516225))\n+\n+        with pytest.raises(TypeError, match=re.escape(message)):\n+            attr.asdict(instance, retain_collection_types=True)\n+\n \n class TestAsTuple:\n     \"\"\"\n@@ -390,6 +437,52 @@ def test_sets_no_retain(self, C, set_type):\n \n         assert (1, [1, 2, 3]) == d\n \n+    def test_named_tuple_retain_type(self):\n+        \"\"\"\n+        Namedtuples can be serialized if retain_collection_types is True.\n+\n+        See #1164\n+        \"\"\"\n+\n+        class Coordinates(NamedTuple):\n+            lat: float\n+            lon: float\n+\n+        @attr.s\n+        class A:\n+            coords: Coordinates = attr.ib()\n+\n+        instance = A(Coordinates(50.419019, 30.516225))\n+\n+        assert (Coordinates(50.419019, 30.516225),) == attr.astuple(\n+            instance, retain_collection_types=True\n+        )\n+\n+    def test_type_error_with_retain_type(self):\n+        \"\"\"\n+        Serialization that fails with TypeError leaves the error through if\n+        they're not tuples.\n+\n+        See #1164\n+        \"\"\"\n+\n+        message = \"__new__() missing 1 required positional argument (astuple)\"\n+\n+        class Coordinates(list):\n+            def __init__(self, first, *rest):\n+                if isinstance(first, list):\n+                    raise TypeError(message)\n+                super().__init__([first, *rest])\n+\n+        @attr.s\n+        class A:\n+            coords: Coordinates = attr.ib()\n+\n+        instance = A(Coordinates(50.419019, 30.516225))\n+\n+        with pytest.raises(TypeError, match=re.escape(message)):\n+            attr.astuple(instance, retain_collection_types=True)\n+\n \n class TestHas:\n     \"\"\"\n", "problem_statement": "NamedTuple serialization fails to work\nMRE:\r\n```python\r\nimport attrs\r\nfrom typing import NamedTuple\r\nclass MyNamedTuple(NamedTuple):\r\n    one: str\r\n    two: int\r\n@attrs.define\r\nclass MyAttrsClass:\r\n    inner: MyNamedTuple\r\nprint(attrs.asdict(MyAttrsClass(MyNamedTuple(\"Hello!\", 0))))\r\n```\r\nExpected output:\r\n```\r\n{'inner': MyNamedTuple(one='Hello!', two=0)}\r\n```\r\nor at least even a\r\n```\r\n{'inner': ('Hello!', 0)}\r\n```\r\nInstead we get \r\n```\r\nFile ~/.local/pipx/venvs/jupyter/lib/python3.11/site-packages/attr/_funcs.py:75, in asdict(inst, recurse, filter, dict_factory, retain_collection_types, value_serializer)\r\n     73 elif isinstance(v, (tuple, list, set, frozenset)):\r\n     74     cf = v.__class__ if retain_collection_types is True else list\r\n---> 75     rv[a.name] = cf(\r\n     76         [\r\n     77             _asdict_anything(\r\n     78                 i,\r\n     79                 is_key=False,\r\n     80                 filter=filter,\r\n     81                 dict_factory=dict_factory,\r\n     82                 retain_collection_types=retain_collection_types,\r\n     83                 value_serializer=value_serializer,\r\n     84             )\r\n     85             for i in v\r\n     86         ]\r\n     87     )\r\n     88 elif isinstance(v, dict):\r\n     89     df = dict_factory\r\n\r\nTypeError: MyNamedTuple.__new__() missing 1 required positional argument: 'two'\r\n```\r\n\r\nPython: 3.11.0\r\nAttrs: 23.1.0\n", "hints_text": "", "created_at": "2023-07-19T17:37:24Z"}
{"repo": "python-attrs/attrs", "pull_number": 1122, "instance_id": "python-attrs__attrs-1122", "issue_numbers": ["937"], "base_commit": "5a7d978d8a7050961f62159c63fd2b7ad7b1c7d2", "patch": "diff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -270,15 +270,16 @@ def optional(validator):\n     which can be set to ``None`` in addition to satisfying the requirements of\n     the sub-validator.\n \n-    :param validator: A validator (or a list of validators) that is used for\n-        non-``None`` values.\n-    :type validator: callable or `list` of callables.\n+    :param Callable | tuple[Callable] | list[Callable] validator: A validator\n+        (or validators) that is used for non-``None`` values.\n \n     .. versionadded:: 15.1.0\n     .. versionchanged:: 17.1.0 *validator* can be a list of validators.\n+    .. versionchanged:: 23.1.0 *validator* can also be a tuple of validators.\n     \"\"\"\n-    if isinstance(validator, list):\n+    if isinstance(validator, (list, tuple)):\n         return _OptionalValidator(_AndValidator(validator))\n+\n     return _OptionalValidator(validator)\n \n \n", "test_patch": "diff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -384,7 +384,12 @@ def test_repr(self, ifoo):\n \n \n @pytest.mark.parametrize(\n-    \"validator\", [instance_of(int), [always_pass, instance_of(int)]]\n+    \"validator\",\n+    [\n+        instance_of(int),\n+        [always_pass, instance_of(int)],\n+        (always_pass, instance_of(int)),\n+    ],\n )\n class TestOptional:\n     \"\"\"\n@@ -437,6 +442,11 @@ def test_repr(self, validator):\n                 \"<optional validator for _AndValidator(_validators=[{func}, \"\n                 \"<instance_of validator for type <class 'int'>>]) or None>\"\n             ).format(func=repr(always_pass))\n+        elif isinstance(validator, tuple):\n+            repr_s = (\n+                \"<optional validator for _AndValidator(_validators=({func}, \"\n+                \"<instance_of validator for type <class 'int'>>)) or None>\"\n+            ).format(func=repr(always_pass))\n         else:\n             repr_s = (\n                 \"<optional validator for <instance_of validator for type \"\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -236,6 +236,15 @@ class Validated:\n     p: Any = attr.ib(\n         validator=attr.validators.not_(attr.validators.in_(\"abc\"), msg=None)\n     )\n+    q: Any = attr.ib(\n+        validator=attrs.validators.optional(attrs.validators.instance_of(C))\n+    )\n+    r: Any = attr.ib(\n+        validator=attrs.validators.optional([attrs.validators.instance_of(C)])\n+    )\n+    s: Any = attr.ib(\n+        validator=attrs.validators.optional((attrs.validators.instance_of(C),))\n+    )\n \n \n @attr.define\n", "problem_statement": "Optional validator should handle a tuple of validators\nSee relevant discussion in this discussion:\r\nhttps://github.com/python-attrs/attrs/pull/925#discussion_r827665676\n", "hints_text": "", "created_at": "2023-04-05T09:13:22Z"}
{"repo": "python-attrs/attrs", "pull_number": 1117, "instance_id": "python-attrs__attrs-1117", "issue_numbers": ["1109"], "base_commit": "22ae8473fb88d6e585b05c709e81e1a46398a649", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -351,9 +351,10 @@ def assoc(inst, **changes):\n     return new\n \n \n-def evolve(inst, **changes):\n+def evolve(*args, **changes):\n     \"\"\"\n-    Create a new instance, based on *inst* with *changes* applied.\n+    Create a new instance, based on the first positional argument with\n+    *changes* applied.\n \n     :param inst: Instance of a class with *attrs* attributes.\n     :param changes: Keyword changes in the new copy.\n@@ -365,8 +366,40 @@ def evolve(inst, **changes):\n     :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n-    ..  versionadded:: 17.1.0\n+    .. versionadded:: 17.1.0\n+    .. deprecated:: 23.1.0\n+       It is now deprecated to pass the instance using the keyword argument\n+       *inst*. It will raise a warning until at least April 2024, after which\n+       it will become an error. Always pass the instance as a positional\n+       argument.\n     \"\"\"\n+    # Try to get instance by positional argument first.\n+    # Use changes otherwise and warn it'll break.\n+    if args:\n+        try:\n+            (inst,) = args\n+        except ValueError:\n+            raise TypeError(\n+                f\"evolve() takes 1 positional argument, but {len(args)} \"\n+                \"were given\"\n+            ) from None\n+    else:\n+        try:\n+            inst = changes.pop(\"inst\")\n+        except KeyError:\n+            raise TypeError(\n+                \"evolve() missing 1 required positional argument: 'inst'\"\n+            ) from None\n+\n+        import warnings\n+\n+        warnings.warn(\n+            \"Passing the instance per keyword argument is deprecated and \"\n+            \"will stop working in, or after, April 2024.\",\n+            DeprecationWarning,\n+            stacklevel=2,\n+        )\n+\n     cls = inst.__class__\n     attrs = fields(cls)\n     for a in attrs:\n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -689,3 +689,47 @@ class Cls2:\n         assert Cls1({\"foo\": 42, \"param2\": 42}) == attr.evolve(\n             obj1a, param1=obj2b\n         )\n+\n+    def test_inst_kw(self):\n+        \"\"\"\n+        If `inst` is passed per kw argument, a warning is raised.\n+        See #1109\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            pass\n+\n+        with pytest.warns(DeprecationWarning) as wi:\n+            evolve(inst=C())\n+\n+        assert __file__ == wi.list[0].filename\n+\n+    def test_no_inst(self):\n+        \"\"\"\n+        Missing inst argument raises a TypeError like Python would.\n+        \"\"\"\n+        with pytest.raises(TypeError, match=r\"evolve\\(\\) missing 1\"):\n+            evolve(x=1)\n+\n+    def test_too_many_pos_args(self):\n+        \"\"\"\n+        More than one positional argument raises a TypeError like Python would.\n+        \"\"\"\n+        with pytest.raises(\n+            TypeError,\n+            match=r\"evolve\\(\\) takes 1 positional argument, but 2 were given\",\n+        ):\n+            evolve(1, 2)\n+\n+    def test_can_change_inst(self):\n+        \"\"\"\n+        If the instance is passed by positional argument, a field named `inst`\n+        can be changed.\n+        \"\"\"\n+\n+        @attr.define\n+        class C:\n+            inst: int\n+\n+        assert C(42) == evolve(C(23), inst=42)\n", "problem_statement": "Make evolve 1st arg positional-only\nIt's arbitrary that the 1st argument is named `inst` and could conflict with a field.\r\n\r\nSince PEP-570 positional-only arguments require Python 3.8 and next major version will be \u2265 Python 3.7, we can do it the old-fashion way in the next breaking version (as this is an API change), i.e.\r\n```python\r\ndef evolve(*args, **changes):\r\n  (inst,) = args\r\n  ...\r\n```\n", "hints_text": "Wow that's gross :D \u2013 I wonder if that's possible to express for typing? It would probably break some people who passed it as keyword arguments\u2026 \ud83e\udd14\nattrs has type stubs so the way it looks to typing can be modern w/PEP-570.\n\nAlso, recently I've merged https://github.com/python/mypy/pull/14526 where you can provide the instance only positionally, so in attrs it will be positional only from the next release due to plugin code.\nDataclasses did something similar, albeit with warning and not a breaking change. Maybe we want to do the same: https://bugs.python.org/issue37163\nFWIW, they did break later as announced in the issue:\r\n\r\n```\r\nIn [2]: dataclasses.replace?\r\nSignature: dataclasses.replace(obj, /, **changes)\r\nDocstring:\r\nReturn a new object replacing specified fields with new values.\r\n\r\nThis is especially useful for frozen classes.  Example usage::\r\n\r\n  @dataclass(frozen=True)\r\n  class C:\r\n      x: int\r\n      y: int\r\n\r\n  c = C(1, 2)\r\n  c1 = replace(c, x=3)\r\n  assert c1.x == 3 and c1.y == 2\r\nFile:      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\r\nType:      function\r\n```\r\n\r\nguess we could warn now and break in a year.", "created_at": "2023-04-03T16:19:29Z"}
{"repo": "python-attrs/attrs", "pull_number": 1107, "instance_id": "python-attrs__attrs-1107", "issue_numbers": ["1082"], "base_commit": "359c2db460f4410e86782a99eef06dabbfd96d34", "patch": "diff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -167,6 +167,7 @@ def field(\n     hash=None,\n     init=True,\n     metadata=None,\n+    type=None,\n     converter=None,\n     factory=None,\n     kw_only=False,\n@@ -179,6 +180,10 @@ def field(\n     Identical to `attr.ib`, except keyword-only and with some arguments\n     removed.\n \n+    .. versionadded:: 22.3.0\n+       The *type* parameter has been re-added; mostly for\n+       {func}`attrs.make_class`. Please note that type checkers ignore this\n+       metadata.\n     .. versionadded:: 20.1.0\n     \"\"\"\n     return attrib(\n@@ -188,6 +193,7 @@ def field(\n         hash=hash,\n         init=init,\n         metadata=metadata,\n+        type=type,\n         converter=converter,\n         factory=factory,\n         kw_only=kw_only,\n", "test_patch": "diff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -28,6 +28,16 @@ def test_simple(self):\n         \"\"\"\n         C(\"1\", 2)\n \n+    def test_field_type(self):\n+        \"\"\"\n+        Make class with attrs.field and type parameter.\n+        \"\"\"\n+        classFields = {\"testint\": attrs.field(type=int)}\n+\n+        A = attrs.make_class(\"A\", classFields)\n+\n+        assert int == attrs.fields(A).testint.type\n+\n     def test_no_slots(self):\n         \"\"\"\n         slots can be deactivated.\n", "problem_statement": "Add `type` back to `attrs.field()` for use in `attrs.make_class()`\nI'm using `attrs.make_class()` to dynamically construct a class based on other attrs classes, and it would be nice to be able to specify the `type` of the fields on the generated class using `attrs.field()` instead of `attr.ib()`. In other words, this works:\r\n\r\n```python\r\nfields = {\r\n    field.name: attr.ib(type=field.type)\r\n    for field in itertools.chain.from_iterable(\r\n        attrs.fields(t) for t in SOME_ATTRS_CLASSES\r\n    )\r\n    if not field.name.startswith(\"_\")\r\n}\r\n\r\nMyClass = attrs.make_class(\"MyClass\", fields)\r\n```\r\n\r\nbut this does not:\r\n\r\n```python\r\nfields = {\r\n    field.name: attrs.field(type=field.type)\r\n    for field in itertools.chain.from_iterable(\r\n        attrs.fields(t) for t in SOME_ATTRS_CLASSES\r\n    )\r\n    if not field.name.startswith(\"_\")\r\n}\r\n\r\nMyClass = attrs.make_class(\"MyClass\", fields)\r\n```\n", "hints_text": "Aw man yeah when I celebrated to get rid of that, I forgot about `make_class`. \ud83d\ude48\nI'm working on the implementation. ", "created_at": "2023-02-28T09:41:01Z"}
{"repo": "python-attrs/attrs", "pull_number": 1080, "instance_id": "python-attrs__attrs-1080", "issue_numbers": ["1077"], "base_commit": "0de967d6ece1606234ac56d5fe58a800d1b0434f", "patch": "diff --git a/src/attr/_cmp.py b/src/attr/_cmp.py\n--- a/src/attr/_cmp.py\n+++ b/src/attr/_cmp.py\n@@ -20,22 +20,22 @@ def cmp_using(\n     class_name=\"Comparable\",\n ):\n     \"\"\"\n-    Create a class that can be passed into `attr.ib`'s ``eq``, ``order``, and\n-    ``cmp`` arguments to customize field comparison.\n-\n-    The resulting class will have a full set of ordering methods if\n-    at least one of ``{lt, le, gt, ge}`` and ``eq``  are provided.\n-\n-    :param Optional[callable] eq: `callable` used to evaluate equality\n-        of two objects.\n-    :param Optional[callable] lt: `callable` used to evaluate whether\n-        one object is less than another object.\n-    :param Optional[callable] le: `callable` used to evaluate whether\n-        one object is less than or equal to another object.\n-    :param Optional[callable] gt: `callable` used to evaluate whether\n-        one object is greater than another object.\n-    :param Optional[callable] ge: `callable` used to evaluate whether\n-        one object is greater than or equal to another object.\n+    Create a class that can be passed into `attrs.field`'s ``eq``, ``order``,\n+    and ``cmp`` arguments to customize field comparison.\n+\n+    The resulting class will have a full set of ordering methods if at least\n+    one of ``{lt, le, gt, ge}`` and ``eq``  are provided.\n+\n+    :param Optional[callable] eq: `callable` used to evaluate equality of two\n+        objects.\n+    :param Optional[callable] lt: `callable` used to evaluate whether one\n+        object is less than another object.\n+    :param Optional[callable] le: `callable` used to evaluate whether one\n+        object is less than or equal to another object.\n+    :param Optional[callable] gt: `callable` used to evaluate whether one\n+        object is greater than another object.\n+    :param Optional[callable] ge: `callable` used to evaluate whether one\n+        object is greater than or equal to another object.\n \n     :param bool require_same_type: When `True`, equality and ordering methods\n         will return `NotImplemented` if objects are not of the same type.\ndiff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -16,13 +16,13 @@ def asdict(\n     value_serializer=None,\n ):\n     \"\"\"\n-    Return the ``attrs`` attribute values of *inst* as a dict.\n+    Return the *attrs* attribute values of *inst* as a dict.\n \n-    Optionally recurse into other ``attrs``-decorated classes.\n+    Optionally recurse into other *attrs*-decorated classes.\n \n-    :param inst: Instance of an ``attrs``-decorated class.\n+    :param inst: Instance of an *attrs*-decorated class.\n     :param bool recurse: Recurse into classes that are also\n-        ``attrs``-decorated.\n+        *attrs*-decorated.\n     :param callable filter: A callable whose return code determines whether an\n         attribute or element is included (``True``) or dropped (``False``).  Is\n         called with the `attrs.Attribute` as the first argument and the\n@@ -40,7 +40,7 @@ def asdict(\n \n     :rtype: return type of *dict_factory*\n \n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n     ..  versionadded:: 16.0.0 *dict_factory*\n@@ -195,13 +195,13 @@ def astuple(\n     retain_collection_types=False,\n ):\n     \"\"\"\n-    Return the ``attrs`` attribute values of *inst* as a tuple.\n+    Return the *attrs* attribute values of *inst* as a tuple.\n \n-    Optionally recurse into other ``attrs``-decorated classes.\n+    Optionally recurse into other *attrs*-decorated classes.\n \n-    :param inst: Instance of an ``attrs``-decorated class.\n+    :param inst: Instance of an *attrs*-decorated class.\n     :param bool recurse: Recurse into classes that are also\n-        ``attrs``-decorated.\n+        *attrs*-decorated.\n     :param callable filter: A callable whose return code determines whether an\n         attribute or element is included (``True``) or dropped (``False``).  Is\n         called with the `attrs.Attribute` as the first argument and the\n@@ -215,7 +215,7 @@ def astuple(\n \n     :rtype: return type of *tuple_factory*\n \n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n     ..  versionadded:: 16.2.0\n@@ -289,7 +289,7 @@ def astuple(\n \n def has(cls):\n     \"\"\"\n-    Check whether *cls* is a class with ``attrs`` attributes.\n+    Check whether *cls* is a class with *attrs* attributes.\n \n     :param type cls: Class to introspect.\n     :raise TypeError: If *cls* is not a class.\n@@ -303,14 +303,14 @@ def assoc(inst, **changes):\n     \"\"\"\n     Copy *inst* and apply *changes*.\n \n-    :param inst: Instance of a class with ``attrs`` attributes.\n+    :param inst: Instance of a class with *attrs* attributes.\n     :param changes: Keyword changes in the new copy.\n \n     :return: A copy of inst with *changes* incorporated.\n \n-    :raise attr.exceptions.AttrsAttributeNotFoundError: If *attr_name* couldn't\n-        be found on *cls*.\n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.AttrsAttributeNotFoundError: If *attr_name*\n+        couldn't be found on *cls*.\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n     ..  deprecated:: 17.1.0\n@@ -341,14 +341,14 @@ def evolve(inst, **changes):\n     \"\"\"\n     Create a new instance, based on *inst* with *changes* applied.\n \n-    :param inst: Instance of a class with ``attrs`` attributes.\n+    :param inst: Instance of a class with *attrs* attributes.\n     :param changes: Keyword changes in the new copy.\n \n     :return: A copy of inst with *changes* incorporated.\n \n     :raise TypeError: If *attr_name* couldn't be found in the class\n         ``__init__``.\n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n     ..  versionadded:: 17.1.0\n@@ -385,10 +385,10 @@ def resolve_types(cls, globalns=None, localns=None, attribs=None):\n     :param Optional[dict] localns: Dictionary containing local variables.\n     :param Optional[list] attribs: List of attribs for the given class.\n         This is necessary when calling from inside a ``field_transformer``\n-        since *cls* is not an ``attrs`` class yet.\n+        since *cls* is not an *attrs* class yet.\n \n     :raise TypeError: If *cls* is not a class.\n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class and you didn't pass any attribs.\n     :raise NameError: If types cannot be resolved because of missing variables.\n \ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -109,9 +109,12 @@ def attrib(\n     ..  warning::\n \n         Does *not* do anything unless the class is also decorated with\n-        `attr.s`!\n+        `attr.s` / `attrs.define` / et cetera!\n \n-    :param default: A value that is used if an ``attrs``-generated ``__init__``\n+    Please consider using `attrs.field` in new code (``attr.ib`` will *never*\n+    go away, though).\n+\n+    :param default: A value that is used if an *attrs*-generated ``__init__``\n         is used and no value is passed while instantiating or the attribute is\n         excluded using ``init=False``.\n \n@@ -130,7 +133,7 @@ def attrib(\n     :param callable factory: Syntactic sugar for\n         ``default=attr.Factory(factory)``.\n \n-    :param validator: `callable` that is called by ``attrs``-generated\n+    :param validator: `callable` that is called by *attrs*-generated\n         ``__init__`` methods after the instance has been initialized.  They\n         receive the initialized instance, the :func:`~attrs.Attribute`, and the\n         passed value.\n@@ -142,7 +145,7 @@ def attrib(\n         all pass.\n \n         Validators can be globally disabled and re-enabled using\n-        `get_run_validators`.\n+        `attrs.validators.get_disabled` / `attrs.validators.set_disabled`.\n \n         The validator can also be set using decorator notation as shown below.\n \n@@ -184,7 +187,7 @@ def attrib(\n         value.  In that case this attributed is unconditionally initialized\n         with the specified default value or factory.\n     :param callable converter: `callable` that is called by\n-        ``attrs``-generated ``__init__`` methods to convert attribute's value\n+        *attrs*-generated ``__init__`` methods to convert attribute's value\n         to the desired format.  It is given the passed-in value, and the\n         returned value will be used as the new value of the attribute.  The\n         value is converted before being passed to the validator, if any.\n@@ -197,7 +200,7 @@ def attrib(\n         Regardless of the approach used, the type will be stored on\n         ``Attribute.type``.\n \n-        Please note that ``attrs`` doesn't do anything with this metadata by\n+        Please note that *attrs* doesn't do anything with this metadata by\n         itself. You can use it as part of your own code or for\n         `static type checking <types>`.\n     :param kw_only: Make this attribute keyword-only in the generated\n@@ -1211,12 +1214,15 @@ def attrs(\n     A class decorator that adds :term:`dunder methods` according to the\n     specified attributes using `attr.ib` or the *these* argument.\n \n+    Please consider using `attrs.define` / `attrs.frozen` in new code\n+    (``attr.s`` will *never* go away, though).\n+\n     :param these: A dictionary of name to `attr.ib` mappings.  This is\n         useful to avoid the definition of your attributes within the class body\n         because you can't (e.g. if you want to add ``__repr__`` methods to\n         Django models) or don't want to.\n \n-        If *these* is not ``None``, ``attrs`` will *not* search the class body\n+        If *these* is not ``None``, *attrs* will *not* search the class body\n         for attributes and will *not* remove any attributes from it.\n \n         The order is deduced from the order of the attributes inside *these*.\n@@ -1233,14 +1239,14 @@ def attrs(\n         inherited from some base class).\n \n         So for example by implementing ``__eq__`` on a class yourself,\n-        ``attrs`` will deduce ``eq=False`` and will create *neither*\n+        *attrs* will deduce ``eq=False`` and will create *neither*\n         ``__eq__`` *nor* ``__ne__`` (but Python classes come with a sensible\n         ``__ne__`` by default, so it *should* be enough to only implement\n         ``__eq__`` in most cases).\n \n         .. warning::\n \n-           If you prevent ``attrs`` from creating the ordering methods for you\n+           If you prevent *attrs* from creating the ordering methods for you\n            (``order=False``, e.g. by implementing ``__le__``), it becomes\n            *your* responsibility to make sure its ordering is sound. The best\n            way is to use the `functools.total_ordering` decorator.\n@@ -1250,14 +1256,14 @@ def attrs(\n         *cmp*, or *hash* overrides whatever *auto_detect* would determine.\n \n     :param bool repr: Create a ``__repr__`` method with a human readable\n-        representation of ``attrs`` attributes..\n+        representation of *attrs* attributes..\n     :param bool str: Create a ``__str__`` method that is identical to\n         ``__repr__``.  This is usually not necessary except for\n         `Exception`\\ s.\n     :param Optional[bool] eq: If ``True`` or ``None`` (default), add ``__eq__``\n         and ``__ne__`` methods that check two instances for equality.\n \n-        They compare the instances as if they were tuples of their ``attrs``\n+        They compare the instances as if they were tuples of their *attrs*\n         attributes if and only if the types of both classes are *identical*!\n     :param Optional[bool] order: If ``True``, add ``__lt__``, ``__le__``,\n         ``__gt__``, and ``__ge__`` methods that behave like *eq* above and\n@@ -1268,7 +1274,7 @@ def attrs(\n     :param Optional[bool] unsafe_hash: If ``None`` (default), the ``__hash__``\n         method is generated according how *eq* and *frozen* are set.\n \n-        1. If *both* are True, ``attrs`` will generate a ``__hash__`` for you.\n+        1. If *both* are True, *attrs* will generate a ``__hash__`` for you.\n         2. If *eq* is True and *frozen* is False, ``__hash__`` will be set to\n            None, marking it unhashable (which it is).\n         3. If *eq* is False, ``__hash__`` will be left untouched meaning the\n@@ -1276,7 +1282,7 @@ def attrs(\n            ``object``, this means it will fall back to id-based hashing.).\n \n         Although not recommended, you can decide for yourself and force\n-        ``attrs`` to create one (e.g. if the class is immutable even though you\n+        *attrs* to create one (e.g. if the class is immutable even though you\n         didn't freeze it programmatically) by passing ``True`` or not.  Both of\n         these cases are rather special and should be used carefully.\n \n@@ -1287,7 +1293,7 @@ def attrs(\n     :param Optional[bool] hash: Alias for *unsafe_hash*. *unsafe_hash* takes\n         precedence.\n     :param bool init: Create a ``__init__`` method that initializes the\n-        ``attrs`` attributes. Leading underscores are stripped for the argument\n+        *attrs* attributes. Leading underscores are stripped for the argument\n         name. If a ``__attrs_pre_init__`` method exists on the class, it will\n         be called before the class is initialized. If a ``__attrs_post_init__``\n         method exists on the class, it will be called after the class is fully\n@@ -1303,7 +1309,7 @@ def attrs(\n         we encourage you to read the :term:`glossary entry <slotted classes>`.\n     :param bool frozen: Make instances immutable after initialization.  If\n         someone attempts to modify a frozen instance,\n-        `attr.exceptions.FrozenInstanceError` is raised.\n+        `attrs.exceptions.FrozenInstanceError` is raised.\n \n         .. note::\n \n@@ -1328,7 +1334,7 @@ def attrs(\n     :param bool auto_attribs: If ``True``, collect :pep:`526`-annotated\n         attributes from the class body.\n \n-        In this case, you **must** annotate every field.  If ``attrs``\n+        In this case, you **must** annotate every field.  If *attrs*\n         encounters a field that is set to an `attr.ib` but lacks a type\n         annotation, an `attr.exceptions.UnannotatedAttributeError` is\n         raised.  Use ``field_name: typing.Any = attr.ib(...)`` if you don't\n@@ -1344,9 +1350,9 @@ def attrs(\n \n         .. warning::\n            For features that use the attribute name to create decorators (e.g.\n-           `validators <validators>`), you still *must* assign `attr.ib` to\n-           them. Otherwise Python will either not find the name or try to use\n-           the default value to call e.g. ``validator`` on it.\n+           :ref:`validators <validators>`), you still *must* assign `attr.ib`\n+           to them. Otherwise Python will either not find the name or try to\n+           use the default value to call e.g. ``validator`` on it.\n \n            These errors can be quite confusing and probably the most common bug\n            report on our bug tracker.\n@@ -1367,14 +1373,14 @@ def attrs(\n         class:\n \n         - the values for *eq*, *order*, and *hash* are ignored and the\n-          instances compare and hash by the instance's ids (N.B. ``attrs`` will\n+          instances compare and hash by the instance's ids (N.B. *attrs* will\n           *not* remove existing implementations of ``__hash__`` or the equality\n           methods. It just won't add own ones.),\n         - all attributes that are either passed into ``__init__`` or have a\n           default value are additionally available as a tuple in the ``args``\n           attribute,\n         - the value of *str* is ignored leaving ``__str__`` to base classes.\n-    :param bool collect_by_mro: Setting this to `True` fixes the way ``attrs``\n+    :param bool collect_by_mro: Setting this to `True` fixes the way *attrs*\n        collects attributes from base classes.  The default behavior is\n        incorrect in certain cases of multiple inheritance.  It should be on by\n        default but is kept off for backward-compatibility.\n@@ -1413,7 +1419,7 @@ def attrs(\n \n     :param Optional[callable] field_transformer:\n         A function that is called with the original class object and all\n-        fields right before ``attrs`` finalizes the class.  You can use\n+        fields right before *attrs* finalizes the class.  You can use\n         this, e.g., to automatically add converters or validators to\n         fields based on their types.  See `transform-fields` for more details.\n \n@@ -1891,7 +1897,7 @@ def _add_repr(cls, ns=None, attrs=None):\n \n def fields(cls):\n     \"\"\"\n-    Return the tuple of ``attrs`` attributes for a class.\n+    Return the tuple of *attrs* attributes for a class.\n \n     The tuple also allows accessing the fields by their names (see below for\n     examples).\n@@ -1899,13 +1905,13 @@ def fields(cls):\n     :param type cls: Class to introspect.\n \n     :raise TypeError: If *cls* is not a class.\n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n     :rtype: tuple (with name accessors) of `attrs.Attribute`\n \n-    ..  versionchanged:: 16.2.0 Returned tuple allows accessing the fields\n-        by name.\n+    .. versionchanged:: 16.2.0 Returned tuple allows accessing the fields\n+       by name.\n     \"\"\"\n     if not isinstance(cls, type):\n         raise TypeError(\"Passed object must be a class.\")\n@@ -1917,13 +1923,13 @@ def fields(cls):\n \n def fields_dict(cls):\n     \"\"\"\n-    Return an ordered dictionary of ``attrs`` attributes for a class, whose\n+    Return an ordered dictionary of *attrs* attributes for a class, whose\n     keys are the attribute names.\n \n     :param type cls: Class to introspect.\n \n     :raise TypeError: If *cls* is not a class.\n-    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+    :raise attrs.exceptions.NotAnAttrsClassError: If *cls* is not an *attrs*\n         class.\n \n     :rtype: dict\n@@ -1944,7 +1950,7 @@ def validate(inst):\n \n     Leaves all exceptions through.\n \n-    :param inst: Instance of a class with ``attrs`` attributes.\n+    :param inst: Instance of a class with *attrs* attributes.\n     \"\"\"\n     if _config._run_validators is False:\n         return\n@@ -2382,6 +2388,10 @@ class Attribute:\n     \"\"\"\n     *Read-only* representation of an attribute.\n \n+    .. warning::\n+\n+       You should never instantiate this class yourself.\n+\n     The class has *all* arguments of `attr.ib` (except for ``factory``\n     which is only syntactic sugar for ``default=Factory(...)`` plus the\n     following:\n@@ -2527,13 +2537,13 @@ def from_counting_attr(cls, name, ca, type=None):\n             **inst_dict,\n         )\n \n-    # Don't use attr.evolve since fields(Attribute) doesn't work\n+    # Don't use attrs.evolve since fields(Attribute) doesn't work\n     def evolve(self, **changes):\n         \"\"\"\n         Copy *self* and apply *changes*.\n \n-        This works similarly to `attr.evolve` but that function does not work\n-        with ``Attribute``.\n+        This works similarly to `attrs.evolve` but that function does not work\n+        with `Attribute`.\n \n         It is mainly meant to be used for `transform-fields`.\n \n@@ -2768,10 +2778,6 @@ class Factory:\n     __slots__ = (\"factory\", \"takes_self\")\n \n     def __init__(self, factory, takes_self=False):\n-        \"\"\"\n-        `Factory` is part of the default machinery so if we want a default\n-        value here, we have to implement it ourselves.\n-        \"\"\"\n         self.factory = factory\n         self.takes_self = takes_self\n \ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -46,7 +46,7 @@ def define(\n     match_args=True,\n ):\n     r\"\"\"\n-    Define an ``attrs`` class.\n+    Define an *attrs* class.\n \n     Differences to the classic `attr.s` that it uses underneath:\n \ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\n--- a/src/attr/exceptions.py\n+++ b/src/attr/exceptions.py\n@@ -34,7 +34,7 @@ class FrozenAttributeError(FrozenError):\n \n class AttrsAttributeNotFoundError(ValueError):\n     \"\"\"\n-    An ``attrs`` function couldn't find an attribute that the user asked for.\n+    An *attrs* function couldn't find an attribute that the user asked for.\n \n     .. versionadded:: 16.2.0\n     \"\"\"\n@@ -42,7 +42,7 @@ class AttrsAttributeNotFoundError(ValueError):\n \n class NotAnAttrsClassError(ValueError):\n     \"\"\"\n-    A non-``attrs`` class has been passed into an ``attrs`` function.\n+    A non-*attrs* class has been passed into an *attrs* function.\n \n     .. versionadded:: 16.2.0\n     \"\"\"\n@@ -50,7 +50,7 @@ class NotAnAttrsClassError(ValueError):\n \n class DefaultAlreadySetError(RuntimeError):\n     \"\"\"\n-    A default has been set using ``attr.ib()`` and is attempted to be reset\n+    A default has been set when defining the field and is attempted to be reset\n     using the decorator.\n \n     .. versionadded:: 17.1.0\n@@ -59,8 +59,7 @@ class DefaultAlreadySetError(RuntimeError):\n \n class UnannotatedAttributeError(RuntimeError):\n     \"\"\"\n-    A class with ``auto_attribs=True`` has an ``attr.ib()`` without a type\n-    annotation.\n+    A class with ``auto_attribs=True`` has a field without a type annotation.\n \n     .. versionadded:: 17.3.0\n     \"\"\"\n@@ -68,7 +67,7 @@ class UnannotatedAttributeError(RuntimeError):\n \n class PythonTooOldError(RuntimeError):\n     \"\"\"\n-    It was attempted to use an ``attrs`` feature that requires a newer Python\n+    It was attempted to use an *attrs* feature that requires a newer Python\n     version.\n \n     .. versionadded:: 18.2.0\n@@ -77,8 +76,8 @@ class PythonTooOldError(RuntimeError):\n \n class NotCallableError(TypeError):\n     \"\"\"\n-    A ``attr.ib()`` requiring a callable has been set with a value\n-    that is not callable.\n+    A field requiring a callable has been set with a value that is not\n+    callable.\n \n     .. versionadded:: 19.2.0\n     \"\"\"\ndiff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -359,13 +359,13 @@ def __repr__(self):\n \n def is_callable():\n     \"\"\"\n-    A validator that raises a `attr.exceptions.NotCallableError` if the\n+    A validator that raises a `attrs.exceptions.NotCallableError` if the\n     initializer is called with a value for this particular attribute\n     that is not callable.\n \n     .. versionadded:: 19.1.0\n \n-    :raises `attr.exceptions.NotCallableError`: With a human readable error\n+    :raises attrs.exceptions.NotCallableError: With a human readable error\n         message containing the attribute (`attrs.Attribute`) name,\n         and the value it got.\n     \"\"\"\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1106,7 +1106,7 @@ def test_instance(self, C):\n \n     def test_handler_non_attrs_class(self):\n         \"\"\"\n-        Raises `ValueError` if passed a non-``attrs`` instance.\n+        Raises `ValueError` if passed a non-*attrs* instance.\n         \"\"\"\n         with pytest.raises(NotAnAttrsClassError) as e:\n             fields(object)\n@@ -1148,7 +1148,7 @@ def test_instance(self, C):\n \n     def test_handler_non_attrs_class(self):\n         \"\"\"\n-        Raises `ValueError` if passed a non-``attrs`` instance.\n+        Raises `ValueError` if passed a non-*attrs* instance.\n         \"\"\"\n         with pytest.raises(NotAnAttrsClassError) as e:\n             fields_dict(object)\n", "problem_statement": "Some API doc entries in objects.inv have double-attr module prefixes\ne.g. `attr.attr.cmp_using`\r\n\r\ncursory looking suggests it's autodoc vs manual.\n", "hints_text": "Ah, I missed the dedicated issue and left the comments @ https://github.com/python-attrs/attrs/issues/1073#issuecomment-1369072401 & https://github.com/python-attrs/attrs/issues/1073#issuecomment-1369077722.", "created_at": "2023-01-04T11:39:22Z"}
{"repo": "python-attrs/attrs", "pull_number": 1075, "instance_id": "python-attrs__attrs-1075", "issue_numbers": ["1074"], "base_commit": "88d2a377487effdac54acdedf1d7d6c400f002e5", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -2818,13 +2818,13 @@ def __setstate__(self, state):\n \n \n def make_class(name, attrs, bases=(object,), **attributes_arguments):\n-    \"\"\"\n+    r\"\"\"\n     A quick way to create a new class called *name* with *attrs*.\n \n     :param str name: The name for the new class.\n \n     :param attrs: A list of names or a dictionary of mappings of names to\n-        attributes.\n+        `attr.ib`\\ s / `attrs.field`\\ s.\n \n         The order is deduced from the order of the names or attributes inside\n         *attrs*.  Otherwise the order of the definition of the attributes is\n", "test_patch": "", "problem_statement": "make_class() fails when passing dict of Attributes\nI noticed this fails, but in my understanding of the manual it should work:\r\n```python\r\nimport attrs\r\n\r\n@attrs.define\r\nclass Foo:\r\n    bar: int\r\n\r\na = attrs.fields(Foo)[0]\r\nattrs.make_class(\"Foo\", dict(bar=a))\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_attrs.py\", line 9, in <module>\r\n    attrs.make_class(\"Foo\", dict(bar=a))\r\n  File \"/usr/lib/python3.10/site-packages/attr/_make.py\", line 2888, in make_class\r\n    return _attrs(these=cls_dict, **attributes_arguments)(type_)\r\n  File \"/usr/lib/python3.10/site-packages/attr/_make.py\", line 1491, in wrap\r\n    builder = _ClassBuilder(\r\n  File \"/usr/lib/python3.10/site-packages/attr/_make.py\", line 658, in __init__\r\n    attrs, base_attrs, base_map = _transform_attrs(\r\n  File \"/usr/lib/python3.10/site-packages/attr/_make.py\", line 529, in _transform_attrs\r\n    own_attrs = [\r\n  File \"/usr/lib/python3.10/site-packages/attr/_make.py\", line 530, in <listcomp>\r\n    Attribute.from_counting_attr(\r\n  File \"/usr/lib/python3.10/site-packages/attr/_make.py\", line 2531, in from_counting_attr\r\n    validator=ca._validator,\r\nAttributeError: 'Attribute' object has no attribute '_validator'. Did you mean: 'validator'?\r\n\r\n```\n", "hints_text": "This fixes it for me now , so I can continue working:\r\nhttps://github.com/python-attrs/attrs/blob/88d2a377487effdac54acdedf1d7d6c400f002e5/src/attr/_make.py#L2531-L2532\r\n\r\n```python\r\nvalidator=getattr(ca, \"_validator\", None),\r\ndefault=getattr(ca, \"_default\", ca.default),\r\n```\r\n\r\nThe real problem is probably somewhere else, I leave that up to the authors of the library :)\nBonus bug report:\r\n\r\nWith the above fix applied, I discovered that one can now pass Attributes in the wrong order: First an attribute with a default set, then one with default=NOTHING will produce this error:\r\n`ValueError: No mandatory attributes allowed after an attribute with a default value or factory.`\r\n\r\nSince 3.7 the insertion order of a dict is guaranteed, but I would argue that it would be less painful if `make_class` could automatically reorder the attributes if needed.\nOof that's not a bug, but documentation rot, because make_class has fallen a bit to the wayside.\r\n\r\nAs you can see in the example in https://www.attrs.org/en/stable/api.html#attrs.make_class, it doesn't take an instance of `Attribute` but a result of calling `attr.ib()` and it was never updated to new APIs.\r\n\r\nLooking closer, in the end this seems to be another instance of #637, but adding the angle of `make_class` which should be kept in mind.", "created_at": "2022-12-30T16:21:05Z"}
{"repo": "python-attrs/attrs", "pull_number": 1065, "instance_id": "python-attrs__attrs-1065", "issue_numbers": ["1003"], "base_commit": "67dc8cc261a5ef64f576ce73f2281cc9021d8fb4", "patch": "diff --git a/docs/conf.py b/docs/conf.py\n--- a/docs/conf.py\n+++ b/docs/conf.py\n@@ -45,6 +45,11 @@\n     \"sphinxcontrib.towncrier\",\n ]\n \n+myst_enable_extensions = [\n+    \"colon_fence\",\n+    \"smartquotes\",\n+    \"deflist\",\n+]\n \n # Add any paths that contain templates here, relative to this directory.\n templates_path = [\"_templates\"]\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1217,6 +1217,7 @@ def attrs(\n     on_setattr=None,\n     field_transformer=None,\n     match_args=True,\n+    unsafe_hash=None,\n ):\n     r\"\"\"\n     A class decorator that adds :term:`dunder methods` according to the\n@@ -1279,8 +1280,8 @@ def attrs(\n         *eq*.\n     :param Optional[bool] cmp: Setting *cmp* is equivalent to setting *eq*\n         and *order* to the same value. Must not be mixed with *eq* or *order*.\n-    :param Optional[bool] hash: If ``None`` (default), the ``__hash__`` method\n-        is generated according how *eq* and *frozen* are set.\n+    :param Optional[bool] unsafe_hash: If ``None`` (default), the ``__hash__``\n+        method is generated according how *eq* and *frozen* are set.\n \n         1. If *both* are True, ``attrs`` will generate a ``__hash__`` for you.\n         2. If *eq* is True and *frozen* is False, ``__hash__`` will be set to\n@@ -1298,6 +1299,8 @@ def attrs(\n         `object.__hash__`, and the `GitHub issue that led to the default \\\n         behavior <https://github.com/python-attrs/attrs/issues/136>`_ for more\n         details.\n+    :param Optional[bool] hash: Alias for *unsafe_hash*. *unsafe_hash* takes\n+        precedence.\n     :param bool init: Create a ``__init__`` method that initializes the\n         ``attrs`` attributes. Leading underscores are stripped for the argument\n         name. If a ``__attrs_pre_init__`` method exists on the class, it will\n@@ -1469,9 +1472,14 @@ def attrs(\n     .. versionchanged:: 21.1.0 Support for ``__attrs_pre_init__``\n     .. versionchanged:: 21.1.0 *cmp* undeprecated\n     .. versionadded:: 21.3.0 *match_args*\n+    .. versionadded:: 22.2.0\n+       *unsafe_hash* as an alias for *hash* (for :pep:`681` compliance).\n     \"\"\"\n     eq_, order_ = _determine_attrs_eq_order(cmp, eq, order, None)\n-    hash_ = hash  # work around the lack of nonlocal\n+\n+    # unsafe_hash takes precedence due to PEP 681.\n+    if unsafe_hash is not None:\n+        hash = unsafe_hash\n \n     if isinstance(on_setattr, (list, tuple)):\n         on_setattr = setters.pipe(*on_setattr)\n@@ -1527,14 +1535,14 @@ def wrap(cls):\n \n         builder.add_setattr()\n \n+        nonlocal hash\n         if (\n-            hash_ is None\n+            hash is None\n             and auto_detect is True\n             and _has_own_attribute(cls, \"__hash__\")\n         ):\n             hash = False\n-        else:\n-            hash = hash_\n+\n         if hash is not True and hash is not False and hash is not None:\n             # Can't use `hash in` because 1 == True for example.\n             raise TypeError(\ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -26,6 +26,7 @@ def define(\n     *,\n     these=None,\n     repr=None,\n+    unsafe_hash=None,\n     hash=None,\n     init=None,\n     slots=True,\n@@ -81,6 +82,8 @@ def define(\n \n     .. versionadded:: 20.1.0\n     .. versionchanged:: 21.3.0 Converters are also run ``on_setattr``.\n+    .. versionadded:: 22.2.0\n+       *unsafe_hash* as an alias for *hash* (for :pep:`681` compliance).\n     \"\"\"\n \n     def do_it(cls, auto_attribs):\n@@ -89,6 +92,7 @@ def do_it(cls, auto_attribs):\n             these=these,\n             repr=repr,\n             hash=hash,\n+            unsafe_hash=unsafe_hash,\n             init=init,\n             slots=slots,\n             frozen=frozen,\n", "test_patch": "diff --git a/tests/dataclass_transform_example.py b/tests/dataclass_transform_example.py\n--- a/tests/dataclass_transform_example.py\n+++ b/tests/dataclass_transform_example.py\n@@ -55,3 +55,9 @@ class AliasedField:\n af = AliasedField(42)\n \n reveal_type(af.__init__)  # noqa\n+\n+\n+# unsafe_hash is accepted\n+@attrs.define(unsafe_hash=True)\n+class Hashable:\n+    pass\ndiff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -739,3 +739,14 @@ class D(C):\n         assert \"_setattr('x', x)\" in src\n         assert \"_setattr('y', y)\" in src\n         assert object.__setattr__ != D.__setattr__\n+\n+    def test_unsafe_hash(self, slots):\n+        \"\"\"\n+        attr.s(unsafe_hash=True) makes a class hashable.\n+        \"\"\"\n+\n+        @attr.s(slots=slots, unsafe_hash=True)\n+        class Hashable:\n+            pass\n+\n+        assert hash(Hashable())\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -452,3 +452,8 @@ def accessing_from_attrs() -> None:\n foo = object\n if attrs.has(foo) or attr.has(foo):\n     foo.__attrs_attrs__\n+\n+\n+@attrs.define(unsafe_hash=True)\n+class Hashable:\n+    pass\n", "problem_statement": "Add unsafe_hash for PEP 681\nI've been asked to add `unsafe_hash` as an alias for `hash` **at class level** for PEP 618 (data class transforms).\r\n\r\nI'm not enthusiastic about the lack of symmetry between class-level and field-level hash but this is not the hill I'm dying on.\n", "hints_text": "[PEP-681](https://peps.python.org/pep-0681/) not 618 if anyone's looking (title right, prose transposed), and specs are in [PEP-557](https://peps.python.org/pep-0557/#id7)", "created_at": "2022-12-01T10:16:44Z"}
{"repo": "python-attrs/attrs", "pull_number": 1009, "instance_id": "python-attrs__attrs-1009", "issue_numbers": ["1004"], "base_commit": "5ecc39749a98c7ec3fc63b8cbaa82de5eb17c173", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -922,7 +922,7 @@ def slots_getstate(self):\n             \"\"\"\n             Automatically created by attrs.\n             \"\"\"\n-            return tuple(getattr(self, name) for name in state_attr_names)\n+            return {name: getattr(self, name) for name in state_attr_names}\n \n         hash_caching_enabled = self._cache_hash\n \n@@ -931,8 +931,9 @@ def slots_setstate(self, state):\n             Automatically created by attrs.\n             \"\"\"\n             __bound_setattr = _obj_setattr.__get__(self)\n-            for name, value in zip(state_attr_names, state):\n-                __bound_setattr(name, value)\n+            for name in state_attr_names:\n+                if name in state:\n+                    __bound_setattr(name, state[name])\n \n             # The hash code cache is not included when the object is\n             # serialized, but it still needs to be initialized to None to\n", "test_patch": "diff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -9,6 +9,8 @@\n import types\n import weakref\n \n+from unittest import mock\n+\n import pytest\n \n import attr\n@@ -743,3 +745,58 @@ def f(self):\n \n     assert B(11).f == 121\n     assert B(17).f == 289\n+\n+\n+@attr.s(slots=True)\n+class A:\n+    x = attr.ib()\n+    b = attr.ib()\n+    c = attr.ib()\n+\n+\n+@pytest.mark.parametrize(\"cls\", [A])\n+def test_slots_unpickle_after_attr_removed(cls):\n+    \"\"\"\n+    We don't assign attributes we don't have anymore if the class has\n+    removed it.\n+    \"\"\"\n+    a = cls(1, 2, 3)\n+    a_pickled = pickle.dumps(a)\n+    a_unpickled = pickle.loads(a_pickled)\n+    assert a_unpickled == a\n+\n+    @attr.s(slots=True)\n+    class NEW_A:\n+        x = attr.ib()\n+        c = attr.ib()\n+\n+    with mock.patch(f\"{__name__}.A\", NEW_A):\n+        new_a = pickle.loads(a_pickled)\n+        assert new_a.x == 1\n+        assert new_a.c == 3\n+        assert not hasattr(new_a, \"b\")\n+\n+\n+@pytest.mark.parametrize(\"cls\", [A])\n+def test_slots_unpickle_after_attr_added(cls):\n+    \"\"\"\n+    We don't assign attribute we haven't had before if the class has one added.\n+    \"\"\"\n+    a = cls(1, 2, 3)\n+    a_pickled = pickle.dumps(a)\n+    a_unpickled = pickle.loads(a_pickled)\n+    assert a_unpickled == a\n+\n+    @attr.s(slots=True)\n+    class NEW_A:\n+        x = attr.ib()\n+        b = attr.ib()\n+        d = attr.ib()\n+        c = attr.ib()\n+\n+    with mock.patch(f\"{__name__}.A\", NEW_A):\n+        new_a = pickle.loads(a_pickled)\n+        assert new_a.x == 1\n+        assert new_a.b == 2\n+        assert new_a.c == 3\n+        assert not hasattr(new_a, \"d\")\n", "problem_statement": "Current default implementation of __getstate__ and __setstate__ could be made safer\nThis is a known \"sharp edge\" of pickle, but attrs could make this a bit safer by slightly modifying the default implementation of `__getstate__` and `__setstate__`. The problem is that due to returning a tuple in the default implementation of `__getstate__`, removing a member, and then unpickling from a previous version can be __very__ unsafe. This is not a hypothetical situation - it commonly happens when an object is pickled, and then stored in a data-store of some sort, and unpickled some time later by a changed version of the code. \r\n\r\nHere's a simple reproducer that demonstrates it (python 3.10, attrs 22.1.0):\r\n\r\n```python\r\nimport pickle\r\n\r\nimport attr\r\n\r\n@attr.s(slots=True, hash=False, auto_attribs=True)\r\nclass Test:\r\n    count: int\r\n    enable_minor_feature: bool\r\n    should_launch_missiles: bool\r\n\r\nt = Test(count=1, should_launch_missiles=False, enable_minor_feature=True)\r\nprint(t)  # Test(count=1, enable_minor_feature=True, should_launch_missiles=False)\r\ntp = pickle.dumps(t)\r\n\r\n@attr.s(slots=True, hash=False, auto_attribs=True)\r\nclass Test:\r\n    count: int\r\n    should_launch_missiles: bool\r\n\r\ntl = pickle.loads(tp)\r\nprint(tl)  # Test(count=1, should_launch_missiles=True)  <== an attribute is assigned a dangerously wrong value\r\n```\r\n\r\nWhile there's certainly an argument to be made that pickle should not be used for such things (and I'd agree) - the default implementation could, I believe, be made safer. Raise if things don't match, or even ignore unknown attributes in __setstate__,  by potentially returning a dictionary instead of a tuple [here](https://github.com/python-attrs/attrs/blob/c58ffd4e4cba5d5e58356722b985fc362358c48e/src/attr/_make.py#L925) would help.\n", "hints_text": "Have you tried replacing the tuple by the dict and see how much it breaks? Performance difference should be benign, since we save ourselves zipping.\nI wanted to get some thoughts on the feasibility of making the change at all first. Let me put together a patch and see how much it breaks, and we can take it from there. Thanks :)\nI don't think our implementation of pickling is a public API. So if you can make it compatible, that should  be OK.", "created_at": "2022-08-16T16:34:33Z"}
{"repo": "python-attrs/attrs", "pull_number": 988, "instance_id": "python-attrs__attrs-988", "issue_numbers": ["965"], "base_commit": "107367d437484006a7d01854e91e478401690087", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -1,9 +1,8 @@\n # SPDX-License-Identifier: MIT\n \n-\n from hypothesis import HealthCheck, settings\n \n-from attr._compat import PY36, PY310\n+from attr._compat import PY310\n \n \n def pytest_configure(config):\n@@ -15,14 +14,5 @@ def pytest_configure(config):\n \n \n collect_ignore = []\n-if not PY36:\n-    collect_ignore.extend(\n-        [\n-            \"tests/test_annotations.py\",\n-            \"tests/test_hooks.py\",\n-            \"tests/test_init_subclass.py\",\n-            \"tests/test_next_gen.py\",\n-        ]\n-    )\n if not PY310:\n     collect_ignore.extend([\"tests/test_pattern_matching.py\"])\ndiff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -4,7 +4,6 @@\n import os\n import platform\n import re\n-import sys\n \n from setuptools import find_packages, setup\n \n@@ -33,7 +32,6 @@\n     \"Operating System :: OS Independent\",\n     \"Programming Language :: Python\",\n     \"Programming Language :: Python :: 3\",\n-    \"Programming Language :: Python :: 3.5\",\n     \"Programming Language :: Python :: 3.6\",\n     \"Programming Language :: Python :: 3.7\",\n     \"Programming Language :: Python :: 3.8\",\n@@ -57,10 +55,7 @@\n         \"pytest>=4.3.0\",  # 4.3.0 dropped last use of `convert`\n     ],\n }\n-if (\n-    sys.version_info[:2] >= (3, 6)\n-    and platform.python_implementation() != \"PyPy\"\n-):\n+if platform.python_implementation() != \"PyPy\":\n     EXTRAS_REQUIRE[\"tests_no_zope\"].extend(\n         [\"mypy>=0.900,!=0.940\", \"pytest-mypy-plugins\"]\n     )\n@@ -92,11 +87,11 @@ def find_meta(meta):\n     Extract __*meta*__ from META_FILE.\n     \"\"\"\n     meta_match = re.search(\n-        r\"^__{meta}__ = ['\\\"]([^'\\\"]*)['\\\"]\".format(meta=meta), META_FILE, re.M\n+        rf\"^__{meta}__ = ['\\\"]([^'\\\"]*)['\\\"]\", META_FILE, re.M\n     )\n     if meta_match:\n         return meta_match.group(1)\n-    raise RuntimeError(\"Unable to find __{meta}__ string.\".format(meta=meta))\n+    raise RuntimeError(f\"Unable to find __{meta}__ string.\")\n \n \n LOGO = \"\"\"\n@@ -119,7 +114,7 @@ def find_meta(meta):\n         re.S,\n     ).group(1)\n     + \"\\n\\n`Full changelog \"\n-    + \"<{url}en/stable/changelog.html>`_.\\n\\n\".format(url=URL)\n+    + f\"<{URL}en/stable/changelog.html>`_.\\n\\n\"\n     + read(\"AUTHORS.rst\")\n )\n \n@@ -141,7 +136,7 @@ def find_meta(meta):\n         long_description_content_type=\"text/x-rst\",\n         packages=PACKAGES,\n         package_dir={\"\": \"src\"},\n-        python_requires=\">=3.5\",\n+        python_requires=\">=3.6\",\n         zip_safe=False,\n         classifiers=CLASSIFIERS,\n         install_requires=INSTALL_REQUIRES,\ndiff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -1,8 +1,5 @@\n # SPDX-License-Identifier: MIT\n \n-\n-import sys\n-\n from functools import partial\n \n from . import converters, exceptions, filters, setters, validators\n@@ -20,6 +17,7 @@\n     make_class,\n     validate,\n )\n+from ._next_gen import define, field, frozen, mutable\n from ._version_info import VersionInfo\n \n \n@@ -56,15 +54,19 @@\n     \"attrs\",\n     \"cmp_using\",\n     \"converters\",\n+    \"define\",\n     \"evolve\",\n     \"exceptions\",\n+    \"field\",\n     \"fields\",\n     \"fields_dict\",\n     \"filters\",\n+    \"frozen\",\n     \"get_run_validators\",\n     \"has\",\n     \"ib\",\n     \"make_class\",\n+    \"mutable\",\n     \"resolve_types\",\n     \"s\",\n     \"set_run_validators\",\n@@ -72,8 +74,3 @@\n     \"validate\",\n     \"validators\",\n ]\n-\n-if sys.version_info[:2] >= (3, 6):\n-    from ._next_gen import define, field, frozen, mutable  # noqa: F401\n-\n-    __all__.extend((\"define\", \"field\", \"frozen\", \"mutable\"))\ndiff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -12,19 +12,9 @@\n \n \n PYPY = platform.python_implementation() == \"PyPy\"\n-PY36 = sys.version_info[:2] >= (3, 6)\n-HAS_F_STRINGS = PY36\n PY310 = sys.version_info[:2] >= (3, 10)\n \n \n-if PYPY or PY36:\n-    ordered_dict = dict\n-else:\n-    from collections import OrderedDict\n-\n-    ordered_dict = OrderedDict\n-\n-\n def just_warn(*args, **kw):\n     warnings.warn(\n         \"Running interpreter doesn't sufficiently support code object \"\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -11,14 +11,7 @@\n # We need to import _compat itself in addition to the _compat members to avoid\n # having the thread-local in the globals here.\n from . import _compat, _config, setters\n-from ._compat import (\n-    HAS_F_STRINGS,\n-    PY310,\n-    PYPY,\n-    _AnnotationExtractor,\n-    ordered_dict,\n-    set_closure_cell,\n-)\n+from ._compat import PY310, PYPY, _AnnotationExtractor, set_closure_cell\n from .exceptions import (\n     DefaultAlreadySetError,\n     FrozenInstanceError,\n@@ -201,9 +194,9 @@ def attrib(\n         value is converted before being passed to the validator, if any.\n     :param metadata: An arbitrary mapping, to be used by third-party\n         components.  See `extending_metadata`.\n-    :param type: The type of the attribute.  In Python 3.6 or greater, the\n-        preferred method to specify the type is using a variable annotation\n-        (see :pep:`526`).\n+\n+    :param type: The type of the attribute. Nowadays, the preferred method to\n+        specify the type is using a variable annotation (see :pep:`526`).\n         This argument is provided for backward compatibility.\n         Regardless of the approach used, the type will be stored on\n         ``Attribute.type``.\n@@ -323,7 +316,7 @@ def _make_method(name, script, filename, globs):\n         if old_val == linecache_tuple:\n             break\n         else:\n-            filename = \"{}-{}>\".format(base_filename[:-1], count)\n+            filename = f\"{base_filename[:-1]}-{count}>\"\n             count += 1\n \n     _compile_and_eval(script, globs, locs, filename)\n@@ -341,9 +334,9 @@ class MyClassAttributes(tuple):\n         __slots__ = ()\n         x = property(itemgetter(0))\n     \"\"\"\n-    attr_class_name = \"{}Attributes\".format(cls_name)\n+    attr_class_name = f\"{cls_name}Attributes\"\n     attr_class_template = [\n-        \"class {}(tuple):\".format(attr_class_name),\n+        f\"class {attr_class_name}(tuple):\",\n         \"    __slots__ = ()\",\n     ]\n     if attr_names:\n@@ -418,13 +411,6 @@ def _get_annotations(cls):\n     return {}\n \n \n-def _counter_getter(e):\n-    \"\"\"\n-    Key function for sorting to avoid re-creating a lambda for every class.\n-    \"\"\"\n-    return e[1].counter\n-\n-\n def _collect_base_attrs(cls, taken_attr_names):\n     \"\"\"\n     Collect attr.ibs from base classes of *cls*, except *taken_attr_names*.\n@@ -502,9 +488,6 @@ def _transform_attrs(\n \n     if these is not None:\n         ca_list = [(name, ca) for name, ca in these.items()]\n-\n-        if not isinstance(these, ordered_dict):\n-            ca_list.sort(key=_counter_getter)\n     elif auto_attribs is True:\n         ca_names = {\n             name\n@@ -735,7 +718,7 @@ def __init__(\n             ) = self._make_getstate_setstate()\n \n     def __repr__(self):\n-        return \"<_ClassBuilder(cls={cls})>\".format(cls=self._cls.__name__)\n+        return f\"<_ClassBuilder(cls={self._cls.__name__})>\"\n \n     def build_class(self):\n         \"\"\"\n@@ -1218,10 +1201,7 @@ def attrs(\n         If *these* is not ``None``, ``attrs`` will *not* search the class body\n         for attributes and will *not* remove any attributes from it.\n \n-        If *these* is an ordered dict (`dict` on Python 3.6+,\n-        `collections.OrderedDict` otherwise), the order is deduced from\n-        the order of the attributes inside *these*.  Otherwise the order\n-        of the definition of the attributes is used.\n+        The order is deduced from the order of the attributes inside *these*.\n \n     :type these: `dict` of `str` to `attr.ib`\n \n@@ -1329,7 +1309,7 @@ def attrs(\n     :param bool weakref_slot: Make instances weak-referenceable.  This has no\n         effect unless ``slots`` is also enabled.\n     :param bool auto_attribs: If ``True``, collect :pep:`526`-annotated\n-        attributes (Python 3.6 and later only) from the class body.\n+        attributes from the class body.\n \n         In this case, you **must** annotate every field.  If ``attrs``\n         encounters a field that is set to an `attr.ib` but lacks a type\n@@ -1833,126 +1813,61 @@ def _add_eq(cls, attrs=None):\n     return cls\n \n \n-if HAS_F_STRINGS:\n-\n-    def _make_repr(attrs, ns, cls):\n-        unique_filename = _generate_unique_filename(cls, \"repr\")\n-        # Figure out which attributes to include, and which function to use to\n-        # format them. The a.repr value can be either bool or a custom\n-        # callable.\n-        attr_names_with_reprs = tuple(\n-            (a.name, (repr if a.repr is True else a.repr), a.init)\n-            for a in attrs\n-            if a.repr is not False\n+def _make_repr(attrs, ns, cls):\n+    unique_filename = _generate_unique_filename(cls, \"repr\")\n+    # Figure out which attributes to include, and which function to use to\n+    # format them. The a.repr value can be either bool or a custom\n+    # callable.\n+    attr_names_with_reprs = tuple(\n+        (a.name, (repr if a.repr is True else a.repr), a.init)\n+        for a in attrs\n+        if a.repr is not False\n+    )\n+    globs = {\n+        name + \"_repr\": r for name, r, _ in attr_names_with_reprs if r != repr\n+    }\n+    globs[\"_compat\"] = _compat\n+    globs[\"AttributeError\"] = AttributeError\n+    globs[\"NOTHING\"] = NOTHING\n+    attribute_fragments = []\n+    for name, r, i in attr_names_with_reprs:\n+        accessor = (\n+            \"self.\" + name if i else 'getattr(self, \"' + name + '\", NOTHING)'\n         )\n-        globs = {\n-            name + \"_repr\": r\n-            for name, r, _ in attr_names_with_reprs\n-            if r != repr\n-        }\n-        globs[\"_compat\"] = _compat\n-        globs[\"AttributeError\"] = AttributeError\n-        globs[\"NOTHING\"] = NOTHING\n-        attribute_fragments = []\n-        for name, r, i in attr_names_with_reprs:\n-            accessor = (\n-                \"self.\" + name\n-                if i\n-                else 'getattr(self, \"' + name + '\", NOTHING)'\n-            )\n-            fragment = (\n-                \"%s={%s!r}\" % (name, accessor)\n-                if r == repr\n-                else \"%s={%s_repr(%s)}\" % (name, name, accessor)\n-            )\n-            attribute_fragments.append(fragment)\n-        repr_fragment = \", \".join(attribute_fragments)\n-\n-        if ns is None:\n-            cls_name_fragment = (\n-                '{self.__class__.__qualname__.rsplit(\">.\", 1)[-1]}'\n-            )\n-        else:\n-            cls_name_fragment = ns + \".{self.__class__.__name__}\"\n-\n-        lines = [\n-            \"def __repr__(self):\",\n-            \"  try:\",\n-            \"    already_repring = _compat.repr_context.already_repring\",\n-            \"  except AttributeError:\",\n-            \"    already_repring = {id(self),}\",\n-            \"    _compat.repr_context.already_repring = already_repring\",\n-            \"  else:\",\n-            \"    if id(self) in already_repring:\",\n-            \"      return '...'\",\n-            \"    else:\",\n-            \"      already_repring.add(id(self))\",\n-            \"  try:\",\n-            \"    return f'%s(%s)'\" % (cls_name_fragment, repr_fragment),\n-            \"  finally:\",\n-            \"    already_repring.remove(id(self))\",\n-        ]\n-\n-        return _make_method(\n-            \"__repr__\", \"\\n\".join(lines), unique_filename, globs=globs\n+        fragment = (\n+            \"%s={%s!r}\" % (name, accessor)\n+            if r == repr\n+            else \"%s={%s_repr(%s)}\" % (name, name, accessor)\n         )\n+        attribute_fragments.append(fragment)\n+    repr_fragment = \", \".join(attribute_fragments)\n \n-else:\n-\n-    def _make_repr(attrs, ns, _):\n-        \"\"\"\n-        Make a repr method that includes relevant *attrs*, adding *ns* to the\n-        full name.\n-        \"\"\"\n-\n-        # Figure out which attributes to include, and which function to use to\n-        # format them. The a.repr value can be either bool or a custom\n-        # callable.\n-        attr_names_with_reprs = tuple(\n-            (a.name, repr if a.repr is True else a.repr)\n-            for a in attrs\n-            if a.repr is not False\n-        )\n-\n-        def __repr__(self):\n-            \"\"\"\n-            Automatically created by attrs.\n-            \"\"\"\n-            try:\n-                already_repring = _compat.repr_context.already_repring\n-            except AttributeError:\n-                already_repring = set()\n-                _compat.repr_context.already_repring = already_repring\n-\n-            if id(self) in already_repring:\n-                return \"...\"\n-            real_cls = self.__class__\n-            if ns is None:\n-                class_name = real_cls.__qualname__.rsplit(\">.\", 1)[-1]\n-            else:\n-                class_name = ns + \".\" + real_cls.__name__\n+    if ns is None:\n+        cls_name_fragment = '{self.__class__.__qualname__.rsplit(\">.\", 1)[-1]}'\n+    else:\n+        cls_name_fragment = ns + \".{self.__class__.__name__}\"\n \n-            # Since 'self' remains on the stack (i.e.: strongly referenced)\n-            # for the duration of this call, it's safe to depend on id(...)\n-            # stability, and not need to track the instance and therefore\n-            # worry about properties like weakref- or hash-ability.\n-            already_repring.add(id(self))\n-            try:\n-                result = [class_name, \"(\"]\n-                first = True\n-                for name, attr_repr in attr_names_with_reprs:\n-                    if first:\n-                        first = False\n-                    else:\n-                        result.append(\", \")\n-                    result.extend(\n-                        (name, \"=\", attr_repr(getattr(self, name, NOTHING)))\n-                    )\n-                return \"\".join(result) + \")\"\n-            finally:\n-                already_repring.remove(id(self))\n+    lines = [\n+        \"def __repr__(self):\",\n+        \"  try:\",\n+        \"    already_repring = _compat.repr_context.already_repring\",\n+        \"  except AttributeError:\",\n+        \"    already_repring = {id(self),}\",\n+        \"    _compat.repr_context.already_repring = already_repring\",\n+        \"  else:\",\n+        \"    if id(self) in already_repring:\",\n+        \"      return '...'\",\n+        \"    else:\",\n+        \"      already_repring.add(id(self))\",\n+        \"  try:\",\n+        \"    return f'%s(%s)'\" % (cls_name_fragment, repr_fragment),\n+        \"  finally:\",\n+        \"    already_repring.remove(id(self))\",\n+    ]\n \n-        return __repr__\n+    return _make_method(\n+        \"__repr__\", \"\\n\".join(lines), unique_filename, globs=globs\n+    )\n \n \n def _add_repr(cls, ns=None, attrs=None):\n@@ -1988,9 +1903,7 @@ def fields(cls):\n         raise TypeError(\"Passed object must be a class.\")\n     attrs = getattr(cls, \"__attrs_attrs__\", None)\n     if attrs is None:\n-        raise NotAnAttrsClassError(\n-            \"{cls!r} is not an attrs-decorated class.\".format(cls=cls)\n-        )\n+        raise NotAnAttrsClassError(f\"{cls!r} is not an attrs-decorated class.\")\n     return attrs\n \n \n@@ -2005,10 +1918,7 @@ def fields_dict(cls):\n     :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n         class.\n \n-    :rtype: an ordered dict where keys are attribute names and values are\n-        `attrs.Attribute`\\\\ s. This will be a `dict` if it's\n-        naturally ordered like on Python 3.6+ or an\n-        :class:`~collections.OrderedDict` otherwise.\n+    :rtype: dict\n \n     .. versionadded:: 18.1.0\n     \"\"\"\n@@ -2016,10 +1926,8 @@ def fields_dict(cls):\n         raise TypeError(\"Passed object must be a class.\")\n     attrs = getattr(cls, \"__attrs_attrs__\", None)\n     if attrs is None:\n-        raise NotAnAttrsClassError(\n-            \"{cls!r} is not an attrs-decorated class.\".format(cls=cls)\n-        )\n-    return ordered_dict((a.name, a) for a in attrs)\n+        raise NotAnAttrsClassError(f\"{cls!r} is not an attrs-decorated class.\")\n+    return {a.name: a for a in attrs}\n \n \n def validate(inst):\n@@ -2579,7 +2487,7 @@ def from_counting_attr(cls, name, ca, type=None):\n             type=type,\n             cmp=None,\n             inherited=False,\n-            **inst_dict\n+            **inst_dict,\n         )\n \n     # Don't use attr.evolve since fields(Attribute) doesn't work\n@@ -2865,10 +2773,9 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n     :param attrs: A list of names or a dictionary of mappings of names to\n         attributes.\n \n-        If *attrs* is a list or an ordered dict (`dict` on Python 3.6+,\n-        `collections.OrderedDict` otherwise), the order is deduced from\n-        the order of the names or attributes inside *attrs*.  Otherwise the\n-        order of the definition of the attributes is used.\n+        The order is deduced from the order of the names or attributes inside\n+        *attrs*.  Otherwise the order of the definition of the attributes is\n+        used.\n     :type attrs: `list` or `dict`\n \n     :param tuple bases: Classes that the new class will subclass.\ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -1,8 +1,8 @@\n # SPDX-License-Identifier: MIT\n \n \"\"\"\n-These are Python 3.6+-only and keyword-only APIs that call `attr.s` and\n-`attr.ib` with different default values.\n+These are keyword-only APIs that call `attr.s` and `attr.ib` with different\n+default values.\n \"\"\"\n \n \ndiff --git a/src/attr/converters.py b/src/attr/converters.py\n--- a/src/attr/converters.py\n+++ b/src/attr/converters.py\n@@ -141,4 +141,4 @@ def to_bool(val):\n     except TypeError:\n         # Raised when \"val\" is not hashable (e.g., lists)\n         pass\n-    raise ValueError(\"Cannot convert value to bool: {}\".format(val))\n+    raise ValueError(f\"Cannot convert value to bool: {val}\")\ndiff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -391,7 +391,7 @@ def __repr__(self):\n         iterable_identifier = (\n             \"\"\n             if self.iterable_validator is None\n-            else \" {iterable!r}\".format(iterable=self.iterable_validator)\n+            else f\" {self.iterable_validator!r}\"\n         )\n         return (\n             \"<deep_iterable validator for{iterable_identifier}\"\n@@ -548,7 +548,7 @@ def __call__(self, inst, attr, value):\n             )\n \n     def __repr__(self):\n-        return \"<max_len validator for {max}>\".format(max=self.max_length)\n+        return f\"<max_len validator for {self.max_length}>\"\n \n \n def max_len(length):\n@@ -579,7 +579,7 @@ def __call__(self, inst, attr, value):\n             )\n \n     def __repr__(self):\n-        return \"<min_len validator for {min}>\".format(min=self.min_length)\n+        return f\"<min_len validator for {self.min_length}>\"\n \n \n def min_len(length):\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -2,8 +2,6 @@\n \n \"\"\"\n Tests for PEP-526 type annotations.\n-\n-Python 3.6+ only.\n \"\"\"\n \n import sys\n@@ -397,7 +395,7 @@ def test_annotations_strings(self, slots):\n         \"\"\"\n         String annotations are passed into __init__ as is.\n \n-        It fails on 3.6 due to a bug in Python.\n+        The strings keep changing between releases.\n         \"\"\"\n         import typing as t\n \ndiff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -15,7 +15,7 @@\n import attr\n \n from attr import asdict, assoc, astuple, evolve, fields, has\n-from attr._compat import Mapping, Sequence, ordered_dict\n+from attr._compat import Mapping, Sequence\n from attr.exceptions import AttrsAttributeNotFoundError\n from attr.validators import instance_of\n \n@@ -196,7 +196,7 @@ def test_asdict_preserve_order(self, cls):\n         Field order should be preserved when dumping to an ordered_dict.\n         \"\"\"\n         instance = cls()\n-        dict_instance = asdict(instance, dict_factory=ordered_dict)\n+        dict_instance = asdict(instance, dict_factory=dict)\n \n         assert [a.name for a in fields(cls)] == list(dict_instance.keys())\n \n@@ -483,9 +483,7 @@ def test_unknown(self, C):\n         ) as e, pytest.deprecated_call():\n             assoc(C(), aaaa=2)\n \n-        assert (\n-            \"aaaa is not an attrs attribute on {cls!r}.\".format(cls=C),\n-        ) == e.value.args\n+        assert (f\"aaaa is not an attrs attribute on {C!r}.\",) == e.value.args\n \n     def test_frozen(self):\n         \"\"\"\ndiff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -17,7 +17,6 @@\n \n import attr\n \n-from attr._compat import PY36\n from attr._make import NOTHING, Attribute\n from attr.exceptions import FrozenInstanceError\n \n@@ -224,9 +223,9 @@ def test_subclassing_with_extra_attrs(self, cls):\n         assert i.x is i.meth() is obj\n         assert i.y == 2\n         if cls is Sub:\n-            assert \"Sub(x={obj}, y=2)\".format(obj=obj) == repr(i)\n+            assert f\"Sub(x={obj}, y=2)\" == repr(i)\n         else:\n-            assert \"SubSlots(x={obj}, y=2)\".format(obj=obj) == repr(i)\n+            assert f\"SubSlots(x={obj}, y=2)\" == repr(i)\n \n     @pytest.mark.parametrize(\"base\", [Base, BaseSlots])\n     def test_subclass_without_extra_attrs(self, base):\n@@ -241,7 +240,7 @@ class Sub2(base):\n         obj = object()\n         i = Sub2(x=obj)\n         assert i.x is i.meth() is obj\n-        assert \"Sub2(x={obj})\".format(obj=obj) == repr(i)\n+        assert f\"Sub2(x={obj})\" == repr(i)\n \n     @pytest.mark.parametrize(\n         \"frozen_class\",\n@@ -701,7 +700,6 @@ class D(C):\n         assert \"self.y = y\" in src\n         assert object.__setattr__ == D.__setattr__\n \n-    @pytest.mark.skipif(not PY36, reason=\"NG APIs are 3.6+\")\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_no_setattr_with_ng_defaults(self, slots):\n         \"\"\"\ndiff --git a/tests/test_init_subclass.py b/tests/test_init_subclass.py\n--- a/tests/test_init_subclass.py\n+++ b/tests/test_init_subclass.py\n@@ -2,8 +2,6 @@\n \n \"\"\"\n Tests for `__init_subclass__` related tests.\n-\n-Python 3.6+ only.\n \"\"\"\n \n import pytest\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -22,7 +22,7 @@\n import attr\n \n from attr import _config\n-from attr._compat import PY310, ordered_dict\n+from attr._compat import PY310\n from attr._make import (\n     Attribute,\n     Factory,\n@@ -297,7 +297,7 @@ def test_these_ordered(self):\n         b = attr.ib(default=2)\n         a = attr.ib(default=1)\n \n-        @attr.s(these=ordered_dict([(\"a\", a), (\"b\", b)]))\n+        @attr.s(these=dict([(\"a\", a), (\"b\", b)]))\n         class C:\n             pass\n \n@@ -1071,7 +1071,7 @@ def test_make_class_ordered(self):\n         b = attr.ib(default=2)\n         a = attr.ib(default=1)\n \n-        C = attr.make_class(\"C\", ordered_dict([(\"a\", a), (\"b\", b)]))\n+        C = attr.make_class(\"C\", dict([(\"a\", a), (\"b\", b)]))\n \n         assert \"C(a=1, b=2)\" == repr(C())\n \n@@ -1114,7 +1114,7 @@ def test_handler_non_attrs_class(self):\n             fields(object)\n \n         assert (\n-            \"{o!r} is not an attrs-decorated class.\".format(o=object)\n+            f\"{object!r} is not an attrs-decorated class.\"\n         ) == e.value.args[0]\n \n     @given(simple_classes())\n@@ -1156,7 +1156,7 @@ def test_handler_non_attrs_class(self):\n             fields_dict(object)\n \n         assert (\n-            \"{o!r} is not an attrs-decorated class.\".format(o=object)\n+            f\"{object!r} is not an attrs-decorated class.\"\n         ) == e.value.args[0]\n \n     @given(simple_classes())\n@@ -1166,7 +1166,7 @@ def test_fields_dict(self, C):\n         \"\"\"\n         d = fields_dict(C)\n \n-        assert isinstance(d, ordered_dict)\n+        assert isinstance(d, dict)\n         assert list(fields(C)) == list(d.values())\n         assert [a.name for a in fields(C)] == [field_name for field_name in d]\n \n@@ -1214,7 +1214,7 @@ def test_converter_factory_property(self, val, init):\n         \"\"\"\n         C = make_class(\n             \"C\",\n-            ordered_dict(\n+            dict(\n                 [\n                     (\"y\", attr.ib()),\n                     (\ndiff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -1,7 +1,7 @@\n # SPDX-License-Identifier: MIT\n \n \"\"\"\n-Python 3-only integration tests for provisional next-generation APIs.\n+Integration tests for next-generation APIs.\n \"\"\"\n \n import re\ndiff --git a/tests/test_pyright.py b/tests/test_pyright.py\n--- a/tests/test_pyright.py\n+++ b/tests/test_pyright.py\n@@ -4,17 +4,13 @@\n import os.path\n import shutil\n import subprocess\n-import sys\n \n import pytest\n \n import attr\n \n \n-if sys.version_info < (3, 6):\n-    _found_pyright = False\n-else:\n-    _found_pyright = shutil.which(\"pyright\")\n+_found_pyright = shutil.which(\"pyright\")\n \n \n @attr.s(frozen=True)\n", "problem_statement": "Cannot import attrs for Python 3.5\nFirst of all, attrs is great, thanks to all who work on it.\r\n\r\nOn Python 3.5, the next-gen API (`define`, `field`, etc.) is not defined in `attr/__init__.py`, which causes an ImportError on startup.  Here's a reproducer:\r\n\r\n```\r\n# python3\r\nPython 3.5.3 (default, Dec  3 2018, 20:11:08) \r\n[GCC 7.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import attrs\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.5/site-packages/attrs/__init__.py\", line 3, in <module>\r\n    from attr import (\r\nImportError: cannot import name 'define'\r\n```\r\n\r\nLooks like it's happening because of these lines in `attr/__init__`: https://github.com/python-attrs/attrs/blob/main/src/attr/__init__.py#L76-L79\r\n\r\nalong with  https://github.com/python-attrs/attrs/blob/main/src/attrs/__init__.py#L19 (which tries to import those names unconditionally).\n", "hints_text": "That is expected, because the `attrs` import path is 3.6-only:\r\n\r\n<img width=\"810\" alt=\"Screenshot 2022-06-07 at 13 44 52@2x\" src=\"https://user-images.githubusercontent.com/41240/172371553-504e2f8c-592b-4c5e-ae34-7d6849a62291.png\">\r\n\nAh!  Got it.  Thanks.  \r\n\r\nWould you be interested in a PR for attrs that adds a more helpful error message, something like this in `attrs/__init__.py`?\r\n\r\n```python3\r\n# at the top of attrs/__init__.py\r\nimport sys\r\n\r\nif sys.version_info[:2] <= 3, 5:\r\n    raise ImportError('The attrs namespace is only available for Python > 3.5. Please use the attr namespace instead.')\r\n```\nIf you'd like to contribute that, fire away. I'm just not sure how much longer we're gonna support Python 3.5 though. :)", "created_at": "2022-07-29T04:12:11Z"}
{"repo": "python-attrs/attrs", "pull_number": 969, "instance_id": "python-attrs__attrs-969", "issue_numbers": ["910"], "base_commit": "a7e82b5c4121633cff792ed1cbc371843d590960", "patch": "diff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -39,6 +39,7 @@\n     \"Programming Language :: Python :: 3.8\",\n     \"Programming Language :: Python :: 3.9\",\n     \"Programming Language :: Python :: 3.10\",\n+    \"Programming Language :: Python :: 3.11\",\n     \"Programming Language :: Python :: Implementation :: CPython\",\n     \"Programming Language :: Python :: Implementation :: PyPy\",\n     \"Topic :: Software Development :: Libraries :: Python Modules\",\ndiff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -111,12 +111,10 @@ def force_x_to_be_a_cell():  # pragma: no cover\n         # Convert this code object to a code object that sets the\n         # function's first _freevar_ (not cellvar) to the argument.\n         if sys.version_info >= (3, 8):\n-            # CPython 3.8+ has an incompatible CodeType signature\n-            # (added a posonlyargcount argument) but also added\n-            # CodeType.replace() to do this without counting parameters.\n-            set_first_freevar_code = co.replace(\n-                co_cellvars=co.co_freevars, co_freevars=co.co_cellvars\n-            )\n+\n+            def set_closure_cell(cell, value):\n+                cell.cell_contents = value\n+\n         else:\n             args = [co.co_argcount]\n             args.append(co.co_kwonlyargcount)\n@@ -140,15 +138,15 @@ def force_x_to_be_a_cell():  # pragma: no cover\n             )\n             set_first_freevar_code = types.CodeType(*args)\n \n-        def set_closure_cell(cell, value):\n-            # Create a function using the set_first_freevar_code,\n-            # whose first closure cell is `cell`. Calling it will\n-            # change the value of that cell.\n-            setter = types.FunctionType(\n-                set_first_freevar_code, {}, \"setter\", (), (cell,)\n-            )\n-            # And call it to set the cell.\n-            setter(value)\n+            def set_closure_cell(cell, value):\n+                # Create a function using the set_first_freevar_code,\n+                # whose first closure cell is `cell`. Calling it will\n+                # change the value of that cell.\n+                setter = types.FunctionType(\n+                    set_first_freevar_code, {}, \"setter\", (), (cell,)\n+                )\n+                # And call it to set the cell.\n+                setter(value)\n \n         # Make sure it works on this interpreter:\n         def make_func_with_cell():\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -94,6 +94,10 @@ class C:\n         assert 1 == len(attr.fields(C))\n         assert_init_annotations(C, x=typing.List[int])\n \n+    @pytest.mark.skipif(\n+        sys.version_info[:2] < (3, 11),\n+        reason=\"Incompatible behavior on older Pythons\",\n+    )\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_auto_attribs(self, slots):\n         \"\"\"\n@@ -149,7 +153,7 @@ class C:\n             x=typing.List[int],\n             y=int,\n             z=int,\n-            foo=typing.Optional[typing.Any],\n+            foo=typing.Any,\n         )\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n@@ -384,8 +388,9 @@ def noop():\n \n         assert attr.converters.optional(noop).__annotations__ == {}\n \n-    @pytest.mark.xfail(\n-        sys.version_info[:2] == (3, 6), reason=\"Does not work on 3.6.\"\n+    @pytest.mark.skipif(\n+        sys.version_info[:2] < (3, 11),\n+        reason=\"Incompatible behavior on older Pythons\",\n     )\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_annotations_strings(self, slots):\n@@ -417,7 +422,7 @@ class C:\n             x=typing.List[int],\n             y=int,\n             z=int,\n-            foo=typing.Optional[typing.Any],\n+            foo=typing.Any,\n         )\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -2275,7 +2275,9 @@ class C:\n             def __getstate__(self):\n                 return (\"hi\",)\n \n-        assert None is getattr(C(), \"__setstate__\", None)\n+        assert getattr(object, \"__setstate__\", None) is getattr(\n+            C, \"__setstate__\", None\n+        )\n \n         @attr.s(slots=slots, auto_detect=True)\n         class C:\n@@ -2291,7 +2293,9 @@ def __setstate__(self, state):\n         i.__setstate__(())\n \n         assert True is i.called\n-        assert None is getattr(C(), \"__getstate__\", None)\n+        assert getattr(object, \"__getstate__\", None) is getattr(\n+            C, \"__getstate__\", None\n+        )\n \n     @pytest.mark.skipif(PY310, reason=\"Pre-3.10 only.\")\n     def test_match_args_pre_310(self):\ndiff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -660,10 +660,12 @@ def test_no_getstate_setstate_for_dict_classes(self):\n         As long as getstate_setstate is None, nothing is done to dict\n         classes.\n         \"\"\"\n-        i = C1(1, 2)\n-\n-        assert None is getattr(i, \"__getstate__\", None)\n-        assert None is getattr(i, \"__setstate__\", None)\n+        assert getattr(object, \"__getstate__\", None) is getattr(\n+            C1, \"__getstate__\", None\n+        )\n+        assert getattr(object, \"__setstate__\", None) is getattr(\n+            C1, \"__setstate__\", None\n+        )\n \n     def test_no_getstate_setstate_if_option_false(self):\n         \"\"\"\n@@ -674,10 +676,12 @@ def test_no_getstate_setstate_if_option_false(self):\n         class C:\n             x = attr.ib()\n \n-        i = C(42)\n-\n-        assert None is getattr(i, \"__getstate__\", None)\n-        assert None is getattr(i, \"__setstate__\", None)\n+        assert getattr(object, \"__getstate__\", None) is getattr(\n+            C, \"__getstate__\", None\n+        )\n+        assert getattr(object, \"__setstate__\", None) is getattr(\n+            C, \"__setstate__\", None\n+        )\n \n     @pytest.mark.parametrize(\"cls\", [C2(1), C2Slots(1)])\n     def test_getstate_set_state_force_true(self, cls):\n", "problem_statement": "Fix set_closure_cell on 3.11\nThe fix for 3.11 compatibility (https://github.com/python-attrs/attrs/issues/907).\r\n\r\nMaybe hold off on merging until a discussion on BPO.\n", "hints_text": "I guess we'll have to finish this up before 3.11? :-/\nI don't think the other failing tests were related to this, but other 3.11 incompatibilities. Since the beta is out I can revisit this", "created_at": "2022-06-09T12:31:11Z"}
{"repo": "python-attrs/attrs", "pull_number": 896, "instance_id": "python-attrs__attrs-896", "issue_numbers": ["895"], "base_commit": "03dd7136cf1ccc58c9612531ba9711892830c1fb", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1888,7 +1888,7 @@ def _add_eq(cls, attrs=None):\n if HAS_F_STRINGS:\n \n     def _make_repr(attrs, ns, cls):\n-        unique_filename = \"repr\"\n+        unique_filename = _generate_unique_filename(cls, \"repr\")\n         # Figure out which attributes to include, and which function to use to\n         # format them. The a.repr value can be either bool or a custom\n         # callable.\n", "test_patch": "", "problem_statement": "attrs 21.3.0 breaks coverage report on Python 3.6 (regression from 21.2.0)\nWith attrs 21.3.0, if I run a script that does `import attr` using `coverage`, I get an error from `coverage report`.\r\n\r\n```console\r\n$ python3 --version\r\nPython 3.6.15\r\n$ echo 'import attr' > test.py\r\n$ pip3 install attrs coverage\r\n\u2026\r\nSuccessfully installed attrs-21.3.0 coverage-6.2\r\n$ coverage run test.py\r\n$ coverage report\r\nNo source for code: '/tmp/rep-1>'.\r\n```\r\n\r\nThis worked with attrs 21.2.0.\r\n\r\n```console\r\n$ pip3 install attrs==21.2.0\r\n\u2026\r\nSuccessfully installed attrs-21.2.0\r\n$ coverage run test.py\r\n$ coverage report\r\nName      Stmts   Miss  Cover\r\n-----------------------------\r\ntest.py       1      0   100%\r\n-----------------------------\r\nTOTAL         1      0   100%\r\n```\r\n\r\nI bisected the problem to commit 5a368d82997570bdad2ba371e897cc777809461f (#858). Cc @thetorpedodog @hynek.\n", "hints_text": "Interesting. Could be a coverage bug? Not sure why this would break it.\npython 3.7 has same issue\r\n\r\nworking in CI/CD\r\n\r\n```\r\nRunning with gitlab-runner 14.6.0~beta.71.gf035ecbf (f035ecbf)\r\n  on green-5.shared.runners-manager.gitlab.com/default xS6Vzpvo\r\nPreparing the \"docker+machine\" executor\r\nUsing Docker executor with image python:3.7-slim-buster ...\r\nPulling docker image python:3.7-slim-buster ...\r\n\r\n[...]\r\n\r\nCollecting attrs>=19.2.0\r\n  Downloading attrs-21.3.0-py2.py3-none-any.whl (61 kB)\r\n[...]\r\n\r\ncoverage report -i\r\n/usr/local/lib/python3.7/site-packages/coverage/report.py:87: CoverageWarning: Couldn't parse '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-10>': No source for code: '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-10>'. (couldnt-parse)\r\n  coverage._warn(msg, slug=\"couldnt-parse\")\r\n/usr/local/lib/python3.7/site-packages/coverage/report.py:87: CoverageWarning: Couldn't parse '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-11>': No source for code: '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-11>'. (couldnt-parse)\r\n  coverage._warn(msg, slug=\"couldnt-parse\")\r\n/usr/local/lib/python3.7/site-packages/coverage/report.py:87: CoverageWarning: Couldn't parse '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-12>': No source for code: '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-12>'. (couldnt-parse)\r\n  coverage._warn(msg, slug=\"couldnt-parse\")\r\n/usr/local/lib/python3.7/site-packages/coverage/report.py:87: CoverageWarning: Couldn't parse '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-13>': No source for code: '/builds/Jade/jade/jadeapp/jade-rest-auth/rep-13>'. (couldnt-parse)\r\n\r\n[...]\r\n\r\ncoverage xml\r\nNo source for code: '/builds/DeepNatural/deepnaturalai/deepapi/deepapi-rest-auth/rep-10>'.\r\nmake: *** [Makefile:37: coverage] Error 1\r\n```\r\n\r\nbut when i fixed attrs==21.2.0, its work\n@nedbat any idea? \ud83e\udd14", "created_at": "2021-12-29T06:57:31Z"}
{"repo": "python-attrs/attrs", "pull_number": 888, "instance_id": "python-attrs__attrs-888", "issue_numbers": ["646"], "base_commit": "17067930128e78a9c3c7c5280b5417b7bce82657", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -46,6 +46,8 @@ def asdict(\n     ..  versionadded:: 16.0.0 *dict_factory*\n     ..  versionadded:: 16.1.0 *retain_collection_types*\n     ..  versionadded:: 20.3.0 *value_serializer*\n+    ..  versionadded:: 21.3.0 If a dict has a collection for a key, it is\n+        serialized as a tuple.\n     \"\"\"\n     attrs = fields(inst.__class__)\n     rv = dict_factory()\n@@ -61,11 +63,11 @@ def asdict(\n             if has(v.__class__):\n                 rv[a.name] = asdict(\n                     v,\n-                    True,\n-                    filter,\n-                    dict_factory,\n-                    retain_collection_types,\n-                    value_serializer,\n+                    recurse=True,\n+                    filter=filter,\n+                    dict_factory=dict_factory,\n+                    retain_collection_types=retain_collection_types,\n+                    value_serializer=value_serializer,\n                 )\n             elif isinstance(v, (tuple, list, set, frozenset)):\n                 cf = v.__class__ if retain_collection_types is True else list\n@@ -73,10 +75,11 @@ def asdict(\n                     [\n                         _asdict_anything(\n                             i,\n-                            filter,\n-                            dict_factory,\n-                            retain_collection_types,\n-                            value_serializer,\n+                            is_key=False,\n+                            filter=filter,\n+                            dict_factory=dict_factory,\n+                            retain_collection_types=retain_collection_types,\n+                            value_serializer=value_serializer,\n                         )\n                         for i in v\n                     ]\n@@ -87,17 +90,19 @@ def asdict(\n                     (\n                         _asdict_anything(\n                             kk,\n-                            filter,\n-                            df,\n-                            retain_collection_types,\n-                            value_serializer,\n+                            is_key=True,\n+                            filter=filter,\n+                            dict_factory=df,\n+                            retain_collection_types=retain_collection_types,\n+                            value_serializer=value_serializer,\n                         ),\n                         _asdict_anything(\n                             vv,\n-                            filter,\n-                            df,\n-                            retain_collection_types,\n-                            value_serializer,\n+                            is_key=False,\n+                            filter=filter,\n+                            dict_factory=df,\n+                            retain_collection_types=retain_collection_types,\n+                            value_serializer=value_serializer,\n                         ),\n                     )\n                     for kk, vv in iteritems(v)\n@@ -111,6 +116,7 @@ def asdict(\n \n def _asdict_anything(\n     val,\n+    is_key,\n     filter,\n     dict_factory,\n     retain_collection_types,\n@@ -123,22 +129,29 @@ def _asdict_anything(\n         # Attrs class.\n         rv = asdict(\n             val,\n-            True,\n-            filter,\n-            dict_factory,\n-            retain_collection_types,\n-            value_serializer,\n+            recurse=True,\n+            filter=filter,\n+            dict_factory=dict_factory,\n+            retain_collection_types=retain_collection_types,\n+            value_serializer=value_serializer,\n         )\n     elif isinstance(val, (tuple, list, set, frozenset)):\n-        cf = val.__class__ if retain_collection_types is True else list\n+        if retain_collection_types is True:\n+            cf = val.__class__\n+        elif is_key:\n+            cf = tuple\n+        else:\n+            cf = list\n+\n         rv = cf(\n             [\n                 _asdict_anything(\n                     i,\n-                    filter,\n-                    dict_factory,\n-                    retain_collection_types,\n-                    value_serializer,\n+                    is_key=False,\n+                    filter=filter,\n+                    dict_factory=dict_factory,\n+                    retain_collection_types=retain_collection_types,\n+                    value_serializer=value_serializer,\n                 )\n                 for i in val\n             ]\n@@ -148,10 +161,20 @@ def _asdict_anything(\n         rv = df(\n             (\n                 _asdict_anything(\n-                    kk, filter, df, retain_collection_types, value_serializer\n+                    kk,\n+                    is_key=True,\n+                    filter=filter,\n+                    dict_factory=df,\n+                    retain_collection_types=retain_collection_types,\n+                    value_serializer=value_serializer,\n                 ),\n                 _asdict_anything(\n-                    vv, filter, df, retain_collection_types, value_serializer\n+                    vv,\n+                    is_key=False,\n+                    filter=filter,\n+                    dict_factory=df,\n+                    retain_collection_types=retain_collection_types,\n+                    value_serializer=value_serializer,\n                 ),\n             )\n             for kk, vv in iteritems(val)\n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -26,7 +26,7 @@\n \n \n @pytest.fixture(scope=\"session\", name=\"C\")\n-def fixture_C():\n+def _C():\n     \"\"\"\n     Return a simple but fully featured attrs class with an x and a y attribute.\n     \"\"\"\n@@ -199,6 +199,37 @@ def test_asdict_preserve_order(self, cls):\n \n         assert [a.name for a in fields(cls)] == list(dict_instance.keys())\n \n+    def test_retain_keys_are_tuples(self):\n+        \"\"\"\n+        retain_collect_types also retains keys.\n+        \"\"\"\n+\n+        @attr.s\n+        class A(object):\n+            a = attr.ib()\n+\n+        instance = A({(1,): 1})\n+\n+        assert {\"a\": {(1,): 1}} == attr.asdict(\n+            instance, retain_collection_types=True\n+        )\n+\n+    def test_tuple_keys(self):\n+        \"\"\"\n+        If a key is collection type, retain_collection_types is False,\n+         the key is serialized as a tuple.\n+\n+        See #646\n+        \"\"\"\n+\n+        @attr.s\n+        class A(object):\n+            a = attr.ib()\n+\n+        instance = A({(1,): 1})\n+\n+        assert {\"a\": {(1,): 1}} == attr.asdict(instance)\n+\n \n class TestAsTuple(object):\n     \"\"\"\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -293,3 +293,7 @@ class FactoryTest:\n class MatchArgs:\n     a: int = attr.ib()\n     b: int = attr.ib()\n+\n+\n+attr.asdict(FactoryTest())\n+attr.asdict(FactoryTest(), retain_collection_types=False)\n", "problem_statement": "`asdict` fails for attributes of type Mapping with keys of type `Tuple`\n```\r\n@attr.s\r\nclass A:\r\n    a = attr.ib()\r\n        \r\ninstance = A({(1, ): 1})\r\nattr.asdict(instance)\r\n```\r\nproduces: \r\n`TypeError: unhashable type: 'list'` \r\n\r\nwhen the `retain_collection_types` flag is set to false (the default).  This can take a while to figure out, since the error is not the most descriptive (and the classes are not toy examples like this one).\r\nI just thought it would be worth mentioning. In any case, thanks for this awesome library.\n", "hints_text": "I stumbled upon the same issue and it is indeed not easy to figure out what is going wrong. I'm trying to think how this could be fixed. @hynek Could you comment on the following? Thanks!\r\n\r\n- Would it be acceptable to change the default value for `retain_collection_types` to `True`? This would reduce the likelihood of this issue to appear unexpectedly. It is not a full fix though.\r\n\r\n- Would it be ok to use `tuple` as default collection type, when `retain_collection_types=False`? I would expect this to completely resolve the issue.\nWe cannot change the defaults for attr.asdict due to backward compatibility but we can do that for the upcoming attrs.asdict.\n@hynek I understand. I've been thinking about related corner cases for `asdict`, which may also be addressed when making a newer version.\r\n\r\nFrozen sets are not changed into a default collection type, while sets are:\r\n\r\n```python\r\n>>> import attr\r\n>>> @attr.s\r\n... class A:\r\n...     a = attr.ib()\r\n... \r\n>>> instance = A(frozenset([1, 2]))\r\n>>> attr.asdict(instance)\r\n{'a': frozenset({1, 2})}\r\n>>>\r\n>>> instance = A(set([1, 2]))\r\n>>> attr.asdict(instance)\r\n{'a': [1, 2]}\r\n>>>\r\n```\r\n\r\nThis type of behavior can be made consistent in general by checking whether objects are instances of the classes defined in [collections.abc](https://docs.python.org/3/library/collections.html#collections.Counter).\r\n\r\n(Before making a new version, it would also be useful to understand the motivation for the current behavior.)\r\n\r\n\nI have just merged #704 that fixes the frozenset issue \u2013 sorry for the late reply!\nI have created a new issue for the new defaults, so closing this one.\nNo problem. Thank you for fixing!\nI think I still experience this issue on latest stable `attrs == 21.2.0`. Is this expected?\r\n\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.s\r\nclass Test:\r\n    x = attr.ib()\r\n\r\nt = Test(x={(1, 2): 3})\r\nattr.asdict(t)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/tmp/t.py\", line 11, in <module>\r\n    attr.asdict(t)\r\n  File \"/tmp/.venv/lib/python3.9/site-packages/attr/_funcs.py\", line 86, in asdict\r\n    rv[a.name] = df(\r\nTypeError: unhashable type: 'list'\r\n```\nYou have to pass `retain_collection_types=True` because we can't change the default value \u2013 that would be a very breaking change.\r\n\r\nWe intend to change it when you can import it from [`attrs`](https://www.attrs.org/en/stable/changelog.html#deprecations). I hope I'll get to it later this year.", "created_at": "2021-12-15T08:24:52Z"}
{"repo": "python-attrs/attrs", "pull_number": 887, "instance_id": "python-attrs__attrs-887", "issue_numbers": ["487", "705"], "base_commit": "a23fe5f8c802e01190a2894ac33130c691b97358", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -1,10 +1,8 @@\n from __future__ import absolute_import, division, print_function\n \n-import sys\n-\n from hypothesis import HealthCheck, settings\n \n-from attr._compat import PY310\n+from attr._compat import PY36, PY310\n \n \n def pytest_configure(config):\n@@ -16,7 +14,7 @@ def pytest_configure(config):\n \n \n collect_ignore = []\n-if sys.version_info[:2] < (3, 6):\n+if not PY36:\n     collect_ignore.extend(\n         [\n             \"tests/test_annotations.py\",\ndiff --git a/src/attr/_config.py b/src/attr/_config.py\n--- a/src/attr/_config.py\n+++ b/src/attr/_config.py\n@@ -11,7 +11,7 @@ def set_run_validators(run):\n     Set whether or not validators are run.  By default, they are run.\n \n     .. deprecated:: 21.3.0 It will not be removed, but it also will not be\n-        moved to new ``attrs`` namespace.  Use `attr.validators.set_disabled()`\n+        moved to new ``attrs`` namespace. Use `attrs.validators.set_disabled()`\n         instead.\n     \"\"\"\n     if not isinstance(run, bool):\n@@ -25,7 +25,7 @@ def get_run_validators():\n     Return whether or not validators are run.\n \n     .. deprecated:: 21.3.0 It will not be removed, but it also will not be\n-        moved to new ``attrs`` namespace.  Use `attr.validators.get_disabled()`\n+        moved to new ``attrs`` namespace. Use `attrs.validators.get_disabled()`\n         instead.\n     \"\"\"\n     return _run_validators\ndiff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -25,7 +25,7 @@ def asdict(\n         ``attrs``-decorated.\n     :param callable filter: A callable whose return code determines whether an\n         attribute or element is included (``True``) or dropped (``False``).  Is\n-        called with the `attr.Attribute` as the first argument and the\n+        called with the `attrs.Attribute` as the first argument and the\n         value as the second argument.\n     :param callable dict_factory: A callable to produce dictionaries from.  For\n         example, to produce ordered dictionaries instead of normal Python\n@@ -204,7 +204,7 @@ def astuple(\n         ``attrs``-decorated.\n     :param callable filter: A callable whose return code determines whether an\n         attribute or element is included (``True``) or dropped (``False``).  Is\n-        called with the `attr.Attribute` as the first argument and the\n+        called with the `attrs.Attribute` as the first argument and the\n         value as the second argument.\n     :param callable tuple_factory: A callable to produce tuples from.  For\n         example, to produce lists instead of tuples.\n@@ -314,7 +314,9 @@ def assoc(inst, **changes):\n         class.\n \n     ..  deprecated:: 17.1.0\n-        Use `evolve` instead.\n+        Use `attrs.evolve` instead if you can.\n+        This function will not be removed du to the slightly different approach\n+        compared to `attrs.evolve`.\n     \"\"\"\n     import warnings\n \n@@ -393,8 +395,8 @@ class and you didn't pass any attribs.\n     :raise NameError: If types cannot be resolved because of missing variables.\n \n     :returns: *cls* so you can use this function also as a class decorator.\n-        Please note that you have to apply it **after** `attr.s`. That means\n-        the decorator has to come in the line **before** `attr.s`.\n+        Please note that you have to apply it **after** `attrs.define`. That\n+        means the decorator has to come in the line **before** `attrs.define`.\n \n     ..  versionadded:: 20.1.0\n     ..  versionadded:: 21.1.0 *attribs*\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -147,11 +147,11 @@ def attrib(\n         is used and no value is passed while instantiating or the attribute is\n         excluded using ``init=False``.\n \n-        If the value is an instance of `Factory`, its callable will be\n+        If the value is an instance of `attrs.Factory`, its callable will be\n         used to construct a new value (useful for mutable data types like lists\n         or dicts).\n \n-        If a default is not set (or set manually to `attr.NOTHING`), a value\n+        If a default is not set (or set manually to `attrs.NOTHING`), a value\n         *must* be supplied when instantiating; otherwise a `TypeError`\n         will be raised.\n \n@@ -164,7 +164,7 @@ def attrib(\n \n     :param validator: `callable` that is called by ``attrs``-generated\n         ``__init__`` methods after the instance has been initialized.  They\n-        receive the initialized instance, the `Attribute`, and the\n+        receive the initialized instance, the :func:`~attrs.Attribute`, and the\n         passed value.\n \n         The return value is *not* inspected so the validator has to throw an\n@@ -237,10 +237,10 @@ def attrib(\n         parameter is ignored).\n     :param on_setattr: Allows to overwrite the *on_setattr* setting from\n         `attr.s`. If left `None`, the *on_setattr* value from `attr.s` is used.\n-        Set to `attr.setters.NO_OP` to run **no** `setattr` hooks for this\n+        Set to `attrs.setters.NO_OP` to run **no** `setattr` hooks for this\n         attribute -- regardless of the setting in `attr.s`.\n     :type on_setattr: `callable`, or a list of callables, or `None`, or\n-        `attr.setters.NO_OP`\n+        `attrs.setters.NO_OP`\n \n     .. versionadded:: 15.2.0 *convert*\n     .. versionadded:: 16.3.0 *metadata*\n@@ -1286,7 +1286,7 @@ def attrs(\n         *cmp*, or *hash* overrides whatever *auto_detect* would determine.\n \n         *auto_detect* requires Python 3. Setting it ``True`` on Python 2 raises\n-        a `PythonTooOldError`.\n+        an `attrs.exceptions.PythonTooOldError`.\n \n     :param bool repr: Create a ``__repr__`` method with a human readable\n         representation of ``attrs`` attributes..\n@@ -1373,7 +1373,7 @@ def attrs(\n \n         If you assign a value to those attributes (e.g. ``x: int = 42``), that\n         value becomes the default value like if it were passed using\n-        ``attr.ib(default=42)``.  Passing an instance of `Factory` also\n+        ``attr.ib(default=42)``.  Passing an instance of `attrs.Factory` also\n         works as expected in most cases (see warning below).\n \n         Attributes annotated as `typing.ClassVar`, and attributes that are\n@@ -1445,7 +1445,7 @@ def attrs(\n         the callable.\n \n         If a list of callables is passed, they're automatically wrapped in an\n-        `attr.setters.pipe`.\n+        `attrs.setters.pipe`.\n \n     :param Optional[callable] field_transformer:\n         A function that is called with the original class object and all\n@@ -2037,7 +2037,7 @@ def fields(cls):\n     :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n         class.\n \n-    :rtype: tuple (with name accessors) of `attr.Attribute`\n+    :rtype: tuple (with name accessors) of `attrs.Attribute`\n \n     ..  versionchanged:: 16.2.0 Returned tuple allows accessing the fields\n         by name.\n@@ -2064,7 +2064,7 @@ def fields_dict(cls):\n         class.\n \n     :rtype: an ordered dict where keys are attribute names and values are\n-        `attr.Attribute`\\\\ s. This will be a `dict` if it's\n+        `attrs.Attribute`\\\\ s. This will be a `dict` if it's\n         naturally ordered like on Python 3.6+ or an\n         :class:`~collections.OrderedDict` otherwise.\n \n@@ -2951,7 +2951,7 @@ class Factory(object):\n     \"\"\"\n     Stores a factory callable.\n \n-    If passed as the default value to `attr.ib`, the factory is used to\n+    If passed as the default value to `attrs.field`, the factory is used to\n     generate a new value.\n \n     :param callable factory: A callable that takes either none or exactly one\ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -3,11 +3,12 @@\n `attr.ib` with different default values.\n \"\"\"\n \n-from functools import partial\n \n-from attr.exceptions import UnannotatedAttributeError\n+from functools import partial\n \n from . import setters\n+from ._funcs import asdict as _asdict\n+from ._funcs import astuple as _astuple\n from ._make import (\n     NOTHING,\n     _frozen_setattrs,\n@@ -15,6 +16,7 @@\n     attrib,\n     attrs,\n )\n+from .exceptions import UnannotatedAttributeError\n \n \n def define(\n@@ -43,8 +45,23 @@ def define(\n     r\"\"\"\n     Define an ``attrs`` class.\n \n-    The behavioral differences to `attr.s` are the handling of the\n-    *auto_attribs* option:\n+    Differences to the classic `attr.s` that it uses underneath:\n+\n+    - Automatically detect whether or not *auto_attribs* should be `True`\n+      (c.f. *auto_attribs* parameter).\n+    - If *frozen* is `False`, run converters and validators when setting an\n+      attribute by default.\n+    - *slots=True* (see :term:`slotted classes` for potentially surprising\n+      behaviors)\n+    - *auto_exc=True*\n+    - *auto_detect=True*\n+    - *order=False*\n+    - *match_args=True*\n+    - Some options that were only relevant on Python 2 or were kept around for\n+      backwards-compatibility have been removed.\n+\n+    Please note that these are all defaults and you can change them as you\n+    wish.\n \n     :param Optional[bool] auto_attribs: If set to `True` or `False`, it behaves\n        exactly like `attr.s`. If left `None`, `attr.s` will try to guess:\n@@ -54,8 +71,7 @@ def define(\n        2. Otherwise it assumes *auto_attribs=False* and tries to collect\n           `attr.ib`\\ s.\n \n-    and that mutable classes (``frozen=False``) convert and validate on\n-    ``__setattr__``.\n+    For now, please refer to `attr.s` for the rest of the parameters.\n \n     .. versionadded:: 20.1.0\n     .. versionchanged:: 21.3.0 Converters are also run ``on_setattr``.\n@@ -168,3 +184,31 @@ def field(\n         order=order,\n         on_setattr=on_setattr,\n     )\n+\n+\n+def asdict(inst, *, recurse=True, filter=None, value_serializer=None):\n+    \"\"\"\n+    Same as `attr.asdict`, except that collections types are always retained\n+    and dict is always used as *dict_factory*.\n+\n+    .. versionadded:: 21.3.0\n+    \"\"\"\n+    return _asdict(\n+        inst=inst,\n+        recurse=recurse,\n+        filter=filter,\n+        value_serializer=value_serializer,\n+        retain_collection_types=True,\n+    )\n+\n+\n+def astuple(inst, *, recurse=True, filter=None):\n+    \"\"\"\n+    Same as `attr.astuple`, except that collections types are always retained\n+    and `tuple` is always used as the *tuple_factory*.\n+\n+    .. versionadded:: 21.3.0\n+    \"\"\"\n+    return _astuple(\n+        inst=inst, recurse=recurse, filter=filter, retain_collection_types=True\n+    )\ndiff --git a/src/attr/converters.py b/src/attr/converters.py\n--- a/src/attr/converters.py\n+++ b/src/attr/converters.py\n@@ -14,9 +14,10 @@\n \n \n __all__ = [\n-    \"pipe\",\n-    \"optional\",\n     \"default_if_none\",\n+    \"optional\",\n+    \"pipe\",\n+    \"to_bool\",\n ]\n \n \n@@ -65,14 +66,14 @@ def default_if_none(default=NOTHING, factory=None):\n     result of *factory*.\n \n     :param default: Value to be used if ``None`` is passed. Passing an instance\n-       of `attr.Factory` is supported, however the ``takes_self`` option\n+       of `attrs.Factory` is supported, however the ``takes_self`` option\n        is *not*.\n     :param callable factory: A callable that takes no parameters whose result\n        is used if ``None`` is passed.\n \n     :raises TypeError: If **neither** *default* or *factory* is passed.\n     :raises TypeError: If **both** *default* and *factory* are passed.\n-    :raises ValueError: If an instance of `attr.Factory` is passed with\n+    :raises ValueError: If an instance of `attrs.Factory` is passed with\n        ``takes_self=True``.\n \n     .. versionadded:: 18.2.0\ndiff --git a/src/attr/filters.py b/src/attr/filters.py\n--- a/src/attr/filters.py\n+++ b/src/attr/filters.py\n@@ -23,7 +23,7 @@ def include(*what):\n     Include *what*.\n \n     :param what: What to include.\n-    :type what: `list` of `type` or `attr.Attribute`\\\\ s\n+    :type what: `list` of `type` or `attrs.Attribute`\\\\ s\n \n     :rtype: `callable`\n     \"\"\"\n@@ -40,7 +40,7 @@ def exclude(*what):\n     Exclude *what*.\n \n     :param what: What to exclude.\n-    :type what: `list` of classes or `attr.Attribute`\\\\ s.\n+    :type what: `list` of classes or `attrs.Attribute`\\\\ s.\n \n     :rtype: `callable`\n     \"\"\"\ndiff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -127,7 +127,7 @@ def instance_of(type):\n     :type type: type or tuple of types\n \n     :raises TypeError: With a human readable error message, the attribute\n-        (of type `attr.Attribute`), the expected type, and the value it\n+        (of type `attrs.Attribute`), the expected type, and the value it\n         got.\n     \"\"\"\n     return _InstanceOfValidator(type)\n@@ -250,7 +250,7 @@ def provides(interface):\n     :type interface: ``zope.interface.Interface``\n \n     :raises TypeError: With a human readable error message, the attribute\n-        (of type `attr.Attribute`), the expected interface, and the\n+        (of type `attrs.Attribute`), the expected interface, and the\n         value it got.\n     \"\"\"\n     return _ProvidesValidator(interface)\n@@ -323,7 +323,7 @@ def in_(options):\n     :type options: list, tuple, `enum.Enum`, ...\n \n     :raises ValueError: With a human readable error message, the attribute (of\n-       type `attr.Attribute`), the expected options, and the value it\n+       type `attrs.Attribute`), the expected options, and the value it\n        got.\n \n     .. versionadded:: 17.1.0\n@@ -362,7 +362,7 @@ def is_callable():\n     .. versionadded:: 19.1.0\n \n     :raises `attr.exceptions.NotCallableError`: With a human readable error\n-        message containing the attribute (`attr.Attribute`) name,\n+        message containing the attribute (`attrs.Attribute`) name,\n         and the value it got.\n     \"\"\"\n     return _IsCallableValidator()\ndiff --git a/src/attrs/__init__.py b/src/attrs/__init__.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attrs/__init__.py\n@@ -0,0 +1,68 @@\n+from attr import (\n+    NOTHING,\n+    Attribute,\n+    Factory,\n+    __author__,\n+    __copyright__,\n+    __description__,\n+    __doc__,\n+    __email__,\n+    __license__,\n+    __title__,\n+    __url__,\n+    __version__,\n+    __version_info__,\n+    assoc,\n+    cmp_using,\n+    define,\n+    evolve,\n+    field,\n+    fields,\n+    fields_dict,\n+    frozen,\n+    has,\n+    make_class,\n+    mutable,\n+    resolve_types,\n+    validate,\n+)\n+from attr._next_gen import asdict, astuple\n+\n+from . import converters, exceptions, filters, setters, validators\n+\n+\n+__all__ = [\n+    \"__author__\",\n+    \"__copyright__\",\n+    \"__description__\",\n+    \"__doc__\",\n+    \"__email__\",\n+    \"__license__\",\n+    \"__title__\",\n+    \"__url__\",\n+    \"__version__\",\n+    \"__version_info__\",\n+    \"asdict\",\n+    \"assoc\",\n+    \"astuple\",\n+    \"Attribute\",\n+    \"cmp_using\",\n+    \"converters\",\n+    \"define\",\n+    \"evolve\",\n+    \"exceptions\",\n+    \"Factory\",\n+    \"field\",\n+    \"fields_dict\",\n+    \"fields\",\n+    \"filters\",\n+    \"frozen\",\n+    \"has\",\n+    \"make_class\",\n+    \"mutable\",\n+    \"NOTHING\",\n+    \"resolve_types\",\n+    \"setters\",\n+    \"validate\",\n+    \"validators\",\n+]\ndiff --git a/src/attrs/converters.py b/src/attrs/converters.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attrs/converters.py\n@@ -0,0 +1 @@\n+from attr.converters import *  # noqa\ndiff --git a/src/attrs/exceptions.py b/src/attrs/exceptions.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attrs/exceptions.py\n@@ -0,0 +1 @@\n+from attr.exceptions import *  # noqa\ndiff --git a/src/attrs/filters.py b/src/attrs/filters.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attrs/filters.py\n@@ -0,0 +1 @@\n+from attr.filters import *  # noqa\ndiff --git a/src/attrs/setters.py b/src/attrs/setters.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attrs/setters.py\n@@ -0,0 +1 @@\n+from attr.setters import *  # noqa\ndiff --git a/src/attrs/validators.py b/src/attrs/validators.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attrs/validators.py\n@@ -0,0 +1 @@\n+from attr.validators import *  # noqa\n", "test_patch": "diff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -8,10 +8,11 @@\n \n import pytest\n \n-import attr\n+import attr as _attr  # don't use it by accident\n+import attrs\n \n \n-@attr.define\n+@attrs.define\n class C:\n     x: str\n     y: int\n@@ -29,7 +30,7 @@ def test_no_slots(self):\n         slots can be deactivated.\n         \"\"\"\n \n-        @attr.define(slots=False)\n+        @attrs.define(slots=False)\n         class NoSlots:\n             x: int\n \n@@ -42,9 +43,9 @@ def test_validates(self):\n         Validators at __init__ and __setattr__ work.\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class Validated:\n-            x: int = attr.field(validator=attr.validators.instance_of(int))\n+            x: int = attrs.field(validator=attrs.validators.instance_of(int))\n \n         v = Validated(1)\n \n@@ -61,7 +62,7 @@ def test_no_order(self):\n         with pytest.raises(TypeError):\n             C(\"1\", 2) < C(\"2\", 3)\n \n-        @attr.define(order=True)\n+        @attrs.define(order=True)\n         class Ordered:\n             x: int\n \n@@ -71,23 +72,23 @@ def test_override_auto_attribs_true(self):\n         \"\"\"\n         Don't guess if auto_attrib is set explicitly.\n \n-        Having an unannotated attr.ib/attr.field fails.\n+        Having an unannotated attrs.ib/attrs.field fails.\n         \"\"\"\n-        with pytest.raises(attr.exceptions.UnannotatedAttributeError):\n+        with pytest.raises(attrs.exceptions.UnannotatedAttributeError):\n \n-            @attr.define(auto_attribs=True)\n+            @attrs.define(auto_attribs=True)\n             class ThisFails:\n-                x = attr.field()\n+                x = attrs.field()\n                 y: int\n \n     def test_override_auto_attribs_false(self):\n         \"\"\"\n         Don't guess if auto_attrib is set explicitly.\n \n-        Annotated fields that don't carry an attr.ib are ignored.\n+        Annotated fields that don't carry an attrs.ib are ignored.\n         \"\"\"\n \n-        @attr.define(auto_attribs=False)\n+        @attrs.define(auto_attribs=False)\n         class NoFields:\n             x: int\n             y: int\n@@ -99,16 +100,16 @@ def test_auto_attribs_detect(self):\n         define correctly detects if a class lacks type annotations.\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class OldSchool:\n-            x = attr.field()\n+            x = attrs.field()\n \n         assert OldSchool(1) == OldSchool(1)\n \n         # Test with maybe_cls = None\n-        @attr.define()\n+        @attrs.define()\n         class OldSchool2:\n-            x = attr.field()\n+            x = attrs.field()\n \n         assert OldSchool2(1) == OldSchool2(1)\n \n@@ -117,10 +118,10 @@ def test_auto_attribs_detect_fields_and_annotations(self):\n         define infers auto_attribs=True if fields have type annotations\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class NewSchool:\n             x: int\n-            y: list = attr.field()\n+            y: list = attrs.field()\n \n             @y.validator\n             def _validate_y(self, attribute, value):\n@@ -130,14 +131,14 @@ def _validate_y(self, attribute, value):\n         assert NewSchool(1, 1) == NewSchool(1, 1)\n         with pytest.raises(ValueError):\n             NewSchool(1, -1)\n-        assert list(attr.fields_dict(NewSchool).keys()) == [\"x\", \"y\"]\n+        assert list(attrs.fields_dict(NewSchool).keys()) == [\"x\", \"y\"]\n \n     def test_auto_attribs_partially_annotated(self):\n         \"\"\"\n         define infers auto_attribs=True if any type annotations are found\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class NewSchool:\n             x: int\n             y: list\n@@ -145,7 +146,7 @@ class NewSchool:\n \n         # fields are defined for any annotated attributes\n         assert NewSchool(1, []) == NewSchool(1, [])\n-        assert list(attr.fields_dict(NewSchool).keys()) == [\"x\", \"y\"]\n+        assert list(attrs.fields_dict(NewSchool).keys()) == [\"x\", \"y\"]\n \n         # while the unannotated attributes are left as class vars\n         assert NewSchool.z == 10\n@@ -156,14 +157,14 @@ def test_auto_attribs_detect_annotations(self):\n         define correctly detects if a class has type annotations.\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class NewSchool:\n             x: int\n \n         assert NewSchool(1) == NewSchool(1)\n \n         # Test with maybe_cls = None\n-        @attr.define()\n+        @attrs.define()\n         class NewSchool2:\n             x: int\n \n@@ -174,7 +175,7 @@ def test_exception(self):\n         Exceptions are detected and correctly handled.\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class E(Exception):\n             msg: str\n             other: int\n@@ -190,16 +191,16 @@ class E(Exception):\n \n     def test_frozen(self):\n         \"\"\"\n-        attr.frozen freezes classes.\n+        attrs.frozen freezes classes.\n         \"\"\"\n \n-        @attr.frozen\n+        @attrs.frozen\n         class F:\n             x: str\n \n         f = F(1)\n \n-        with pytest.raises(attr.exceptions.FrozenInstanceError):\n+        with pytest.raises(attrs.exceptions.FrozenInstanceError):\n             f.x = 2\n \n     def test_auto_detect_eq(self):\n@@ -209,7 +210,7 @@ def test_auto_detect_eq(self):\n         Regression test for #670.\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class C:\n             def __eq__(self, o):\n                 raise ValueError()\n@@ -219,35 +220,35 @@ def __eq__(self, o):\n \n     def test_subclass_frozen(self):\n         \"\"\"\n-        It's possible to subclass an `attr.frozen` class and the frozen-ness is\n-        inherited.\n+        It's possible to subclass an `attrs.frozen` class and the frozen-ness\n+        is inherited.\n         \"\"\"\n \n-        @attr.frozen\n+        @attrs.frozen\n         class A:\n             a: int\n \n-        @attr.frozen\n+        @attrs.frozen\n         class B(A):\n             b: int\n \n-        @attr.define(on_setattr=attr.setters.NO_OP)\n+        @attrs.define(on_setattr=attrs.setters.NO_OP)\n         class C(B):\n             c: int\n \n         assert B(1, 2) == B(1, 2)\n         assert C(1, 2, 3) == C(1, 2, 3)\n \n-        with pytest.raises(attr.exceptions.FrozenInstanceError):\n+        with pytest.raises(attrs.exceptions.FrozenInstanceError):\n             A(1).a = 1\n \n-        with pytest.raises(attr.exceptions.FrozenInstanceError):\n+        with pytest.raises(attrs.exceptions.FrozenInstanceError):\n             B(1, 2).a = 1\n \n-        with pytest.raises(attr.exceptions.FrozenInstanceError):\n+        with pytest.raises(attrs.exceptions.FrozenInstanceError):\n             B(1, 2).b = 2\n \n-        with pytest.raises(attr.exceptions.FrozenInstanceError):\n+        with pytest.raises(attrs.exceptions.FrozenInstanceError):\n             C(1, 2, 3).c = 3\n \n     def test_catches_frozen_on_setattr(self):\n@@ -256,7 +257,7 @@ def test_catches_frozen_on_setattr(self):\n         immutability is inherited.\n         \"\"\"\n \n-        @attr.define(frozen=True)\n+        @attrs.define(frozen=True)\n         class A:\n             pass\n \n@@ -264,7 +265,7 @@ class A:\n             ValueError, match=\"Frozen classes can't use on_setattr.\"\n         ):\n \n-            @attr.define(frozen=True, on_setattr=attr.setters.validate)\n+            @attrs.define(frozen=True, on_setattr=attrs.setters.validate)\n             class B:\n                 pass\n \n@@ -276,17 +277,17 @@ class B:\n             ),\n         ):\n \n-            @attr.define(on_setattr=attr.setters.validate)\n+            @attrs.define(on_setattr=attrs.setters.validate)\n             class C(A):\n                 pass\n \n     @pytest.mark.parametrize(\n         \"decorator\",\n         [\n-            partial(attr.s, frozen=True, slots=True, auto_exc=True),\n-            attr.frozen,\n-            attr.define,\n-            attr.mutable,\n+            partial(_attr.s, frozen=True, slots=True, auto_exc=True),\n+            attrs.frozen,\n+            attrs.define,\n+            attrs.mutable,\n         ],\n     )\n     def test_discard_context(self, decorator):\n@@ -298,7 +299,7 @@ def test_discard_context(self, decorator):\n \n         @decorator\n         class MyException(Exception):\n-            x: str = attr.ib()\n+            x: str = attrs.field()\n \n         with pytest.raises(MyException) as ei:\n             try:\n@@ -314,9 +315,9 @@ def test_converts_and_validates_by_default(self):\n         If no on_setattr is set, assume setters.convert, setters.validate.\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class C:\n-            x: int = attr.field(converter=int)\n+            x: int = attrs.field(converter=int)\n \n             @x.validator\n             def _v(self, _, value):\n@@ -341,7 +342,7 @@ def test_mro_ng(self):\n         See #428\n         \"\"\"\n \n-        @attr.define\n+        @attrs.define\n         class A:\n \n             x: int = 10\n@@ -349,21 +350,89 @@ class A:\n             def xx(self):\n                 return 10\n \n-        @attr.define\n+        @attrs.define\n         class B(A):\n             y: int = 20\n \n-        @attr.define\n+        @attrs.define\n         class C(A):\n             x: int = 50\n \n             def xx(self):\n                 return 50\n \n-        @attr.define\n+        @attrs.define\n         class D(B, C):\n             pass\n \n         d = D()\n \n         assert d.x == d.xx()\n+\n+\n+class TestAsTuple:\n+    def test_smoke(self):\n+        \"\"\"\n+        `attrs.astuple` only changes defaults, so we just call it and compare.\n+        \"\"\"\n+        inst = C(\"foo\", 42)\n+\n+        assert attrs.astuple(inst) == _attr.astuple(inst)\n+\n+\n+class TestAsDict:\n+    def test_smoke(self):\n+        \"\"\"\n+        `attrs.asdict` only changes defaults, so we just call it and compare.\n+        \"\"\"\n+        inst = C(\"foo\", {(1,): 42})\n+\n+        assert attrs.asdict(inst) == _attr.asdict(\n+            inst, retain_collection_types=True\n+        )\n+\n+\n+class TestImports:\n+    \"\"\"\n+    Verify our re-imports and mirroring works.\n+    \"\"\"\n+\n+    def test_converters(self):\n+        \"\"\"\n+        Importing from attrs.converters works.\n+        \"\"\"\n+        from attrs.converters import optional\n+\n+        assert optional is _attr.converters.optional\n+\n+    def test_exceptions(self):\n+        \"\"\"\n+        Importing from attrs.exceptions works.\n+        \"\"\"\n+        from attrs.exceptions import FrozenError\n+\n+        assert FrozenError is _attr.exceptions.FrozenError\n+\n+    def test_filters(self):\n+        \"\"\"\n+        Importing from attrs.filters works.\n+        \"\"\"\n+        from attrs.filters import include\n+\n+        assert include is _attr.filters.include\n+\n+    def test_setters(self):\n+        \"\"\"\n+        Importing from attrs.setters works.\n+        \"\"\"\n+        from attrs.setters import pipe\n+\n+        assert pipe is _attr.setters.pipe\n+\n+    def test_validators(self):\n+        \"\"\"\n+        Importing from attrs.validators works.\n+        \"\"\"\n+        from attrs.validators import and_\n+\n+        assert and_ is _attr.validators.and_\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -3,6 +3,7 @@\n from typing import Any, Dict, List, Tuple, Union\n \n import attr\n+import attrs\n \n \n # Typing via \"type\" Argument ---\n@@ -59,6 +60,14 @@ class FF:\n     z: Any = attr.ib()\n \n \n+@attrs.define\n+class FFF:\n+    z: int\n+\n+\n+FFF(1)\n+\n+\n # Inheritance --\n \n \n@@ -96,6 +105,19 @@ class Error(Exception):\n     str(e)\n \n \n+@attrs.define\n+class Error2(Exception):\n+    x: int\n+\n+\n+try:\n+    raise Error2(1)\n+except Error as e:\n+    e.x\n+    e.args\n+    str(e)\n+\n+\n # Converters\n # XXX: Currently converters can only be functions so none of this works\n # although the stubs should be correct.\n@@ -179,7 +201,7 @@ class Validated:\n         validator=attr.validators.instance_of((int, str))\n     )\n     k: Union[int, str, C] = attr.ib(\n-        validator=attr.validators.instance_of((int, C, str))\n+        validator=attrs.validators.instance_of((int, C, str))\n     )\n \n \n@@ -188,9 +210,17 @@ class Validated2:\n     num: int = attr.field(validator=attr.validators.ge(0))\n \n \n+@attrs.define\n+class Validated3:\n+    num: int = attr.field(validator=attr.validators.ge(0))\n+\n+\n with attr.validators.disabled():\n     Validated2(num=-1)\n \n+with attrs.validators.disabled():\n+    Validated3(num=-1)\n+\n try:\n     attr.validators.set_disabled(True)\n     Validated2(num=-1)\n@@ -207,6 +237,14 @@ class WithCustomRepr:\n     d: bool = attr.ib(repr=str)\n \n \n+@attrs.define\n+class WithCustomRepr2:\n+    a: int = attrs.field(repr=True)\n+    b: str = attrs.field(repr=False)\n+    c: str = attrs.field(repr=lambda value: \"c is for cookie\")\n+    d: bool = attrs.field(repr=str)\n+\n+\n # Check some of our own types\n @attr.s(eq=True, order=False)\n class OrderFlags:\n@@ -228,16 +266,43 @@ class ValidatedSetter:\n     )\n \n \n+@attrs.define(on_setattr=attr.setters.validate)\n+class ValidatedSetter2:\n+    a: int\n+    b: str = attrs.field(on_setattr=attrs.setters.NO_OP)\n+    c: bool = attrs.field(on_setattr=attrs.setters.frozen)\n+    d: int = attrs.field(\n+        on_setattr=[attrs.setters.convert, attrs.setters.validate]\n+    )\n+    e: bool = attrs.field(\n+        on_setattr=attrs.setters.pipe(\n+            attrs.setters.convert, attrs.setters.validate\n+        )\n+    )\n+\n+\n # field_transformer\n def ft_hook(cls: type, attribs: List[attr.Attribute]) -> List[attr.Attribute]:\n     return attribs\n \n \n+# field_transformer\n+def ft_hook2(\n+    cls: type, attribs: List[attrs.Attribute]\n+) -> List[attrs.Attribute]:\n+    return attribs\n+\n+\n @attr.s(field_transformer=ft_hook)\n class TransformedAttrs:\n     x: int\n \n \n+@attrs.define(field_transformer=ft_hook2)\n+class TransformedAttrs2:\n+    x: int\n+\n+\n # Auto-detect\n @attr.s(auto_detect=True)\n class AutoDetect:\n@@ -276,6 +341,11 @@ class NGFrozen:\n a.evolve(repr=False)\n \n \n+attrs.fields(NGFrozen).x.evolve(eq=False)\n+a = attrs.fields(NGFrozen).x\n+a.evolve(repr=False)\n+\n+\n @attr.s(collect_by_mro=True)\n class MRO:\n     pass\n@@ -288,6 +358,17 @@ class FactoryTest:\n     c: List[int] = attr.ib(default=attr.Factory((lambda s: s.a), True))\n \n \n+@attrs.define\n+class FactoryTest2:\n+    a: List[int] = attrs.field(default=attrs.Factory(list))\n+    b: List[Any] = attrs.field(default=attrs.Factory(list, False))\n+    c: List[int] = attrs.field(default=attrs.Factory((lambda s: s.a), True))\n+\n+\n+attrs.asdict(FactoryTest2())\n+attr.asdict(FactoryTest(), tuple_keys=True)\n+\n+\n # Check match_args stub\n @attr.s(match_args=False)\n class MatchArgs:\n@@ -297,3 +378,41 @@ class MatchArgs:\n \n attr.asdict(FactoryTest())\n attr.asdict(FactoryTest(), retain_collection_types=False)\n+\n+\n+# Check match_args stub\n+@attrs.define(match_args=False)\n+class MatchArgs2:\n+    a: int\n+    b: int\n+\n+\n+# NG versions of asdict/astuple\n+attrs.asdict(MatchArgs2(1, 2))\n+attrs.astuple(MatchArgs2(1, 2))\n+\n+\n+def importing_from_attr() -> None:\n+    \"\"\"\n+    Use a function to keep the ns clean.\n+    \"\"\"\n+    from attr.converters import optional\n+    from attr.exceptions import FrozenError\n+    from attr.filters import include\n+    from attr.setters import frozen\n+    from attr.validators import and_\n+\n+    assert optional and FrozenError and include and frozen and and_\n+\n+\n+def importing_from_attrs() -> None:\n+    \"\"\"\n+    Use a function to keep the ns clean.\n+    \"\"\"\n+    from attrs.converters import optional\n+    from attrs.exceptions import FrozenError\n+    from attrs.filters import include\n+    from attrs.setters import frozen\n+    from attrs.validators import and_\n+\n+    assert optional and FrozenError and include and frozen and and_\n", "problem_statement": "[RFC] Inconvenient defaults?\nAs part of \u201cProject`import attrs`\u201d (see also #408) we get a unique opportunity to change default options/behaviors that grew over the years but couldn't be fixed due to backward-compatibility restrictions.\r\n\r\nThe rough plan is create a new, friendlier API on top of `@attr.s` and `attr.ib()` that won't go anywhere.\r\n\r\nThe following is cast in stone:\r\n\r\n- `auto_attribs=True`\r\n- consistent (Python 3-style) hashing behavior on every Python version\r\n- #428 \r\n\r\nThe following would be really nice to have:\r\n\r\n- #368 but it might need too much thinking/research\r\n\r\nWhat else is bugging you?\r\n\r\n***\r\n\r\nOne thing that I just can't make up my mind is related to #223: should we make `slots=True` the default? I\u2019m quite confident that in 99,9% of cases it's the right thing to do and will guide people to write better classes.\r\n\r\nHowever on the other hand, our approach of rewriting classes breaks in certain scenarios, usually involving metaclasses.\r\n\r\nSo the question is, whether we want to tolerate a higher rate of bogus bug reports/help requests or make the default case nicer?\r\n\r\nI welcome your input.\r\n\r\n***\r\n\r\nFinally a controversial idea: we could make `import attrs` Python 3 only. There isn't much baggage we'd get rid of but there is _some_ and 2020 is less than a year ahead. It would also allow us to embrace enums as part of our API.\nBetter defaults for asdict/astuple\n- Would it be acceptable to change the default value for `retain_collection_types` to `True`? This would reduce the likelihood of this issue to appear unexpectedly. It is not a full fix though.\r\n\r\n- Would it be ok to use `tuple` as default collection type, when `retain_collection_types=False`? I would expect this to completely resolve the issue.\r\n\r\n_Originally posted by @tovrstra in https://github.com/python-attrs/attrs/issues/646#issuecomment-682167908_\n", "hints_text": "\"we could make import attrs Python 3 only.\" -> +1. \r\n\r\n\"It would also allow us to embrace enums as part of our API.\" -> That would be awesome.\r\n\nI absolutely agree with your point on `slots=True`, but I would recommend not making it the default. I'm always surprised by how many people have no idea that this amazing feature exists; you need to at the very least explain in the documentation what it is anyway, so it can be used to recommend its use and guide people to write better classes. :slightly_smiling_face: \r\n\r\nI'm also in favour of Python3-only `import attrs`.\r\n\r\n> What else is bugging you?\r\n\r\nA question: My main issue with `attrs` has always been its decorator-based syntax and inability to instantiate using `__init__`. To be clear, it's my personal preference and not a general opinion on How Things Should Be Done [TM], but I've always liked the subclassing approach found in e.g. `schematics`. Also, I've often explained the concept of data classes (regardless of the implementation) as \"ORM without the R\", as it maps nicely with people's experience with Django and others. So I just have to ask, it there a possibility to have an optional method of implementing `attrs` as a parent/abstract class and/or a mixin?\r\n\r\nThanks for all the amazing work!\n> So I just have to ask, it there a possibility to have an optional method of implementing `attrs` as a parent/abstract class and/or a mixin?\r\n\r\nNo, but you could probably use metaclasses and our programmatic interface (make_class) to build it yourself?\nIn a world of AWS Lambda and other RAM-second based billing systems, making \"slots=True\" the default will literally save people money (since it uses less RAM, and avoids pointless dict creation for each instance).\r\n\r\nIf it fails, then folks are likely to get noisy exceptions that a few asked-and-answered questions on Stack Overflow will teach them to resolve with \"slots=False\".\n> If it fails, then folks are likely to get noisy exceptions that a few asked-and-answered questions on Stack Overflow will teach them to resolve with \"slots=False\".\r\n\r\nCould even seed SO with a couple of self-answered Q&A covering common error cases where `slots=False` is the fix.\n> If it fails, then folks are likely to get noisy exceptions that a few asked-and-answered questions on Stack Overflow will teach them to resolve with \"slots=False\".\r\n\r\nI tend to agree; it just goes a bit against `attrs`\u2019s principle of \u201cjust adding some stuff\u201d to your classes.\r\n\nMy feelpinion: `frozen=True` should be the default. Probably the option should be renamed to `mutable`, so you say `mutable=True` for when you know what you are doing. \n> My feelpinion: `frozen=True` should be the default. Probably the option should be renamed to `mutable`, so you say `mutable=True` for when you know what you are doing.\r\n\r\nDisagree here. `frozen=True` only works for me in situations where (1) the entire contents of all instances will be known at instantiation-time in all cases, and (2) where no derived/calculated members will be needed (i.e., where `@property`s are sufficient for all derived members because the calculations are fast).\r\n\r\nI use attrs classes a lot in my data analysis work, and often I'll have something expensive I need to do with the arguments passed in at initialization. I absolutely want to do that expensive thing exactly once for each instance, and AFAIK I have to do it as something like:\r\n\r\n```\r\n@attr.s(slots=True)\r\nclass Foo:\r\n\r\n    input_var = attr.ib()\r\n    expensive_derived_var = attr.ib(init=False)\r\n\r\n    def __attrs_post_init__(self):\r\n        self.expensive_derived_var = self.calculate_expensive_thing()\r\n\r\n    def calculate_expensive_thing(self):\r\n        ...\r\n        {expensive stuff with self.input_var}\r\n        ...\r\n```\r\n\r\nWith `frozen=True`, I can't set `self.expensive_derived_var` in `__attrs_post_init__`.\r\n\r\nThat being said, I have no idea whether my needs here at all represent the majority of use-cases.\nI love myself some value types but `frozen=True` ain\u2019t happening. :)\r\n\r\nIt just doesn\u2019t fit Python too well. But IIRC we\u2019ve decided on an own function for it?\nI agree with `frozen=False` as the default, but kinda like using the term `mutable`, unless there is a significant difference between the meaning in `attrs` and Python in general. So I guess I would vote for the `mutable=True` as default.\r\n\r\nOh, and I think that @bskinn's argument against `frozen=True` equally applies to `slots=True`; I still think they should both be off by default. Unless I'm mistaken, `slots` applies to the attributes defined via `attrs` and no additional attributes can't be added, is that right?\n> No, but you could probably use metaclasses and our programmatic interface (make_class) to build it yourself?\r\n\r\nPossibly, will look into it.\nThe reason why it's called `frozen` is because that's how we call these things in Python (frozenset etc) and I don't want to open a new nomenclature out of purity. I've seen good things fail too often because of the stubbornness of its maintainers to be a good Python citizen.\r\n\r\nAnd yes, `slots=True` prevents new attributes and you really shouldn't add ad-hoc attributes so that's a feature. If you need it, you can always say `slots=False` and the class has a warning attached to itself, that the attribute list is not comprehensive.\n> we\u2019ve decided on an own function for it?\r\n\r\nDid we? Where can I read about that?\n> Where can I read about that?\r\n\r\nhttps://github.com/python-attrs/attrs/issues/408#issuecomment-442552322\r\n\r\nIt's gonna be `@attrs.define` and `@attrs.frozen`. Depending on https://hynek.me/about/#gratitude I might add an `attrs.mutable` alias for `define`. ;)\n> Depending on https://hynek.me/about/#a-name-gratitude-a-gratitude I might add an `attrs.mutable` alias for `define`. ;)\r\n\r\nIt\u2019s working \ud83d\ude31! Thank you so much @berislavlopac! \u2764\ufe0f\nKeep up the good work! :wink: \nI actually think `slots=True` has a useful proofreading function, and thus has more (albeit definitely not iron-clad) merit as a default as compared to `frozen`: `slots=True` guards against typos in external code that uses the class.\r\n\r\nI agree that a default `slots=True` has the potential to introduce confusing errors, but this at least might be mitigated by customizing the exception message... something like: \"... Either you have made a typo in accessing a member, or you should define this class with @attr.s(slots=False)\".\nJust a thought -- if we're using separate decorators for defining frozen and mutable classes, perhaps the former can have `slots=True` and the latter `slots=False`? :thinking: Just thinking out loud...\nDefinitely makes sense to me for `slots=True` to be default on `@attrs.frozen`. \n\nThat could be one distinction between (a possibly yet-again-renamed) `.define` and `.mutable`... `slots=True` on the former and `slots=False` on the latter...\nI also agree that `frozen=True` should not be the default for reasons @hynek gives above, but I wanted to note that @bskin's use-case above works fine for frozen classes with a small tweak. Rather than:\r\n\r\n```\r\n@attr.s(slots=True)\r\nclass Foo:\r\n\r\n    input_var = attr.ib()\r\n    expensive_derived_var = attr.ib(init=False)\r\n\r\n    def __attrs_post_init__(self):\r\n        self.expensive_derived_var = self.calculate_expensive_thing()\r\n\r\n    def calculate_expensive_thing(self):\r\n        ...\r\n        {expensive stuff with self.input_var}\r\n        ...\r\n```\r\n\r\ndo\r\n\r\n```\r\n@attr.s(slots=True, frozen=True)\r\nclass Foo:\r\n\r\n    input_var = attr.ib()\r\n    expensive_derived_var = attr.ib(init=False)\r\n\r\n    @expensive_derived_thing.default\r\n    def calculate_expensive_thing(self):\r\n        ...\r\n        {expensive stuff with self.input_var}\r\n        ...\r\n        return {computed value}\r\n```\r\n\r\nI wonder if this pattern is common enough to merit an example in the documentation.\r\n\r\nNote that these derived attributes still participate in hash, cmp, etc. unless you turn them off (https://github.com/python-attrs/attrs/issues/310).\n> That could be one distinction between (a possibly yet-again-renamed) .define and .mutable... slots=True on the former and slots=False on the latter...\r\n\r\nOn one hand, I like this approach, as it provides a number of different ways to skin this cat. On the other, I feel this goes against \"one obvious way to do it\", introducing simply too many combinations to keep in mind:\r\n\r\n- `define` with `slots=True` and `frozen=False`\r\n- `mutable` with `slots=False` and `frozen=False`\r\n- `frozen` with `slots=True` and `frozen=True`\r\n\r\nSo I'm not sure. :laughing: Overall, I think I'm leaning slightly towards simplicity:\r\n\r\n- `define` with `slots=False` and `frozen=False`\r\n- `frozen` with `slots=True` and `frozen=True`\r\n\r\nEspecially if there are more differences between the two methods than just the default values of `slots` and `frozen`. And I can live without the `mutable` alias.\nYeah.  I don't think `mutable` and `define` should be different.  The intent with that alias wasn't to complicate the matrix but to allow pedantic folks like me to be explicit about whether a class is mutable or frozen, as opposed to \"the usual sort\" or frozen.\nYeah there's not gonna be any more diversions. It's bad enough to have `attrs.frozen` and `attrs.define`. :)\nNot to derail an excellent conversation about mutability, but has `attrs` ever considered building in support for disallowing 'empty' values for attributes that are not assigned a default?\r\n\r\nFor instance, in my own little world, I can't think of a single case where, given the type\r\n\r\n```\r\n@attr.s(auto_attribs=True)\r\nclass MyDatabaseType:\r\n    username: str\r\n    firstname: str\r\n    email_addresses: List[str]\r\n\r\n    favorite_colors: List[str] = attr.Factory(list)\r\n    bio: str = ''\r\n```\r\n\r\nI would ever want to allow empty strings or lists for the attributes where I did not specifically provide a default. To me, making something optional is the same thing as providing a default, and vice-versa - under all other circumstances (well, at least for strings and collections types), an empty value is a sign of failure.\r\n\r\nObviously I can write validators for each of these items, but that ends up being at least 2 extra lines in the class definition for each attribute, or a single, very long line using `attr.ib` syntax, where previously the class definition was extremely clean.\r\n\r\nI am probably totally wrong about all this, and would love to have it explained to me why. But if I'm not, may I suggest adding a flag to the decorator that, if provided, enables this basic level of validation for all `str` and `list`/`set`/other collection types for which a default value is not provided?\r\n\r\nAgain, I apologize for jumping into this ongoing conversation about better defaults - this is probably a simple feature request. But as it seems like _default_ behavior to me, I couldn't resist.  Thanks for an incredible project that has made programming with classes/typing in Python literally 500% more pleasant!\n@petergaultney That sounds a bit off-topic for this thread, which is more about cleaning up the API around existing functionality.  You're asking for a new feature, which you've filed as #495; it'll be easier to track that conversation there.\nI just remembered another common \"pain\" point: equality & comparison. Equality should be on by default, ordering off. I think?\nAnother one: auto-detect methods that are defined on the current class (and the current class only): #324\n> I just remembered another common \"pain\" point: equality & comparison. Equality should be on by default, ordering off. I think?\r\n\r\n+100\r\n\r\nSounds like it's already captured but I personally have to type `@attr.s(hash=True)` for every attrs class, so that'd be great to change yeah.\r\n\r\n(I have to read the rest of this thread but I'm being lazy since I just saw this issue pinned :)\r\n\r\nAnd the other one that bugs me often is silently ignoring methods that are replaced. I.e.:\r\n\r\n```\r\n>>> @attr.s\r\n... class Foo(object):\r\n...     def __init__(self):\r\n...         print 12\r\n```\r\n\r\nshould IMO do something different than what it does today -- either the old characteristic behavior where that gets used as `attrs_post_init` or an error at class creation time.\n(Probably the latter, considering the same can't be done for someone defining `__repr__` with `repr=True`)\nI like the name `order=` instead of `cmp=`, as dataclasses does, since `cmp` is a bit opaque -- \"what is 'compare' anyway?\", and `order` sounds like [`functools.total_ordering`](https://docs.python.org/3/library/functools.html#functools.total_ordering) which is good.\r\n\r\nMaybe it's too late to change that though.\n> Maybe it's too late to change that though.\r\n\r\nIt's not for `import attrs`.\r\n\r\nI like `eq` and `order`!\nRegarding mutability/frozen in an `auto_attribs` setting. Python 3.8 now has a `typing.Final` type qualifier ([PEP 591](https://www.python.org/dev/peps/pep-0591/)), also available to older versions in `typing_extensions.Final`. This has some overlap with `frozen`:\r\n\r\nAt type checking time, `frozen` is equivalent to marking all fields `Final`. So `Final` is more flexible, since if just one field is mutable, all the others can still be marked `Final`. But it is less ergonomic, though maybe we can convince `typing` to add a decorator which flips the default `Final`ity.\r\n\r\nAt run time, attrs adds runtime checks that the fields are not mutated, while `Final` doesn't. But I suppose attrs can detect `Final`, and add the same checks? So that should be equivalent.\nThanks for this effort, great stuff. I would humbly submit https://github.com/python-attrs/attrs/issues/391 for consideration. Stripping private attrs should not happen by default and instead be configurable with `private_stripping=True` or something like that.\nWe are about to standardize on `from attr import dataclass` everywhere in our codebase so I'm just wondering if there's been any movement on this lately :)\nWell, I'm annoyed of typing `@attr.s(auto_attribs=True, auto_exc=True, slots=True)` as the next person.\r\n\r\nAnd I've been cranking out PRs to fix all things that I want fixed before `import attrs` (notably #642, #635, and #607) but sadly nobody was reviewing so I just merged after two weeks of silence. So that takes a while with all the timeouts.\r\n\r\nThe last big remaining thing are pre-attribute `on_setattr` hooks that allow for both freezing single attributes and force validation on setting attributes. Been procrastinating on the spec for a while now but `attr.ib(on_setattr=run_validator)` seems like the correct default value and it would be a shame to not include it.\n> Well, I'm annoyed of typing @attr.s(auto_attribs=True, auto_exc=True, slots=True) as the next person.\r\n\r\nPerhaps a solution might be a \"templating\" approach, e.g. with some kind of a `AttrsTemplate` class or namedtuple:\r\n\r\n```python\r\nmy_template_1 = AttrsTemplate(auto_attrib=True)\r\nmy_template_2 = AttrsTemplate(auto_attrib=True, auto_exc=True)\r\n\r\n@attr.s(template=my_template_1)\r\nclass Foo:\r\n   ...\r\n```\r\n\r\n> The last big remaining thing are pre-attribute `on_setattr` hooks that allow for both freezing single attributes and force validation on setting attributes\r\n\r\nOooh I just needed that recently, ended up using metadata to denote \"mutability\" of an attribute.\nWork has started in #645!\n@berislavlopac in theory the templating approach can be accomplished by meta-decorators, right?\r\n\r\n```\r\ndef my_template_1(cls=None, **kwargs):\r\n    def decorator(cls):\r\n        return attrs(cls, **kwargs, auto_attrib=True, auto_exc=True)\r\n    return decorator(cls) if cls else decorator\r\n```\r\n\r\nI wonder if either documenting this pattern or providing some sugar for it, e.g.\r\n\r\n```\r\ndef attrs_template(**template_kwargs):\r\n    def the_template(cls=None, **attrs_kwargs):\r\n        def decorator(cls):\r\n            merged_kwargs = {**attrs_kwargs, **template_kwargs}\r\n            return attrs(cls, **merged_kwargs)\r\n        return decorator(cls) if cls else decorator\r\n    return the_template\r\n\r\nmy_template_1 = attrs_template(auto_exc=True, auto_attribs=True)\r\n\r\n@my_template_1(frozen=True)\r\nclass Foo:\r\n    bar: int\r\n```\r\n\r\n\nExcellent point, haven't though of this approach -- it would definitely be useful to at least be documented if not implemented in this way.\n@berislavlopac @petergaultney I use this approach all the time (https://github.com/Tinche/flattrs/blob/master/src/flattr/_fb_attrs.py#L35). Note that it needs special boilerplate if you're using mypy, and mypy doesn't perfectly support it.\n> `attr.ib(on_setattr=run_validator)`\r\n\r\nPerhaps _attr.ib(on_setattr=validate)_ would be a little more concise?\r\n\n> > `attr.ib(on_setattr=run_validator)`\r\n> \r\n> Perhaps _attr.ib(on_setattr=validate)_ would be a little more concise?\r\n\r\nThat\u2019s not really an issue since it\u2019s gonna be the default in upcoming APIs. I don\u2019t think we need to pollute our APIs with any sugar for it in the meantime.\nYou can simply use `partial`:\r\n\r\n```python\r\n>>> from functools import partial\r\n>>>\r\n>>> auto = partial(attrs, auto_attribs=True, auto_exc=True)\r\n>>>\r\n>>> @auto(frozen=True)  # additional parameters\r\n... class Foo:\r\n...     foo: int\r\n...\r\n>>> @auto               # no parameters and no parentheses\r\n... class Bar:\r\n...     bar: str\r\n...\r\n>>> Foo?\r\nInit signature: Foo(foo: int) -> None\r\n  ...\r\n>>> Bar?\r\nInit signature: Bar(bar: str) -> None\r\n  ...\r\n```\r\n\r\nYou can even stack these:\r\n\r\n```python\r\n>>> frozen = partial(auto, frozen=True)\r\n```\r\n\r\nGiven how easy and readable and pythonic this is, I think having the least magical defaults is very reasonable. Perhaps with the exception of `cache_hash`, are there reasons to not enable this by default for frozen instances?\r\n\r\nMypy is the bigger problem here, as it currently doesn't understand `partial`, and doesn't even understand `auto = attrs; @auto; class ...`\r\n\r\n\r\nP.S. I personally would like to be able to drop parentheses on `attrib` like this:\r\n\r\n```python\r\n@attrs\r\nclass Foo:\r\n    foo = attrib\r\n```\nSadly the mypy angle ruined this approach that I used to use all the time. :(\n> Mypy is the bigger problem here, as it currently doesn't understand `partial`, and doesn't even understand `auto = attrs; @auto; class ...`\r\n\r\nThis partial application decorator-forwarding usecase can be managed with a micro-plugin for mypy - you basically need something that says:\r\n\r\n```\r\nimport typing as ty\r\nfrom mypy.plugin import Plugin, ClassDefContext\r\nfrom mypy.plugins.attrs import attrs_class_maker_callback\r\n\r\nMODULE_PATH_TO_YOUR_DECORATOR = \"your.module.path.autoattrs\"\r\n\r\nclass AutoAttrsDecoratorPlugin(Plugin):\r\n    def get_class_decorator_hook(\r\n        self, fullname: str\r\n    ) -> ty.Optional[ty.Callable[[ClassDefContext], None]]:\r\n        def fwd_auto(cls_def_ctx: ClassDefContext):\r\n            if fullname == MODULE_PATH_TO_YOUR_DECORATOR:\r\n                attr_class_maker_callback(cls_def_ctx, True)\r\n        if fullname == MODULE_PATH_TO_YOUR_DECORATOR:\r\n            return fwd_auto\r\n        return None\r\n\r\ndef plugin(_version):\r\n    return AutoAttrsDecoratorPlugin\r\n```\r\n\r\nWhat this doesn't support is things like frozen - however the mypy attrs plugin itself could be trivially rewritten to expose those parameters directly for these sorts of mypy plugins.\r\n\r\n@hynek do you think mypy would accept a PR to make the built-in plugin more directly reusable? This whole mess of plugin code could probably be rewritten to be a one-liner that 'registers' a decorator with the mypy plugin.\n> @hynek do you think mypy would accept a PR to make the built-in plugin more directly reusable? This whole mess of plugin code could probably be rewritten to be a one-liner that 'registers' a decorator with the mypy plugin.\r\n\r\nI've opened an issue asking for this almost two years ago: https://github.com/python/mypy/issues/5406\r\n\r\nFWIW, #650 is of interest here too.\n> doesn't even understand `auto = attrs`;\r\n\r\nby the way, while assignment doesn't make mypy happy, importing under a different name does:\r\n\r\n```python\r\nif TYPE_CHECKING:\r\n    from attr import attrs as slotted\r\nelse:\r\n    slotted = functools.partial(attrs, slots=True)\r\n```\none thing which breaks some functional programming stuff, is the fact you can't do bracketed lookup with attrs objects\r\n```\r\na = {\"name\": \"a\"} \r\na[\"name\"] \r\n# a\r\n\r\n@attrs\r\nclass Person:\r\n    name: str = attrib()\r\n\r\na = Person(name=\"a\")\r\na[\"name\"]\r\n# TypeError: 'Person' object is not subscriptable\r\n```\r\nmeans you can't do functional lenses, lookPath, assocPath, dissocPath, evolvePath, are all legit, makes me miss Ramda!\r\nhow can we make attrs better for functional programming?\nYou can always implement your own `__getitem__`...\n```\r\n    def __getitem__(self, key):\r\n        return self.__getattribute__(key)\r\n```\r\nworked like a charm, thanks for reminding me, that would be a fun default to add!\nPlease check out #666 y'all.\nSo FTR, NG APIs will ship as stable in 21.1, _now_ is the last chance to ask for changes in APIs that are annoying.\r\n\r\nSo far there's #705 but I'm sure there might be more?\r\n\r\nTo be clear: define/mutable/frozen/field are set in stone now. But there's a buttload of other APIs that may benefit from polish?\nI just want to say thanks for `order=False` by default.  :pray: \nI think retain=True makes a lot of sense. \r\n\r\nAs much as I love tuples (and immutable data in general), it seems risky to (essentially) auto-convert lists to tuples. I imagine there's too much code out there that relies on the Python-wide \"default\" of mutable container types. It would work fine for my use cases, though.", "created_at": "2021-12-15T07:01:27Z"}
{"repo": "python-attrs/attrs", "pull_number": 886, "instance_id": "python-attrs__attrs-886", "issue_numbers": ["835"], "base_commit": "8ae0bd904d6147ce37750fa7ec336f951c14495c", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -59,6 +59,8 @@\n # Unique object for unequivocal getattr() defaults.\n _sentinel = object()\n \n+_ng_default_on_setattr = setters.pipe(setters.convert, setters.validate)\n+\n \n class _Nothing(object):\n     \"\"\"\n@@ -722,13 +724,31 @@ def __init__(\n             self._cls_dict[\"__delattr__\"] = _frozen_delattrs\n \n             self._wrote_own_setattr = True\n-        elif on_setattr == setters.validate:\n+        elif on_setattr in (\n+            _ng_default_on_setattr,\n+            setters.validate,\n+            setters.convert,\n+        ):\n+            has_validator = has_converter = False\n             for a in attrs:\n                 if a.validator is not None:\n+                    has_validator = True\n+                if a.converter is not None:\n+                    has_converter = True\n+\n+                if has_validator and has_converter:\n                     break\n-            else:\n-                # If class-level on_setattr is set to validating, but there's\n-                # no field to validate, pretend like there's no on_setattr.\n+            if (\n+                (\n+                    on_setattr == _ng_default_on_setattr\n+                    and not (has_validator or has_converter)\n+                )\n+                or (on_setattr == setters.validate and not has_validator)\n+                or (on_setattr == setters.convert and not has_converter)\n+            ):\n+                # If class-level on_setattr is set to convert + validate, but\n+                # there's no field to convert or validate, pretend like there's\n+                # no on_setattr.\n                 self._on_setattr = None\n \n         if getstate_setstate:\n@@ -2123,9 +2143,7 @@ def _make_init(\n                 raise ValueError(\"Frozen classes can't use on_setattr.\")\n \n             needs_cached_setattr = True\n-        elif (\n-            has_cls_on_setattr and a.on_setattr is not setters.NO_OP\n-        ) or _is_slot_attr(a.name, base_attr_map):\n+        elif has_cls_on_setattr and a.on_setattr is not setters.NO_OP:\n             needs_cached_setattr = True\n \n     unique_filename = _generate_unique_filename(cls, \"init\")\ndiff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -8,7 +8,13 @@\n from attr.exceptions import UnannotatedAttributeError\n \n from . import setters\n-from ._make import NOTHING, _frozen_setattrs, attrib, attrs\n+from ._make import (\n+    NOTHING,\n+    _frozen_setattrs,\n+    _ng_default_on_setattr,\n+    attrib,\n+    attrs,\n+)\n \n \n def define(\n@@ -35,8 +41,10 @@ def define(\n     match_args=True,\n ):\n     r\"\"\"\n-    The only behavioral differences are the handling of the *auto_attribs*\n-    option:\n+    Define an ``attrs`` class.\n+\n+    The behavioral differences to `attr.s` are the handling of the\n+    *auto_attribs* option:\n \n     :param Optional[bool] auto_attribs: If set to `True` or `False`, it behaves\n        exactly like `attr.s`. If left `None`, `attr.s` will try to guess:\n@@ -46,9 +54,11 @@ def define(\n        2. Otherwise it assumes *auto_attribs=False* and tries to collect\n           `attr.ib`\\ s.\n \n-    and that mutable classes (``frozen=False``) validate on ``__setattr__``.\n+    and that mutable classes (``frozen=False``) convert and validate on\n+    ``__setattr__``.\n \n     .. versionadded:: 20.1.0\n+    .. versionchanged:: 21.3.0 Converters are also run ``on_setattr``.\n     \"\"\"\n \n     def do_it(cls, auto_attribs):\n@@ -86,9 +96,9 @@ def wrap(cls):\n \n         had_on_setattr = on_setattr not in (None, setters.NO_OP)\n \n-        # By default, mutable classes validate on setattr.\n+        # By default, mutable classes convert & validate on setattr.\n         if frozen is False and on_setattr is None:\n-            on_setattr = setters.validate\n+            on_setattr = _ng_default_on_setattr\n \n         # However, if we subclass a frozen class, we inherit the immutability\n         # and disable on_setattr.\n", "test_patch": "diff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -17,7 +17,7 @@\n \n import attr\n \n-from attr._compat import PY2, TYPE\n+from attr._compat import PY2, PY36, TYPE\n from attr._make import NOTHING, Attribute\n from attr.exceptions import FrozenInstanceError\n \n@@ -692,8 +692,9 @@ class C(object):\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_no_setattr_if_validate_without_validators(self, slots):\n         \"\"\"\n-        If a class has on_setattr=attr.setters.validate (default in NG APIs)\n-        but sets no validators, don't use the (slower) setattr in __init__.\n+        If a class has on_setattr=attr.setters.validate (former default in NG\n+        APIs) but sets no validators, don't use the (slower) setattr in\n+        __init__.\n \n         Regression test for #816.\n         \"\"\"\n@@ -713,6 +714,58 @@ class D(C):\n         assert \"self.y = y\" in src\n         assert object.__setattr__ == D.__setattr__\n \n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_no_setattr_if_convert_without_converters(self, slots):\n+        \"\"\"\n+        If a class has on_setattr=attr.setters.convert but sets no validators,\n+        don't use the (slower) setattr in __init__.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=attr.setters.convert)\n+        class C(object):\n+            x = attr.ib()\n+\n+        @attr.s(on_setattr=attr.setters.convert)\n+        class D(C):\n+            y = attr.ib()\n+\n+        src = inspect.getsource(D.__init__)\n+\n+        assert \"setattr\" not in src\n+        assert \"self.x = x\" in src\n+        assert \"self.y = y\" in src\n+        assert object.__setattr__ == D.__setattr__\n+\n+    @pytest.mark.skipif(not PY36, reason=\"NG APIs are 3.6+\")\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_no_setattr_with_ng_defaults(self, slots):\n+        \"\"\"\n+        If a class has the NG default on_setattr=[convert, validate] but sets\n+        no validators or converters, don't use the (slower) setattr in\n+        __init__.\n+        \"\"\"\n+\n+        @attr.define\n+        class C(object):\n+            x = attr.ib()\n+\n+        src = inspect.getsource(C.__init__)\n+\n+        assert \"setattr\" not in src\n+        assert \"self.x = x\" in src\n+        assert object.__setattr__ == C.__setattr__\n+\n+        @attr.define\n+        class D(C):\n+            y = attr.ib()\n+\n+        src = inspect.getsource(D.__init__)\n+\n+        assert \"setattr\" not in src\n+        assert \"self.x = x\" in src\n+        assert \"self.y = y\" in src\n+        assert object.__setattr__ == D.__setattr__\n+\n     def test_on_setattr_detect_inherited_validators(self):\n         \"\"\"\n         _make_init detects the presence of a validator even if the field is\ndiff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -308,3 +308,28 @@ class MyException(Exception):\n \n         assert \"foo\" == ei.value.x\n         assert ei.value.__cause__ is None\n+\n+    def test_converts_and_validates_by_default(self):\n+        \"\"\"\n+        If no on_setattr is set, assume setters.convert, setters.validate.\n+        \"\"\"\n+\n+        @attr.define\n+        class C:\n+            x: int = attr.field(converter=int)\n+\n+            @x.validator\n+            def _v(self, _, value):\n+                if value < 10:\n+                    raise ValueError(\"must be >=10\")\n+\n+        inst = C(10)\n+\n+        # Converts\n+        inst.x = \"11\"\n+\n+        assert 11 == inst.x\n+\n+        # Validates\n+        with pytest.raises(ValueError, match=\"must be >=10\"):\n+            inst.x = \"9\"\n", "problem_statement": "Clarification - Converters vs on_setattr / Convert automatically when setting \nattrs version: 21.2.0\r\n\r\nUsing the documentation [on Converters](https://www.attrs.org/en/stable/init.html#converters) it was not immediately clear that converters only work on instantiation of a new attrs-enhanced class. (Or I totally missed something.) \r\n\r\n1. Is this the intended function? That the type conversion only happens on class instantiation and not when setting an attribute? (e.g. ```o.x = \"2\" ``` in the example in the documentation)\r\n    * If yes: Perhaps the documentation could be clarified to explain this and also provide a clear example of using ```on_setattr``` to also run the converter\r\n    * If no: Perhaps there's a bug because setting an attribute when a converter is specified does not work\r\n\r\nAnd further: from a logical design standpoint, it seems that if you're specifying a converter to be run at class instantiation [which means *all* values on *new* instances are run through that converter....] what circumstances would you *not* want that to run when setting attributes? Part of the purpose of converters is to ensure consistent typing and normalization (from the documentation: _\"Finally, sometimes you may want to normalize the values coming in. For that\u00a0attrs\u00a0comes with converters.\"_). Given that, it seems strange that you could break that normalization by simply setting an attribute.\r\n\r\nTL;DR: Converters only run on class instantiation. Shouldn't they be run when setting an attribute as well?\n", "hints_text": "Marking as documentation because `on_setattr` seems to lack narrative docs, and running converters and validators on set as well as init time is probably a common enough use case to warrant some text.\nI'm not sure where to put narrative information\u2026should we open a new chapter for it?\nI just ran into this behavior that validators are run on instantiation only. \r\nPlease find time to add this to https://www.attrs.org/en/stable/examples.html#validators as a warning. Its behavior is fine as it is as long as its documented. \r\nAs far as documenting on_setattr is concerned doing it bellow validators on same page would be nice. \r\nI have tried to implement it the same way i did validator (by using decorator example) but ended up with TypeError: 'NoneType\" object is not callable. In the end i just used standard python way to define setter via decorator. \r\nThanks\nI have added blurbs in 95b70bd, although I hope that by the next release, the examples will be rewritten using NG APIs.\r\n\r\n---\r\n\r\nAs for the original issue \u2013 I'm willing to break b/w compat here since the APIs are new and the impact is limited to few people. I honestly don't remember why I chose to only run validators \u2013 maybe because people kept complaining about it and I just\u2026forgot about converters?\n@hynek \r\nI am also complaining ! ;-)\r\nI would definitely need the converters also on_setattr !\r\n\r\n```\r\n@attr.define(slots=True)\r\nclass MyDataClass(object):\r\n    my_value=attr.ib(default=0, converter=int)\r\n\r\n>>> my_data=MyDataClass()\r\n>>> my_data.my_value='1'\r\n>>> assert 1 == my_data.my_value\r\n```\r\nbetter yesterday then tomorrow ;-),  i just needed to write ugly and slow own converters - \r\nit would have saved me a lot of effort it that would work.\r\n\r\nI just came here to put a question why it is not working - and landed at this thread.\r\n\r\nyours sincerely, und Gr\u00fc\u00dfe nach Berlin\r\n\r\nbitranox, Vienna\r\n\r\n\r\n", "created_at": "2021-12-13T13:23:03Z"}
{"repo": "python-attrs/attrs", "pull_number": 877, "instance_id": "python-attrs__attrs-877", "issue_numbers": ["875"], "base_commit": "fe19f4b341dbba5cda14b11d6a184105891c67e5", "patch": "diff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -14,6 +14,12 @@\n from .exceptions import NotCallableError\n \n \n+try:\n+    Pattern = re.Pattern\n+except AttributeError:  # Python <3.7 lacks a Pattern type.\n+    Pattern = type(re.compile(\"\"))\n+\n+\n __all__ = [\n     \"and_\",\n     \"deep_iterable\",\n@@ -129,8 +135,7 @@ def instance_of(type):\n \n @attrs(repr=False, frozen=True, slots=True)\n class _MatchesReValidator(object):\n-    regex = attrib()\n-    flags = attrib()\n+    pattern = attrib()\n     match_func = attrib()\n \n     def __call__(self, inst, attr, value):\n@@ -139,18 +144,18 @@ def __call__(self, inst, attr, value):\n         \"\"\"\n         if not self.match_func(value):\n             raise ValueError(\n-                \"'{name}' must match regex {regex!r}\"\n+                \"'{name}' must match regex {pattern!r}\"\n                 \" ({value!r} doesn't)\".format(\n-                    name=attr.name, regex=self.regex.pattern, value=value\n+                    name=attr.name, pattern=self.pattern.pattern, value=value\n                 ),\n                 attr,\n-                self.regex,\n+                self.pattern,\n                 value,\n             )\n \n     def __repr__(self):\n-        return \"<matches_re validator for pattern {regex!r}>\".format(\n-            regex=self.regex\n+        return \"<matches_re validator for pattern {pattern!r}>\".format(\n+            pattern=self.pattern\n         )\n \n \n@@ -159,7 +164,7 @@ def matches_re(regex, flags=0, func=None):\n     A validator that raises `ValueError` if the initializer is called\n     with a string that doesn't match *regex*.\n \n-    :param str regex: a regex string to match against\n+    :param regex: a regex string or precompiled pattern to match against\n     :param int flags: flags that will be passed to the underlying re function\n         (default 0)\n     :param callable func: which underlying `re` function to call (options\n@@ -169,34 +174,44 @@ def matches_re(regex, flags=0, func=None):\n         but on a pre-`re.compile`\\ ed pattern.\n \n     .. versionadded:: 19.2.0\n+    .. versionchanged:: 21.3.0 *regex* can be a pre-compiled pattern.\n     \"\"\"\n     fullmatch = getattr(re, \"fullmatch\", None)\n     valid_funcs = (fullmatch, None, re.search, re.match)\n     if func not in valid_funcs:\n         raise ValueError(\n-            \"'func' must be one of %s.\"\n-            % (\n+            \"'func' must be one of {}.\".format(\n                 \", \".join(\n                     sorted(\n                         e and e.__name__ or \"None\" for e in set(valid_funcs)\n                     )\n-                ),\n+                )\n             )\n         )\n \n-    pattern = re.compile(regex, flags)\n+    if isinstance(regex, Pattern):\n+        if flags:\n+            raise TypeError(\n+                \"'flags' can only be used with a string pattern; \"\n+                \"pass flags to re.compile() instead\"\n+            )\n+        pattern = regex\n+    else:\n+        pattern = re.compile(regex, flags)\n+\n     if func is re.match:\n         match_func = pattern.match\n     elif func is re.search:\n         match_func = pattern.search\n-    else:\n-        if fullmatch:\n-            match_func = pattern.fullmatch\n-        else:\n-            pattern = re.compile(r\"(?:{})\\Z\".format(regex), flags)\n-            match_func = pattern.match\n+    elif fullmatch:\n+        match_func = pattern.fullmatch\n+    else:  # Python 2 fullmatch emulation (https://bugs.python.org/issue16203)\n+        pattern = re.compile(\n+            r\"(?:{})\\Z\".format(pattern.pattern), pattern.flags\n+        )\n+        match_func = pattern.match\n \n-    return _MatchesReValidator(pattern, flags, match_func)\n+    return _MatchesReValidator(pattern, match_func)\n \n \n @attrs(repr=False, slots=True, hash=True)\n", "test_patch": "diff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -176,9 +176,9 @@ def test_match(self):\n \n         @attr.s\n         class ReTester(object):\n-            str_match = attr.ib(validator=matches_re(\"a\"))\n+            str_match = attr.ib(validator=matches_re(\"a|ab\"))\n \n-        ReTester(\"a\")  # shouldn't raise exceptions\n+        ReTester(\"ab\")  # shouldn't raise exceptions\n         with pytest.raises(TypeError):\n             ReTester(1)\n         with pytest.raises(ValueError):\n@@ -197,6 +197,29 @@ class MatchTester(object):\n \n         MatchTester(\"A1\")  # test flags and using re.match\n \n+    def test_precompiled_pattern(self):\n+        \"\"\"\n+        Pre-compiled patterns are accepted.\n+        \"\"\"\n+        pattern = re.compile(\"a\")\n+\n+        @attr.s\n+        class RePatternTester(object):\n+            val = attr.ib(validator=matches_re(pattern))\n+\n+        RePatternTester(\"a\")\n+\n+    def test_precompiled_pattern_no_flags(self):\n+        \"\"\"\n+        A pre-compiled pattern cannot be combined with a 'flags' argument.\n+        \"\"\"\n+        pattern = re.compile(\"\")\n+\n+        with pytest.raises(\n+            TypeError, match=\"can only be used with a string pattern\"\n+        ):\n+            matches_re(pattern, flags=re.IGNORECASE)\n+\n     def test_different_func(self):\n         \"\"\"\n         Changing the match functions works.\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -167,7 +167,7 @@ class Validated:\n             attr.validators.instance_of(C), attr.validators.instance_of(D)\n         ),\n     )\n-    e: str = attr.ib(validator=attr.validators.matches_re(r\"foo\"))\n+    e: str = attr.ib(validator=attr.validators.matches_re(re.compile(r\"foo\")))\n     f: str = attr.ib(\n         validator=attr.validators.matches_re(r\"foo\", flags=42, func=re.search)\n     )\n", "problem_statement": "matches_re() should accept re.Pattern in addition to str\n`attr.validators.matches_re()` does not accept precompiled regular expressions, and instead requires a `str` pattern (and optional flags).\r\n\r\nthis is not ideal when using existing compiled regular expressions, which already can have flags etc.\r\n\r\nit would be a nice addition if the same helper accepts `re.Pattern` (py37+) or `typing.Pattern` for those living in the past.\r\n\r\nopen questions:\r\n\r\n- would `flags=` be allowed if a `re.Pattern` is passed? compiled patterns cannot be \u2018reinterpreted\u2019 safely with different flags (e.g. `re.VERBOSE` changes many semantics). that means options are a) reject by raising an exception or b) ignore. my preference is raising.\r\n- in general any reason not to do this?\n", "hints_text": "(oh and i can take care of pull request etc)\nsure, go for it and raise if the alternative is not safe", "created_at": "2021-11-29T17:59:55Z"}
{"repo": "python-attrs/attrs", "pull_number": 847, "instance_id": "python-attrs__attrs-847", "issue_numbers": ["839"], "base_commit": "44ea327ab7f3a9c33578b1895f65314a81858dae", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -2573,19 +2573,26 @@ class Attribute(object):\n     \"\"\"\n     *Read-only* representation of an attribute.\n \n+    The class has *all* arguments of `attr.ib` (except for ``factory``\n+    which is only syntactic sugar for ``default=Factory(...)`` plus the\n+    following:\n+\n+    - ``name`` (`str`): The name of the attribute.\n+    - ``inherited`` (`bool`): Whether or not that attribute has been inherited\n+      from a base class.\n+    - ``eq_key`` and ``order_key`` (`typing.Callable` or `None`): The callables\n+      that are used for comparing and ordering objects by this attribute,\n+      respectively. These are set by passing a callable to `attr.ib`'s ``eq``,\n+      ``order``, or ``cmp`` arguments. See also :ref:`comparison customization\n+      <custom-comparison>`.\n+\n     Instances of this class are frequently used for introspection purposes\n     like:\n \n     - `fields` returns a tuple of them.\n     - Validators get them passed as the first argument.\n-    - The *field transformer* hook receives a list of them.\n-\n-    :attribute name: The name of the attribute.\n-    :attribute inherited: Whether or not that attribute has been inherited from\n-        a base class.\n-\n-    Plus *all* arguments of `attr.ib` (except for ``factory``\n-    which is only syntactic sugar for ``default=Factory(...)``.\n+    - The :ref:`field transformer <transform-fields>` hook receives a list of\n+      them.\n \n     .. versionadded:: 20.1.0 *inherited*\n     .. versionadded:: 20.1.0 *on_setattr*\n", "test_patch": "", "problem_statement": "eq_key and order_key undocumented\nI'd expect to see some docs here https://www.attrs.org/en/latest/api.html#attr.s and maybe an example\n", "hints_text": "There is no such thing? \ud83d\ude05 \r\n\r\ncmp/eq/order take additionally callables and there\u2019s https://www.attrs.org/en/latest/api.html#attr.cmp_using to help writing them? Or am I missing something?\nah this is on https://www.attrs.org/en/stable/api.html#attr.Attribute\r\n\r\n> New in version 21.1.0: eq_key and order_key\r\n\n> There is no such thing? sweat_smile\r\n\r\nah indeed! the doc should be on `attr.Attribute` \r\n", "created_at": "2021-10-02T15:00:19Z"}
{"repo": "python-attrs/attrs", "pull_number": 843, "instance_id": "python-attrs__attrs-843", "issue_numbers": ["842"], "base_commit": "7c99a4953085186790a28dd441a93dc665f61269", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -377,11 +377,9 @@ class and you didn't pass any attribs.\n     ..  versionadded:: 21.1.0 *attribs*\n \n     \"\"\"\n-    try:\n-        # Since calling get_type_hints is expensive we cache whether we've\n-        # done it already.\n-        cls.__attrs_types_resolved__\n-    except AttributeError:\n+    # Since calling get_type_hints is expensive we cache whether we've\n+    # done it already.\n+    if getattr(cls, \"__attrs_types_resolved__\", None) != cls:\n         import typing\n \n         hints = typing.get_type_hints(cls, globalns=globalns, localns=localns)\n@@ -389,7 +387,9 @@ class and you didn't pass any attribs.\n             if field.name in hints:\n                 # Since fields have been frozen we must work around it.\n                 _obj_setattr(field, \"type\", hints[field.name])\n-        cls.__attrs_types_resolved__ = True\n+        # We store the class we resolved so that subclasses know they haven't\n+        # been resolved.\n+        cls.__attrs_types_resolved__ = cls\n \n     # Return the class so you can use it as a decorator too.\n     return cls\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -618,6 +618,40 @@ class C:\n         with pytest.raises(NameError):\n             typing.get_type_hints(C.__init__)\n \n+    def test_inheritance(self):\n+        \"\"\"\n+        Subclasses can be resolved after the parent is resolved.\n+        \"\"\"\n+\n+        @attr.define()\n+        class A:\n+            n: \"int\"\n+\n+        @attr.define()\n+        class B(A):\n+            pass\n+\n+        attr.resolve_types(A)\n+        attr.resolve_types(B)\n+\n+        assert int == attr.fields(A).n.type\n+        assert int == attr.fields(B).n.type\n+\n+    def test_resolve_twice(self):\n+        \"\"\"\n+        You can call resolve_types as many times as you like.\n+        This test is here mostly for coverage.\n+        \"\"\"\n+\n+        @attr.define()\n+        class A:\n+            n: \"int\"\n+\n+        attr.resolve_types(A)\n+        assert int == attr.fields(A).n.type\n+        attr.resolve_types(A)\n+        assert int == attr.fields(A).n.type\n+\n \n @pytest.mark.parametrize(\n     \"annot\",\n", "problem_statement": "`attr.resolve_types` caches badly with inheritence\nReproduction case:\r\n\r\n```py\r\nfrom __future__ import annotations\r\n\r\nimport attr\r\n\r\n@attr.define()\r\nclass A:\r\n  n: int\r\n\r\n@attr.define()\r\nclass B(A):\r\n  pass\r\n\r\nattr.resolve_types(A)\r\nattr.resolve_types(B)\r\n\r\nprint(attr.fields(B))\r\n```\r\n\r\nI believe this is because `B` is somehow inheriting `A`'s `__attrs_types_resolved__`, even though it gets set later -- which means that it never had its types resolved, but it thinks it has.\r\n\r\nThis came up when I was using cattrs (I raised an issue there about a trouble I had debugging too :^), which means I do not control the resolution order of types without applying a `attr.resolve_types` decorator to every class (which might not work -- I'm not sure all my class declarations are in order either...)\n", "hints_text": "Oh.  This is a good one. Thanks for the report.  I'll get a fix in soon.  \r\n\r\n", "created_at": "2021-09-19T14:39:56Z"}
{"repo": "python-attrs/attrs", "pull_number": 830, "instance_id": "python-attrs__attrs-830", "issue_numbers": ["813", "813"], "base_commit": "2ca7aada707167cda9b3c8bbc2fd195e4f1aa422", "patch": "diff --git a/src/attr/converters.py b/src/attr/converters.py\n--- a/src/attr/converters.py\n+++ b/src/attr/converters.py\n@@ -109,3 +109,44 @@ def default_if_none_converter(val):\n             return default\n \n     return default_if_none_converter\n+\n+\n+def to_bool(val):\n+    \"\"\"\n+    Convert \"boolean\" strings (e.g., from env. vars.) to real booleans.\n+\n+    Values mapping to :code:`True`:\n+\n+    - :code:`True`\n+    - :code:`\"true\"` / :code:`\"t\"`\n+    - :code:`\"yes\"` / :code:`\"y\"`\n+    - :code:`\"on\"`\n+    - :code:`\"1\"`\n+    - :code:`1`\n+\n+    Values mapping to :code:`False`:\n+\n+    - :code:`False`\n+    - :code:`\"false\"` / :code:`\"f\"`\n+    - :code:`\"no\"` / :code:`\"n\"`\n+    - :code:`\"off\"`\n+    - :code:`\"0\"`\n+    - :code:`0`\n+\n+    :raises ValueError: for any other value.\n+\n+    .. versionadded:: 21.3.0\n+    \"\"\"\n+    if isinstance(val, str):\n+        val = val.lower()\n+    truthy = {True, \"true\", \"t\", \"yes\", \"y\", \"on\", \"1\", 1}\n+    falsy = {False, \"false\", \"f\", \"no\", \"n\", \"off\", \"0\", 0}\n+    try:\n+        if val in truthy:\n+            return True\n+        if val in falsy:\n+            return False\n+    except TypeError:\n+        # Raised when \"val\" is not hashable (e.g., lists)\n+        pass\n+    raise ValueError(\"Cannot convert value to bool: {}\".format(val))\n", "test_patch": "diff --git a/tests/test_converters.py b/tests/test_converters.py\n--- a/tests/test_converters.py\n+++ b/tests/test_converters.py\n@@ -4,14 +4,12 @@\n \n from __future__ import absolute_import\n \n-from distutils.util import strtobool\n-\n import pytest\n \n import attr\n \n from attr import Factory, attrib\n-from attr.converters import default_if_none, optional, pipe\n+from attr.converters import default_if_none, optional, pipe, to_bool\n \n \n class TestOptional(object):\n@@ -106,7 +104,7 @@ def test_success(self):\n         \"\"\"\n         Succeeds if all wrapped converters succeed.\n         \"\"\"\n-        c = pipe(str, strtobool, bool)\n+        c = pipe(str, to_bool, bool)\n \n         assert True is c(\"True\") is c(True)\n \n@@ -114,7 +112,7 @@ def test_fail(self):\n         \"\"\"\n         Fails if any wrapped converter fails.\n         \"\"\"\n-        c = pipe(str, strtobool)\n+        c = pipe(str, to_bool)\n \n         # First wrapped converter fails:\n         with pytest.raises(ValueError):\n@@ -131,8 +129,33 @@ def test_sugar(self):\n \n         @attr.s\n         class C(object):\n-            a1 = attrib(default=\"True\", converter=pipe(str, strtobool, bool))\n-            a2 = attrib(default=True, converter=[str, strtobool, bool])\n+            a1 = attrib(default=\"True\", converter=pipe(str, to_bool, bool))\n+            a2 = attrib(default=True, converter=[str, to_bool, bool])\n \n         c = C()\n         assert True is c.a1 is c.a2\n+\n+\n+class TestToBool(object):\n+    def test_unhashable(self):\n+        \"\"\"\n+        Fails if value is unhashable.\n+        \"\"\"\n+        with pytest.raises(ValueError, match=\"Cannot convert value to bool\"):\n+            to_bool([])\n+\n+    def test_truthy(self):\n+        \"\"\"\n+        Fails if truthy values are incorrectly converted.\n+        \"\"\"\n+        assert to_bool(\"t\")\n+        assert to_bool(\"yes\")\n+        assert to_bool(\"on\")\n+\n+    def test_falsy(self):\n+        \"\"\"\n+        Fails if falsy values are incorrectly converted.\n+        \"\"\"\n+        assert not to_bool(\"f\")\n+        assert not to_bool(\"no\")\n+        assert not to_bool(\"off\")\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -118,6 +118,20 @@ class Error(Exception):\n # ConvCDefaultIfNone(None)\n \n \n+# @attr.s\n+# class ConvCToBool:\n+#     x: int = attr.ib(converter=attr.converters.to_bool)\n+\n+\n+# ConvCToBool(1)\n+# ConvCToBool(True)\n+# ConvCToBool(\"on\")\n+# ConvCToBool(\"yes\")\n+# ConvCToBool(0)\n+# ConvCToBool(False)\n+# ConvCToBool(\"n\")\n+\n+\n # Validators\n @attr.s\n class Validated:\n", "problem_statement": "Python 3.10 deprecation in tests due to distutils \nThe function is simple enough to be vendored for tests.\r\n\r\n```\r\ntests/test_converters.py:7\r\n  /root/checked_repos/attrs/tests/test_converters.py:7: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n    from distutils.util import strtobool\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\r\n```\r\n\r\nhttps://github.com/python-attrs/attrs/blob/d0cff8face92478c950ba05a7d9403b1e342407a/tests/test_converters.py#L7\nPython 3.10 deprecation in tests due to distutils \nThe function is simple enough to be vendored for tests.\r\n\r\n```\r\ntests/test_converters.py:7\r\n  /root/checked_repos/attrs/tests/test_converters.py:7: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\r\n    from distutils.util import strtobool\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\r\n```\r\n\r\nhttps://github.com/python-attrs/attrs/blob/d0cff8face92478c950ba05a7d9403b1e342407a/tests/test_converters.py#L7\n", "hints_text": "I\u2018d add this as\r\n```python\r\ndef to_bool(val: Any) -> bool:\r\n    \"\"\"\r\n    Convert \"boolean\" strings (e.g., from env. vars.) to real booleans.\r\n\r\n    Values mapping to :code:`True`:\r\n\r\n    - :code:`True`\r\n    - :code:`\"true\"` / :code:`\"t\"`\r\n    - :code:`\"yes\"` / :code:`\"y\"`\r\n    - :code:`\"on\"`\r\n    - :code:`\"1\"`\r\n    - :code:`1`\r\n\r\n    Values mapping to :code:`False`:\r\n\r\n    - :code:`False`\r\n    - :code:`\"false\"` / :code:`\"f\"`\r\n    - :code:`\"no\"` / :code:`\"n\"`\r\n    - :code:`\"off\"`\r\n    - :code:`\"0\"`\r\n    - :code:`0`\r\n\r\n    Raise :exc:`ValueError` for any other value.\r\n    \"\"\"\r\n    if isinstance(val, str):\r\n        val = val.lower()\r\n    truthy = {True, \"true\", \"t\", \"yes\", \"y\", \"on\", \"1\", 1}\r\n    falsy = {False, \"false\", \"f\", \"no\", \"n\", \"off\", \"0\", 0}\r\n    try:\r\n        if val in truthy:\r\n            return True\r\n        if val in falsy:\r\n            return False\r\n    except TypeError:\r\n        # Raised when \"val\" is not hashable (e.g., lists)\r\n        pass\r\n    raise ValueError(f\"Cannot convert value to bool: {val}\")\r\n```\r\nto `converters.py`.  It could then also be used as field converter. \r\n\r\nThis function is already part of typed-settings and I intended to eventually move it to attrs.\r\n\r\n@hynek, what do you think?\nSGTM but remember to put the annotations into the stub file. :)\nI\u2018d add this as\r\n```python\r\ndef to_bool(val: Any) -> bool:\r\n    \"\"\"\r\n    Convert \"boolean\" strings (e.g., from env. vars.) to real booleans.\r\n\r\n    Values mapping to :code:`True`:\r\n\r\n    - :code:`True`\r\n    - :code:`\"true\"` / :code:`\"t\"`\r\n    - :code:`\"yes\"` / :code:`\"y\"`\r\n    - :code:`\"on\"`\r\n    - :code:`\"1\"`\r\n    - :code:`1`\r\n\r\n    Values mapping to :code:`False`:\r\n\r\n    - :code:`False`\r\n    - :code:`\"false\"` / :code:`\"f\"`\r\n    - :code:`\"no\"` / :code:`\"n\"`\r\n    - :code:`\"off\"`\r\n    - :code:`\"0\"`\r\n    - :code:`0`\r\n\r\n    Raise :exc:`ValueError` for any other value.\r\n    \"\"\"\r\n    if isinstance(val, str):\r\n        val = val.lower()\r\n    truthy = {True, \"true\", \"t\", \"yes\", \"y\", \"on\", \"1\", 1}\r\n    falsy = {False, \"false\", \"f\", \"no\", \"n\", \"off\", \"0\", 0}\r\n    try:\r\n        if val in truthy:\r\n            return True\r\n        if val in falsy:\r\n            return False\r\n    except TypeError:\r\n        # Raised when \"val\" is not hashable (e.g., lists)\r\n        pass\r\n    raise ValueError(f\"Cannot convert value to bool: {val}\")\r\n```\r\nto `converters.py`.  It could then also be used as field converter. \r\n\r\nThis function is already part of typed-settings and I intended to eventually move it to attrs.\r\n\r\n@hynek, what do you think?\nSGTM but remember to put the annotations into the stub file. :)", "created_at": "2021-07-07T19:40:01Z"}
{"repo": "python-attrs/attrs", "pull_number": 817, "instance_id": "python-attrs__attrs-817", "issue_numbers": ["816"], "base_commit": "8ae2d6f1c3c067c941fd9d212e52972c7d3382cc", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -654,7 +654,7 @@ class _ClassBuilder(object):\n         \"_on_setattr\",\n         \"_slots\",\n         \"_weakref_slot\",\n-        \"_has_own_setattr\",\n+        \"_wrote_own_setattr\",\n         \"_has_custom_setattr\",\n     )\n \n@@ -701,7 +701,7 @@ def __init__(\n         self._on_setattr = on_setattr\n \n         self._has_custom_setattr = has_custom_setattr\n-        self._has_own_setattr = False\n+        self._wrote_own_setattr = False\n \n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n \n@@ -709,7 +709,15 @@ def __init__(\n             self._cls_dict[\"__setattr__\"] = _frozen_setattrs\n             self._cls_dict[\"__delattr__\"] = _frozen_delattrs\n \n-            self._has_own_setattr = True\n+            self._wrote_own_setattr = True\n+        elif on_setattr == setters.validate:\n+            for a in attrs:\n+                if a.validator is not None:\n+                    break\n+            else:\n+                # If class-level on_setattr is set to validating, but there's\n+                # no field to validate, pretend like there's no on_setattr.\n+                self._on_setattr = None\n \n         if getstate_setstate:\n             (\n@@ -759,7 +767,7 @@ def _patch_original_class(self):\n \n         # If we've inherited an attrs __setattr__ and don't write our own,\n         # reset it to object's.\n-        if not self._has_own_setattr and getattr(\n+        if not self._wrote_own_setattr and getattr(\n             cls, \"__attrs_own_setattr__\", False\n         ):\n             cls.__attrs_own_setattr__ = False\n@@ -787,7 +795,7 @@ def _create_slots_class(self):\n         # XXX: a non-attrs class and subclass the resulting class with an attrs\n         # XXX: class.  See `test_slotted_confused` for details.  For now that's\n         # XXX: OK with us.\n-        if not self._has_own_setattr:\n+        if not self._wrote_own_setattr:\n             cd[\"__attrs_own_setattr__\"] = False\n \n             if not self._has_custom_setattr:\n@@ -958,8 +966,7 @@ def add_init(self):\n                 self._cache_hash,\n                 self._base_attr_map,\n                 self._is_exc,\n-                self._on_setattr is not None\n-                and self._on_setattr is not setters.NO_OP,\n+                self._on_setattr,\n                 attrs_init=False,\n             )\n         )\n@@ -978,8 +985,7 @@ def add_attrs_init(self):\n                 self._cache_hash,\n                 self._base_attr_map,\n                 self._is_exc,\n-                self._on_setattr is not None\n-                and self._on_setattr is not setters.NO_OP,\n+                self._on_setattr,\n                 attrs_init=True,\n             )\n         )\n@@ -1038,7 +1044,7 @@ def __setattr__(self, name, val):\n \n         self._cls_dict[\"__attrs_own_setattr__\"] = True\n         self._cls_dict[\"__setattr__\"] = self._add_method_dunders(__setattr__)\n-        self._has_own_setattr = True\n+        self._wrote_own_setattr = True\n \n         return self\n \n@@ -2008,10 +2014,14 @@ def _make_init(\n     cache_hash,\n     base_attr_map,\n     is_exc,\n-    has_global_on_setattr,\n+    cls_on_setattr,\n     attrs_init,\n ):\n-    if frozen and has_global_on_setattr:\n+    has_cls_on_setattr = (\n+        cls_on_setattr is not None and cls_on_setattr is not setters.NO_OP\n+    )\n+\n+    if frozen and has_cls_on_setattr:\n         raise ValueError(\"Frozen classes can't use on_setattr.\")\n \n     needs_cached_setattr = cache_hash or frozen\n@@ -2030,7 +2040,7 @@ def _make_init(\n \n             needs_cached_setattr = True\n         elif (\n-            has_global_on_setattr and a.on_setattr is not setters.NO_OP\n+            has_cls_on_setattr and a.on_setattr is not setters.NO_OP\n         ) or _is_slot_attr(a.name, base_attr_map):\n             needs_cached_setattr = True\n \n@@ -2046,7 +2056,7 @@ def _make_init(\n         base_attr_map,\n         is_exc,\n         needs_cached_setattr,\n-        has_global_on_setattr,\n+        has_cls_on_setattr,\n         attrs_init,\n     )\n     if cls.__module__ in sys.modules:\n@@ -2183,7 +2193,7 @@ def _attrs_to_init_script(\n     base_attr_map,\n     is_exc,\n     needs_cached_setattr,\n-    has_global_on_setattr,\n+    has_cls_on_setattr,\n     attrs_init,\n ):\n     \"\"\"\n@@ -2257,7 +2267,7 @@ def fmt_setter_with_converter(\n \n         attr_name = a.name\n         has_on_setattr = a.on_setattr is not None or (\n-            a.on_setattr is not setters.NO_OP and has_global_on_setattr\n+            a.on_setattr is not setters.NO_OP and has_cls_on_setattr\n         )\n         arg_name = a.name.lstrip(\"_\")\n \n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -94,7 +94,7 @@ def _add_init(cls, frozen):\n         cache_hash=False,\n         base_attr_map={},\n         is_exc=False,\n-        has_global_on_setattr=False,\n+        cls_on_setattr=None,\n         attrs_init=False,\n     )\n     return cls\ndiff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -4,6 +4,7 @@\n \n from __future__ import absolute_import, division, print_function\n \n+import inspect\n import pickle\n \n from copy import deepcopy\n@@ -687,3 +688,48 @@ class C(object):\n             \"2021-06-01.  Please use `eq` and `order` instead.\"\n             == w.message.args[0]\n         )\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_no_setattr_if_validate_without_validators(self, slots):\n+        \"\"\"\n+        If a class has on_setattr=attr.setters.validate (default in NG APIs)\n+        but sets no validators, don't use the (slower) setattr in __init__.\n+\n+        Regression test for #816.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=attr.setters.validate)\n+        class C(object):\n+            x = attr.ib()\n+\n+        @attr.s(on_setattr=attr.setters.validate)\n+        class D(C):\n+            y = attr.ib()\n+\n+        src = inspect.getsource(D.__init__)\n+\n+        assert \"setattr\" not in src\n+        assert \"self.x = x\" in src\n+        assert \"self.y = y\" in src\n+        assert object.__setattr__ == D.__setattr__\n+\n+    def test_on_setattr_detect_inherited_validators(self):\n+        \"\"\"\n+        _make_init detects the presence of a validator even if the field is\n+        inherited.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=attr.setters.validate)\n+        class C(object):\n+            x = attr.ib(validator=42)\n+\n+        @attr.s(on_setattr=attr.setters.validate)\n+        class D(C):\n+            y = attr.ib()\n+\n+        src = inspect.getsource(D.__init__)\n+\n+        assert \"_setattr = _cached_setattr\" in src\n+        assert \"_setattr('x', x)\" in src\n+        assert \"_setattr('y', y)\" in src\n+        assert object.__setattr__ != D.__setattr__\n", "problem_statement": "Warning in docs about frozen classes no longer applicable\nIf you check the docs on frozen classes (https://www.attrs.org/en/stable/how-does-it-work.html#immutability), you'll note it says \"You should avoid instantiating lots of frozen slotted classes [...] in performance-critical code.\"\r\n\r\nHowever... with `attr.define`/`attr.frozen` both take the same amount of time.\r\n\r\n```py\r\nIn [1]: import attr\r\n\r\nIn [2]: @attr.frozen\r\n   ...: class SlottedFrozen:\r\n   ...:     foo: int\r\n   ...:     bar: int\r\n   ...:     baz: str\r\n   ...:     bing: float = 5.0\r\n   ...: \r\n\r\nIn [3]: @attr.define\r\n   ...: class SlottedUnfrozen:\r\n   ...:     foo: int\r\n   ...:     bar: int\r\n   ...:     baz: str\r\n   ...:     bing: float = 5.0\r\n   ...: \r\n\r\nIn [4]: @attr.s(slots=True, frozen=True, auto_attribs=True)\r\n   ...: class OldSlottedFrozen:\r\n   ...:     foo: int\r\n   ...:     bar: int\r\n   ...:     baz: str\r\n   ...:     bing: float = 5.0\r\n   ...: \r\n\r\nIn [5]: @attr.s(slots=True, auto_attribs=True)\r\n   ...: class OldSlottedUnfrozen:\r\n   ...:     foo: int\r\n   ...:     bar: int\r\n   ...:     baz: str\r\n   ...:     bing: float = 5.0\r\n   ...: \r\n\r\nIn [6]: %timeit SlottedFrozen(7, 42, \"hi!\")\r\n553 ns \u00b1 10.6 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)\r\n\r\nIn [7]: %timeit SlottedUnfrozen(7, 42, \"hi!\")\r\n566 ns \u00b1 17.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)\r\n\r\nIn [8]: %timeit OldSlottedFrozen(7, 42, \"hi!\")\r\n553 ns \u00b1 8.64 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)\r\n\r\nIn [9]: %timeit OldSlottedUnfrozen(7, 42, \"hi!\")\r\n296 ns \u00b1 3.09 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)\r\n```\r\n\r\nWhat's up? Well, turns out the new API is setting `on_setattr=attr.setters.validate`. This turns the `__init__` from this: (old)\r\n```py\r\nIn [14]: print(inspect.getsource(OldSlottedUnfrozen.__init__))\r\ndef __init__(self, foo, bar, baz, bing=attr_dict['bing'].default):\r\n    self.foo = foo\r\n    self.bar = bar\r\n    self.baz = baz\r\n    self.bing = bing\r\n```\r\n\r\nTo this: (new)\r\n```py\r\nIn [15]: print(inspect.getsource(SlottedUnfrozen.__init__))\r\ndef __init__(self, foo, bar, baz, bing=attr_dict['bing'].default):\r\n    _setattr = _cached_setattr.__get__(self, self.__class__)\r\n    _setattr('foo', foo)\r\n    _setattr('bar', bar)\r\n    _setattr('baz', baz)\r\n    _setattr('bing', bing)\r\n```\r\n\r\nPossible solutions:\r\n - Mark that the note no longer applies\r\n - Make a fast path -- only set `on_setattr=attr.setters.validate` in new API if there is a validator.\n", "hints_text": "Ooph, I was not aware of this. A fast path would be great here.\nYeah fast path is definitely the way here. I'm surprised there isn't one \u2013 I suspect I just forgot to implement it.", "created_at": "2021-05-16T10:15:41Z"}
{"repo": "python-attrs/attrs", "pull_number": 806, "instance_id": "python-attrs__attrs-806", "issue_numbers": ["804"], "base_commit": "24a2c1e7a5b1b1b979a647de2ef36a35ff4c39a1", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -319,8 +319,7 @@ def evolve(inst, **changes):\n     Create a new instance, based on *inst* with *changes* applied.\n \n     :param inst: Instance of a class with ``attrs`` attributes.\n-    :param changes: Keyword changes in the new copy.  Nested ``attrs`` classes\n-       can be updated by passing (nested) dicts of values.\n+    :param changes: Keyword changes in the new copy.\n \n     :return: A copy of inst with *changes* incorporated.\n \n@@ -338,13 +337,8 @@ def evolve(inst, **changes):\n             continue\n         attr_name = a.name  # To deal with private attributes.\n         init_name = attr_name if attr_name[0] != \"_\" else attr_name[1:]\n-        value = getattr(inst, attr_name)\n         if init_name not in changes:\n-            # Add original value to changes\n-            changes[init_name] = value\n-        elif has(value):\n-            # Evolve nested attrs classes\n-            changes[init_name] = evolve(value, **changes[init_name])\n+            changes[init_name] = getattr(inst, attr_name)\n \n     return cls(**changes)\n \n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -598,43 +598,50 @@ class C(object):\n \n         assert evolve(C(1), a=2).a == 2\n \n-    def test_recursive(self):\n+    def test_regression_attrs_classes(self):\n         \"\"\"\n-        evolve() recursively evolves nested attrs classes when a dict is\n-        passed for an attribute.\n+        evolve() can evolve fields that are instances of attrs classes.\n+\n+        Regression test for #804\n         \"\"\"\n \n         @attr.s\n-        class N2(object):\n-            e = attr.ib(type=int)\n+        class Cls1(object):\n+            param1 = attr.ib()\n \n         @attr.s\n-        class N1(object):\n-            c = attr.ib(type=N2)\n-            d = attr.ib(type=int)\n+        class Cls2(object):\n+            param2 = attr.ib()\n \n-        @attr.s\n-        class C(object):\n-            a = attr.ib(type=N1)\n-            b = attr.ib(type=int)\n+        obj2a = Cls2(param2=\"a\")\n+        obj2b = Cls2(param2=\"b\")\n \n-        c1 = C(N1(N2(1), 2), 3)\n-        c2 = evolve(c1, a={\"c\": {\"e\": 23}}, b=42)\n+        obj1a = Cls1(param1=obj2a)\n \n-        assert c2 == C(N1(N2(23), 2), 42)\n+        assert Cls1(param1=Cls2(param2=\"b\")) == attr.evolve(\n+            obj1a, param1=obj2b\n+        )\n \n-    def test_recursive_dict_val(self):\n+    def test_dicts(self):\n         \"\"\"\n-        evolve() only attempts recursion when the current value is an ``attrs``\n-        class.  Dictionaries as values can be replaced like any other value.\n+        evolve() can replace an attrs class instance with a dict.\n+\n+        See #806\n         \"\"\"\n \n         @attr.s\n-        class C(object):\n-            a = attr.ib(type=dict)\n-            b = attr.ib(type=int)\n+        class Cls1(object):\n+            param1 = attr.ib()\n+\n+        @attr.s\n+        class Cls2(object):\n+            param2 = attr.ib()\n \n-        c1 = C({\"spam\": 1}, 2)\n-        c2 = evolve(c1, a={\"eggs\": 2}, b=42)\n+        obj2a = Cls2(param2=\"a\")\n+        obj2b = {\"foo\": 42, \"param2\": 42}\n \n-        assert c2 == C({\"eggs\": 2}, 42)\n+        obj1a = Cls1(param1=obj2a)\n+\n+        assert Cls1({\"foo\": 42, \"param2\": 42}) == attr.evolve(\n+            obj1a, param1=obj2b\n+        )\n", "problem_statement": "`attr.evolve` no longer supports setting an attr object as attribute\nHi,\r\n\r\nI don't know if this is an intentional side-effect of #759, but `attr.evolve` no longer works in the non-recursive recursive case if the argument is an attr class.\r\n\r\nHere is a snippet to reproduce it:\r\n\r\n```py\r\nimport attr\r\n\r\n@attr.s\r\nclass Cls1:\r\n    param1 = attr.ib()\r\n\r\n\r\n@attr.s\r\nclass Cls2:\r\n    param2 = attr.ib()\r\n\r\n\r\nobj2a = Cls2(param2=\"a\")\r\nobj2b = Cls2(param2=\"b\")\r\n\r\nobj1a = Cls1(param1=obj2a)\r\nobj1b = attr.evolve(obj1a, param1=obj2b)\r\n\r\nprint(obj1b)\r\n```\r\n\r\nBefore fe6eb3120013833d1927374eb5e826b72815a775, it printed this: `Cls1(param1=Cls2(param2='b'))`\r\n\r\nBut after this commit, it raises this error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 17, in <module>\r\n    obj1b = attr.evolve(obj1a, param1=obj2b)\r\n  File \"/home/dev/.local/lib/python3.7/site-packages/attrs-21.2.0.dev0-py3.7.egg/attr/_funcs.py\", line 347, in evolve\r\n    changes[init_name] = evolve(value, **changes[init_name])\r\nTypeError: evolve() argument after ** must be a mapping, not Cls2\r\n```\r\n\r\nThanks!\n", "hints_text": "same here. Issue is in attr._funcs.evolve at:\r\n```\r\n    for a in attrs:\r\n        ...\r\n        elif has(value):\r\n            # Evolve nested attrs classes\r\n            changes[init_name] = evolve(value, **changes[init_name])\r\n```\r\n`value` - is old value (param1 from example above)\r\n`changes[init_name]` - is new value (obj2b from above) \r\nbut for recursive evolve it should be dict\r\nprobably the best way to make it backward compatible will be to check\r\n`elif has(value) and isinstance(changes[init_name], Mapping):`\nYeah, we'll have to revert #759 and push out 21.2.\r\n\r\nI'm gonna wait a bit with the release to see if there's other breakages that should be fixed.", "created_at": "2021-05-06T12:26:12Z"}
{"repo": "python-attrs/attrs", "pull_number": 786, "instance_id": "python-attrs__attrs-786", "issue_numbers": ["668"], "base_commit": "6d1d5e9055c708611dab50650afb2de97543c2f6", "patch": "diff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -1,8 +1,6 @@\n \"\"\"\n-This is a Python 3.6 and later-only, keyword-only, and **provisional** API that\n-calls `attr.s` with different default values.\n-\n-Provisional APIs that shall become \"import attrs\" one glorious day.\n+These are Python 3.6+-only and keyword-only APIs that call `attr.s` and\n+`attr.ib` with different default values.\n \"\"\"\n \n from functools import partial\n", "test_patch": "", "problem_statement": "Feedback to next generation APIs\nThis is the issue to discuss the defaults and behavior of `attr.define()`, `attr.mutable()`, and `attr.frozen()` before they are finalized inside the new `attrs` namespace.\r\n\r\nFeedback that we find justified will be spun out into separate issues.\r\n\r\nKnown issues:\r\n\r\n- mypy doesn't know about the new-style APIs yet and there's nothing _we_ can do about it. However you can use [this mypy plugin](https://gist.github.com/hynek/1e3844d0c99e479e716169034b5fa963#file-attrs_ng_plugin-py) for now (for more details see https://www.attrs.org/en/stable/extending.html#wrapping-the-decorator). PR is submitted in https://github.com/python/mypy/pull/9396.\r\n- `__eq__` and `__ne__` aren't correctly auto-detected (fixed) #670 \r\n- Unannotated attributes fail if `define` is called with arguments/parantheses (fixed) #673\r\n- Inheriting from frozen classes requires to manually set `on_setattr` to None (fixed). https://github.com/python-attrs/attrs/issues/668#issuecomment-678689981)\n", "hints_text": "Overall I love the new APIs. When updating some code to use `@attr.define` instead of `@attr.s(auto_attribs=True)`, I was surprised by one behavior of slotted classes -- you don't seem to be able to use `unittest.mock.patch.object()` on methods on instances of slotted classes. It's not a result of anything in attrs (in the code snippet below I don't use attrs at all), but it might be worth noting in [the docs](https://www.attrs.org/en/stable/glossary.html#term-slotted-classes) since making `slots=True` the default behavior means attrs will be how many people encounter this for the first time.\r\n\r\n```python\r\nimport unittest.mock\r\n\r\nclass Slotted:\r\n    __slots__ = ()\r\n\r\n    def method(self):\r\n        return 1\r\n\r\ns = Slotted()\r\nassert s.method() == 1\r\n\r\nwith unittest.mock.patch.object(s, \"method\", return_value=3):\r\n    assert s.method() == 3\r\n\r\n# Errors with:\r\n# Traceback (most recent call last):\r\n#   File \"/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/unittest/mock.py\", line 1490, in __enter__\r\n#     setattr(self.target, self.attribute, new_attr)\r\n# AttributeError: 'Slotted' object attribute 'method' is read-only\r\n```\nAh yeah, thanks for that reminder, I will add it to the glossary!\nHmm. I'm not sure I like the hybrid behavior.  \r\n\r\nImagine I forget to annotate something.  Now instead of getting a nice error at import time I have to wait until I try to create something.\r\n```\r\nfrom attr import define, field\r\n\r\n@define()\r\nclass A:\r\n    x: int\r\n    y = field(8)\r\n```\r\n\r\nOh this case is actually pretty bad because I might not catch it even if i do `A(8)` \r\n\r\n\nI thought about this for a while too.\r\n\r\nI decided it\u2019s worth the comfort because the only possible confusing error state is the one you describe and it\u2019s impossible to miss even short-term when an attribute is missing. I\u2019m open to being convinced otherwise but ISTM that in practice this trade-off is worth it. \ud83e\udd14 \nHow about the following: `auto_attrib=None` = Hybrid, everything else means what it means now?\nWhat's the default value?  (I suggest auto_attribs=True but that's my personal preference because I always write type annotated code)\r\n\r\nI'd also like it if auto_attrib=None would raise if it found a mixture of attribs and annotations.  Is it ok to add this to _transform_attrs or is affecting attr.s not something we should do?\r\n \n> What's the default value? (I suggest auto_attribs=True but that's my personal preference because I always write type annotated code)\r\n> \r\n> I'd also like it if auto_attrib=None would raise if it found a mixture of attribs and annotations. Is it ok to add this to _transform_attrs or is affecting attr.s not something we should do?\r\n\r\nWell None would be default which means \u201cguess\u201d. I\u2019m Camp True too, but I don\u2019t want to punish the typing haters for whine attrs is currently the only refuge.\r\n\r\nI don\u2019t thing an error on a mix of attr.ib and annotations is feasible because there a valid use cases for that. Maybe raise an error but add an option to override it?\nI don't really see a good use for this:\r\n```\r\n@define()\r\nclass A:\r\n    x: int\r\n    y = field(8)\r\n```\r\nA.x won't exist and you won't be able to add it because of `__slots__`. Worst of all, mypy will think it exists.\r\n\r\nPerhaps this could be ok:\r\n```\r\n@define()\r\nclass A:\r\n    x: int = 72\r\n    y = field(8)\r\n```\r\n\r\nBut one could argue that it should be:\r\n```\r\n@define()\r\nclass A:\r\n    x: ClassVar[int] = 72\r\n    y = field(8)\r\n```\r\n\r\nBecause it's gonna be a Class attribute not an instance one.\r\n\r\n\r\n\nOh and thinking about it more `auto_attribs=None` is a fine default value.  Because if I use annotations they'll work the way I want them.  (i.e. I don't have to add `auto_attribs=True` everywhere.\nTo be clear: it\u2019s 100% not gonna be necessary to pass slots=True or auto_attribs=True because that\u2019s _my_ settings. \ud83d\ude05 The q now is how to handle your scenario.  Truth to be told we can raise an error and when someone complains, we can still add an option to allow for it?\nThat option could be `auto_attribs=False`. :) Or did you want some kind of global disable?\nGod No \ud83d\ude05! I\u2019m just trying to find a way where the common use case is not passing anything and it just works \u2013 ideally without exposing the users to sharp edges.\nJust did a quick regex change on our code base, looking for trouble.  I did find 2 interesting issues:\r\n\r\n1.  A blind replace of `attr.dataclass` with `attr.define` yielded this which raises an error.\r\n```\r\n@attr.define(frozen=True)\r\nclass Base:\r\n   ...\r\n```\r\n\r\nValueError: Frozen classes can't use on_setattr.\r\n\r\n\r\n2. So I updated it to `@attr.frozen`. But then I hit another error:\r\n\r\n```\r\n@attr.frozen\r\nclass Base:\r\n ...\r\n\r\n@attr.define\r\nclass Child(Base):\r\n   ...\r\n```\r\n\r\nValueError: Frozen classes can't use on_setattr.\r\nThis time on Child.\r\n\r\nSo one just has to treat frozen=True as a special case.  Not a big thing but since we're talking about how the API feels. \nI'm working on the mypy plugin but I am gonna need to know the final answer on how \"hybrid\" mode wants to work if there are both annotations and attribs.  I think the options are:\r\n\r\n1. Take only the ones that have `= attr.ib()`\r\n2. Take only the annotated ones.\r\n3. Take both.\r\n4. Raise an exception.\r\n\r\n\r\nHmm. I thought #3 would be easy to implement (just don't raise the error) but it turns out we can't tell the order between annotated and un-annotated attributes.\r\n```\r\nclass A:\r\n   x: int\r\n   y = attr.ib()\r\n\r\ncls.__annotations__  ->   [x]\r\ncls.__dict__.keys(). -> [y]\r\n```\r\nBut which is actually first? \r\n\r\n#2 is kind of a weird one.  Why throw away those attr.ib()s?\r\n#1 is relatively easy to implement.  Because it's just a try catch.\r\n#4 Might require the user to add `ClassVar` in order to add it. \r\n\r\nOh I should note that I think this should still be fine:\r\n\r\n```\r\n@define\r\nclass A:\r\n   x: int = field()\r\n   y = field()\r\n```\r\n\r\nWe shouldn't force you to have to annotate everything.\r\nHmm. That might make 4 harder to implement.  :)\n> Just did a quick regex change on our code base, looking for trouble. I did find 2 interesting issues:\r\n> \r\n> 1. A blind replace of `attr.dataclass` with `attr.define` yielded this which raises an error.\r\n> \r\n> ```\r\n> @attr.define(frozen=True)\r\n> class Base:\r\n>    ...\r\n> ```\r\n> \r\n> ValueError: Frozen classes can't use on_setattr.\r\n> \r\n> 1. So I updated it to `@attr.frozen`. But then I hit another error:\r\n> \r\n> ```\r\n> @attr.frozen\r\n> class Base:\r\n>  ...\r\n> \r\n> @attr.define\r\n> class Child(Base):\r\n>    ...\r\n> ```\r\n> \r\n> ValueError: Frozen classes can't use on_setattr.\r\n> This time on Child.\r\n> \r\n> So one just has to treat frozen=True as a special case. Not a big thing but since we're talking about how the API feels.\r\n\r\nOof, both aren't great.\r\n\r\nI guess we should set `on_setattr=None` and only use the default if the class isn't effectively frozen?\n(I have moved the hybrid discussion to #676 since it's non-trivial and also very important)\nI've played around with new generation API a little, trying to migrate a part of my project onto it to feel the taste. \r\n\r\nFirst of all - little classes work perfectly and with less boilerplate (I almost always use `dataclass(frozen=True)`), that's great :)\r\n\r\nBut it also feels like slotted classes are bad choice for my case \r\n* I sometimes use mixins to add a kw_only attrib (with converters and validators) to my class which results in `multiple bases have instance lay-out conflict`. I've ended up aliasing `mixin = partial(define, slots=False, kw_only=True)` for such classes, but I'm not sure if it's a great practice. \r\n* I've also run into an issue with property if it's used for `init=False` attributes - I've got my property descriptor overridden by auto-generated slot descriptor :( \r\n\r\nI hope `attr.s/attr.dataclass` wouldn't be removed or some sane shortcuts for `dict`-classes would be provided :)\nattr.s/attr.dataclass definitely aren't going anywhere.\nHi,\r\n    Why `attr.field` `kw_only` default is False?\r\nhttps://github.com/python-attrs/attrs/blob/1e0e5664fb007cb8d22c5eb440468a2e252993ee/src/attr/_next_gen.py#L136\r\n    According to the docs(https://www.attrs.org/en/stable/api.html#attr.field) it should keyword-only, no? But it is the same as in:\r\nhttps://github.com/python-attrs/attrs/blob/1e0e5664fb007cb8d22c5eb440468a2e252993ee/src/attr/_make.py#L110\nHi!\r\nThe documentation means that `attr.field` signature is keyword-only (all attributes are keyword-only - say, it's incorrect to write `attr.field(5)` and one should mention attribute name `attr.field(default=5)`).\r\nThe `kw_only` attribute default hadn't change and is `False`.\nAh, ok :) I thought it was about `kw_only` being `True` by default(at least this is how I plan to use it most of the time). Thanks for clarification!\nIf your intention is to have a keyword-only constructor - you can use `attr.s(kw_only=True)` instead of passing argument to `attr.ib` manually all the time :)\nYep :+1:, just had some weird constructs to work around pos/kw args with the older versions of attrs, so now migrating them to `field`s ...\r\nThanks again! Next generation APIs look great! (maybe some minor doc improvement :smiley: so people like me don't get confused)\nI'd second that, I thought it meant that changed for a second and was quite surprised at how large of a change would be, until I saw the `*` and guessed what it really meant.\nBy the way, are the next gen APIs intentionally missing type info? Both define and field return Any, breaking the nice MyPy setup. Switching back to .ib and .s fixes it.\nFor `field` it shouldn't be returning `Any` there are overloads.  Can you post the code of what you're seeing?  As to `define` \r\n\r\n> mypy doesn't know about the new-style APIs yet and there's nothing we can do about it. However you can use this mypy plugin for now (for more details see https://www.attrs.org/en/stable/extending.html#wrapping-the-decorator). PR is submitted in python/mypy#9396.\r\n\r\nThe PR has been merged but there hasn't been a mypy release.\r\n\r\n\r\n\n> Can you post the code of what you're seeing? As to define\r\n\r\nSure, I'm using pre-commit and mypy so don't have the original, but this minimal change back shows the problem: https://github.com/henryiii/hypernewsviewer/pull/1\r\n\r\nThe problem seems to be field is missing type annotations too; so later on it returns \"Any\" because MyPy can't deduce anything about it.\r\n\r\n> The PR has been merged but there hasn't been a mypy release.\r\n\r\nMyPy releases are a little slow sometimes. Python 3.9 style `list[int]` is in master but not in a release yet either... :'( (really waiting for the `int | float` 3.10 syntax, though...)\nOh I see.  You need to install the `attrs` package in the same virtual env as `mypy` is running from. This is because `attrs` ships its own stubs.  There are `attrs` stubs in `typeshed` (which is shipped with mypy) but they are older and we're thinking of just removing them entirely.  I'm not too familar with `poetry` so I'm not sure if there's a different way to configure that.\n> There are attrs stubs in typeshed \r\n\r\nahh, I bet that explains it. I am at least some of the time running via pre-commit, and I don\u2019t have attrs in the extra dependencies there. Though I really thought I saw this both ways. I\u2019ll check tomorrow, but I bet that\u2019s the problem, I didn\u2019t know it could partially work with no attrs installed. ", "created_at": "2021-04-06T06:12:26Z"}
{"repo": "python-attrs/attrs", "pull_number": 782, "instance_id": "python-attrs__attrs-782", "issue_numbers": ["781"], "base_commit": "0a6f8075eb8d9d52d9316e9d6e5ec2d12ff2e1a7", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -41,7 +41,12 @@\n _tuple_property_pat = (\n     \"    {attr_name} = _attrs_property(_attrs_itemgetter({index}))\"\n )\n-_classvar_prefixes = (\"typing.ClassVar\", \"t.ClassVar\", \"ClassVar\")\n+_classvar_prefixes = (\n+    \"typing.ClassVar\",\n+    \"t.ClassVar\",\n+    \"ClassVar\",\n+    \"typing_extensions.ClassVar\",\n+)\n # we don't use a double-underscore prefix because that triggers\n # name mangling when trying to create a slot for the field\n # (when slots=True)\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -418,6 +418,18 @@ class C:\n             foo=typing.Optional[typing.Any],\n         )\n \n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_typing_extensions_classvar(self, slots):\n+        \"\"\"\n+        If ClassVar is coming from typing_extensions, it is recognized too.\n+        \"\"\"\n+\n+        @attr.s(auto_attribs=True, slots=slots)\n+        class C:\n+            cls_var: \"typing_extensions.ClassVar\" = 23  # noqa\n+\n+        assert_init_annotations(C)\n+\n     def test_keyword_only_auto_attribs(self):\n         \"\"\"\n         `kw_only` propagates to attributes defined via `auto_attribs`.\n", "problem_statement": "python3.10 interacts badly with typing_extensions.ClassVar\n```python\r\nfrom typing import Callable, Optional, ClassVar\r\n\r\nimport typing_extensions\r\nimport attr\r\n\r\n\r\n@attr.s(auto_attribs=True)\r\nclass Ham:\r\n    ham: typing_extensions.ClassVar[int] = 0\r\n    spam: int\r\n    eggs: Optional[int] = attr.ib(init=False, default=None)\r\n```\r\n\r\n```pytb\r\npython3.10 foo.py\r\nTraceback (most recent call last):\r\n  File \"/home/graingert/projects/twisted/foo.py\", line 8, in <module>\r\n    class Ham:\r\n  File \"/home/graingert/projects/twisted/.tox/py310-alldeps-nocov/lib/python3.10/site-packages/attr/_make.py\", line 1292, in wrap\r\n    builder = _ClassBuilder(\r\n  File \"/home/graingert/projects/twisted/.tox/py310-alldeps-nocov/lib/python3.10/site-packages/attr/_make.py\", line 604, in __init__\r\n    attrs, base_attrs, base_map = _transform_attrs(\r\n  File \"/home/graingert/projects/twisted/.tox/py310-alldeps-nocov/lib/python3.10/site-packages/attr/_make.py\", line 518, in _transform_attrs\r\n    raise ValueError(\r\nValueError: No mandatory attributes allowed after an attribute with a default value or factory.  Attribute in question: Attribute(name='spam', default=NOTHING, validator=None, repr=True, eq=True, order=True, hash=None, init=True, metadata=mappingproxy({}), type='int', converter=None, kw_only=False, inherited=False, on_setattr=None)\r\n```\n", "hints_text": "it seems to work fine if I use `from typing_extensions import ClassVar`\r\n\r\n```python\r\nfrom typing import Callable, Optional, ClassVar\r\n\r\nfrom typing_extensions import ClassVar\r\nimport attr\r\n\r\n\r\n@attr.s(auto_attribs=True)\r\nclass Ham:\r\n    ham: ClassVar[int] = 0\r\n    spam: int\r\n    eggs: Optional[int] = attr.ib(init=False, default=None)\r\n```\nYeah we just do a string comparison on `typing.ClassVar` or `ClassVar`.  Can you use `from typing import ClassVar`?  (I don't recall which supported versions of python include it these days)\n@euresti here's the context: \r\nhttps://github.com/twisted/twisted/pull/1559/files#diff-592f0a2a781d4b88035bcd58b8686ce792e80e17b7e93cb25bba26efab963250R958\nI'm avoiding the `from ... import` to avoid clashing with `twisted.internet.Protocol`\nAh.  Try \r\n```\r\nimport typing\r\n\r\ntyping.ClassVar[...]\r\n```\r\n\r\nThis should be available in python > 3.5.3.\r\n\r\nIf you need to support older pythons you can put it in quotes. i.e.\r\n```\r\n_log: \"typing.ClassVar[Logger]\" = Logger()\r\n```\r\n\nNote: `attrs` should probably support `typing_extensions.ClassVar`  I'm just trying to give you a workaround.\nAh I should totally be using `from typing import ClassVar` I mistakenly thought it was new in 3.8", "created_at": "2021-03-20T09:08:23Z"}
{"repo": "python-attrs/attrs", "pull_number": 771, "instance_id": "python-attrs__attrs-771", "issue_numbers": ["767"], "base_commit": "ec249f62b3b0c88daee29e3dd56015de8fb23c06", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -27,9 +27,3 @@ def pytest_configure(config):\n     )\n if not PY310:\n     collect_ignore.extend([\"tests/test_pattern_matching.py\"])\n-if PY310:\n-    collect_ignore.extend(\n-        [\n-            \"tests/test_mypy.yml\",\n-        ]\n-    )\n", "test_patch": "", "problem_statement": "test_mypy.yml fails hilariously on Python 3.10\nThe error list is long than my scrollback buffer, but here's an example:\r\n\r\n```\r\n/Users/hynek/FOSS/attrs/tests/test_mypy.yml:118:\r\nE   pytest_mypy_plugins.utils.TypecheckAssertionError: Invalid output:\r\nE   Expected:\r\nE     main:6: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE     main:11: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE     main:16: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE     main:21: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE   Actual:\r\nE     ../../../../../../Users/hynek/FOSS/attrs/.tox/py310/lib/python3.10/site-packages/mypy/typeshed/stdlib/3/types.pyi:334: error: Name '_NotImplementedType' is not defined (diff)\r\nE     main:6: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE     main:11: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE     main:16: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE     main:21: error: Incompatible return value type (got \"int\", expected \"str\") (diff)\r\nE\r\nE   Alignment of first line difference:\r\nE     E: main:6: error: Incompatible return value type (got \"int\", expected \"str\"...\r\nE     A: ../../../../../../Users/hynek/FOSS/attrs/.tox/py310/lib/python3.10/site-...\r\nE        ^\r\n```\r\n\r\nor\r\n\r\n```\r\n/Users/hynek/FOSS/attrs/tests/test_mypy.yml:277:\r\nE   pytest_mypy_plugins.utils.TypecheckAssertionError: Invalid output:\r\nE   Expected:\r\nE     main:5: note: Revealed type is 'def (a: builtins.int) -> main.A' (diff)\r\nE     main:7: error: Unsupported left operand type for < (\"A\") (diff)\r\nE     main:8: error: Unsupported left operand type for <= (\"A\") (diff)\r\nE     main:9: error: Unsupported left operand type for > (\"A\") (diff)\r\nE     ...\r\nE   Actual:\r\nE     ../../../../../../Users/hynek/FOSS/attrs/.tox/py310/lib/python3.10/site-packages/mypy/typeshed/stdlib/3/types.pyi:334: error: Name '_NotImplementedType' is not defined (diff)\r\nE     main:5: note: Revealed type is 'def (a: builtins.int) -> main.A' (diff)\r\nE     main:7: error: Unsupported left operand type for < (\"A\") (diff)\r\nE     main:8: error: Unsupported left operand type for <= (\"A\") (diff)\r\nE     main:9: error: Unsupported left operand type for > (\"A\") (diff)\r\nE     ...\r\nE\r\nE   Alignment of first line difference:\r\nE     E: main:5: note: Revealed type is 'def (a: builtins.int) -> main.A'...\r\nE     A: ../../../../../../Users/hynek/FOSS/attrs/.tox/py310/lib/python3.10/site-...\r\nE        ^\r\n```\r\n\r\nI'm not sure what to do about it at all but I guess we _should_ fix it going forward.\n", "hints_text": "", "created_at": "2021-02-25T15:04:01Z"}
{"repo": "python-attrs/attrs", "pull_number": 770, "instance_id": "python-attrs__attrs-770", "issue_numbers": ["756"], "base_commit": "58d2adce57f2c4e447eb12b892ebbb09cccbdcc3", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -28,6 +28,15 @@\n     def isclass(klass):\n         return isinstance(klass, (type, types.ClassType))\n \n+    def new_class(name, bases, kwds, exec_body):\n+        \"\"\"\n+        A minimal stub of types.new_class that we need for make_class.\n+        \"\"\"\n+        ns = {}\n+        exec_body(ns)\n+\n+        return type(name, bases, ns)\n+\n     # TYPE is used in exceptions, repr(int) is different on Python 2 and 3.\n     TYPE = \"type\"\n \n@@ -122,6 +131,8 @@ def isclass(klass):\n     def iteritems(d):\n         return d.items()\n \n+    new_class = types.new_class\n+\n     def metadata_proxy(d):\n         return types.MappingProxyType(dict(d))\n \ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -17,6 +17,7 @@\n     isclass,\n     iteritems,\n     metadata_proxy,\n+    new_class,\n     ordered_dict,\n     set_closure_cell,\n )\n@@ -2928,7 +2929,8 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n     if user_init is not None:\n         body[\"__init__\"] = user_init\n \n-    type_ = type(name, bases, body)\n+    type_ = new_class(name, bases, {}, lambda ns: ns.update(body))\n+\n     # For pickling to work, the __module__ variable needs to be set to the\n     # frame where the class is created.  Bypass this step in environments where\n     # sys._getframe is not defined (Jython for example) or sys._getframe is not\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1118,6 +1118,22 @@ def test_make_class_ordered(self):\n \n         assert \"C(a=1, b=2)\" == repr(C())\n \n+    @pytest.mark.skipif(PY2, reason=\"Python 3-only\")\n+    def test_generic_dynamic_class(self):\n+        \"\"\"\n+        make_class can create generic dynamic classes.\n+\n+        https://github.com/python-attrs/attrs/issues/756\n+        https://bugs.python.org/issue33188\n+        \"\"\"\n+        from types import new_class\n+        from typing import Generic, TypeVar\n+\n+        MyTypeVar = TypeVar(\"MyTypeVar\")\n+        MyParent = new_class(\"MyParent\", (Generic[MyTypeVar],), {})\n+\n+        attr.make_class(\"test\", {\"id\": attr.ib(type=str)}, (MyParent[int],))\n+\n \n class TestFields(object):\n     \"\"\"\n", "problem_statement": "attr.make_class does not work with Python>=3.7\nIn attr.make_class function line 2818: `type_ = type(name, bases, body)` cannot be used for dynamic generic class creation beyond python 3.7 and leads to an error `TypeError: type() doesn't support MRO entry resolution; use types.new_class()`.\r\n\r\nThe error can be recreated with:\r\n```\r\nfrom typing import TypeVar, Generic\r\nfrom types import new_class\r\nimport attr\r\n\r\nMyTypeVar = TypeVar(\"MyTypeVar\")\r\nMyParent = new_class(\"MyParent\", (Generic[MyTypeVar],), {})\r\n\r\n\r\nattr.make_class('test', {'id': attr.ib(type=str)}, (MyParent[int],))\r\n```\r\n\r\nAs mentioned in the error it can be fixed by replacing `type_ = type(name, bases, body)` with `types.new_class(name, bases, body)`. \r\n\r\nThis issue has been discussed here in detail: [https://bugs.python.org/issue33188](https://bugs.python.org/issue33188).\n", "hints_text": "", "created_at": "2021-02-25T13:06:10Z"}
{"repo": "python-attrs/attrs", "pull_number": 763, "instance_id": "python-attrs__attrs-763", "issue_numbers": ["716"], "base_commit": "44ac46114603f8fa7c1142dd338da16c5373d8df", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -23,3 +23,10 @@ def pytest_configure(config):\n             \"tests/test_next_gen.py\",\n         ]\n     )\n+if sys.version_info[:2] >= (3, 10):\n+    collect_ignore.extend(\n+        [\n+            \"tests/test_mypy.yml\",\n+            \"tests/test_hooks.py\",\n+        ]\n+    )\ndiff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -36,6 +36,7 @@\n     \"Programming Language :: Python :: 3.7\",\n     \"Programming Language :: Python :: 3.8\",\n     \"Programming Language :: Python :: 3.9\",\n+    \"Programming Language :: Python :: 3.10\",\n     \"Programming Language :: Python :: Implementation :: CPython\",\n     \"Programming Language :: Python :: Implementation :: PyPy\",\n     \"Topic :: Software Development :: Libraries :: Python Modules\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -384,7 +384,13 @@ def _is_class_var(annot):\n     annotations which would put attrs-based classes at a performance\n     disadvantage compared to plain old classes.\n     \"\"\"\n-    return str(annot).startswith(_classvar_prefixes)\n+    annot = str(annot)\n+\n+    # Annotation can be quoted.\n+    if annot.startswith((\"'\", '\"')) and annot.endswith((\"'\", '\"')):\n+        annot = annot[1:-1]\n+\n+    return annot.startswith(_classvar_prefixes)\n \n \n def _has_own_attribute(cls, attrib_name):\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -4,6 +4,7 @@\n Python 3.6+ only.\n \"\"\"\n \n+import sys\n import types\n import typing\n \n@@ -11,10 +12,21 @@\n \n import attr\n \n-from attr._make import _classvar_prefixes\n+from attr._make import _is_class_var\n from attr.exceptions import UnannotatedAttributeError\n \n \n+def assert_init_annotations(cls, **annotations):\n+    \"\"\"\n+    Assert cls.__init__ has the correct annotations.\n+    \"\"\"\n+    __tracebackhide__ = True\n+\n+    annotations[\"return\"] = type(None)\n+\n+    assert annotations == typing.get_type_hints(cls.__init__)\n+\n+\n class TestAnnotations:\n     \"\"\"\n     Tests for types derived from variable annotations (PEP-526).\n@@ -25,6 +37,7 @@ def test_basic_annotations(self):\n         Sets the `Attribute.type` attr from basic type annotations.\n         \"\"\"\n \n+        @attr.resolve_types\n         @attr.s\n         class C:\n             x: int = attr.ib()\n@@ -34,11 +47,7 @@ class C:\n         assert int is attr.fields(C).x.type\n         assert str is attr.fields(C).y.type\n         assert None is attr.fields(C).z.type\n-        assert C.__init__.__annotations__ == {\n-            \"x\": int,\n-            \"y\": str,\n-            \"return\": None,\n-        }\n+        assert_init_annotations(C, x=int, y=str)\n \n     def test_catches_basic_type_conflict(self):\n         \"\"\"\n@@ -59,6 +68,7 @@ def test_typing_annotations(self):\n         Sets the `Attribute.type` attr from typing annotations.\n         \"\"\"\n \n+        @attr.resolve_types\n         @attr.s\n         class C:\n             x: typing.List[int] = attr.ib()\n@@ -66,27 +76,21 @@ class C:\n \n         assert typing.List[int] is attr.fields(C).x.type\n         assert typing.Optional[str] is attr.fields(C).y.type\n-        assert C.__init__.__annotations__ == {\n-            \"x\": typing.List[int],\n-            \"y\": typing.Optional[str],\n-            \"return\": None,\n-        }\n+        assert_init_annotations(C, x=typing.List[int], y=typing.Optional[str])\n \n     def test_only_attrs_annotations_collected(self):\n         \"\"\"\n         Annotations that aren't set to an attr.ib are ignored.\n         \"\"\"\n \n+        @attr.resolve_types\n         @attr.s\n         class C:\n             x: typing.List[int] = attr.ib()\n             y: int\n \n         assert 1 == len(attr.fields(C))\n-        assert C.__init__.__annotations__ == {\n-            \"x\": typing.List[int],\n-            \"return\": None,\n-        }\n+        assert_init_annotations(C, x=typing.List[int])\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_auto_attribs(self, slots):\n@@ -111,6 +115,8 @@ class C:\n         assert \"a\" in attr_names  # just double check that the set works\n         assert \"cls_var\" not in attr_names\n \n+        attr.resolve_types(C)\n+\n         assert int == attr.fields(C).a.type\n \n         assert attr.Factory(list) == attr.fields(C).x.default\n@@ -135,14 +141,14 @@ class C:\n             i.y = 23\n             assert 23 == i.y\n \n-        assert C.__init__.__annotations__ == {\n-            \"a\": int,\n-            \"x\": typing.List[int],\n-            \"y\": int,\n-            \"z\": int,\n-            \"foo\": typing.Any,\n-            \"return\": None,\n-        }\n+        assert_init_annotations(\n+            C,\n+            a=int,\n+            x=typing.List[int],\n+            y=int,\n+            z=int,\n+            foo=typing.Optional[typing.Any],\n+        )\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_auto_attribs_unannotated(self, slots):\n@@ -171,28 +177,26 @@ def test_auto_attribs_subclassing(self, slots):\n         Ref #291\n         \"\"\"\n \n+        @attr.resolve_types\n         @attr.s(slots=slots, auto_attribs=True)\n         class A:\n             a: int = 1\n \n+        @attr.resolve_types\n         @attr.s(slots=slots, auto_attribs=True)\n         class B(A):\n             b: int = 2\n \n+        @attr.resolve_types\n         @attr.s(slots=slots, auto_attribs=True)\n         class C(A):\n             pass\n \n         assert \"B(a=1, b=2)\" == repr(B())\n         assert \"C(a=1)\" == repr(C())\n-\n-        assert A.__init__.__annotations__ == {\"a\": int, \"return\": None}\n-        assert B.__init__.__annotations__ == {\n-            \"a\": int,\n-            \"b\": int,\n-            \"return\": None,\n-        }\n-        assert C.__init__.__annotations__ == {\"a\": int, \"return\": None}\n+        assert_init_annotations(A, a=int)\n+        assert_init_annotations(B, a=int, b=int)\n+        assert_init_annotations(C, a=int)\n \n     def test_converter_annotations(self):\n         \"\"\"\n@@ -207,7 +211,7 @@ def int2str(x: int) -> str:\n         class A:\n             a = attr.ib(converter=int2str)\n \n-        assert A.__init__.__annotations__ == {\"a\": int, \"return\": None}\n+        assert_init_annotations(A, a=int)\n \n         def int2str_(x: int, y: str = \"\"):\n             return str(x)\n@@ -216,7 +220,7 @@ def int2str_(x: int, y: str = \"\"):\n         class A:\n             a = attr.ib(converter=int2str_)\n \n-        assert A.__init__.__annotations__ == {\"a\": int, \"return\": None}\n+        assert_init_annotations(A, a=int)\n \n     def test_converter_attrib_annotations(self):\n         \"\"\"\n@@ -232,11 +236,7 @@ class A:\n             a: str = attr.ib(converter=int2str)\n             b = attr.ib(converter=int2str, type=str)\n \n-        assert A.__init__.__annotations__ == {\n-            \"a\": int,\n-            \"b\": int,\n-            \"return\": None,\n-        }\n+        assert_init_annotations(A, a=int, b=int)\n \n     def test_non_introspectable_converter(self):\n         \"\"\"\n@@ -382,30 +382,41 @@ def noop():\n \n         assert attr.converters.optional(noop).__annotations__ == {}\n \n+    @pytest.mark.xfail(\n+        sys.version_info[:2] == (3, 6), reason=\"Does not work on 3.6.\"\n+    )\n     @pytest.mark.parametrize(\"slots\", [True, False])\n-    @pytest.mark.parametrize(\"classvar\", _classvar_prefixes)\n-    def test_annotations_strings(self, slots, classvar):\n+    def test_annotations_strings(self, slots):\n         \"\"\"\n         String annotations are passed into __init__ as is.\n+\n+        It fails on 3.6 due to a bug in Python.\n         \"\"\"\n+        import typing as t\n+\n+        from typing import ClassVar\n \n         @attr.s(auto_attribs=True, slots=slots)\n         class C:\n-            cls_var: classvar + \"[int]\" = 23\n+            cls_var1: \"typing.ClassVar[int]\" = 23\n+            cls_var2: \"ClassVar[int]\" = 23\n+            cls_var3: \"t.ClassVar[int]\" = 23\n             a: \"int\"\n             x: \"typing.List[int]\" = attr.Factory(list)\n             y: \"int\" = 2\n             z: \"int\" = attr.ib(default=3)\n             foo: \"typing.Any\" = None\n \n-        assert C.__init__.__annotations__ == {\n-            \"a\": \"int\",\n-            \"x\": \"typing.List[int]\",\n-            \"y\": \"int\",\n-            \"z\": \"int\",\n-            \"foo\": \"typing.Any\",\n-            \"return\": None,\n-        }\n+        attr.resolve_types(C, locals(), globals())\n+\n+        assert_init_annotations(\n+            C,\n+            a=int,\n+            x=typing.List[int],\n+            y=int,\n+            z=int,\n+            foo=typing.Optional[typing.Any],\n+        )\n \n     def test_keyword_only_auto_attribs(self):\n         \"\"\"\n@@ -487,10 +498,6 @@ class C:\n             y = attr.ib(type=str)\n             z = attr.ib()\n \n-        assert \"int\" == attr.fields(C).x.type\n-        assert str is attr.fields(C).y.type\n-        assert None is attr.fields(C).z.type\n-\n         attr.resolve_types(C)\n \n         assert int is attr.fields(C).x.type\n@@ -509,10 +516,6 @@ class A:\n             b: typing.List[\"int\"]\n             c: \"typing.List[int]\"\n \n-        assert typing.List[int] == attr.fields(A).a.type\n-        assert typing.List[\"int\"] == attr.fields(A).b.type\n-        assert \"typing.List[int]\" == attr.fields(A).c.type\n-\n         # Note: I don't have to pass globals and locals here because\n         # int is a builtin and will be available in any scope.\n         attr.resolve_types(A)\n@@ -549,9 +552,6 @@ class A:\n             a: \"A\"\n             b: typing.Optional[\"A\"]  # noqa: will resolve below\n \n-        assert \"A\" == attr.fields(A).a.type\n-        assert typing.Optional[\"A\"] == attr.fields(A).b.type\n-\n         attr.resolve_types(A, globals(), locals())\n \n         assert A == attr.fields(A).a.type\n@@ -571,10 +571,11 @@ class A:\n         class B:\n             a: A\n \n-        assert typing.List[\"B\"] == attr.fields(A).a.type\n-        assert A == attr.fields(B).a.type\n-\n         attr.resolve_types(A, globals(), locals())\n+        attr.resolve_types(B, globals(), locals())\n+\n+        assert typing.List[B] == attr.fields(A).a.type\n+        assert A == attr.fields(B).a.type\n \n         assert typing.List[B] == attr.fields(A).a.type\n         assert A == attr.fields(B).a.type\n@@ -588,10 +589,7 @@ def test_init_type_hints(self):\n         class C:\n             x = attr.ib(type=\"typing.List[int]\")\n \n-        assert typing.get_type_hints(C.__init__) == {\n-            \"return\": type(None),\n-            \"x\": typing.List[int],\n-        }\n+        assert_init_annotations(C, x=typing.List[int])\n \n     def test_init_type_hints_fake_module(self):\n         \"\"\"\n@@ -607,3 +605,19 @@ class C:\n \n         with pytest.raises(NameError):\n             typing.get_type_hints(C.__init__)\n+\n+\n+@pytest.mark.parametrize(\n+    \"annot\",\n+    [\n+        typing.ClassVar,\n+        \"typing.ClassVar\",\n+        \"'typing.ClassVar[dict]'\",\n+        \"t.ClassVar[int]\",\n+    ],\n+)\n+def test_is_class_var(annot):\n+    \"\"\"\n+    ClassVars are detected, even if they're a string or quoted.\n+    \"\"\"\n+    assert _is_class_var(annot)\ndiff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -729,9 +729,8 @@ def test_init(self, slots, frozen):\n         with pytest.raises(TypeError) as e:\n             C(a=1, b=2)\n \n-        assert (\n+        assert e.value.args[0].endswith(\n             \"__init__() got an unexpected keyword argument 'a'\"\n-            == e.value.args[0]\n         )\n \n     @given(booleans(), booleans())\ndiff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -552,7 +552,7 @@ def test_unknown(self, C):\n         else:\n             expected = \"__init__() got an unexpected keyword argument 'aaaa'\"\n \n-        assert (expected,) == e.value.args\n+        assert e.value.args[0].endswith(expected)\n \n     def test_validator_failure(self):\n         \"\"\"\n", "problem_statement": "Python 3.10 compatibility\nHello.\r\n\r\nWe have already started testing RPM packages in Fedora with Python 3.10a2 and attrs is currently not compatible.\r\n\r\nThe problem is caused by the implementation of [PEP 563](https://www.python.org/dev/peps/pep-0563/#abstract) \u2014 type annotations are now stored as strings which cause asserts like this one to fail:\r\n\r\n```python\r\nclass TestAnnotations:\r\n    \"\"\"\r\n    Tests for types derived from variable annotations (PEP-526).\r\n    \"\"\"\r\n\r\n    def test_basic_annotations(self):\r\n        \"\"\"\r\n        Sets the `Attribute.type` attr from basic type annotations.\r\n        \"\"\"\r\n\r\n        @attr.s\r\n        class C:\r\n            x: int = attr.ib()\r\n            y = attr.ib(type=str)\r\n            z = attr.ib()\r\n\r\n        assert int is attr.fields(C).x.type\r\n```\r\n\r\nThe value stored in `attr.fields(C).x.type` is a string \"int\" instead of a class int.\r\n\r\nIt seems it was discussed before in https://github.com/python-attrs/attrs/issues/424\n", "hints_text": "Do we need to call `attr.resolve_types` first in the test?\nDo I understand it correctly that we are waiting for https://github.com/python-attrs/attrs/issues/593 here?\nYes. :(\nFTR, when issue 593 is fixed now, I can use `attr.resolve_types(C)` in the `test_basic_annotations` and that makes the previously mentioned `assert int is attr.fields(C).x.type` pass but the last assert in the test:\r\n\r\n```python\r\nassert C.__init__.__annotations__ == {\r\n    \"x\": int,\r\n    \"y\": str,\r\n    \"return\": None,\r\n}\r\n```\r\n\r\nstill complains about `{'x': 'int'} != {'x': <class 'int'>}`. I'm not sure how much you want to make the attrs behave the same under Python 3.10. If that's the goal, we should probably keep tests untouched.\nThe test needs to be changed to get_type_hints I'm afraid. There's a bunch more stuff breaking that I'm working on rn.", "created_at": "2021-02-19T10:58:43Z"}
{"repo": "python-attrs/attrs", "pull_number": 760, "instance_id": "python-attrs__attrs-760", "issue_numbers": ["593"], "base_commit": "78335e9b49eff2eaf2dc31d0bcc3caa0169cfc60", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -286,6 +286,36 @@ def attrib(\n     )\n \n \n+def _compile_and_eval(script, globs, locs=None, filename=\"\"):\n+    \"\"\"\n+    \"Exec\" the script with the given global (globs) and local (locs) variables.\n+    \"\"\"\n+    bytecode = compile(script, filename, \"exec\")\n+    eval(bytecode, globs, locs)\n+\n+\n+def _make_method(name, script, filename, globs=None):\n+    \"\"\"\n+    Create the method with the script given and return the method object.\n+    \"\"\"\n+    locs = {}\n+    if globs is None:\n+        globs = {}\n+\n+    _compile_and_eval(script, globs, locs, filename)\n+\n+    # In order of debuggers like PDB being able to step through the code,\n+    # we add a fake linecache entry.\n+    linecache.cache[filename] = (\n+        len(script),\n+        None,\n+        script.splitlines(True),\n+        filename,\n+    )\n+\n+    return locs[name]\n+\n+\n def _make_attr_tuple_class(cls_name, attr_names):\n     \"\"\"\n     Create a tuple subclass to hold `Attribute`s for an `attrs` class.\n@@ -309,8 +339,7 @@ class MyClassAttributes(tuple):\n     else:\n         attr_class_template.append(\"    pass\")\n     globs = {\"_attrs_itemgetter\": itemgetter, \"_attrs_property\": property}\n-    eval(compile(\"\\n\".join(attr_class_template), \"\", \"exec\"), globs)\n-\n+    _compile_and_eval(\"\\n\".join(attr_class_template), globs)\n     return globs[attr_class_name]\n \n \n@@ -1591,21 +1620,7 @@ def append_hash_computation_lines(prefix, indent):\n         append_hash_computation_lines(\"return \", tab)\n \n     script = \"\\n\".join(method_lines)\n-    globs = {}\n-    locs = {}\n-    bytecode = compile(script, unique_filename, \"exec\")\n-    eval(bytecode, globs, locs)\n-\n-    # In order of debuggers like PDB being able to step through the code,\n-    # we add a fake linecache entry.\n-    linecache.cache[unique_filename] = (\n-        len(script),\n-        None,\n-        script.splitlines(True),\n-        unique_filename,\n-    )\n-\n-    return locs[\"__hash__\"]\n+    return _make_method(\"__hash__\", script, unique_filename)\n \n \n def _add_hash(cls, attrs):\n@@ -1661,20 +1676,7 @@ def _make_eq(cls, attrs):\n         lines.append(\"    return True\")\n \n     script = \"\\n\".join(lines)\n-    globs = {}\n-    locs = {}\n-    bytecode = compile(script, unique_filename, \"exec\")\n-    eval(bytecode, globs, locs)\n-\n-    # In order of debuggers like PDB being able to step through the code,\n-    # we add a fake linecache entry.\n-    linecache.cache[unique_filename] = (\n-        len(script),\n-        None,\n-        script.splitlines(True),\n-        unique_filename,\n-    )\n-    return locs[\"__eq__\"]\n+    return _make_method(\"__eq__\", script, unique_filename)\n \n \n def _make_order(cls, attrs):\n@@ -1949,8 +1951,10 @@ def _make_init(\n         has_global_on_setattr,\n         attrs_init,\n     )\n-    locs = {}\n-    bytecode = compile(script, unique_filename, \"exec\")\n+    if cls.__module__ in sys.modules:\n+        # This makes typing.get_type_hints(CLS.__init__) resolve string types.\n+        globs.update(sys.modules[cls.__module__].__dict__)\n+\n     globs.update({\"NOTHING\": NOTHING, \"attr_dict\": attr_dict})\n \n     if needs_cached_setattr:\n@@ -1958,18 +1962,12 @@ def _make_init(\n         # setattr hooks.\n         globs[\"_cached_setattr\"] = _obj_setattr\n \n-    eval(bytecode, globs, locs)\n-\n-    # In order of debuggers like PDB being able to step through the code,\n-    # we add a fake linecache entry.\n-    linecache.cache[unique_filename] = (\n-        len(script),\n-        None,\n-        script.splitlines(True),\n+    init = _make_method(\n+        \"__attrs_init__\" if attrs_init else \"__init__\",\n+        script,\n         unique_filename,\n+        globs,\n     )\n-\n-    init = locs[\"__attrs_init__\"] if attrs_init else locs[\"__init__\"]\n     init.__annotations__ = annotations\n \n     return init\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -578,3 +578,32 @@ class B:\n \n         assert typing.List[B] == attr.fields(A).a.type\n         assert A == attr.fields(B).a.type\n+\n+    def test_init_type_hints(self):\n+        \"\"\"\n+        Forward references in __init__ can be automatically resolved.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            x = attr.ib(type=\"typing.List[int]\")\n+\n+        assert typing.get_type_hints(C.__init__) == {\n+            \"return\": type(None),\n+            \"x\": typing.List[int],\n+        }\n+\n+    def test_init_type_hints_fake_module(self):\n+        \"\"\"\n+        If you somehow set the __module__ to something that doesn't exist\n+        you'll lose __init__ resolution.\n+        \"\"\"\n+\n+        class C:\n+            x = attr.ib(type=\"typing.List[int]\")\n+\n+        C.__module__ = \"totally fake\"\n+        C = attr.s(C)\n+\n+        with pytest.raises(NameError):\n+            typing.get_type_hints(C.__init__)\n", "problem_statement": "Deferred type annotations are evaluated in the wrong execution context\nTo reproduce, run the following program:\r\n```python\r\nimport attr\r\nfrom typing import List, get_type_hints\r\n\r\n@attr.s\r\nclass C:\r\n    x = attr.ib(type='List[int]')\r\n\r\nprint(get_type_hints(C.__init__))\r\n```\r\n\r\n#### Expected result\r\n```\r\n{'return': <class 'NoneType'>, 'x': typing.List[int]}\r\n```\r\n\r\n#### Actual result\r\n```\r\nTraceback (most recent call last):\r\n  File \"example.py\", line 8, in <module>\r\n    print(get_type_hints(C.__init__))\r\n  File \"C:\\Python37\\lib\\typing.py\", line 1001, in get_type_hints\r\n    value = _eval_type(value, globalns, localns)\r\n  File \"C:\\Python37\\lib\\typing.py\", line 260, in _eval_type\r\n    return t._evaluate(globalns, localns)\r\n  File \"C:\\Python37\\lib\\typing.py\", line 464, in _evaluate\r\n    eval(self.__forward_code__, globalns, localns),\r\n  File \"<string>\", line 1, in <module>\r\nNameError: name 'List' is not defined\r\n```\r\n\r\nThis annotation should be evaluated in the context of the module where it's defined, where `List` is in globals.\r\n\r\n#### Version info\r\n```\r\nattrs 19.3.0\r\nPython 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 22:22:05) [MSC v.1916 64 bit (AMD64)] on win32\r\n```\n", "hints_text": "I'm not sure that's something we can achieve TBH.\nI'm having the same problem. Is there any workaround in which the original `__init__.__globals__` can be accessed somehow? \r\n\r\nAlso, is there any way to know if a `__init__` method was created by `attrs`? (i.e. `is_attrs_init(C.__innit_)`)\r\n\r\n\nPS. You can workaround it with:\r\n\r\n```\r\n get_type_hints(C.__init__, sys.modules[C.__module__].__dict__)\r\n```\r\nor \r\n\r\n```\r\nget_type_hints(C.__init__, globalns=globals())\r\n```\r\n\nThanks @euresti for the proposals :+1: . Unfortunately, I think they won't work for me:\r\n\r\n**First proposal**:\r\n```py\r\n get_type_hints(C.__init__, sys.modules[C.__module__].__dict__)\r\n```\r\nI need to obtain the hints only from the `__init__` method so unless I can obtain the class from the method `__init__` this solution won't work for me. Do you know if there is any way to obtain the class from the `__init__` method? I mean, is possible to implement the method `get_cls_from_attrs_init` such that:\r\n```py\r\nassert get_cls_from_attrs_init(C.__init__) == C\r\n```\r\n\r\n**Second proposal**\r\n```py\r\nget_type_hints(C.__init__, globalns=globals())\r\n``` \r\nThe problem with this proposal is that the globals obtained from `globals()` are from a different module than `C.__init__` module in my case, so it is not working. \r\n\r\nThank you!\nYou don't need the class. You only need the module:\r\n```\r\ndef hints(method):\r\n     return get_type_hints(method, sys.modules[method.__module__].__dict__)\r\n```\r\n\r\n\nThanks, @euresti :+1: . That is very helpful, serves for most of my cases, thanks. But it is not working for the case of classes defined within functions. The following fails with `NameError: name 'B' is not defined`:\r\n```py\r\nimport sys\r\nfrom typing import get_type_hints\r\nimport attr\r\n\r\ndef hints(method):\r\n    return get_type_hints(method, sys.modules[method.__module__].__dict__)\r\n\r\ndef resolve():\r\n    @attr.s(auto_attribs=True)\r\n    class A:\r\n        b: 'B'\r\n\r\n    @attr.s(auto_attribs=True)\r\n    class B:\r\n        pass\r\n\r\n    return hints(A.__init__)\r\n\r\nresolve()\r\n```\r\nAny idea if there is any workaround for that?\r\n\r\nBy the other hand, I have discovered that this issue will get worse in future python 4.0, where [posponed evaluation of annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations) will be the default. \r\n\r\nThe following fails with `NameError: name 'B' is not defined` on Python 3.7. But it works if `from __future__ import annotations` is commented. And then it will fail by default in the upcoming Python 4.0. \r\n```py\r\nfrom __future__ import annotations\r\n\r\nfrom typing import get_type_hints\r\n\r\nimport attr\r\n\r\nclass B:\r\n    pass\r\n\r\n@attr.s(auto_attribs=True)\r\nclass A:\r\n    b: B\r\n\r\nget_type_hints(A.__init__)\r\n``` \r\n\r\nHope this is hepful. \nLocal scopes are very hard to remember.  Do you need to pass around `__init__` methods?  One should not be calling those anyway.  Maybe your code can accept the `B` for these cases.  (Full disclosure I have no idea what your code is doing)\r\n\r\n> this issue will get worse in future python 4.0, where posponed evaluation of annotations will be the default.\r\n\r\nThat's because in python 4 this\r\n```\r\n@attr.s(auto_attribs=True)\r\nclass A:\r\n    b: B\r\n```\r\nis actually \r\n```\r\n@attr.s(auto_attribs=True)\r\nclass A:\r\n    b: \"B\"\r\n```\r\n\r\n\n> Local scopes are very hard to remember. Do you need to pass around __init__ methods? One should not be calling those anyway. Maybe your code can accept the B for these cases. (Full disclosure I have no idea what your code is doing)\r\n\r\n@euresti some context: a library inspects signature of functions (`__init__` method in this case, for classes), and does dependency injection based on type annotations. \r\n\r\nSo if we have `__init__(self, a: A)`, we'd create an instance of A and pass it to `__init__`. \r\n\r\nFor this it needs to be able to retrieve typing information reliably, at runtime; this breaks for attr.s classes.\r\n\r\n\nSo there are 2 places where these values are stored.  `cls.__annotations__`  of in `field.type`.  If you plan to use `get_type_hints` then you could do something like this to \"resolve\" the ForwardRefs\r\n```\r\ndef foo():\r\n   @dataclass\r\n   class Foo:\r\n      x: \"Optional[Foo]\"\r\n\r\n   print(Foo.__annotations__)\r\n   Foo.__annotations__ = get_type_hints(Foo, localns=locals())\r\n\r\n   return Foo\r\n\r\nX = foo()\r\nprint(get_type_hints(X))\r\n```\r\n\r\nOtherwise you have to do something like this:\r\n```\r\n   hints = get_type_hints(cls, localns=locals())\r\n   for field in attr.fields(cls):\r\n      if field.name in hints:\r\n         # field is a FrozenInstance. The only way to update it is using object.__setattr__\r\n         object.__setattr__(field, \"type\", hints[field.name])\r\n```\r\n\r\nIn the end we just decided the simplest solution was to enforce that all classes are created at module scope and then `get_type_hints(cls)` is guaranteed to work. \nTo clarify using your example:\r\n```\r\nimport sys\r\nfrom typing import get_type_hints\r\nimport attr\r\n\r\ndef hints(method, localns):\r\n    return get_type_hints(method, sys.modules[method.__module__].__dict__, localns=localns)\r\n\r\ndef resolve():\r\n    @attr.s(auto_attribs=True)\r\n    class A:\r\n        b: 'B'\r\n\r\n    @attr.s(auto_attribs=True)\r\n    class B:\r\n        pass\r\n\r\n    return hints(A.__init__, localns=locals())\r\n\r\nprint(resolve())\r\n```\r\n\r\nYou could even use `inspect.currentframe().f_back` in your `hints` method to get the globals and locals at the call site.\nI learned today that `dataclasses` fixed this issue (`get_type_hints(C.__init__)`) by passing the correct `globals` into the `exec` call.\r\n\r\nhttps://github.com/python/cpython/pull/9518\r\n\r\nBasically on class creation they save the class module dict,  `globals = sys.modules[cls.__module__].__dict__` and then pass it in to exec.  I don't know if that would work for attrs though.\r\n\r\n\n> I don't know if that would work for attrs though.\r\n\r\nIs that a gut feeling or do you see blockers?\nI haven't looked deep at the attrs code. I notice that dataclasses just uses exec whereas attrs uses compile + eval.  Basically since the code is not identical I couldn't say that it would 100% work to do the same as dataclasses.\nHmhm. FWIW, we used to use compile/exec until\u2026this happened https://github.com/python-attrs/attrs/pull/87#issuecomment-246111177.\nIt would be nice to move this forward because we are already in Python 3.10 alpha 5 and our possibilities to change something big are limited in beta releases.", "created_at": "2021-02-16T17:13:15Z"}
{"repo": "python-attrs/attrs", "pull_number": 732, "instance_id": "python-attrs__attrs-732", "issue_numbers": ["720"], "base_commit": "3d274d0bfab142bc45504533f2c2b5f5ce519fd7", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -69,6 +69,12 @@ def __new__(cls):\n     def __repr__(self):\n         return \"NOTHING\"\n \n+    def __bool__(self):\n+        return False\n+\n+    def __len__(self):\n+        return 0  # __bool__ for Python 2\n+\n \n NOTHING = _Nothing()\n \"\"\"\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -808,6 +808,13 @@ def test_eq(self):\n         assert not (_Nothing() != _Nothing())\n         assert 1 != _Nothing()\n \n+    def test_false(self):\n+        \"\"\"\n+        NOTHING evaluates as falsey.\n+        \"\"\"\n+        assert not NOTHING\n+        assert False is bool(NOTHING)\n+\n \n @attr.s(hash=True, order=True)\n class C(object):\n", "problem_statement": "Make bool(attr.NOTHING) == False\n`attr.NOTHING` describes an non-existing/unset attribute in an object.\r\nHowever, `bool(attr.NOTHING)` currently evaluates to True which is unnatural and does not really fit.\r\n\r\n## Other python empty values\r\n\r\nThe meaning of `attr.NOTHING` is very near to `None` but in contrast the latter one evaluates to False.\r\n\r\nIt is also very common that \u2018empty-values\u2019 evaluates to False in Python:\r\n\r\n```python\r\n>>> import attr\r\n>>> bool(attr.NOTHING)\r\nTrue\r\n>>> bool(None)\r\nFalse\r\n>>> bool('')\r\nFalse\r\n>>> bool([])\r\nFalse\r\n>>> bool({})\r\nFalse\r\n```\r\n\r\nAnd `bool(attr.NOTHING)` does not fit there.\r\n\r\n## If case \u201anon-empty\u2018 value\r\n\r\nWhen I want to process a non-empty value I would naturally write:\r\n\r\n```python\r\n# foo is here an instance of an attrs decorated class with the bar attribute\r\n\r\nif foo.bar:\r\n    ... # Do something on a non-empty value\r\n```\r\n\r\nHowever, the above if case would enter if `bar` is `attr.NOTHING`.\r\nHence, you have to write:\r\n\r\n```python\r\nif foo.bar is not attr.NOTHING and foo.bar:\r\n    ... # Do something on a non-empty value\r\n```\r\n\r\nAnd this is kind of wired and can be easily forgotten (Like me until I found out that `attr.NOTHING` is True ;-) ).\r\n\r\nI am aware that usually an instance attribute should normally not be assigned with `attr.NOTHING`, but an Exception should be raised somewhere. However, with an own init, wrappers, not so simple cases, or custom converters, this can happen \u2013 and in this case I would expect that `attr.NOTHING` is behaving like other python empty-values and that `if foo.bar` would not be entered.\r\n\r\n## Interface change\r\n\r\nMaking `bool(attr.NOTHING) == False` would be a more or less severe interface change.\r\nIs `bool(attr.NOTHING) == False` on purpose for some reason?\r\nLike I said attributes should normally not be assigned with `attr.NOTHING`, so it might be a rare case; and direct tests if something is `attr.NOTHING` should be done by `some_value is attr.NOTHING` anyway \u2013 or in other words is someone already relying on the fact that `bool(attr.NOTHING) == True`? Then it would be a severe change, but I guess not.\r\n\r\nSo lets change bool(attr.NOTHING) to False by adding the following to `attr._make._Nothing`?\r\n\r\n```python\r\ndef __bool__(self):\r\n    return False\r\n```\n", "hints_text": "Makes sense to me.  I quickly implemented your proposed change.  All tests keep passing.  \ud83d\udc4d ", "created_at": "2020-12-13T05:58:40Z"}
{"repo": "python-attrs/attrs", "pull_number": 712, "instance_id": "python-attrs__attrs-712", "issue_numbers": ["703"], "base_commit": "6b4a1f1ce65162afe54e7101b263859bf8b2177e", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -91,7 +91,7 @@ def metadata_proxy(d):\n         res.data.update(d)  # We blocked update, so we have to do it like this.\n         return res\n \n-    def just_warn(*args, **kw):  # pragma: nocover\n+    def just_warn(*args, **kw):  # pragma: no cover\n         \"\"\"\n         We only warn on Python 3 because we are not aware of any concrete\n         consequences of not setting the cell on Python 2.\n@@ -132,7 +132,7 @@ def make_set_closure_cell():\n     \"\"\"\n     # pypy makes this easy. (It also supports the logic below, but\n     # why not do the easy/fast thing?)\n-    if PYPY:  # pragma: no cover\n+    if PYPY:\n \n         def set_closure_cell(cell, value):\n             cell.__setstate__((value,))\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -12,6 +12,7 @@\n from . import _config, setters\n from ._compat import (\n     PY2,\n+    PYPY,\n     isclass,\n     iteritems,\n     metadata_proxy,\n@@ -527,11 +528,29 @@ def _transform_attrs(\n     return _Attributes((attrs, base_attrs, base_attr_map))\n \n \n-def _frozen_setattrs(self, name, value):\n-    \"\"\"\n-    Attached to frozen classes as __setattr__.\n-    \"\"\"\n-    raise FrozenInstanceError()\n+if PYPY:\n+\n+    def _frozen_setattrs(self, name, value):\n+        \"\"\"\n+        Attached to frozen classes as __setattr__.\n+        \"\"\"\n+        if isinstance(self, BaseException) and name in (\n+            \"__cause__\",\n+            \"__context__\",\n+        ):\n+            BaseException.__setattr__(self, name, value)\n+            return\n+\n+        raise FrozenInstanceError()\n+\n+\n+else:\n+\n+    def _frozen_setattrs(self, name, value):\n+        \"\"\"\n+        Attached to frozen classes as __setattr__.\n+        \"\"\"\n+        raise FrozenInstanceError()\n \n \n def _frozen_delattrs(self, name):\n", "test_patch": "diff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -4,6 +4,8 @@\n \n import re\n \n+from functools import partial\n+\n import pytest\n \n import attr\n@@ -238,3 +240,32 @@ class B:\n             @attr.define(on_setattr=attr.setters.validate)\n             class C(A):\n                 pass\n+\n+    @pytest.mark.parametrize(\n+        \"decorator\",\n+        [\n+            partial(attr.s, frozen=True, slots=True, auto_exc=True),\n+            attr.frozen,\n+            attr.define,\n+            attr.mutable,\n+        ],\n+    )\n+    def test_discard_context(self, decorator):\n+        \"\"\"\n+        raise from None works.\n+\n+        Regression test for #703.\n+        \"\"\"\n+\n+        @decorator\n+        class MyException(Exception):\n+            x: str = attr.ib()\n+\n+        with pytest.raises(MyException) as ei:\n+            try:\n+                raise ValueError()\n+            except ValueError:\n+                raise MyException(\"foo\") from None\n+\n+        assert \"foo\" == ei.value.x\n+        assert ei.value.__cause__ is None\n", "problem_statement": "Frozen Exceptions cannot be thrown from Exception Handler in PyPy \nConsider the following code, which generates some random exception, which is then rethrown as a custom attrs exception class (in this case suppressing the context using [PEP 409](https://www.python.org/dev/peps/pep-0409/)'s `from None`):\r\n```python\r\nimport attr\r\n\r\n@attr.s(frozen=True, slots=True, auto_exc=True)\r\nclass MyException(BaseException):\r\n    msg:str = attr.ib()\r\n\r\ntry:\r\n    next(iter([]))\r\nexcept StopIteration:\r\n    raise MyException(\"test\") from None\r\n```\r\nIn CPython, this works as expected:\r\n```\r\nTraceback (most recent call last):\r\n  File \"scratch.py\", line 10, in <module>\r\n    raise MyException(\"test\") from None\r\n__main__.MyException: test\r\n```\r\nOn PyPy, this yields a very weird, different exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"scratch.py\", line 8, in <module>\r\n    next(iter([]))\r\nStopIteration\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"scratch.py\", line 10, in <module>\r\n    raise MyException(\"test\") from None\r\n  File \".venv-pypy3/site-packages/attr/_make.py\", line 528, in _frozen_setattrs\r\n    raise FrozenInstanceError()\r\nattr.exceptions.FrozenInstanceError\r\n```\r\nI assume this is related to how `__context__` and `__cause__` are set when (re-)raising exceptions (see also the linked PEP for some info on that). The PEP says \"To support raise Exception from None, `__context__` will stay as it is, but `__cause__` will start out as Ellipsis and will change to None when the raise Exception from None method is used.\", so it's weird that only PyPy seems to be wrong here (which is also the reason I'm reporting this against attrs and not PyPy). Maybe CPython doesn't completely adhere to that and doesn't change the value in this case - or changes it bypassing the high-level `__setattr__` API. Note that leaving the `from None` out doesn't change the weird behaviour. Maybe the `__setattr__` frozen check should be skipped for `__context__` and `__cause__` of exceptions?\r\n\r\nThe versions of the interpreters I'm using are:\r\n```\r\n$ pypy3 -V\r\nPython 3.6.9 (78d4c48fa091, Apr 30 2020, 07:55:31)\r\n[PyPy 7.3.1 with GCC 10.0.1 20200328 (Red Hat 10.0.1-0.11)]\r\n$ python3.9 -VV\r\nPython 3.9.0 (default, Oct  6 2020, 00:00:00) \r\n[GCC 10.2.1 20200723 (Red Hat 10.2.1-1)]\r\n```\n", "hints_text": "", "created_at": "2020-11-04T09:05:46Z"}
{"repo": "python-attrs/attrs", "pull_number": 704, "instance_id": "python-attrs__attrs-704", "issue_numbers": ["657"], "base_commit": "577691c40544b284cfbe3d7b381a5942c92d6d91", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -53,8 +53,10 @@ def asdict(\n         v = getattr(inst, a.name)\n         if filter is not None and not filter(a, v):\n             continue\n+\n         if value_serializer is not None:\n             v = value_serializer(inst, a, v)\n+\n         if recurse is True:\n             if has(v.__class__):\n                 rv[a.name] = asdict(\n@@ -65,7 +67,7 @@ def asdict(\n                     retain_collection_types,\n                     value_serializer,\n                 )\n-            elif isinstance(v, (tuple, list, set)):\n+            elif isinstance(v, (tuple, list, set, frozenset)):\n                 cf = v.__class__ if retain_collection_types is True else list\n                 rv[a.name] = cf(\n                     [\n@@ -127,7 +129,7 @@ def _asdict_anything(\n             retain_collection_types,\n             value_serializer,\n         )\n-    elif isinstance(val, (tuple, list, set)):\n+    elif isinstance(val, (tuple, list, set, frozenset)):\n         cf = val.__class__ if retain_collection_types is True else list\n         rv = cf(\n             [\n@@ -158,6 +160,7 @@ def _asdict_anything(\n         rv = val\n         if value_serializer is not None:\n             rv = value_serializer(None, None, rv)\n+\n     return rv\n \n \n@@ -212,7 +215,7 @@ def astuple(\n                         retain_collection_types=retain,\n                     )\n                 )\n-            elif isinstance(v, (tuple, list, set)):\n+            elif isinstance(v, (tuple, list, set, frozenset)):\n                 cf = v.__class__ if retain is True else list\n                 rv.append(\n                     cf(\n@@ -257,6 +260,7 @@ def astuple(\n                 rv.append(v)\n         else:\n             rv.append(v)\n+\n     return rv if tuple_factory is list else tuple_factory(rv)\n \n \n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -149,12 +149,26 @@ def test_lists_tuples_retain_type(self, container, C):\n             retain_collection_types=True,\n         )\n \n+    @given(set_type=st.sampled_from((set, frozenset)))\n+    def test_sets_no_retain(self, C, set_type):\n+        \"\"\"\n+        Set types are converted to lists if retain_collection_types=False.\n+        \"\"\"\n+        d = asdict(\n+            C(1, set_type((1, 2, 3))),\n+            retain_collection_types=False,\n+            recurse=True,\n+        )\n+\n+        assert {\"x\": 1, \"y\": [1, 2, 3]} == d\n+\n     @given(st.sampled_from(MAPPING_TYPES))\n     def test_dicts(self, C, dict_factory):\n         \"\"\"\n         If recurse is True, also recurse into dicts.\n         \"\"\"\n         res = asdict(C(1, {\"a\": C(4, 5)}), dict_factory=dict_factory)\n+\n         assert {\"x\": 1, \"y\": {\"a\": {\"x\": 4, \"y\": 5}}} == res\n         assert isinstance(res, dict_factory)\n \n@@ -330,6 +344,19 @@ def test_roundtrip(self, cls, tuple_class):\n \n         assert instance == roundtrip_instance\n \n+    @given(set_type=st.sampled_from((set, frozenset)))\n+    def test_sets_no_retain(self, C, set_type):\n+        \"\"\"\n+        Set types are converted to lists if retain_collection_types=False.\n+        \"\"\"\n+        d = astuple(\n+            C(1, set_type((1, 2, 3))),\n+            retain_collection_types=False,\n+            recurse=True,\n+        )\n+\n+        assert (1, [1, 2, 3]) == d\n+\n \n class TestHas(object):\n     \"\"\"\n", "problem_statement": "attr.asdict(retain_collection_types=False) doesn't support frozenset\nHey, I ran into some surprising behavior when using `attr.asdict()` with a frozen set.\r\nI was expecting `retain_collection_types=False` to convert a frozenset to a list, as it does with a tuple or list, but it keeps it as a frozenset\r\n\r\nExample\r\n```py3\r\nimport attr\r\n\r\n@attr.s\r\nclass Foo:\r\n    bar = attr.ib()\r\n\r\nDATA = (1, 2, 3)\r\nprint(\"set:\", attr.asdict(Foo(set(DATA))))\r\nprint(\"frozenset\", attr.asdict(Foo(frozenset(DATA))))\r\n```\r\n\r\nOutput:\r\n```sh\r\n$ python attr_demo.py\r\nset: {'bar': [1, 2, 3]}\r\nfrozenset {'bar': frozenset({1, 2, 3})}\r\n```\r\n\r\nExpected Output\r\n```sh\r\n$ python attr_demo.py\r\nset: {'bar': [1, 2, 3]}\r\nfrozenset  {'bar': [1, 2, 3]}\r\n```\r\n\r\n\r\nit looks like the code change is adding `frozenset` to the `isinstance` check on https://github.com/python-attrs/attrs/blob/master/src/attr/_funcs.py#L55\r\n\n", "hints_text": "", "created_at": "2020-10-19T08:05:34Z"}
{"repo": "python-attrs/attrs", "pull_number": 684, "instance_id": "python-attrs__attrs-684", "issue_numbers": ["682"], "base_commit": "dfb2ee284d6229d8bffe6cba6be66a747116cd27", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -2185,6 +2185,8 @@ class Attribute(object):\n \n     .. versionadded:: 20.1.0 *inherited*\n     .. versionadded:: 20.1.0 *on_setattr*\n+    .. versionchanged:: 20.2.0 *inherited* is not taken into account for\n+        equality checks and hashing anymore.\n \n     For the full version history of the fields, see `attr.ib`.\n     \"\"\"\n@@ -2354,8 +2356,11 @@ def _setattrs(self, name_values_pairs):\n ]\n \n Attribute = _add_hash(\n-    _add_eq(_add_repr(Attribute, attrs=_a), attrs=_a),\n-    attrs=[a for a in _a if a.hash],\n+    _add_eq(\n+        _add_repr(Attribute, attrs=_a),\n+        attrs=[a for a in _a if a.name != \"inherited\"],\n+    ),\n+    attrs=[a for a in _a if a.hash and a.name != \"inherited\"],\n )\n \n \n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -691,6 +691,26 @@ def test_sugar_callable(self):\n             class C(object):\n                 x = attr.ib(factory=Factory(list))\n \n+    def test_inherited_does_not_affect_hashing_and_equality(self):\n+        \"\"\"\n+        Whether or not an Attribute has been inherited doesn't affect how it's\n+        hashed and compared.\n+        \"\"\"\n+\n+        @attr.s\n+        class BaseClass(object):\n+            x = attr.ib()\n+\n+        @attr.s\n+        class SubClass(BaseClass):\n+            pass\n+\n+        ba = attr.fields(BaseClass)[0]\n+        sa = attr.fields(SubClass)[0]\n+\n+        assert ba == sa\n+        assert hash(ba) == hash(sa)\n+\n \n @pytest.mark.skipif(PY2, reason=\"keyword-only arguments are PY3-only.\")\n class TestKeywordOnlyAttributes(object):\n", "problem_statement": "Inherited attributes of subclasses no longer compare equal to the equivalent attributes of base class\nA change between 19.3.0 \u2192 20.1.0 which doesn't seem to be deliberate, but may be related to #635 is that inherited attributes no longer compare equal to the attributes of the base class. Here is a MWE:\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.s()\r\nclass BaseClass(object):\r\n    x = attr.ib()\r\n\r\n@attr.s()\r\nclass SubClass(BaseClass):\r\n    pass\r\n\r\nassert attr.fields(BaseClass)[0].name == attr.fields(SubClass)[0].name   # Succeeds in all versions\r\nassert attr.fields(BaseClass)[0] == attr.fields(SubClass)[0]  # Fails in 20.1.0\r\n```\r\n\r\nInterestingly, if you shadow the attribute, it works as expected:\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.s()\r\nclass BaseClass(object):\r\n    x = attr.ib()\r\n\r\n@attr.s()\r\nclass SubClass(BaseClass):\r\n    x = attr.ib()\r\n\r\n# Works in all versions\r\nassert attr.fields(BaseClass)[0].name == attr.fields(SubClass)[0].name\r\nassert attr.fields(BaseClass)[0] == attr.fields(SubClass)[0]\r\n```\r\n\r\nI think the issue is that `inherited` is included in the calculation of whether two `Attribute`s are equal or not.\r\n\r\nI discovered this when upgrading some code that does something like this:\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.s()\r\nclass BaseClass:\r\n    x = attr.ib()\r\n\r\n@attr.s()\r\nclass SubClass(BaseClass):\r\n    y = attr.ib()\r\n\r\ndef f(x) -> None:\r\n    print(x)\r\n\r\ndef my_function(obj : BaseClass) -> None:\r\n    kwargs = attr.asdict(obj, filter=attr.filters.include(*attr.fields(BaseClass)))\r\n    f(**kwargs)\r\n\r\nif __name__ == \"__main__\":\r\n    my_function(SubClass(1, 2))\r\n```\r\n\r\nThe idea there is that they want to pull out the subset of the structure that corresponds to the base class.\r\n\r\nIn this case, I can imagine working around it by pulling out the `name` attribute for each of the `Attribute`s (since in this case I _think_ they would want the subclass to pass along *any* attribute with the name of an attribute on the base class, not just ones that are configured the same way). I can imagine there might be other problems, though, if `attr.filters.include(*attr.fields(BaseClass))` is a common pattern.\n", "hints_text": "Yeah for all practical purposes, I think we've got it wrong ATM.  And I think hashing should also not take it into account. Technically it's wrong but in practice I think it makes it useless.", "created_at": "2020-09-02T05:54:30Z"}
{"repo": "python-attrs/attrs", "pull_number": 681, "instance_id": "python-attrs__attrs-681", "issue_numbers": ["680"], "base_commit": "bfd7bb49b467e7ab586deb475c23974a91df4dab", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -556,6 +556,7 @@ class _ClassBuilder(object):\n         \"_slots\",\n         \"_weakref_slot\",\n         \"_has_own_setattr\",\n+        \"_has_custom_setattr\",\n     )\n \n     def __init__(\n@@ -593,7 +594,8 @@ def __init__(\n         self._is_exc = is_exc\n         self._on_setattr = on_setattr\n \n-        self._has_own_setattr = has_custom_setattr\n+        self._has_custom_setattr = has_custom_setattr\n+        self._has_own_setattr = False\n \n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n \n@@ -654,7 +656,10 @@ def _patch_original_class(self):\n         if not self._has_own_setattr and getattr(\n             cls, \"__attrs_own_setattr__\", False\n         ):\n-            cls.__setattr__ = object.__setattr__\n+            cls.__attrs_own_setattr__ = False\n+\n+            if not self._has_custom_setattr:\n+                cls.__setattr__ = object.__setattr__\n \n         return cls\n \n@@ -669,24 +674,30 @@ def _create_slots_class(self):\n             if k not in tuple(self._attr_names) + (\"__dict__\", \"__weakref__\")\n         }\n \n-        # Traverse the MRO to check for an existing __weakref__ and\n-        # __setattr__.\n-        custom_setattr_inherited = False\n+        # If our class doesn't have its own implementation of __setattr__\n+        # (either from the user or by us), check the bases, if one of them has\n+        # an attrs-made __setattr__, that needs to be reset. We don't walk the\n+        # MRO because we only care about our immediate base classes.\n+        # XXX: This can be confused by subclassing a slotted attrs class with\n+        # XXX: a non-attrs class and subclass the resulting class with an attrs\n+        # XXX: class.  See `test_slotted_confused` for details.  For now that's\n+        # XXX: OK with us.\n+        if not self._has_own_setattr:\n+            cd[\"__attrs_own_setattr__\"] = False\n+\n+            if not self._has_custom_setattr:\n+                for base_cls in self._cls.__bases__:\n+                    if base_cls.__dict__.get(\"__attrs_own_setattr__\", False):\n+                        cd[\"__setattr__\"] = object.__setattr__\n+                        break\n+\n+        # Traverse the MRO to check for an existing __weakref__.\n         weakref_inherited = False\n         for base_cls in self._cls.__mro__[1:-1]:\n-            d = getattr(base_cls, \"__dict__\", {})\n-\n-            weakref_inherited = weakref_inherited or \"__weakref__\" in d\n-            custom_setattr_inherited = custom_setattr_inherited or not (\n-                d.get(\"__attrs_own_setattr__\", False)\n-            )\n-\n-            if weakref_inherited and custom_setattr_inherited:\n+            if base_cls.__dict__.get(\"__weakref__\", None) is not None:\n+                weakref_inherited = True\n                 break\n \n-        if not self._has_own_setattr and not custom_setattr_inherited:\n-            cd[\"__setattr__\"] = object.__setattr__\n-\n         names = self._attr_names\n         if (\n             self._weakref_slot\n@@ -697,7 +708,7 @@ def _create_slots_class(self):\n             names += (\"__weakref__\",)\n \n         # We only add the names of attributes that aren't inherited.\n-        # Settings __slots__ to inherited attributes wastes memory.\n+        # Setting __slots__ to inherited attributes wastes memory.\n         slot_names = [name for name in names if name not in base_names]\n         if self._cache_hash:\n             slot_names.append(_hash_cache_field)\n@@ -857,20 +868,14 @@ def add_setattr(self):\n         if not sa_attrs:\n             return self\n \n-        if self._has_own_setattr:\n+        if self._has_custom_setattr:\n             # We need to write a __setattr__ but there already is one!\n             raise ValueError(\n                 \"Can't combine custom __setattr__ with on_setattr hooks.\"\n             )\n \n-        cls = self._cls\n-\n+        # docstring comes from _add_method_dunders\n         def __setattr__(self, name, val):\n-            \"\"\"\n-            Method generated by attrs for class %s.\n-            \"\"\" % (\n-                cls.__name__,\n-            )\n             try:\n                 a, hook = sa_attrs[name]\n             except KeyError:\n", "test_patch": "diff --git a/tests/test_setattr.py b/tests/test_setattr.py\n--- a/tests/test_setattr.py\n+++ b/tests/test_setattr.py\n@@ -227,6 +227,9 @@ class NoHook(WithOnSetAttrHook):\n             assert NoHook.__setattr__ == object.__setattr__\n \n         assert 1 == NoHook(1).x\n+        assert Hooked.__attrs_own_setattr__\n+        assert not NoHook.__attrs_own_setattr__\n+        assert WithOnSetAttrHook.__attrs_own_setattr__\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_setattr_inherited_do_not_reset(self, slots):\n@@ -274,6 +277,45 @@ def test_pickling_retains_attrs_own(self, slots):\n \n         assert True is WOSAH.__attrs_own_setattr__\n \n+    def test_slotted_class_can_have_custom_setattr(self):\n+        \"\"\"\n+        A slotted class can define a custom setattr and it doesn't get\n+        overwritten.\n+\n+        Regression test for #680.\n+        \"\"\"\n+\n+        @attr.s(slots=True)\n+        class A(object):\n+            def __setattr__(self, key, value):\n+                raise SystemError\n+\n+        with pytest.raises(SystemError):\n+            A().x = 1\n+\n+    @pytest.mark.xfail(raises=attr.exceptions.FrozenAttributeError)\n+    def test_slotted_confused(self):\n+        \"\"\"\n+        If we have a in-between non-attrs class, setattr reset detection\n+        should still work, but currently doesn't.\n+\n+        It works with dict classes because we can look the finished class and\n+        patch it.  With slotted classes we have to deduce it ourselves.\n+        \"\"\"\n+\n+        @attr.s(slots=True)\n+        class A(object):\n+            x = attr.ib(on_setattr=setters.frozen)\n+\n+        class B(A):\n+            pass\n+\n+        @attr.s(slots=True)\n+        class C(B):\n+            x = attr.ib()\n+\n+        C(1).x = 2\n+\n \n @pytest.mark.skipif(PY2, reason=\"Python 3-only.\")\n class TestSetAttrNoPy2(object):\n@@ -298,6 +340,7 @@ def __setattr__(self, name, val):\n \n         i = RemoveNeedForOurSetAttr(1)\n \n+        assert not RemoveNeedForOurSetAttr.__attrs_own_setattr__\n         assert 2 == i.x\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n@@ -345,3 +388,48 @@ class HookAndCustomSetAttr(object):\n \n                 def __setattr__(self, _, __):\n                     pass\n+\n+    @pytest.mark.parametrize(\"a_slots\", [True, False])\n+    @pytest.mark.parametrize(\"b_slots\", [True, False])\n+    @pytest.mark.parametrize(\"c_slots\", [True, False])\n+    def test_setattr_inherited_do_not_reset_intermediate(\n+        self, a_slots, b_slots, c_slots\n+    ):\n+        \"\"\"\n+        A user-provided intermediate __setattr__ is not reset to\n+        object.__setattr__.\n+\n+        This only can work on Python 3+ with auto_detect activated, such that\n+        attrs can know that there is a user-provided __setattr__.\n+        \"\"\"\n+\n+        @attr.s(slots=a_slots)\n+        class A(object):\n+            x = attr.ib(on_setattr=setters.frozen)\n+\n+        @attr.s(slots=b_slots, auto_detect=True)\n+        class B(A):\n+            x = attr.ib(on_setattr=setters.NO_OP)\n+\n+            def __setattr__(self, key, value):\n+                raise SystemError\n+\n+        @attr.s(slots=c_slots)\n+        class C(B):\n+            pass\n+\n+        assert getattr(A, \"__attrs_own_setattr__\", False) is True\n+        assert getattr(B, \"__attrs_own_setattr__\", False) is False\n+        assert getattr(C, \"__attrs_own_setattr__\", False) is False\n+\n+        with pytest.raises(SystemError):\n+            C(1).x = 3\n+\n+    def test_docstring(self):\n+        \"\"\"\n+        Generated __setattr__ has a useful docstring.\n+        \"\"\"\n+        assert (\n+            \"Method generated by attrs for class WithOnSetAttrHook.\"\n+            == WithOnSetAttrHook.__setattr__.__doc__\n+        )\n", "problem_statement": "Using slots class overrides custom `__setattr__` in 20.1.0\nIn 19.3.0, it was possible to have a custom `__setattr__` on your `slots` class, but in 20.1.0 the custom `__setattr__` is replaced with the default one:\r\n\r\n```python\r\nimport attr\r\n@attr.s(slots=True)\r\nclass A:\r\n    def __setattr__(self, key, value):\r\n        print(f\"{key}: {value}\")\r\n```\r\n\r\nIn 19.3.0:\r\n\r\n```python\r\n>>> A().a = 3\r\na: 3\r\n```\r\n\r\nIn 20.1.0:\r\n\r\n```python\r\n>>> A().a = 3\r\nAttributeError: 'A' object has no attribute 'a'\r\n>>> A.__setattr__\r\n<slot wrapper '__setattr__' of 'object' objects>\r\n```\r\n\r\nWhen `slots=False`, the same thing does not occur.\n", "hints_text": "", "created_at": "2020-09-01T07:50:19Z"}
{"repo": "python-attrs/attrs", "pull_number": 675, "instance_id": "python-attrs__attrs-675", "issue_numbers": ["673"], "base_commit": "d02b76de16fbb011004e16106e63ac1896018e6c", "patch": "diff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -50,9 +50,9 @@ def define(\n     .. versionadded:: 20.1.0\n     \"\"\"\n \n-    def do_it(auto_attribs):\n+    def do_it(cls, auto_attribs):\n         return attrs(\n-            maybe_cls=maybe_cls,\n+            maybe_cls=cls,\n             these=these,\n             repr=repr,\n             hash=hash,\n@@ -74,12 +74,21 @@ def do_it(auto_attribs):\n         )\n \n     if auto_attribs is not None:\n-        return do_it(auto_attribs)\n-\n-    try:\n-        return do_it(True)\n-    except UnannotatedAttributeError:\n-        return do_it(False)\n+        return do_it(maybe_cls, auto_attribs)\n+\n+    def wrap(cls):\n+        # Making this a wrapper ensures this code runs during class creation.\n+        try:\n+            return do_it(cls, True)\n+        except UnannotatedAttributeError:\n+            return do_it(cls, False)\n+\n+    # maybe_cls's type depends on the usage of the decorator.  It's a class\n+    # if it's used as `@attrs` but ``None`` if used as `@attrs()`.\n+    if maybe_cls is None:\n+        return wrap\n+    else:\n+        return wrap(maybe_cls)\n \n \n mutable = define\n", "test_patch": "diff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -101,6 +101,31 @@ class OldSchool:\n \n         assert OldSchool(1) == OldSchool(1)\n \n+        # Test with maybe_cls = None\n+        @attr.define()\n+        class OldSchool2:\n+            x = attr.field()\n+\n+        assert OldSchool2(1) == OldSchool2(1)\n+\n+    def test_auto_attribs_detect_annotations(self):\n+        \"\"\"\n+        define correctly detects if a class has type annotations.\n+        \"\"\"\n+\n+        @attr.define\n+        class NewSchool:\n+            x: int\n+\n+        assert NewSchool(1) == NewSchool(1)\n+\n+        # Test with maybe_cls = None\n+        @attr.define()\n+        class NewSchool2:\n+            x: int\n+\n+        assert NewSchool2(1) == NewSchool2(1)\n+\n     def test_exception(self):\n         \"\"\"\n         Exceptions are detected and correctly handled.\n", "problem_statement": "Hybrid behavior doesn't work when maybe_cls=None and no annotations\nThe doc says:\r\n```\r\n    :param Optional[bool] auto_attribs: If set to `True` or `False`, it behaves\r\n       exactly like `attr.s`. If left `None`, `attr.s` will try to guess:\r\n\r\n       1. If all attributes are annotated and no `attr.ib` is found, it assumes\r\n          *auto_attribs=True*.\r\n       2. Otherwise it assumes *auto_attribs=False* and tries to collect\r\n          `attr.ib`\\ s.\r\n```\r\n\r\nSadly it doesn't exactly work.\r\n```\r\nimport attr\r\n\r\n@attr.define()\r\nclass Trigger:\r\n    a = attr.field()\r\n```\r\n\r\nThe code does this:\r\n```\r\n    try:\r\n        return do_it(True)\r\n    except UnannotatedAttributeError:\r\n        return do_it(False)\r\n```\r\n\r\nBut do_it itself won't raise `UnannotatedAttributeError` until the decorator is applied to the class.\n", "hints_text": "Ah yikes it\u2019s about the `()`. I\u2019m afk for now but any ideas how to make it work? \ud83e\udd14 \nThis seems to work but is not fully tested:\r\n```\r\ndef define(\r\n    maybe_cls=None,\r\n    *,\r\n   ...\r\n):\r\n    def wrap(cls):\r\n        def do_it(auto_attribs):\r\n            return attrs(\r\n                maybe_cls=cls,\r\n                these=these,\r\n                repr=repr,\r\n                hash=hash,\r\n                init=init,\r\n                slots=slots,\r\n                frozen=frozen,\r\n                weakref_slot=weakref_slot,\r\n                str=str,\r\n                auto_attribs=auto_attribs,\r\n                kw_only=kw_only,\r\n                cache_hash=cache_hash,\r\n                auto_exc=auto_exc,\r\n                eq=eq,\r\n                order=order,\r\n                auto_detect=auto_detect,\r\n                collect_by_mro=True,\r\n                getstate_setstate=getstate_setstate,\r\n                on_setattr=on_setattr,\r\n            )\r\n\r\n        if auto_attribs is not None:\r\n            return do_it(auto_attribs)\r\n\r\n        try:\r\n            return do_it(True)\r\n        except UnannotatedAttributeError:\r\n            return do_it(False)\r\n\r\n    # maybe_cls's type depends on the usage of the decorator.  It's a class\r\n    # if it's used as `@attrs` but ``None`` if used as `@attrs()`.\r\n    if maybe_cls is None:\r\n        return wrap\r\n    else:\r\n        return wrap(maybe_cls)\r\n```\r\n\r\nEdit: Fixed the code a bit.", "created_at": "2020-08-23T03:24:34Z"}
{"repo": "python-attrs/attrs", "pull_number": 671, "instance_id": "python-attrs__attrs-671", "issue_numbers": ["670", "670"], "base_commit": "1a29941d5cf74ca585780495cb6c17fd013ec861", "patch": "diff --git a/src/attr/_next_gen.py b/src/attr/_next_gen.py\n--- a/src/attr/_next_gen.py\n+++ b/src/attr/_next_gen.py\n@@ -28,7 +28,7 @@ def define(\n     kw_only=False,\n     cache_hash=False,\n     auto_exc=True,\n-    eq=True,\n+    eq=None,\n     order=False,\n     auto_detect=True,\n     getstate_setstate=None,\n", "test_patch": "diff --git a/tests/test_next_gen.py b/tests/test_next_gen.py\n--- a/tests/test_next_gen.py\n+++ b/tests/test_next_gen.py\n@@ -133,3 +133,18 @@ class F:\n \n         with pytest.raises(attr.exceptions.FrozenInstanceError):\n             f.x = 2\n+\n+    def test_auto_detect_eq(self):\n+        \"\"\"\n+        auto_detect=True works for eq.\n+\n+        Regression test for #670.\n+        \"\"\"\n+\n+        @attr.define\n+        class C:\n+            def __eq__(self, o):\n+                raise ValueError()\n+\n+        with pytest.raises(ValueError):\n+            C() == C()\n", "problem_statement": "@attr.define fails to auto-detect __eq__\n`@attr.define` is failing to auto-detect `__eq__`. My understanding from the docs is that this _should_ work, but `ValueError` is not being raised unless I use `@attr.define(eq=False)`.\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.define\r\nclass Treatment:\r\n    treatment: str\r\n\r\n    def __eq__(self, other):\r\n        raise ValueError\r\n\r\n\r\nassert Treatment(\"foo\") == \"foo\"\r\n```\r\n\r\n```console\r\n$ pytest t.py\r\n================================ test session starts ================================\r\nplatform darwin -- Python 3.8.5, pytest-6.0.1, py-1.8.2, pluggy-0.13.1\r\nrootdir: /Users/andy/tmp\r\nplugins: Faker-4.1.1\r\ncollected 0 items / 1 error                                                         \r\n\r\n====================================== ERRORS =======================================\r\n_______________________________ ERROR collecting t.py _______________________________\r\nt.py:11: in <module>\r\n    assert Treatment(\"foo\") == \"foo\"\r\nE   AssertionError: assert Treatment(treatment='foo') == 'foo'\r\nE    +  where Treatment(treatment='foo') = <class 't.Treatment'>('foo')\r\n============================== short test summary info ==============================\r\nERROR t.py - AssertionError: assert Treatment(treatment='foo') == 'foo'\r\n!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!\r\n```\n@attr.define fails to auto-detect __eq__\n`@attr.define` is failing to auto-detect `__eq__`. My understanding from the docs is that this _should_ work, but `ValueError` is not being raised unless I use `@attr.define(eq=False)`.\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.define\r\nclass Treatment:\r\n    treatment: str\r\n\r\n    def __eq__(self, other):\r\n        raise ValueError\r\n\r\n\r\nassert Treatment(\"foo\") == \"foo\"\r\n```\r\n\r\n```console\r\n$ pytest t.py\r\n================================ test session starts ================================\r\nplatform darwin -- Python 3.8.5, pytest-6.0.1, py-1.8.2, pluggy-0.13.1\r\nrootdir: /Users/andy/tmp\r\nplugins: Faker-4.1.1\r\ncollected 0 items / 1 error                                                         \r\n\r\n====================================== ERRORS =======================================\r\n_______________________________ ERROR collecting t.py _______________________________\r\nt.py:11: in <module>\r\n    assert Treatment(\"foo\") == \"foo\"\r\nE   AssertionError: assert Treatment(treatment='foo') == 'foo'\r\nE    +  where Treatment(treatment='foo') = <class 't.Treatment'>('foo')\r\n============================== short test summary info ==============================\r\nERROR t.py - AssertionError: assert Treatment(treatment='foo') == 'foo'\r\n!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!\r\n```\n", "hints_text": "\n", "created_at": "2020-08-21T03:15:28Z"}
{"repo": "python-attrs/attrs", "pull_number": 663, "instance_id": "python-attrs__attrs-663", "issue_numbers": ["661"], "base_commit": "e554373d16a000c6b022ef3f46b7607f704f4e8b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -557,6 +557,7 @@ class _ClassBuilder(object):\n         \"_on_setattr\",\n         \"_slots\",\n         \"_weakref_slot\",\n+        \"_has_own_setattr\",\n     )\n \n     def __init__(\n@@ -573,6 +574,7 @@ def __init__(\n         is_exc,\n         collect_by_mro,\n         on_setattr,\n+        has_custom_setattr,\n     ):\n         attrs, base_attrs, base_map = _transform_attrs(\n             cls, these, auto_attribs, kw_only, collect_by_mro,\n@@ -585,7 +587,7 @@ def __init__(\n         self._base_attr_map = base_map\n         self._attr_names = tuple(a.name for a in attrs)\n         self._slots = slots\n-        self._frozen = frozen or _has_frozen_base_class(cls)\n+        self._frozen = frozen\n         self._weakref_slot = weakref_slot\n         self._cache_hash = cache_hash\n         self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\n@@ -593,12 +595,16 @@ def __init__(\n         self._is_exc = is_exc\n         self._on_setattr = on_setattr\n \n+        self._has_own_setattr = has_custom_setattr\n+\n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n \n         if frozen:\n             self._cls_dict[\"__setattr__\"] = _frozen_setattrs\n             self._cls_dict[\"__delattr__\"] = _frozen_delattrs\n \n+            self._has_own_setattr = True\n+\n         if getstate_setstate:\n             (\n                 self._cls_dict[\"__getstate__\"],\n@@ -645,6 +651,13 @@ def _patch_original_class(self):\n         for name, value in self._cls_dict.items():\n             setattr(cls, name, value)\n \n+        # If we've inherited an attrs __setattr__ and don't write our own,\n+        # reset it to object's.\n+        if not self._has_own_setattr and getattr(\n+            cls, \"__attrs_own_setattr__\", False\n+        ):\n+            cls.__setattr__ = object.__setattr__\n+\n         return cls\n \n     def _create_slots_class(self):\n@@ -658,14 +671,24 @@ def _create_slots_class(self):\n             if k not in tuple(self._attr_names) + (\"__dict__\", \"__weakref__\")\n         }\n \n+        # Traverse the MRO to check for an existing __weakref__ and\n+        # __setattr__.\n+        custom_setattr_inherited = False\n         weakref_inherited = False\n-\n-        # Traverse the MRO to check for an existing __weakref__.\n         for base_cls in self._cls.__mro__[1:-1]:\n-            if \"__weakref__\" in getattr(base_cls, \"__dict__\", ()):\n-                weakref_inherited = True\n+            d = getattr(base_cls, \"__dict__\", {})\n+\n+            weakref_inherited = weakref_inherited or \"__weakref__\" in d\n+            custom_setattr_inherited = custom_setattr_inherited or not (\n+                d.get(\"__attrs_own_setattr__\", False)\n+            )\n+\n+            if weakref_inherited and custom_setattr_inherited:\n                 break\n \n+        if not self._has_own_setattr and not custom_setattr_inherited:\n+            cd[\"__setattr__\"] = object.__setattr__\n+\n         names = self._attr_names\n         if (\n             self._weakref_slot\n@@ -836,7 +859,20 @@ def add_setattr(self):\n         if not sa_attrs:\n             return self\n \n+        if self._has_own_setattr:\n+            # We need to write a __setattr__ but there already is one!\n+            raise ValueError(\n+                \"Can't combine custom __setattr__ with on_setattr hooks.\"\n+            )\n+\n+        cls = self._cls\n+\n         def __setattr__(self, name, val):\n+            \"\"\"\n+            Method generated by attrs for class %s.\n+            \"\"\" % (\n+                cls.__name__,\n+            )\n             try:\n                 a, hook = sa_attrs[name]\n             except KeyError:\n@@ -846,7 +882,9 @@ def __setattr__(self, name, val):\n \n             _obj_setattr(self, name, nval)\n \n+        self._cls_dict[\"__attrs_own_setattr__\"] = True\n         self._cls_dict[\"__setattr__\"] = self._add_method_dunders(__setattr__)\n+        self._has_own_setattr = True\n \n         return self\n \n@@ -1076,6 +1114,8 @@ def attrs(\n                circumvent that limitation by using\n                ``object.__setattr__(self, \"attribute_name\", value)``.\n \n+            5. Subclasses of a frozen class are frozen too.\n+\n     :param bool weakref_slot: Make instances weak-referenceable.  This has no\n         effect unless ``slots`` is also enabled.\n     :param bool auto_attribs: If ``True``, collect `PEP 526`_-annotated\n@@ -1200,13 +1240,20 @@ def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n             raise TypeError(\"attrs only works with new-style classes.\")\n \n+        is_frozen = frozen or _has_frozen_base_class(cls)\n         is_exc = auto_exc is True and issubclass(cls, BaseException)\n+        has_own_setattr = auto_detect and _has_own_attribute(\n+            cls, \"__setattr__\"\n+        )\n+\n+        if has_own_setattr and is_frozen:\n+            raise ValueError(\"Can't freeze a class with a custom __setattr__.\")\n \n         builder = _ClassBuilder(\n             cls,\n             these,\n             slots,\n-            frozen,\n+            is_frozen,\n             weakref_slot,\n             _determine_whether_to_implement(\n                 cls,\n@@ -1221,6 +1268,7 @@ def wrap(cls):\n             is_exc,\n             collect_by_mro,\n             on_setattr,\n+            has_own_setattr,\n         )\n         if _determine_whether_to_implement(\n             cls, repr, auto_detect, (\"__repr__\",)\n@@ -1263,7 +1311,9 @@ def wrap(cls):\n                     \" hashing must be either explicitly or implicitly \"\n                     \"enabled.\"\n                 )\n-        elif hash is True or (hash is None and eq is True and frozen is True):\n+        elif hash is True or (\n+            hash is None and eq is True and is_frozen is True\n+        ):\n             # Build a __hash__ if told so, or if it's safe.\n             builder.add_hash()\n         else:\n", "test_patch": "diff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -16,11 +16,9 @@\n \n import attr\n \n-from attr import setters\n from attr._compat import PY2, TYPE\n from attr._make import NOTHING, Attribute\n-from attr.exceptions import FrozenAttributeError, FrozenInstanceError\n-from attr.validators import instance_of, matches_re\n+from attr.exceptions import FrozenInstanceError\n \n from .strategies import optional_bool\n \n@@ -112,9 +110,9 @@ class WithMetaSlots(object):\n FromMakeClass = attr.make_class(\"FromMakeClass\", [\"x\"])\n \n \n-class TestDarkMagic(object):\n+class TestFunctional(object):\n     \"\"\"\n-    Integration tests.\n+    Functional tests.\n     \"\"\"\n \n     @pytest.mark.parametrize(\"cls\", [C2, C2Slots])\n@@ -320,6 +318,7 @@ def test_pickle_object(self, cls, protocol):\n             obj = cls(123, 456)\n         else:\n             obj = cls(123)\n+\n         assert repr(obj) == repr(pickle.loads(pickle.dumps(obj, protocol)))\n \n     def test_subclassing_frozen_gives_frozen(self):\n@@ -332,6 +331,9 @@ def test_subclassing_frozen_gives_frozen(self):\n         assert i.x == \"foo\"\n         assert i.y == \"bar\"\n \n+        with pytest.raises(FrozenInstanceError):\n+            i.x = \"baz\"\n+\n     @pytest.mark.parametrize(\"cls\", [WithMeta, WithMetaSlots])\n     def test_metaclass_preserved(self, cls):\n         \"\"\"\n@@ -683,183 +685,3 @@ class C(object):\n             \"2021-06-01.  Please use `eq` and `order` instead.\"\n             == w.message.args[0]\n         )\n-\n-\n-class TestSetAttr(object):\n-    def test_change(self):\n-        \"\"\"\n-        The return value of a hook overwrites the value. But they are not run\n-        on __init__.\n-        \"\"\"\n-\n-        def hook(*a, **kw):\n-            return \"hooked!\"\n-\n-        @attr.s\n-        class Hooked(object):\n-            x = attr.ib(on_setattr=hook)\n-            y = attr.ib()\n-\n-        h = Hooked(\"x\", \"y\")\n-\n-        assert \"x\" == h.x\n-        assert \"y\" == h.y\n-\n-        h.x = \"xxx\"\n-        h.y = \"yyy\"\n-\n-        assert \"yyy\" == h.y\n-        assert \"hooked!\" == h.x\n-\n-    def test_frozen_attribute(self):\n-        \"\"\"\n-        Frozen attributes raise FrozenAttributeError, others are not affected.\n-        \"\"\"\n-\n-        @attr.s\n-        class PartiallyFrozen(object):\n-            x = attr.ib(on_setattr=setters.frozen)\n-            y = attr.ib()\n-\n-        pf = PartiallyFrozen(\"x\", \"y\")\n-\n-        pf.y = \"yyy\"\n-\n-        assert \"yyy\" == pf.y\n-\n-        with pytest.raises(FrozenAttributeError):\n-            pf.x = \"xxx\"\n-\n-        assert \"x\" == pf.x\n-\n-    @pytest.mark.parametrize(\n-        \"on_setattr\",\n-        [setters.validate, [setters.validate], setters.pipe(setters.validate)],\n-    )\n-    def test_validator(self, on_setattr):\n-        \"\"\"\n-        Validators are run and they don't alter the value.\n-        \"\"\"\n-\n-        @attr.s(on_setattr=on_setattr)\n-        class ValidatedAttribute(object):\n-            x = attr.ib()\n-            y = attr.ib(validator=[instance_of(str), matches_re(\"foo.*qux\")])\n-\n-        va = ValidatedAttribute(42, \"foobarqux\")\n-\n-        with pytest.raises(TypeError) as ei:\n-            va.y = 42\n-\n-        assert \"foobarqux\" == va.y\n-\n-        assert ei.value.args[0].startswith(\"'y' must be <\")\n-\n-        with pytest.raises(ValueError) as ei:\n-            va.y = \"quxbarfoo\"\n-\n-        assert ei.value.args[0].startswith(\"'y' must match regex '\")\n-\n-        assert \"foobarqux\" == va.y\n-\n-        va.y = \"foobazqux\"\n-\n-        assert \"foobazqux\" == va.y\n-\n-    def test_pipe(self):\n-        \"\"\"\n-        Multiple hooks are possible, in that case the last return value is\n-        used. They can be supplied using the pipe functions or by passing a\n-        list to on_setattr.\n-        \"\"\"\n-\n-        s = [setters.convert, lambda _, __, nv: nv + 1]\n-\n-        @attr.s\n-        class Piped(object):\n-            x1 = attr.ib(converter=int, on_setattr=setters.pipe(*s))\n-            x2 = attr.ib(converter=int, on_setattr=s)\n-\n-        p = Piped(\"41\", \"22\")\n-\n-        assert 41 == p.x1\n-        assert 22 == p.x2\n-\n-        p.x1 = \"41\"\n-        p.x2 = \"22\"\n-\n-        assert 42 == p.x1\n-        assert 23 == p.x2\n-\n-    def test_make_class(self):\n-        \"\"\"\n-        on_setattr of make_class gets forwarded.\n-        \"\"\"\n-        C = attr.make_class(\"C\", {\"x\": attr.ib()}, on_setattr=setters.frozen)\n-\n-        c = C(1)\n-\n-        with pytest.raises(FrozenAttributeError):\n-            c.x = 2\n-\n-    def test_no_validator_no_converter(self):\n-        \"\"\"\n-        validate and convert tolerate missing validators and converters.\n-        \"\"\"\n-\n-        @attr.s(on_setattr=[setters.convert, setters.validate])\n-        class C(object):\n-            x = attr.ib()\n-\n-        c = C(1)\n-\n-        c.x = 2\n-\n-    def test_validate_respects_run_validators_config(self):\n-        \"\"\"\n-        If run validators is off, validate doesn't run them.\n-        \"\"\"\n-\n-        @attr.s(on_setattr=setters.validate)\n-        class C(object):\n-            x = attr.ib(validator=attr.validators.instance_of(int))\n-\n-        c = C(1)\n-\n-        attr.set_run_validators(False)\n-\n-        c.x = \"1\"\n-\n-        assert \"1\" == c.x\n-\n-        attr.set_run_validators(True)\n-\n-        with pytest.raises(TypeError) as ei:\n-            c.x = \"1\"\n-\n-        assert ei.value.args[0].startswith(\"'x' must be <\")\n-\n-    def test_frozen_on_setattr_class_is_caught(self):\n-        \"\"\"\n-        @attr.s(on_setattr=X, frozen=True) raises an ValueError.\n-        \"\"\"\n-        with pytest.raises(ValueError) as ei:\n-\n-            @attr.s(frozen=True, on_setattr=setters.validate)\n-            class C(object):\n-                x = attr.ib()\n-\n-        assert \"Frozen classes can't use on_setattr.\" == ei.value.args[0]\n-\n-    def test_frozen_on_setattr_attribute_is_caught(self):\n-        \"\"\"\n-        attr.ib(on_setattr=X) on a frozen class raises an ValueError.\n-        \"\"\"\n-\n-        with pytest.raises(ValueError) as ei:\n-\n-            @attr.s(frozen=True)\n-            class C(object):\n-                x = attr.ib(on_setattr=setters.validate)\n-\n-        assert \"Frozen classes can't use on_setattr.\" == ei.value.args[0]\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1466,6 +1466,7 @@ class C(object):\n             False,\n             True,\n             None,\n+            False,\n         )\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n@@ -1491,6 +1492,7 @@ class C(object):\n             False,\n             True,\n             None,\n+            False,\n         )\n \n         cls = (\n@@ -1568,6 +1570,7 @@ class C(object):\n             cache_hash=False,\n             collect_by_mro=True,\n             on_setattr=None,\n+            has_custom_setattr=False,\n         )\n         b._cls = {}  # no __module__; no __qualname__\n \ndiff --git a/tests/test_setattr.py b/tests/test_setattr.py\nnew file mode 100644\n--- /dev/null\n+++ b/tests/test_setattr.py\n@@ -0,0 +1,347 @@\n+from __future__ import absolute_import, division, print_function\n+\n+import pickle\n+\n+import pytest\n+\n+import attr\n+\n+from attr import setters\n+from attr._compat import PY2\n+from attr.exceptions import FrozenAttributeError\n+from attr.validators import instance_of, matches_re\n+\n+\n+@attr.s(frozen=True)\n+class Frozen(object):\n+    x = attr.ib()\n+\n+\n+@attr.s\n+class WithOnSetAttrHook(object):\n+    x = attr.ib(on_setattr=lambda *args: None)\n+\n+\n+class TestSetAttr(object):\n+    def test_change(self):\n+        \"\"\"\n+        The return value of a hook overwrites the value. But they are not run\n+        on __init__.\n+        \"\"\"\n+\n+        def hook(*a, **kw):\n+            return \"hooked!\"\n+\n+        @attr.s\n+        class Hooked(object):\n+            x = attr.ib(on_setattr=hook)\n+            y = attr.ib()\n+\n+        h = Hooked(\"x\", \"y\")\n+\n+        assert \"x\" == h.x\n+        assert \"y\" == h.y\n+\n+        h.x = \"xxx\"\n+        h.y = \"yyy\"\n+\n+        assert \"yyy\" == h.y\n+        assert \"hooked!\" == h.x\n+\n+    def test_frozen_attribute(self):\n+        \"\"\"\n+        Frozen attributes raise FrozenAttributeError, others are not affected.\n+        \"\"\"\n+\n+        @attr.s\n+        class PartiallyFrozen(object):\n+            x = attr.ib(on_setattr=setters.frozen)\n+            y = attr.ib()\n+\n+        pf = PartiallyFrozen(\"x\", \"y\")\n+\n+        pf.y = \"yyy\"\n+\n+        assert \"yyy\" == pf.y\n+\n+        with pytest.raises(FrozenAttributeError):\n+            pf.x = \"xxx\"\n+\n+        assert \"x\" == pf.x\n+\n+    @pytest.mark.parametrize(\n+        \"on_setattr\",\n+        [setters.validate, [setters.validate], setters.pipe(setters.validate)],\n+    )\n+    def test_validator(self, on_setattr):\n+        \"\"\"\n+        Validators are run and they don't alter the value.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=on_setattr)\n+        class ValidatedAttribute(object):\n+            x = attr.ib()\n+            y = attr.ib(validator=[instance_of(str), matches_re(\"foo.*qux\")])\n+\n+        va = ValidatedAttribute(42, \"foobarqux\")\n+\n+        with pytest.raises(TypeError) as ei:\n+            va.y = 42\n+\n+        assert \"foobarqux\" == va.y\n+\n+        assert ei.value.args[0].startswith(\"'y' must be <\")\n+\n+        with pytest.raises(ValueError) as ei:\n+            va.y = \"quxbarfoo\"\n+\n+        assert ei.value.args[0].startswith(\"'y' must match regex '\")\n+\n+        assert \"foobarqux\" == va.y\n+\n+        va.y = \"foobazqux\"\n+\n+        assert \"foobazqux\" == va.y\n+\n+    def test_pipe(self):\n+        \"\"\"\n+        Multiple hooks are possible, in that case the last return value is\n+        used. They can be supplied using the pipe functions or by passing a\n+        list to on_setattr.\n+        \"\"\"\n+\n+        s = [setters.convert, lambda _, __, nv: nv + 1]\n+\n+        @attr.s\n+        class Piped(object):\n+            x1 = attr.ib(converter=int, on_setattr=setters.pipe(*s))\n+            x2 = attr.ib(converter=int, on_setattr=s)\n+\n+        p = Piped(\"41\", \"22\")\n+\n+        assert 41 == p.x1\n+        assert 22 == p.x2\n+\n+        p.x1 = \"41\"\n+        p.x2 = \"22\"\n+\n+        assert 42 == p.x1\n+        assert 23 == p.x2\n+\n+    def test_make_class(self):\n+        \"\"\"\n+        on_setattr of make_class gets forwarded.\n+        \"\"\"\n+        C = attr.make_class(\"C\", {\"x\": attr.ib()}, on_setattr=setters.frozen)\n+\n+        c = C(1)\n+\n+        with pytest.raises(FrozenAttributeError):\n+            c.x = 2\n+\n+    def test_no_validator_no_converter(self):\n+        \"\"\"\n+        validate and convert tolerate missing validators and converters.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=[setters.convert, setters.validate])\n+        class C(object):\n+            x = attr.ib()\n+\n+        c = C(1)\n+\n+        c.x = 2\n+\n+        assert 2 == c.x\n+\n+    def test_validate_respects_run_validators_config(self):\n+        \"\"\"\n+        If run validators is off, validate doesn't run them.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=setters.validate)\n+        class C(object):\n+            x = attr.ib(validator=attr.validators.instance_of(int))\n+\n+        c = C(1)\n+\n+        attr.set_run_validators(False)\n+\n+        c.x = \"1\"\n+\n+        assert \"1\" == c.x\n+\n+        attr.set_run_validators(True)\n+\n+        with pytest.raises(TypeError) as ei:\n+            c.x = \"1\"\n+\n+        assert ei.value.args[0].startswith(\"'x' must be <\")\n+\n+    def test_frozen_on_setattr_class_is_caught(self):\n+        \"\"\"\n+        @attr.s(on_setattr=X, frozen=True) raises an ValueError.\n+        \"\"\"\n+        with pytest.raises(ValueError) as ei:\n+\n+            @attr.s(frozen=True, on_setattr=setters.validate)\n+            class C(object):\n+                x = attr.ib()\n+\n+        assert \"Frozen classes can't use on_setattr.\" == ei.value.args[0]\n+\n+    def test_frozen_on_setattr_attribute_is_caught(self):\n+        \"\"\"\n+        attr.ib(on_setattr=X) on a frozen class raises an ValueError.\n+        \"\"\"\n+\n+        with pytest.raises(ValueError) as ei:\n+\n+            @attr.s(frozen=True)\n+            class C(object):\n+                x = attr.ib(on_setattr=setters.validate)\n+\n+        assert \"Frozen classes can't use on_setattr.\" == ei.value.args[0]\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_setattr_reset_if_no_custom_setattr(self, slots):\n+        \"\"\"\n+        If a class with an active setattr is subclassed and no new setattr\n+        is generated, the __setattr__ is set to object.__setattr__.\n+\n+        We do the double test because of Python 2.\n+        \"\"\"\n+\n+        def boom(*args):\n+            pytest.fail(\"Must not be called.\")\n+\n+        @attr.s\n+        class Hooked(object):\n+            x = attr.ib(on_setattr=boom)\n+\n+        @attr.s(slots=slots)\n+        class NoHook(WithOnSetAttrHook):\n+            x = attr.ib()\n+\n+        if not PY2:\n+            assert NoHook.__setattr__ == object.__setattr__\n+\n+        assert 1 == NoHook(1).x\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_setattr_inherited_do_not_reset(self, slots):\n+        \"\"\"\n+        If we inherit a __setattr__ that has been written by the user, we must\n+        not reset it unless necessary.\n+        \"\"\"\n+\n+        class A(object):\n+            \"\"\"\n+            Not an attrs class on purpose to prevent accidental resets that\n+            would render the asserts meaningless.\n+            \"\"\"\n+\n+            def __setattr__(self, *args):\n+                pass\n+\n+        @attr.s(slots=slots)\n+        class B(A):\n+            pass\n+\n+        assert B.__setattr__ == A.__setattr__\n+\n+        @attr.s(slots=slots)\n+        class C(B):\n+            pass\n+\n+        assert C.__setattr__ == A.__setattr__\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_pickling_retains_attrs_own(self, slots):\n+        \"\"\"\n+        Pickling/Unpickling does not lose ownership information about\n+        __setattr__.\n+        \"\"\"\n+        i = WithOnSetAttrHook(1)\n+\n+        assert True is i.__attrs_own_setattr__\n+\n+        i2 = pickle.loads(pickle.dumps(i))\n+\n+        assert True is i2.__attrs_own_setattr__\n+\n+        WOSAH = pickle.loads(pickle.dumps(WithOnSetAttrHook))\n+\n+        assert True is WOSAH.__attrs_own_setattr__\n+\n+\n+@pytest.mark.skipif(PY2, reason=\"Python 3-only.\")\n+class TestSetAttrNoPy2(object):\n+    \"\"\"\n+    __setattr__ tests for Py3+ to avoid the skip repetition.\n+    \"\"\"\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_setattr_auto_detect_if_no_custom_setattr(self, slots):\n+        \"\"\"\n+        It's possible to remove the on_setattr hook from an attribute and\n+        therefore write a custom __setattr__.\n+        \"\"\"\n+        assert 1 == WithOnSetAttrHook(1).x\n+\n+        @attr.s(auto_detect=True, slots=slots)\n+        class RemoveNeedForOurSetAttr(WithOnSetAttrHook):\n+            x = attr.ib()\n+\n+            def __setattr__(self, name, val):\n+                object.__setattr__(self, name, val * 2)\n+\n+        i = RemoveNeedForOurSetAttr(1)\n+\n+        assert 2 == i.x\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_setattr_restore_respects_auto_detect(self, slots):\n+        \"\"\"\n+        If __setattr__ should be restored but the user supplied its own and\n+        set auto_detect, leave is alone.\n+        \"\"\"\n+\n+        @attr.s(auto_detect=True, slots=slots)\n+        class CustomSetAttr:\n+            def __setattr__(self, _, __):\n+                pass\n+\n+        assert CustomSetAttr.__setattr__ != object.__setattr__\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_setattr_auto_detect_frozen(self, slots):\n+        \"\"\"\n+        frozen=True together with a detected custom __setattr__ are rejected.\n+        \"\"\"\n+        with pytest.raises(\n+            ValueError, match=\"Can't freeze a class with a custom __setattr__.\"\n+        ):\n+\n+            @attr.s(auto_detect=True, slots=slots, frozen=True)\n+            class CustomSetAttr(Frozen):\n+                def __setattr__(self, _, __):\n+                    pass\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_setattr_auto_detect_on_setattr(self, slots):\n+        \"\"\"\n+        on_setattr attributes together with a detected custom __setattr__ are\n+        rejected.\n+        \"\"\"\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Can't combine custom __setattr__ with on_setattr hooks.\",\n+        ):\n+\n+            @attr.s(auto_detect=True, slots=slots)\n+            class HookAndCustomSetAttr(object):\n+                x = attr.ib(on_setattr=lambda *args: None)\n+\n+                def __setattr__(self, _, __):\n+                    pass\n", "problem_statement": "Restore __setattr__ when subclassing and we didn't write a new __setattr__\nCurrently if you do this:\r\n\r\n```python\r\n@attr.s(frozen=True)\r\nclass A:\r\n    a = attr.ib()\r\n\r\n@attr.s\r\nclass B(A):\r\n    b = attr.ib()\r\n```\r\n\r\nB is frozen too, because we don't write a new `__setattr__` to overwrite the old one. Once #660 is merged, this will become an even bigger problem.\r\n\r\nWe have to restore `__setattr__` to `object.__setattr__` if we don't have a reason to overwrite the existing one ourselves.\r\n\r\n`auto_detect=True` should be considered.\n", "hints_text": "OK turns out, the inheritance of frozeness is on purpose #128. Whether or not that was a good idea I'm not sure, but it's not something I'm willing to break.", "created_at": "2020-08-04T13:54:59Z"}
{"repo": "python-attrs/attrs", "pull_number": 660, "instance_id": "python-attrs__attrs-660", "issue_numbers": ["645"], "base_commit": "428bbcf0d3901b83f96951157351e3716df3a04f", "patch": "diff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -50,9 +50,6 @@\n EXTRAS_REQUIRE[\"dev\"] = (\n     EXTRAS_REQUIRE[\"tests\"] + EXTRAS_REQUIRE[\"docs\"] + [\"pre-commit\"]\n )\n-EXTRAS_REQUIRE[\"azure-pipelines\"] = EXTRAS_REQUIRE[\"tests\"] + [\n-    \"pytest-azurepipelines\"\n-]\n \n ###############################################################################\n \ndiff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -2,7 +2,7 @@\n \n from functools import partial\n \n-from . import converters, exceptions, filters, validators\n+from . import converters, exceptions, filters, setters, validators\n from ._config import get_run_validators, set_run_validators\n from ._funcs import asdict, assoc, astuple, evolve, has\n from ._make import (\n@@ -63,6 +63,7 @@\n     \"make_class\",\n     \"s\",\n     \"set_run_validators\",\n+    \"setters\",\n     \"validate\",\n     \"validators\",\n ]\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -9,7 +9,7 @@\n \n from operator import itemgetter\n \n-from . import _config\n+from . import _config, setters\n from ._compat import (\n     PY2,\n     isclass,\n@@ -29,7 +29,7 @@\n \n # This is used at least twice, so cache it here.\n _obj_setattr = object.__setattr__\n-_init_converter_pat = \"__attr_converter_{}\"\n+_init_converter_pat = \"__attr_converter_%s\"\n _init_factory_pat = \"__attr_factory_{}\"\n _tuple_property_pat = (\n     \"    {attr_name} = _attrs_property(_attrs_itemgetter({index}))\"\n@@ -109,6 +109,7 @@ def attrib(\n     kw_only=False,\n     eq=None,\n     order=None,\n+    on_setattr=None,\n ):\n     \"\"\"\n     Create a new attribute on a class.\n@@ -126,7 +127,7 @@ def attrib(\n         used to construct a new value (useful for mutable data types like lists\n         or dicts).\n \n-        If a default is not set (or set manually to ``attr.NOTHING``), a value\n+        If a default is not set (or set manually to `attr.NOTHING`), a value\n         *must* be supplied when instantiating; otherwise a `TypeError`\n         will be raised.\n \n@@ -200,6 +201,12 @@ def attrib(\n     :param kw_only: Make this attribute keyword-only (Python 3+)\n         in the generated ``__init__`` (if ``init`` is ``False``, this\n         parameter is ignored).\n+    :param on_setattr: Allows to overwrite the *on_setattr* setting from\n+        `attr.s`. If left `None`, the *on_setattr* value from `attr.s` is used.\n+        Set to `attr.setters.NO_OP` to run **no** `setattr` hooks for this\n+        attribute -- regardless of the setting in `attr.s`.\n+    :type on_setattr: `callable`, or a list of callables, or `None`, or\n+        `attr.setters.NO_OP`\n \n     .. versionadded:: 15.2.0 *convert*\n     .. versionadded:: 16.3.0 *metadata*\n@@ -217,6 +224,7 @@ def attrib(\n     .. versionchanged:: 19.2.0 *repr* also accepts a custom callable.\n     .. deprecated:: 19.2.0 *cmp* Removal on or after 2021-06-01.\n     .. versionadded:: 19.2.0 *eq* and *order*\n+    .. versionadded:: 20.1.0 *on_setattr*\n     \"\"\"\n     eq, order = _determine_eq_order(cmp, eq, order, True)\n \n@@ -238,6 +246,16 @@ def attrib(\n     if metadata is None:\n         metadata = {}\n \n+    # Apply syntactic sugar by auto-wrapping.\n+    if isinstance(on_setattr, (list, tuple)):\n+        on_setattr = setters.pipe(*on_setattr)\n+\n+    if validator and isinstance(validator, (list, tuple)):\n+        validator = and_(*validator)\n+\n+    if converter and isinstance(converter, (list, tuple)):\n+        converter = chain(*converter)\n+\n     return _CountingAttr(\n         default=default,\n         validator=validator,\n@@ -251,6 +269,7 @@ def attrib(\n         kw_only=kw_only,\n         eq=eq,\n         order=order,\n+        on_setattr=on_setattr,\n     )\n \n \n@@ -524,19 +543,20 @@ class _ClassBuilder(object):\n     \"\"\"\n \n     __slots__ = (\n-        \"_cls\",\n-        \"_cls_dict\",\n+        \"_attr_names\",\n         \"_attrs\",\n+        \"_base_attr_map\",\n         \"_base_names\",\n-        \"_attr_names\",\n-        \"_slots\",\n-        \"_frozen\",\n-        \"_weakref_slot\",\n         \"_cache_hash\",\n-        \"_has_post_init\",\n+        \"_cls\",\n+        \"_cls_dict\",\n         \"_delete_attribs\",\n-        \"_base_attr_map\",\n+        \"_frozen\",\n+        \"_has_post_init\",\n         \"_is_exc\",\n+        \"_on_setattr\",\n+        \"_slots\",\n+        \"_weakref_slot\",\n     )\n \n     def __init__(\n@@ -552,6 +572,7 @@ def __init__(\n         cache_hash,\n         is_exc,\n         collect_by_mro,\n+        on_setattr,\n     ):\n         attrs, base_attrs, base_map = _transform_attrs(\n             cls, these, auto_attribs, kw_only, collect_by_mro,\n@@ -570,6 +591,7 @@ def __init__(\n         self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\n         self._delete_attribs = not bool(these)\n         self._is_exc = is_exc\n+        self._on_setattr = on_setattr\n \n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n \n@@ -774,6 +796,8 @@ def add_init(self):\n                 self._cache_hash,\n                 self._base_attr_map,\n                 self._is_exc,\n+                self._on_setattr is not None\n+                and self._on_setattr is not setters.NO_OP,\n             )\n         )\n \n@@ -799,6 +823,33 @@ def add_order(self):\n \n         return self\n \n+    def add_setattr(self):\n+        if self._frozen:\n+            return self\n+\n+        sa_attrs = {}\n+        for a in self._attrs:\n+            on_setattr = a.on_setattr or self._on_setattr\n+            if on_setattr and on_setattr is not setters.NO_OP:\n+                sa_attrs[a.name] = a, on_setattr\n+\n+        if not sa_attrs:\n+            return self\n+\n+        def __setattr__(self, name, val):\n+            try:\n+                a, hook = sa_attrs[name]\n+            except KeyError:\n+                nval = val\n+            else:\n+                nval = hook(self, a, val)\n+\n+            _obj_setattr(self, name, nval)\n+\n+        self._cls_dict[\"__setattr__\"] = self._add_method_dunders(__setattr__)\n+\n+        return self\n+\n     def _add_method_dunders(self, method):\n         \"\"\"\n         Add __module__ and __qualname__ to a *method* if possible.\n@@ -816,8 +867,8 @@ def _add_method_dunders(self, method):\n             pass\n \n         try:\n-            method.__doc__ = \"Method generated by attrs for class {}.\".format(\n-                self._cls.__qualname__\n+            method.__doc__ = \"Method generated by attrs for class %s.\" % (\n+                self._cls.__qualname__,\n             )\n         except AttributeError:\n             pass\n@@ -908,6 +959,7 @@ def attrs(\n     auto_detect=False,\n     collect_by_mro=False,\n     getstate_setstate=None,\n+    on_setattr=None,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -1090,6 +1142,19 @@ def attrs(\n        on the class (i.e. not inherited), it is set to `False` (this is usually\n        what you want).\n \n+    :param on_setattr: A callable that is run whenever the user attempts to set\n+        an attribute (either by assignment like ``i.x = 42`` or by using\n+        `setattr` like ``setattr(i, \"x\", 42)``). It receives the same argument\n+        as validators: the instance, the attribute that is being modified, and\n+        the new value.\n+\n+        If no exception is raised, the attribute is set to the return value of\n+        the callable.\n+\n+        If a list of callables is passed, they're automatically wrapped in an\n+        `attr.setters.pipe`.\n+\n+\n     .. versionadded:: 16.0.0 *slots*\n     .. versionadded:: 16.1.0 *frozen*\n     .. versionadded:: 16.3.0 *str*\n@@ -1117,6 +1182,7 @@ def attrs(\n     .. versionadded:: 20.1.0 *auto_detect*\n     .. versionadded:: 20.1.0 *collect_by_mro*\n     .. versionadded:: 20.1.0 *getstate_setstate*\n+    .. versionadded:: 20.1.0 *on_setattr*\n     \"\"\"\n     if auto_detect and PY2:\n         raise PythonTooOldError(\n@@ -1126,6 +1192,9 @@ def attrs(\n     eq_, order_ = _determine_eq_order(cmp, eq, order, None)\n     hash_ = hash  # work around the lack of nonlocal\n \n+    if isinstance(on_setattr, (list, tuple)):\n+        on_setattr = setters.pipe(*on_setattr)\n+\n     def wrap(cls):\n \n         if getattr(cls, \"__class__\", None) is None:\n@@ -1151,6 +1220,7 @@ def wrap(cls):\n             cache_hash,\n             is_exc,\n             collect_by_mro,\n+            on_setattr,\n         )\n         if _determine_whether_to_implement(\n             cls, repr, auto_detect, (\"__repr__\",)\n@@ -1169,6 +1239,8 @@ def wrap(cls):\n         ):\n             builder.add_order()\n \n+        builder.add_setattr()\n+\n         if (\n             hash_ is None\n             and auto_detect is True\n@@ -1579,43 +1651,6 @@ def _add_repr(cls, ns=None, attrs=None):\n     return cls\n \n \n-def _make_init(\n-    cls, attrs, post_init, frozen, slots, cache_hash, base_attr_map, is_exc\n-):\n-    attrs = [a for a in attrs if a.init or a.default is not NOTHING]\n-\n-    unique_filename = _generate_unique_filename(cls, \"init\")\n-\n-    script, globs, annotations = _attrs_to_init_script(\n-        attrs, frozen, slots, post_init, cache_hash, base_attr_map, is_exc\n-    )\n-    locs = {}\n-    bytecode = compile(script, unique_filename, \"exec\")\n-    attr_dict = dict((a.name, a) for a in attrs)\n-    globs.update({\"NOTHING\": NOTHING, \"attr_dict\": attr_dict})\n-\n-    if frozen is True:\n-        # Save the lookup overhead in __init__ if we need to circumvent\n-        # immutability.\n-        globs[\"_cached_setattr\"] = _obj_setattr\n-\n-    eval(bytecode, globs, locs)\n-\n-    # In order of debuggers like PDB being able to step through the code,\n-    # we add a fake linecache entry.\n-    linecache.cache[unique_filename] = (\n-        len(script),\n-        None,\n-        script.splitlines(True),\n-        unique_filename,\n-    )\n-\n-    __init__ = locs[\"__init__\"]\n-    __init__.__annotations__ = annotations\n-\n-    return __init__\n-\n-\n def fields(cls):\n     \"\"\"\n     Return the tuple of ``attrs`` attributes for a class.\n@@ -1700,8 +1735,134 @@ def _is_slot_attr(a_name, base_attr_map):\n     return a_name in base_attr_map and _is_slot_cls(base_attr_map[a_name])\n \n \n+def _make_init(\n+    cls,\n+    attrs,\n+    post_init,\n+    frozen,\n+    slots,\n+    cache_hash,\n+    base_attr_map,\n+    is_exc,\n+    has_global_on_setattr,\n+):\n+    if frozen and has_global_on_setattr:\n+        raise ValueError(\"Frozen classes can't use on_setattr.\")\n+\n+    needs_cached_setattr = cache_hash or frozen\n+    filtered_attrs = []\n+    attr_dict = {}\n+    for a in attrs:\n+        if not a.init and a.default is NOTHING:\n+            continue\n+\n+        filtered_attrs.append(a)\n+        attr_dict[a.name] = a\n+\n+        if a.on_setattr is not None:\n+            if frozen is True:\n+                raise ValueError(\"Frozen classes can't use on_setattr.\")\n+\n+            needs_cached_setattr = True\n+        elif (\n+            has_global_on_setattr and a.on_setattr is not setters.NO_OP\n+        ) or _is_slot_attr(a.name, base_attr_map):\n+            needs_cached_setattr = True\n+\n+    unique_filename = _generate_unique_filename(cls, \"init\")\n+\n+    script, globs, annotations = _attrs_to_init_script(\n+        filtered_attrs,\n+        frozen,\n+        slots,\n+        post_init,\n+        cache_hash,\n+        base_attr_map,\n+        is_exc,\n+        needs_cached_setattr,\n+        has_global_on_setattr,\n+    )\n+    locs = {}\n+    bytecode = compile(script, unique_filename, \"exec\")\n+    globs.update({\"NOTHING\": NOTHING, \"attr_dict\": attr_dict})\n+\n+    if needs_cached_setattr:\n+        # Save the lookup overhead in __init__ if we need to circumvent\n+        # setattr hooks.\n+        globs[\"_cached_setattr\"] = _obj_setattr\n+\n+    eval(bytecode, globs, locs)\n+\n+    # In order of debuggers like PDB being able to step through the code,\n+    # we add a fake linecache entry.\n+    linecache.cache[unique_filename] = (\n+        len(script),\n+        None,\n+        script.splitlines(True),\n+        unique_filename,\n+    )\n+\n+    __init__ = locs[\"__init__\"]\n+    __init__.__annotations__ = annotations\n+\n+    return __init__\n+\n+\n+def _setattr(attr_name, value_var, has_on_setattr):\n+    \"\"\"\n+    Use the cached object.setattr to set *attr_name* to *value_var*.\n+    \"\"\"\n+    return \"_setattr('%s', %s)\" % (attr_name, value_var,)\n+\n+\n+def _setattr_with_converter(attr_name, value_var, has_on_setattr):\n+    \"\"\"\n+    Use the cached object.setattr to set *attr_name* to *value_var*, but run\n+    its converter first.\n+    \"\"\"\n+    return \"_setattr('%s', %s(%s))\" % (\n+        attr_name,\n+        _init_converter_pat % (attr_name,),\n+        value_var,\n+    )\n+\n+\n+def _assign(attr_name, value, has_on_setattr):\n+    \"\"\"\n+    Unless *attr_name* has an on_setattr hook, use normal assignment. Otherwise\n+    relegate to _setattr.\n+    \"\"\"\n+    if has_on_setattr:\n+        return _setattr(attr_name, value, True)\n+\n+    return \"self.%s = %s\" % (attr_name, value,)\n+\n+\n+def _assign_with_converter(attr_name, value_var, has_on_setattr):\n+    \"\"\"\n+    Unless *attr_name* has an on_setattr hook, use normal assignment after\n+    conversion. Otherwise relegate to _setattr_with_converter.\n+    \"\"\"\n+    if has_on_setattr:\n+        return _setattr_with_converter(attr_name, value_var, True)\n+\n+    return \"self.%s = %s(%s)\" % (\n+        attr_name,\n+        _init_converter_pat % (attr_name,),\n+        value_var,\n+    )\n+\n+\n def _attrs_to_init_script(\n-    attrs, frozen, slots, post_init, cache_hash, base_attr_map, is_exc\n+    attrs,\n+    frozen,\n+    slots,\n+    post_init,\n+    cache_hash,\n+    base_attr_map,\n+    is_exc,\n+    needs_cached_setattr,\n+    has_global_on_setattr,\n ):\n     \"\"\"\n     Return a script of an initializer for *attrs* and a dict of globals.\n@@ -1712,85 +1873,49 @@ def _attrs_to_init_script(\n     a cached ``object.__setattr__``.\n     \"\"\"\n     lines = []\n-    any_slot_ancestors = any(\n-        _is_slot_attr(a.name, base_attr_map) for a in attrs\n-    )\n+    if needs_cached_setattr:\n+        lines.append(\n+            # Circumvent the __setattr__ descriptor to save one lookup per\n+            # assignment.\n+            # Note _setattr will be used again below if cache_hash is True\n+            \"_setattr = _cached_setattr.__get__(self, self.__class__)\"\n+        )\n+\n     if frozen is True:\n         if slots is True:\n-            lines.append(\n-                # Circumvent the __setattr__ descriptor to save one lookup per\n-                # assignment.\n-                # Note _setattr will be used again below if cache_hash is True\n-                \"_setattr = _cached_setattr.__get__(self, self.__class__)\"\n-            )\n-\n-            def fmt_setter(attr_name, value_var):\n-                return \"_setattr('%(attr_name)s', %(value_var)s)\" % {\n-                    \"attr_name\": attr_name,\n-                    \"value_var\": value_var,\n-                }\n-\n-            def fmt_setter_with_converter(attr_name, value_var):\n-                conv_name = _init_converter_pat.format(attr_name)\n-                return \"_setattr('%(attr_name)s', %(conv)s(%(value_var)s))\" % {\n-                    \"attr_name\": attr_name,\n-                    \"value_var\": value_var,\n-                    \"conv\": conv_name,\n-                }\n-\n+            fmt_setter = _setattr\n+            fmt_setter_with_converter = _setattr_with_converter\n         else:\n             # Dict frozen classes assign directly to __dict__.\n             # But only if the attribute doesn't come from an ancestor slot\n             # class.\n             # Note _inst_dict will be used again below if cache_hash is True\n             lines.append(\"_inst_dict = self.__dict__\")\n-            if any_slot_ancestors:\n-                lines.append(\n-                    # Circumvent the __setattr__ descriptor to save one lookup\n-                    # per assignment.\n-                    \"_setattr = _cached_setattr.__get__(self, self.__class__)\"\n-                )\n \n-            def fmt_setter(attr_name, value_var):\n-                if _is_slot_attr(attr_name, base_attr_map):\n-                    res = \"_setattr('%(attr_name)s', %(value_var)s)\" % {\n-                        \"attr_name\": attr_name,\n-                        \"value_var\": value_var,\n-                    }\n-                else:\n-                    res = \"_inst_dict['%(attr_name)s'] = %(value_var)s\" % {\n-                        \"attr_name\": attr_name,\n-                        \"value_var\": value_var,\n-                    }\n-                return res\n-\n-            def fmt_setter_with_converter(attr_name, value_var):\n-                conv_name = _init_converter_pat.format(attr_name)\n+            def fmt_setter(attr_name, value_var, has_on_setattr):\n                 if _is_slot_attr(attr_name, base_attr_map):\n-                    tmpl = \"_setattr('%(attr_name)s', %(c)s(%(value_var)s))\"\n-                else:\n-                    tmpl = \"_inst_dict['%(attr_name)s'] = %(c)s(%(value_var)s)\"\n-                return tmpl % {\n-                    \"attr_name\": attr_name,\n-                    \"value_var\": value_var,\n-                    \"c\": conv_name,\n-                }\n+                    return _setattr(attr_name, value_var, has_on_setattr)\n+\n+                return \"_inst_dict['%s'] = %s\" % (attr_name, value_var,)\n+\n+            def fmt_setter_with_converter(\n+                attr_name, value_var, has_on_setattr\n+            ):\n+                if has_on_setattr or _is_slot_attr(attr_name, base_attr_map):\n+                    return _setattr_with_converter(\n+                        attr_name, value_var, has_on_setattr\n+                    )\n+\n+                return \"_inst_dict['%s'] = %s(%s)\" % (\n+                    attr_name,\n+                    _init_converter_pat % (attr_name,),\n+                    value_var,\n+                )\n \n     else:\n         # Not frozen.\n-        def fmt_setter(attr_name, value):\n-            return \"self.%(attr_name)s = %(value)s\" % {\n-                \"attr_name\": attr_name,\n-                \"value\": value,\n-            }\n-\n-        def fmt_setter_with_converter(attr_name, value_var):\n-            conv_name = _init_converter_pat.format(attr_name)\n-            return \"self.%(attr_name)s = %(conv)s(%(value_var)s)\" % {\n-                \"attr_name\": attr_name,\n-                \"value_var\": value_var,\n-                \"conv\": conv_name,\n-            }\n+        fmt_setter = _assign\n+        fmt_setter_with_converter = _assign_with_converter\n \n     args = []\n     kw_only_args = []\n@@ -1804,13 +1929,19 @@ def fmt_setter_with_converter(attr_name, value_var):\n     for a in attrs:\n         if a.validator:\n             attrs_to_validate.append(a)\n+\n         attr_name = a.name\n+        has_on_setattr = a.on_setattr is not None or (\n+            a.on_setattr is not setters.NO_OP and has_global_on_setattr\n+        )\n         arg_name = a.name.lstrip(\"_\")\n+\n         has_factory = isinstance(a.default, Factory)\n         if has_factory and a.default.takes_self:\n             maybe_self = \"self\"\n         else:\n             maybe_self = \"\"\n+\n         if a.init is False:\n             if has_factory:\n                 init_factory_name = _init_factory_pat.format(a.name)\n@@ -1818,16 +1949,18 @@ def fmt_setter_with_converter(attr_name, value_var):\n                     lines.append(\n                         fmt_setter_with_converter(\n                             attr_name,\n-                            init_factory_name + \"({0})\".format(maybe_self),\n+                            init_factory_name + \"(%s)\" % (maybe_self,),\n+                            has_on_setattr,\n                         )\n                     )\n-                    conv_name = _init_converter_pat.format(a.name)\n+                    conv_name = _init_converter_pat % (a.name,)\n                     names_for_globals[conv_name] = a.converter\n                 else:\n                     lines.append(\n                         fmt_setter(\n                             attr_name,\n-                            init_factory_name + \"({0})\".format(maybe_self),\n+                            init_factory_name + \"(%s)\" % (maybe_self,),\n+                            has_on_setattr,\n                         )\n                     )\n                 names_for_globals[init_factory_name] = a.default.factory\n@@ -1836,70 +1969,78 @@ def fmt_setter_with_converter(attr_name, value_var):\n                     lines.append(\n                         fmt_setter_with_converter(\n                             attr_name,\n-                            \"attr_dict['{attr_name}'].default\".format(\n-                                attr_name=attr_name\n-                            ),\n+                            \"attr_dict['%s'].default\" % (attr_name,),\n+                            has_on_setattr,\n                         )\n                     )\n-                    conv_name = _init_converter_pat.format(a.name)\n+                    conv_name = _init_converter_pat % (a.name,)\n                     names_for_globals[conv_name] = a.converter\n                 else:\n                     lines.append(\n                         fmt_setter(\n                             attr_name,\n-                            \"attr_dict['{attr_name}'].default\".format(\n-                                attr_name=attr_name\n-                            ),\n+                            \"attr_dict['%s'].default\" % (attr_name,),\n+                            has_on_setattr,\n                         )\n                     )\n         elif a.default is not NOTHING and not has_factory:\n-            arg = \"{arg_name}=attr_dict['{attr_name}'].default\".format(\n-                arg_name=arg_name, attr_name=attr_name\n-            )\n+            arg = \"%s=attr_dict['%s'].default\" % (arg_name, attr_name,)\n             if a.kw_only:\n                 kw_only_args.append(arg)\n             else:\n                 args.append(arg)\n+\n             if a.converter is not None:\n-                lines.append(fmt_setter_with_converter(attr_name, arg_name))\n+                lines.append(\n+                    fmt_setter_with_converter(\n+                        attr_name, arg_name, has_on_setattr,\n+                    )\n+                )\n                 names_for_globals[\n-                    _init_converter_pat.format(a.name)\n+                    _init_converter_pat % (a.name,)\n                 ] = a.converter\n             else:\n-                lines.append(fmt_setter(attr_name, arg_name))\n+                lines.append(fmt_setter(attr_name, arg_name, has_on_setattr))\n+\n         elif has_factory:\n-            arg = \"{arg_name}=NOTHING\".format(arg_name=arg_name)\n+            arg = \"%s=NOTHING\" % (arg_name,)\n             if a.kw_only:\n                 kw_only_args.append(arg)\n             else:\n                 args.append(arg)\n-            lines.append(\n-                \"if {arg_name} is not NOTHING:\".format(arg_name=arg_name)\n-            )\n+            lines.append(\"if %s is not NOTHING:\" % (arg_name,))\n+\n             init_factory_name = _init_factory_pat.format(a.name)\n             if a.converter is not None:\n                 lines.append(\n-                    \"    \" + fmt_setter_with_converter(attr_name, arg_name)\n+                    \"    \"\n+                    + fmt_setter_with_converter(\n+                        attr_name, arg_name, has_on_setattr\n+                    )\n                 )\n                 lines.append(\"else:\")\n                 lines.append(\n                     \"    \"\n                     + fmt_setter_with_converter(\n                         attr_name,\n-                        init_factory_name + \"({0})\".format(maybe_self),\n+                        init_factory_name + \"(\" + maybe_self + \")\",\n+                        has_on_setattr,\n                     )\n                 )\n                 names_for_globals[\n-                    _init_converter_pat.format(a.name)\n+                    _init_converter_pat % (a.name,)\n                 ] = a.converter\n             else:\n-                lines.append(\"    \" + fmt_setter(attr_name, arg_name))\n+                lines.append(\n+                    \"    \" + fmt_setter(attr_name, arg_name, has_on_setattr)\n+                )\n                 lines.append(\"else:\")\n                 lines.append(\n                     \"    \"\n                     + fmt_setter(\n                         attr_name,\n-                        init_factory_name + \"({0})\".format(maybe_self),\n+                        init_factory_name + \"(\" + maybe_self + \")\",\n+                        has_on_setattr,\n                     )\n                 )\n             names_for_globals[init_factory_name] = a.default.factory\n@@ -1908,13 +2049,18 @@ def fmt_setter_with_converter(attr_name, value_var):\n                 kw_only_args.append(arg_name)\n             else:\n                 args.append(arg_name)\n+\n             if a.converter is not None:\n-                lines.append(fmt_setter_with_converter(attr_name, arg_name))\n+                lines.append(\n+                    fmt_setter_with_converter(\n+                        attr_name, arg_name, has_on_setattr\n+                    )\n+                )\n                 names_for_globals[\n-                    _init_converter_pat.format(a.name)\n+                    _init_converter_pat % (a.name,)\n                 ] = a.converter\n             else:\n-                lines.append(fmt_setter(attr_name, arg_name))\n+                lines.append(fmt_setter(attr_name, arg_name, has_on_setattr))\n \n         if a.init is True and a.converter is None and a.type is not None:\n             annotations[arg_name] = a.type\n@@ -1923,13 +2069,14 @@ def fmt_setter_with_converter(attr_name, value_var):\n         names_for_globals[\"_config\"] = _config\n         lines.append(\"if _config._run_validators is True:\")\n         for a in attrs_to_validate:\n-            val_name = \"__attr_validator_{}\".format(a.name)\n-            attr_name = \"__attr_{}\".format(a.name)\n+            val_name = \"__attr_validator_\" + a.name\n+            attr_name = \"__attr_\" + a.name\n             lines.append(\n-                \"    {}(self, {}, self.{})\".format(val_name, attr_name, a.name)\n+                \"    %s(self, %s, self.%s)\" % (val_name, attr_name, a.name)\n             )\n             names_for_globals[val_name] = a.validator\n             names_for_globals[attr_name] = a\n+\n     if post_init:\n         lines.append(\"self.__attrs_post_init__()\")\n \n@@ -1992,6 +2139,7 @@ class Attribute(object):\n     which is only syntactic sugar for ``default=Factory(...)``.\n \n     .. versionadded:: 20.1.0 *inherited*\n+    .. versionadded:: 20.1.0 *on_setattr*\n \n     For the full version history of the fields, see `attr.ib`.\n     \"\"\"\n@@ -2010,6 +2158,7 @@ class Attribute(object):\n         \"converter\",\n         \"kw_only\",\n         \"inherited\",\n+        \"on_setattr\",\n     )\n \n     def __init__(\n@@ -2028,6 +2177,7 @@ def __init__(\n         kw_only=False,\n         eq=None,\n         order=None,\n+        on_setattr=None,\n     ):\n         eq, order = _determine_eq_order(cmp, eq, order, True)\n \n@@ -2056,6 +2206,7 @@ def __init__(\n         bound_setattr(\"type\", type)\n         bound_setattr(\"kw_only\", kw_only)\n         bound_setattr(\"inherited\", inherited)\n+        bound_setattr(\"on_setattr\", on_setattr)\n \n     def __setattr__(self, name, value):\n         raise FrozenInstanceError()\n@@ -2185,6 +2336,7 @@ class _CountingAttr(object):\n         \"converter\",\n         \"type\",\n         \"kw_only\",\n+        \"on_setattr\",\n     )\n     __attrs_attrs__ = tuple(\n         Attribute(\n@@ -2199,6 +2351,7 @@ class _CountingAttr(object):\n             eq=True,\n             order=False,\n             inherited=False,\n+            on_setattr=None,\n         )\n         for name in (\n             \"counter\",\n@@ -2208,6 +2361,7 @@ class _CountingAttr(object):\n             \"order\",\n             \"hash\",\n             \"init\",\n+            \"on_setattr\",\n         )\n     ) + (\n         Attribute(\n@@ -2222,6 +2376,7 @@ class _CountingAttr(object):\n             eq=True,\n             order=False,\n             inherited=False,\n+            on_setattr=None,\n         ),\n     )\n     cls_counter = 0\n@@ -2240,19 +2395,13 @@ def __init__(\n         kw_only,\n         eq,\n         order,\n+        on_setattr,\n     ):\n         _CountingAttr.cls_counter += 1\n         self.counter = _CountingAttr.cls_counter\n         self._default = default\n-        # If validator is a list/tuple, wrap it using helper validator.\n-        if validator and isinstance(validator, (list, tuple)):\n-            self._validator = and_(*validator)\n-        else:\n-            self._validator = validator\n-        if converter and isinstance(converter, (list, tuple)):\n-            self.converter = chain(*converter)\n-        else:\n-            self.converter = converter\n+        self._validator = validator\n+        self.converter = converter\n         self.repr = repr\n         self.eq = eq\n         self.order = order\n@@ -2261,6 +2410,7 @@ def __init__(\n         self.metadata = metadata\n         self.type = type\n         self.kw_only = kw_only\n+        self.on_setattr = on_setattr\n \n     def validator(self, meth):\n         \"\"\"\ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\n--- a/src/attr/exceptions.py\n+++ b/src/attr/exceptions.py\n@@ -1,20 +1,37 @@\n from __future__ import absolute_import, division, print_function\n \n \n-class FrozenInstanceError(AttributeError):\n+class FrozenError(AttributeError):\n     \"\"\"\n-    A frozen/immutable instance has been attempted to be modified.\n+    A frozen/immutable instance or attribute haave been attempted to be\n+    modified.\n \n     It mirrors the behavior of ``namedtuples`` by using the same error message\n     and subclassing `AttributeError`.\n \n-    .. versionadded:: 16.1.0\n+    .. versionadded:: 20.1.0\n     \"\"\"\n \n     msg = \"can't set attribute\"\n     args = [msg]\n \n \n+class FrozenInstanceError(FrozenError):\n+    \"\"\"\n+    A frozen instance has been attempted to be modified.\n+\n+    .. versionadded:: 16.1.0\n+    \"\"\"\n+\n+\n+class FrozenAttributeError(FrozenError):\n+    \"\"\"\n+    A frozen attribute has been attempted to be modified.\n+\n+    .. versionadded:: 20.1.0\n+    \"\"\"\n+\n+\n class AttrsAttributeNotFoundError(ValueError):\n     \"\"\"\n     An ``attrs`` function couldn't find an attribute that the user asked for.\ndiff --git a/src/attr/setters.py b/src/attr/setters.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attr/setters.py\n@@ -0,0 +1,77 @@\n+\"\"\"\n+Commonly used hooks for on_setattr.\n+\"\"\"\n+\n+from __future__ import absolute_import, division, print_function\n+\n+from . import _config\n+from .exceptions import FrozenAttributeError\n+\n+\n+def pipe(*setters):\n+    \"\"\"\n+    Run all *setters* and return the return value of the last one.\n+\n+    .. versionadded:: 20.1.0\n+    \"\"\"\n+\n+    def wrapped_pipe(instance, attrib, new_value):\n+        rv = new_value\n+\n+        for setter in setters:\n+            rv = setter(instance, attrib, rv)\n+\n+        return rv\n+\n+    return wrapped_pipe\n+\n+\n+def frozen(_, __, ___):\n+    \"\"\"\n+    Prevent an attribute to be modified.\n+\n+    .. versionadded:: 20.1.0\n+    \"\"\"\n+    raise FrozenAttributeError()\n+\n+\n+def validate(instance, attrib, new_value):\n+    \"\"\"\n+    Run *attrib*'s validator on *new_value* if it has one.\n+\n+    .. versionadded:: 20.1.0\n+    \"\"\"\n+    if _config._run_validators is False:\n+        return new_value\n+\n+    v = attrib.validator\n+    if not v:\n+        return new_value\n+\n+    v(instance, attrib, new_value)\n+\n+    return new_value\n+\n+\n+def convert(instance, attrib, new_value):\n+    \"\"\"\n+    Run *attrib*'s converter -- if it has one --  on *new_value* and return the\n+    result.\n+\n+    .. versionadded:: 20.1.0\n+    \"\"\"\n+    c = attrib.converter\n+    if c:\n+        return c(new_value)\n+\n+    return new_value\n+\n+\n+NO_OP = object()\n+\"\"\"\n+Sentinel for disabling class-wide *on_setattr* hooks for certain attributes.\n+\n+Does not work in `pipe` or within lists.\n+\n+.. versionadded:: 20.1.0\n+\"\"\"\ndiff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -67,7 +67,7 @@ def instance_of(type):\n     return _InstanceOfValidator(type)\n \n \n-@attrs(repr=False, frozen=True)\n+@attrs(repr=False, frozen=True, slots=True)\n class _MatchesReValidator(object):\n     regex = attrib()\n     flags = attrib()\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -68,6 +68,7 @@ def _add_init(cls, frozen):\n         cache_hash=False,\n         base_attr_map={},\n         is_exc=False,\n+        has_global_on_setattr=False,\n     )\n     return cls\n \ndiff --git a/tests/test_functional.py b/tests/test_functional.py\n--- a/tests/test_functional.py\n+++ b/tests/test_functional.py\n@@ -16,9 +16,11 @@\n \n import attr\n \n+from attr import setters\n from attr._compat import PY2, TYPE\n from attr._make import NOTHING, Attribute\n-from attr.exceptions import FrozenInstanceError\n+from attr.exceptions import FrozenAttributeError, FrozenInstanceError\n+from attr.validators import instance_of, matches_re\n \n from .strategies import optional_bool\n \n@@ -681,3 +683,183 @@ class C(object):\n             \"2021-06-01.  Please use `eq` and `order` instead.\"\n             == w.message.args[0]\n         )\n+\n+\n+class TestSetAttr(object):\n+    def test_change(self):\n+        \"\"\"\n+        The return value of a hook overwrites the value. But they are not run\n+        on __init__.\n+        \"\"\"\n+\n+        def hook(*a, **kw):\n+            return \"hooked!\"\n+\n+        @attr.s\n+        class Hooked(object):\n+            x = attr.ib(on_setattr=hook)\n+            y = attr.ib()\n+\n+        h = Hooked(\"x\", \"y\")\n+\n+        assert \"x\" == h.x\n+        assert \"y\" == h.y\n+\n+        h.x = \"xxx\"\n+        h.y = \"yyy\"\n+\n+        assert \"yyy\" == h.y\n+        assert \"hooked!\" == h.x\n+\n+    def test_frozen_attribute(self):\n+        \"\"\"\n+        Frozen attributes raise FrozenAttributeError, others are not affected.\n+        \"\"\"\n+\n+        @attr.s\n+        class PartiallyFrozen(object):\n+            x = attr.ib(on_setattr=setters.frozen)\n+            y = attr.ib()\n+\n+        pf = PartiallyFrozen(\"x\", \"y\")\n+\n+        pf.y = \"yyy\"\n+\n+        assert \"yyy\" == pf.y\n+\n+        with pytest.raises(FrozenAttributeError):\n+            pf.x = \"xxx\"\n+\n+        assert \"x\" == pf.x\n+\n+    @pytest.mark.parametrize(\n+        \"on_setattr\",\n+        [setters.validate, [setters.validate], setters.pipe(setters.validate)],\n+    )\n+    def test_validator(self, on_setattr):\n+        \"\"\"\n+        Validators are run and they don't alter the value.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=on_setattr)\n+        class ValidatedAttribute(object):\n+            x = attr.ib()\n+            y = attr.ib(validator=[instance_of(str), matches_re(\"foo.*qux\")])\n+\n+        va = ValidatedAttribute(42, \"foobarqux\")\n+\n+        with pytest.raises(TypeError) as ei:\n+            va.y = 42\n+\n+        assert \"foobarqux\" == va.y\n+\n+        assert ei.value.args[0].startswith(\"'y' must be <\")\n+\n+        with pytest.raises(ValueError) as ei:\n+            va.y = \"quxbarfoo\"\n+\n+        assert ei.value.args[0].startswith(\"'y' must match regex '\")\n+\n+        assert \"foobarqux\" == va.y\n+\n+        va.y = \"foobazqux\"\n+\n+        assert \"foobazqux\" == va.y\n+\n+    def test_pipe(self):\n+        \"\"\"\n+        Multiple hooks are possible, in that case the last return value is\n+        used. They can be supplied using the pipe functions or by passing a\n+        list to on_setattr.\n+        \"\"\"\n+\n+        s = [setters.convert, lambda _, __, nv: nv + 1]\n+\n+        @attr.s\n+        class Piped(object):\n+            x1 = attr.ib(converter=int, on_setattr=setters.pipe(*s))\n+            x2 = attr.ib(converter=int, on_setattr=s)\n+\n+        p = Piped(\"41\", \"22\")\n+\n+        assert 41 == p.x1\n+        assert 22 == p.x2\n+\n+        p.x1 = \"41\"\n+        p.x2 = \"22\"\n+\n+        assert 42 == p.x1\n+        assert 23 == p.x2\n+\n+    def test_make_class(self):\n+        \"\"\"\n+        on_setattr of make_class gets forwarded.\n+        \"\"\"\n+        C = attr.make_class(\"C\", {\"x\": attr.ib()}, on_setattr=setters.frozen)\n+\n+        c = C(1)\n+\n+        with pytest.raises(FrozenAttributeError):\n+            c.x = 2\n+\n+    def test_no_validator_no_converter(self):\n+        \"\"\"\n+        validate and convert tolerate missing validators and converters.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=[setters.convert, setters.validate])\n+        class C(object):\n+            x = attr.ib()\n+\n+        c = C(1)\n+\n+        c.x = 2\n+\n+    def test_validate_respects_run_validators_config(self):\n+        \"\"\"\n+        If run validators is off, validate doesn't run them.\n+        \"\"\"\n+\n+        @attr.s(on_setattr=setters.validate)\n+        class C(object):\n+            x = attr.ib(validator=attr.validators.instance_of(int))\n+\n+        c = C(1)\n+\n+        attr.set_run_validators(False)\n+\n+        c.x = \"1\"\n+\n+        assert \"1\" == c.x\n+\n+        attr.set_run_validators(True)\n+\n+        with pytest.raises(TypeError) as ei:\n+            c.x = \"1\"\n+\n+        assert ei.value.args[0].startswith(\"'x' must be <\")\n+\n+    def test_frozen_on_setattr_class_is_caught(self):\n+        \"\"\"\n+        @attr.s(on_setattr=X, frozen=True) raises an ValueError.\n+        \"\"\"\n+        with pytest.raises(ValueError) as ei:\n+\n+            @attr.s(frozen=True, on_setattr=setters.validate)\n+            class C(object):\n+                x = attr.ib()\n+\n+        assert \"Frozen classes can't use on_setattr.\" == ei.value.args[0]\n+\n+    def test_frozen_on_setattr_attribute_is_caught(self):\n+        \"\"\"\n+        attr.ib(on_setattr=X) on a frozen class raises an ValueError.\n+        \"\"\"\n+\n+        with pytest.raises(ValueError) as ei:\n+\n+            @attr.s(frozen=True)\n+            class C(object):\n+                x = attr.ib(on_setattr=setters.validate)\n+\n+        assert \"Frozen classes can't use on_setattr.\" == ei.value.args[0]\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -222,7 +222,7 @@ class C(object):\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n             \"eq=True, order=True, hash=None, init=True, \"\n             \"metadata=mappingproxy({}), type=None, converter=None, \"\n-            \"kw_only=False, inherited=False)\",\n+            \"kw_only=False, inherited=False, on_setattr=None)\",\n         ) == e.value.args\n \n     def test_kw_only(self):\n@@ -1425,7 +1425,18 @@ class C(object):\n             pass\n \n         b = _ClassBuilder(\n-            C, None, True, True, False, False, False, False, False, False, True\n+            C,\n+            None,\n+            True,\n+            True,\n+            False,\n+            False,\n+            False,\n+            False,\n+            False,\n+            False,\n+            True,\n+            None,\n         )\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n@@ -1439,7 +1450,18 @@ class C(object):\n             x = attr.ib()\n \n         b = _ClassBuilder(\n-            C, None, True, True, False, False, False, False, False, False, True\n+            C,\n+            None,\n+            True,\n+            True,\n+            False,\n+            False,\n+            False,\n+            False,\n+            False,\n+            False,\n+            True,\n+            None,\n         )\n \n         cls = (\n@@ -1516,6 +1538,7 @@ class C(object):\n             kw_only=False,\n             cache_hash=False,\n             collect_by_mro=True,\n+            on_setattr=None,\n         )\n         b._cls = {}  # no __module__; no __qualname__\n \ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -185,6 +185,20 @@ class OrderFlags:\n     b = attr.ib(eq=True, order=True)\n \n \n+# on_setattr hooks\n+@attr.s(on_setattr=attr.setters.validate)\n+class ValidatedSetter:\n+    a = attr.ib()\n+    b = attr.ib(on_setattr=attr.setters.NO_OP)\n+    c = attr.ib(on_setattr=attr.setters.frozen)\n+    d = attr.ib(on_setattr=[attr.setters.convert, attr.setters.validate])\n+    d = attr.ib(\n+        on_setattr=attr.setters.pipe(\n+            attr.setters.convert, attr.setters.validate\n+        )\n+    )\n+\n+\n # Auto-detect\n # XXX: needs support in mypy\n # @attr.s(auto_detect=True)\n", "problem_statement": "[RFC] __setattr__ hooks\nThere's two things that people keep asking for:\r\n\r\n1. validation on setting attributes\r\n2. freezing single attributes\r\n\r\nThose two features have something in common: they require `attrs` to write a `__setattr__` method.\r\n\r\nI actually had 1 done when I implemented validators but I took it out again, because I didn't want to tamper with `__setattr__` too. But it totally makes sense to expect that validators run there too.\r\n\r\nNow that argument has gone away thanks to frozen classes and `attrs` is in the `__setattr__` business. So it feels like the right thing to do, to implement it and make it default for _Operation `import attrs`_ (I hope this is legit the last part of the puzzle).\r\n\r\nTo allow for 2 too, I would suggest to add a hook called `on_setattr` (better names welcome) that takes a callable that is called with the instance, the attribute definition, and the new value.\r\n\r\nTo solve 2, the implementation would look like\r\n\r\n```python\r\ndef frozen(_, __, ___):\r\n    raise FrozenInstanceError\r\n```\r\n\r\n***\r\n\r\nOpen questions:\r\n\r\n- what to do about `on_setattr` attributes in a frozen class (incl inheritance)\r\n- what about converters? Maybe it should take a list/`and` like validator/converter do? They would need to work as a chain, returning values for the next one.\n", "hints_text": "I agree not doing validation on attribute set but doing them in `__init__` is probably not reasonable and should be changed.\r\n\r\nAs for the implementation, it'd be ideal if we generated a smart `__setattr__` like we generate a smart `__init__`. If I were doing it I'd write a function basically containing a chain of `if name == {attr0.name} elif name == {attr1.name}` and compile it; it's gnarly but probably the fastest approach (the things we do for speed :).\r\n\r\nNot really sure what you mean with the hook proposal. Don't we have basically two hook frameworks already (validators and converters)? Both of them seem inadequate for frozen attributes though, because they run on `__init__` too. Does it make sense to flesh this out more thoroughly?\nI mean, we could flesh out validators so they would know if they are being run in the `__init__` context or the `__setattr__` context. Then you could implement frozen attributes using a validator.\r\n\r\nIf I was designing this system right now, I'd probably want to use a middleware pattern (kind of like aiohttp's middleware, where it's a pipeline of functions).\n(1) When I first started using Attrs I found the lack of a validate-on-set option a bit strange but over time have become used to the validate-after-init approach ultimately still stopping execution when validators fail. So I, personally, dont have a strong preference.\r\n\r\n(2) This is a feature I would LOVE to have. To date I've been using my own kludge to get this more or less working but I'd much rather have this implemeted professionally.\r\n\r\nWould a class with all attributes frozen singly be functionally equivalent to a frozen class? Presumably not because you can add attributes to a nonfrozen class? _What I would really like to have is the ability to have a class functionally frozen with only attributes marked as not-frozen remaining mutable._\r\n\r\n\r\nPS: Thank you for this amazing package. Using Attrs has resulted in a step change in the quality and productivty of my Python coding.\n@Tinche the question really is how to expose the functionality without painting ourselves into a corner. Right now I can think of three reasons the user might want to tinker with `__setattr__`:\r\n\r\n- validation\r\n- conversion\r\n- freezing\r\n\r\nI guess that could be achieved using `frozen: bool, validate_on_set: bool, convert_on_set: bool` with some thing mutually excluding itself. I suspect tho that it might paint us into a corner (or force us adding dozens more of such arguments) so my suggestion is to approach from `on_setattr=pipe(convert, validate)` (that\u2019s how they run in `__init__` too) and allow people to do whatever they want on `on_setattr`. Hopefully coming up with creative ways we didn\u2019t think of. Freezing would become `on_setattr=explode`.\r\n\r\n***\r\n\r\nAs for the implementation itself I suspect there\u2019s a cut off point where a dict is faster than a long if-then-else but that remains to be benchmarked.\nAh #622 is an example. ", "created_at": "2020-07-10T05:48:56Z"}
{"repo": "python-attrs/attrs", "pull_number": 642, "instance_id": "python-attrs__attrs-642", "issue_numbers": ["512"], "base_commit": "784179bab6457cd603602d37865fc3ecf8a8181a", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -546,6 +546,7 @@ def __init__(\n         slots,\n         frozen,\n         weakref_slot,\n+        getstate_setstate,\n         auto_attribs,\n         kw_only,\n         cache_hash,\n@@ -576,6 +577,12 @@ def __init__(\n             self._cls_dict[\"__setattr__\"] = _frozen_setattrs\n             self._cls_dict[\"__delattr__\"] = _frozen_delattrs\n \n+        if getstate_setstate:\n+            (\n+                self._cls_dict[\"__getstate__\"],\n+                self._cls_dict[\"__setstate__\"],\n+            ) = self._make_getstate_setstate()\n+\n     def __repr__(self):\n         return \"<_ClassBuilder(cls={cls})>\".format(cls=self._cls.__name__)\n \n@@ -657,37 +664,6 @@ def _create_slots_class(self):\n         if qualname is not None:\n             cd[\"__qualname__\"] = qualname\n \n-        # __weakref__ is not writable.\n-        state_attr_names = tuple(\n-            an for an in self._attr_names if an != \"__weakref__\"\n-        )\n-\n-        def slots_getstate(self):\n-            \"\"\"\n-            Automatically created by attrs.\n-            \"\"\"\n-            return tuple(getattr(self, name) for name in state_attr_names)\n-\n-        hash_caching_enabled = self._cache_hash\n-\n-        def slots_setstate(self, state):\n-            \"\"\"\n-            Automatically created by attrs.\n-            \"\"\"\n-            __bound_setattr = _obj_setattr.__get__(self, Attribute)\n-            for name, value in zip(state_attr_names, state):\n-                __bound_setattr(name, value)\n-\n-            # The hash code cache is not included when the object is\n-            # serialized, but it still needs to be initialized to None to\n-            # indicate that the first call to __hash__ should be a cache miss.\n-            if hash_caching_enabled:\n-                __bound_setattr(_hash_cache_field, None)\n-\n-        # slots and frozen require __getstate__/__setstate__ to work\n-        cd[\"__getstate__\"] = slots_getstate\n-        cd[\"__setstate__\"] = slots_setstate\n-\n         # Create new class based on old class and our methods.\n         cls = type(self._cls)(self._cls.__name__, self._cls.__bases__, cd)\n \n@@ -737,6 +713,40 @@ def __str__(self):\n         self._cls_dict[\"__str__\"] = self._add_method_dunders(__str__)\n         return self\n \n+    def _make_getstate_setstate(self):\n+        \"\"\"\n+        Create custom __setstate__ and __getstate__ methods.\n+        \"\"\"\n+        # __weakref__ is not writable.\n+        state_attr_names = tuple(\n+            an for an in self._attr_names if an != \"__weakref__\"\n+        )\n+\n+        def slots_getstate(self):\n+            \"\"\"\n+            Automatically created by attrs.\n+            \"\"\"\n+            return tuple(getattr(self, name) for name in state_attr_names)\n+\n+        hash_caching_enabled = self._cache_hash\n+\n+        def slots_setstate(self, state):\n+            \"\"\"\n+            Automatically created by attrs.\n+            \"\"\"\n+            __bound_setattr = _obj_setattr.__get__(self, Attribute)\n+            for name, value in zip(state_attr_names, state):\n+                __bound_setattr(name, value)\n+\n+            # The hash code cache is not included when the object is\n+            # serialized, but it still needs to be initialized to None to\n+            # indicate that the first call to __hash__ should be a cache\n+            # miss.\n+            if hash_caching_enabled:\n+                __bound_setattr(_hash_cache_field, None)\n+\n+        return slots_getstate, slots_setstate\n+\n     def make_unhashable(self):\n         self._cls_dict[\"__hash__\"] = None\n         return self\n@@ -849,7 +859,9 @@ def _determine_eq_order(cmp, eq, order, default_eq):\n     return eq, order\n \n \n-def _determine_whether_to_implement(cls, flag, auto_detect, dunders):\n+def _determine_whether_to_implement(\n+    cls, flag, auto_detect, dunders, default=True\n+):\n     \"\"\"\n     Check whether we should implement a set of methods for *cls*.\n \n@@ -857,20 +869,22 @@ def _determine_whether_to_implement(cls, flag, auto_detect, dunders):\n     same as passed into @attr.s and *dunders* is a tuple of attribute names\n     whose presence signal that the user has implemented it themselves.\n \n+    Return *default* if no reason for either for or against is found.\n+\n     auto_detect must be False on Python 2.\n     \"\"\"\n-    if flag is True or flag is None and auto_detect is False:\n-        return True\n+    if flag is True or flag is False:\n+        return flag\n \n-    if flag is False:\n-        return False\n+    if flag is None and auto_detect is False:\n+        return default\n \n     # Logically, flag is None and auto_detect is True here.\n     for dunder in dunders:\n         if _has_own_attribute(cls, dunder):\n             return False\n \n-    return True\n+    return default\n \n \n def attrs(\n@@ -893,6 +907,7 @@ def attrs(\n     order=None,\n     auto_detect=False,\n     collect_by_mro=False,\n+    getstate_setstate=None,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -1060,6 +1075,21 @@ def attrs(\n        See issue `#428 <https://github.com/python-attrs/attrs/issues/428>`_ for\n        more details.\n \n+    :param Optional[bool] getstate_setstate:\n+       .. note::\n+          This is usually only interesting for slotted classes and you should\n+          probably just set *auto_detect* to `True`.\n+\n+       If `True`, ``__getstate__`` and\n+       ``__setstate__`` are generated and attached to the class. This is\n+       necessary for slotted classes to be pickleable. If left `None`, it's\n+       `True` by default for slotted classes and ``False`` for dict classes.\n+\n+       If *auto_detect* is `True`, and *getstate_setstate* is left `None`,\n+       and **either** ``__getstate__`` or ``__setstate__`` is detected directly\n+       on the class (i.e. not inherited), it is set to `False` (this is usually\n+       what you want).\n+\n     .. versionadded:: 16.0.0 *slots*\n     .. versionadded:: 16.1.0 *frozen*\n     .. versionadded:: 16.3.0 *str*\n@@ -1086,6 +1116,7 @@ def attrs(\n     .. versionadded:: 19.2.0 *eq* and *order*\n     .. versionadded:: 20.1.0 *auto_detect*\n     .. versionadded:: 20.1.0 *collect_by_mro*\n+    .. versionadded:: 20.1.0 *getstate_setstate*\n     \"\"\"\n     if auto_detect and PY2:\n         raise PythonTooOldError(\n@@ -1093,7 +1124,7 @@ def attrs(\n         )\n \n     eq_, order_ = _determine_eq_order(cmp, eq, order, None)\n-    hash_ = hash  # workaround the lack of nonlocal\n+    hash_ = hash  # work around the lack of nonlocal\n \n     def wrap(cls):\n \n@@ -1108,6 +1139,13 @@ def wrap(cls):\n             slots,\n             frozen,\n             weakref_slot,\n+            _determine_whether_to_implement(\n+                cls,\n+                getstate_setstate,\n+                auto_detect,\n+                (\"__getstate__\", \"__setstate__\"),\n+                default=slots,\n+            ),\n             auto_attribs,\n             kw_only,\n             cache_hash,\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1425,7 +1425,7 @@ class C(object):\n             pass\n \n         b = _ClassBuilder(\n-            C, None, True, True, False, False, False, False, False, True\n+            C, None, True, True, False, False, False, False, False, False, True\n         )\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n@@ -1439,7 +1439,7 @@ class C(object):\n             x = attr.ib()\n \n         b = _ClassBuilder(\n-            C, None, True, True, False, False, False, False, False, True\n+            C, None, True, True, False, False, False, False, False, False, True\n         )\n \n         cls = (\n@@ -1510,6 +1510,7 @@ class C(object):\n             slots=False,\n             frozen=False,\n             weakref_slot=True,\n+            getstate_setstate=False,\n             auto_attribs=False,\n             is_exc=False,\n             kw_only=False,\n@@ -2101,3 +2102,32 @@ def __le__(self, o):\n         assert c1 == c1\n \n         assert c1.own_eq_called\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_detects_setstate_getstate(self, slots):\n+        \"\"\"\n+        __getstate__ and __setstate__ are not overwritten if either is present.\n+        \"\"\"\n+\n+        @attr.s(slots=slots, auto_detect=True)\n+        class C(object):\n+            def __getstate__(self):\n+                return (\"hi\",)\n+\n+        assert None is getattr(C(), \"__setstate__\", None)\n+\n+        @attr.s(slots=slots, auto_detect=True)\n+        class C(object):\n+            called = attr.ib(False)\n+\n+            def __setstate__(self, state):\n+                self.called = True\n+\n+        i = C()\n+\n+        assert False is i.called\n+\n+        i.__setstate__(())\n+\n+        assert True is i.called\n+        assert None is getattr(C(), \"__getstate__\", None)\ndiff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -2,6 +2,7 @@\n Unit tests for slots-related functionality.\n \"\"\"\n \n+import pickle\n import sys\n import types\n import weakref\n@@ -568,3 +569,59 @@ def f(self, a):\n             super(C, self).__init__()\n \n     C(field=1)\n+\n+\n+@attr.s(getstate_setstate=True)\n+class C2(object):\n+    x = attr.ib()\n+\n+\n+@attr.s(slots=True, getstate_setstate=True)\n+class C2Slots(object):\n+    x = attr.ib()\n+\n+\n+class TestPickle(object):\n+    @pytest.mark.parametrize(\"protocol\", range(pickle.HIGHEST_PROTOCOL))\n+    def test_pickleable_by_default(self, protocol):\n+        \"\"\"\n+        If nothing else is passed, slotted classes can be pickled and\n+        unpickled with all supported protocols.\n+        \"\"\"\n+        i1 = C1Slots(1, 2)\n+        i2 = pickle.loads(pickle.dumps(i1, protocol))\n+\n+        assert i1 == i2\n+        assert i1 is not i2\n+\n+    def test_no_getstate_setstate_for_dict_classes(self):\n+        \"\"\"\n+        As long as getstate_setstate is None, nothing is done to dict\n+        classes.\n+        \"\"\"\n+        i = C1(1, 2)\n+\n+        assert None is getattr(i, \"__getstate__\", None)\n+        assert None is getattr(i, \"__setstate__\", None)\n+\n+    def test_no_getstate_setstate_if_option_false(self):\n+        \"\"\"\n+        Don't add getstate/setstate if getstate_setstate is False.\n+        \"\"\"\n+\n+        @attr.s(slots=True, getstate_setstate=False)\n+        class C(object):\n+            x = attr.ib()\n+\n+        i = C(42)\n+\n+        assert None is getattr(i, \"__getstate__\", None)\n+        assert None is getattr(i, \"__setstate__\", None)\n+\n+    @pytest.mark.parametrize(\"cls\", [C2(1), C2Slots(1)])\n+    def test_getstate_set_state_force_true(self, cls):\n+        \"\"\"\n+        If getstate_setstate is True, add them unconditionally.\n+        \"\"\"\n+        assert None is not getattr(cls, \"__getstate__\", None)\n+        assert None is not getattr(cls, \"__setstate__\", None)\n", "problem_statement": "Support custom __getstate__, __setstate__ for slotted classes (or improve docs)?\nThe assertion fails in the following example, but is ok with `slots=False`:\r\n```\r\nimport attr, pickle\r\n\r\n@attr.s(slots=True)\r\nclass MyClass(object):\r\n    a = attr.ib()\r\n    not_picklable = attr.ib()\r\n\r\n    def __getstate__(self):\r\n        return self.a, \"replacement\"\r\n\r\n    def __setstate__(self, state):\r\n        self.a, self.not_picklable = state\r\n\r\nmc = MyClass(\"a\", \"b\")\r\nmc_new = pickle.loads(pickle.dumps(mc))\r\nassert mc_new.not_picklable == \"replacement\"\r\n```\r\nThis is clearly because `attrs` auto creates these methods on the new slots-class: https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L601\r\n\r\nIs there another prefered way to solve this, or would it be possible to support these methods also for slots-classes? If not, it would be good to clarify this in the documentation for [slotted-classes](http://www.attrs.org/en/stable/glossary.html#term-slotted-classes), it says:\r\n\r\n> You can support protocol 0 and 1 by implementing `__getstate__` and `__setstate__` methods yourself. Those methods are created for frozen slotted classes because they won\u2019t pickle otherwise. Think twice before using pickle though.\r\n\r\nThis is confusing to me, since implementing these methods have no effect for slotted classes?\r\n\r\nSomewhat related:\r\nhttps://github.com/python-attrs/attrs/issues/139\r\nhttps://github.com/python-attrs/attrs/issues/475\n", "hints_text": "You have opened this issue in the best possible moment because I'm prototyping a new API right now and this might go in. No promises about timeline and whether it'll be python2-compatible for now tho.\nGlad to hear! In the meantime, I made this suggestion: https://github.com/python-attrs/attrs/pull/513. I think it makes sense. Maybe I'm missing something, but isn't the docs (referenced above) misleading/inconsistent with current behaviour?\nOk, read the docs more carefully and now understand that \"You can support protocol 0 and 1 by implementing `__getstate__` and `__setstate__` methods yourself\" refers to `__slots__` classes in general but _not_ to `attr.s(slots=True)` classes. Still don't see any downside from making it possible to define these methods in `attr.s(slots=True)` classes.\n> Ok, read the docs more carefully and now understand\r\n\r\nWith that you're way ahead of me because I don't understand that paragraph at all anymore. \ud83d\ude05\r\n\r\nIt would be great if we could rewrite it once this has been resolved.", "created_at": "2020-04-28T09:55:40Z"}
{"repo": "python-attrs/attrs", "pull_number": 635, "instance_id": "python-attrs__attrs-635", "issue_numbers": ["428"], "base_commit": "f8f3f598a38163481513785c83a555d09b10bcd5", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -343,12 +343,74 @@ def _counter_getter(e):\n     return e[1].counter\n \n \n-def _transform_attrs(cls, these, auto_attribs, kw_only):\n+def _collect_base_attrs(cls, taken_attr_names):\n+    \"\"\"\n+    Collect attr.ibs from base classes of *cls*, except *taken_attr_names*.\n+    \"\"\"\n+    base_attrs = []\n+    base_attr_map = {}  # A dictionary of base attrs to their classes.\n+\n+    # Traverse the MRO and collect attributes.\n+    for base_cls in reversed(cls.__mro__[1:-1]):\n+        for a in getattr(base_cls, \"__attrs_attrs__\", []):\n+            if a.inherited or a.name in taken_attr_names:\n+                continue\n+\n+            a = a._assoc(inherited=True)\n+            base_attrs.append(a)\n+            base_attr_map[a.name] = base_cls\n+\n+    # For each name, only keep the freshest definition i.e. the furthest at the\n+    # back.  base_attr_map is fine because it gets overwritten with every new\n+    # instance.\n+    filtered = []\n+    seen = set()\n+    for a in reversed(base_attrs):\n+        if a.name in seen:\n+            continue\n+        filtered.insert(0, a)\n+        seen.add(a.name)\n+\n+    return filtered, base_attr_map\n+\n+\n+def _collect_base_attrs_broken(cls, taken_attr_names):\n+    \"\"\"\n+    Collect attr.ibs from base classes of *cls*, except *taken_attr_names*.\n+\n+    N.B. *taken_attr_names* will be mutated.\n+\n+    Adhere to the old incorrect behavior.\n+\n+    Notably it collects from the front and considers inherited attributes which\n+    leads to the buggy behavior reported in #428.\n+    \"\"\"\n+    base_attrs = []\n+    base_attr_map = {}  # A dictionary of base attrs to their classes.\n+\n+    # Traverse the MRO and collect attributes.\n+    for base_cls in cls.__mro__[1:-1]:\n+        for a in getattr(base_cls, \"__attrs_attrs__\", []):\n+            if a.name in taken_attr_names:\n+                continue\n+\n+            a = a._assoc(inherited=True)\n+            taken_attr_names.add(a.name)\n+            base_attrs.append(a)\n+            base_attr_map[a.name] = base_cls\n+\n+    return base_attrs, base_attr_map\n+\n+\n+def _transform_attrs(cls, these, auto_attribs, kw_only, collect_by_mro):\n     \"\"\"\n     Transform all `_CountingAttr`s on a class into `Attribute`s.\n \n     If *these* is passed, use that and don't look for them on the class.\n \n+    *collect_by_mro* is True, collect them in the correct MRO order, otherwise\n+    use the old -- incorrect -- order.  See #428.\n+\n     Return an `_Attributes`.\n     \"\"\"\n     cd = cls.__dict__\n@@ -405,24 +467,14 @@ def _transform_attrs(cls, these, auto_attribs, kw_only):\n         for attr_name, ca in ca_list\n     ]\n \n-    base_attrs = []\n-    base_attr_map = {}  # A dictionary of base attrs to their classes.\n-    taken_attr_names = {a.name: a for a in own_attrs}\n-\n-    # Traverse the MRO and collect attributes.\n-    for base_cls in cls.__mro__[1:-1]:\n-        sub_attrs = getattr(base_cls, \"__attrs_attrs__\", None)\n-        if sub_attrs is None:\n-            continue\n-\n-        for a in sub_attrs:\n-            prev_a = taken_attr_names.get(a.name)\n-            # Only add an attribute if it hasn't been defined before.  This\n-            # allows for overwriting attribute definitions by subclassing.\n-            if prev_a is None:\n-                base_attrs.append(a)\n-                taken_attr_names[a.name] = a\n-                base_attr_map[a.name] = base_cls\n+    if collect_by_mro:\n+        base_attrs, base_attr_map = _collect_base_attrs(\n+            cls, {a.name for a in own_attrs}\n+        )\n+    else:\n+        base_attrs, base_attr_map = _collect_base_attrs_broken(\n+            cls, {a.name for a in own_attrs}\n+        )\n \n     attr_names = [a.name for a in base_attrs + own_attrs]\n \n@@ -498,9 +550,10 @@ def __init__(\n         kw_only,\n         cache_hash,\n         is_exc,\n+        collect_by_mro,\n     ):\n         attrs, base_attrs, base_map = _transform_attrs(\n-            cls, these, auto_attribs, kw_only\n+            cls, these, auto_attribs, kw_only, collect_by_mro,\n         )\n \n         self._cls = cls\n@@ -839,6 +892,7 @@ def attrs(\n     eq=None,\n     order=None,\n     auto_detect=False,\n+    collect_by_mro=False,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -998,6 +1052,13 @@ def attrs(\n           default value are additionally available as a tuple in the ``args``\n           attribute,\n         - the value of *str* is ignored leaving ``__str__`` to base classes.\n+    :param bool collect_by_mro: Setting this to `True` fixes the way ``attrs``\n+       collects attributes from base classes.  The default behavior is\n+       incorrect in certain cases of multiple inheritance.  It should be on by\n+       default but is kept off for backward-compatability.\n+\n+       See issue `#428 <https://github.com/python-attrs/attrs/issues/428>`_ for\n+       more details.\n \n     .. versionadded:: 16.0.0 *slots*\n     .. versionadded:: 16.1.0 *frozen*\n@@ -1024,6 +1085,7 @@ def attrs(\n     .. deprecated:: 19.2.0 *cmp* Removal on or after 2021-06-01.\n     .. versionadded:: 19.2.0 *eq* and *order*\n     .. versionadded:: 20.1.0 *auto_detect*\n+    .. versionadded:: 20.1.0 *collect_by_mro*\n     \"\"\"\n     if auto_detect and PY2:\n         raise PythonTooOldError(\n@@ -1050,6 +1112,7 @@ def wrap(cls):\n             kw_only,\n             cache_hash,\n             is_exc,\n+            collect_by_mro,\n         )\n         if _determine_whether_to_implement(\n             cls, repr, auto_detect, (\"__repr__\",)\n@@ -1884,11 +1947,15 @@ class Attribute(object):\n     *Read-only* representation of an attribute.\n \n     :attribute name: The name of the attribute.\n+    :attribute inherited: Whether or not that attribute has been inherited from\n+        a base class.\n \n     Plus *all* arguments of `attr.ib` (except for ``factory``\n     which is only syntactic sugar for ``default=Factory(...)``.\n \n-    For the version history of the fields, see `attr.ib`.\n+    .. versionadded:: 20.1.0 *inherited*\n+\n+    For the full version history of the fields, see `attr.ib`.\n     \"\"\"\n \n     __slots__ = (\n@@ -1904,6 +1971,7 @@ class Attribute(object):\n         \"type\",\n         \"converter\",\n         \"kw_only\",\n+        \"inherited\",\n     )\n \n     def __init__(\n@@ -1915,6 +1983,7 @@ def __init__(\n         cmp,  # XXX: unused, remove along with other cmp code.\n         hash,\n         init,\n+        inherited,\n         metadata=None,\n         type=None,\n         converter=None,\n@@ -1948,6 +2017,7 @@ def __init__(\n         )\n         bound_setattr(\"type\", type)\n         bound_setattr(\"kw_only\", kw_only)\n+        bound_setattr(\"inherited\", inherited)\n \n     def __setattr__(self, name, value):\n         raise FrozenInstanceError()\n@@ -1970,6 +2040,7 @@ def from_counting_attr(cls, name, ca, type=None):\n                 \"validator\",\n                 \"default\",\n                 \"type\",\n+                \"inherited\",\n             )  # exclude methods and deprecated alias\n         }\n         return cls(\n@@ -1978,6 +2049,7 @@ def from_counting_attr(cls, name, ca, type=None):\n             default=ca._default,\n             type=type,\n             cmp=None,\n+            inherited=False,\n             **inst_dict\n         )\n \n@@ -2042,6 +2114,7 @@ def _setattrs(self, name_values_pairs):\n         order=False,\n         hash=(name != \"metadata\"),\n         init=True,\n+        inherited=False,\n     )\n     for name in Attribute.__slots__\n ]\n@@ -2087,6 +2160,7 @@ class _CountingAttr(object):\n             kw_only=False,\n             eq=True,\n             order=False,\n+            inherited=False,\n         )\n         for name in (\n             \"counter\",\n@@ -2109,6 +2183,7 @@ class _CountingAttr(object):\n             kw_only=False,\n             eq=True,\n             order=False,\n+            inherited=False,\n         ),\n     )\n     cls_counter = 0\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -131,6 +131,7 @@ def test_fields(self, cls):\n                 order=True,\n                 hash=None,\n                 init=True,\n+                inherited=False,\n             ),\n             Attribute(\n                 name=\"y\",\n@@ -142,6 +143,7 @@ def test_fields(self, cls):\n                 order=True,\n                 hash=None,\n                 init=True,\n+                inherited=False,\n             ),\n         ) == attr.fields(cls)\n \n@@ -199,6 +201,7 @@ def test_programmatic(self, slots, frozen):\n                 order=True,\n                 hash=None,\n                 init=True,\n+                inherited=False,\n             ),\n             Attribute(\n                 name=\"b\",\n@@ -210,6 +213,7 @@ def test_programmatic(self, slots, frozen):\n                 order=True,\n                 hash=None,\n                 init=True,\n+                inherited=False,\n             ),\n         ) == attr.fields(PC)\n \ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -167,7 +167,7 @@ def test_no_modifications(self):\n         Does not attach __attrs_attrs__ to the class.\n         \"\"\"\n         C = make_tc()\n-        _transform_attrs(C, None, False, False)\n+        _transform_attrs(C, None, False, False, True)\n \n         assert None is getattr(C, \"__attrs_attrs__\", None)\n \n@@ -176,7 +176,7 @@ def test_normal(self):\n         Transforms every `_CountingAttr` and leaves others (a) be.\n         \"\"\"\n         C = make_tc()\n-        attrs, _, _ = _transform_attrs(C, None, False, False)\n+        attrs, _, _ = _transform_attrs(C, None, False, False, True)\n \n         assert [\"z\", \"y\", \"x\"] == [a.name for a in attrs]\n \n@@ -190,7 +190,7 @@ class C(object):\n             pass\n \n         assert _Attributes(((), [], {})) == _transform_attrs(\n-            C, None, False, False\n+            C, None, False, False, True\n         )\n \n     def test_transforms_to_attribute(self):\n@@ -198,7 +198,7 @@ def test_transforms_to_attribute(self):\n         All `_CountingAttr`s are transformed into `Attribute`s.\n         \"\"\"\n         C = make_tc()\n-        attrs, base_attrs, _ = _transform_attrs(C, None, False, False)\n+        attrs, base_attrs, _ = _transform_attrs(C, None, False, False, True)\n \n         assert [] == base_attrs\n         assert 3 == len(attrs)\n@@ -215,14 +215,14 @@ class C(object):\n             y = attr.ib()\n \n         with pytest.raises(ValueError) as e:\n-            _transform_attrs(C, None, False, False)\n+            _transform_attrs(C, None, False, False, True)\n         assert (\n             \"No mandatory attributes allowed after an attribute with a \"\n             \"default value or factory.  Attribute in question: Attribute\"\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n             \"eq=True, order=True, hash=None, init=True, \"\n             \"metadata=mappingproxy({}), type=None, converter=None, \"\n-            \"kw_only=False)\",\n+            \"kw_only=False, inherited=False)\",\n         ) == e.value.args\n \n     def test_kw_only(self):\n@@ -245,7 +245,7 @@ class C(B):\n             x = attr.ib(default=None)\n             y = attr.ib()\n \n-        attrs, base_attrs, _ = _transform_attrs(C, None, False, True)\n+        attrs, base_attrs, _ = _transform_attrs(C, None, False, True, True)\n \n         assert len(attrs) == 3\n         assert len(base_attrs) == 1\n@@ -268,7 +268,7 @@ class C(Base):\n             y = attr.ib()\n \n         attrs, base_attrs, _ = _transform_attrs(\n-            C, {\"x\": attr.ib()}, False, False\n+            C, {\"x\": attr.ib()}, False, False, True\n         )\n \n         assert [] == base_attrs\n@@ -300,9 +300,9 @@ class C(object):\n \n         assert \"C(a=1, b=2)\" == repr(C())\n \n-    def test_multiple_inheritance(self):\n+    def test_multiple_inheritance_old(self):\n         \"\"\"\n-        Order of attributes doesn't get mixed up by multiple inheritance.\n+        Old multiple inheritance attributre collection behavior is retained.\n \n         See #285\n         \"\"\"\n@@ -337,6 +337,92 @@ class E(C, D):\n             \"d2='d2', e1='e1', e2='e2')\"\n         ) == repr(E())\n \n+    def test_overwrite_proper_mro(self):\n+        \"\"\"\n+        The proper MRO path works single overwrites too.\n+        \"\"\"\n+\n+        @attr.s(collect_by_mro=True)\n+        class C(object):\n+            x = attr.ib(default=1)\n+\n+        @attr.s(collect_by_mro=True)\n+        class D(C):\n+            x = attr.ib(default=2)\n+\n+        assert \"D(x=2)\" == repr(D())\n+\n+    def test_multiple_inheritance_proper_mro(self):\n+        \"\"\"\n+        Attributes are collected according to the MRO.\n+\n+        See #428\n+        \"\"\"\n+\n+        @attr.s\n+        class A(object):\n+            a1 = attr.ib(default=\"a1\")\n+            a2 = attr.ib(default=\"a2\")\n+\n+        @attr.s\n+        class B(A):\n+            b1 = attr.ib(default=\"b1\")\n+            b2 = attr.ib(default=\"b2\")\n+\n+        @attr.s\n+        class C(B, A):\n+            c1 = attr.ib(default=\"c1\")\n+            c2 = attr.ib(default=\"c2\")\n+\n+        @attr.s\n+        class D(A):\n+            d1 = attr.ib(default=\"d1\")\n+            d2 = attr.ib(default=\"d2\")\n+\n+        @attr.s(collect_by_mro=True)\n+        class E(C, D):\n+            e1 = attr.ib(default=\"e1\")\n+            e2 = attr.ib(default=\"e2\")\n+\n+        assert (\n+            \"E(a1='a1', a2='a2', d1='d1', d2='d2', b1='b1', b2='b2', c1='c1', \"\n+            \"c2='c2', e1='e1', e2='e2')\"\n+        ) == repr(E())\n+\n+    def test_mro(self):\n+        \"\"\"\n+        Attributes and methods are looked up the same way.\n+\n+        See #428\n+        \"\"\"\n+\n+        @attr.s\n+        class A(object):\n+\n+            x = attr.ib(10)\n+\n+            def xx(self):\n+                return 10\n+\n+        @attr.s\n+        class B(A):\n+            y = attr.ib(20)\n+\n+        @attr.s\n+        class C(A):\n+            x = attr.ib(50)\n+\n+            def xx(self):\n+                return 50\n+\n+        @attr.s(collect_by_mro=True)\n+        class D(B, C):\n+            pass\n+\n+        d = D()\n+\n+        assert d.x == d.xx()\n+\n \n class TestAttributes(object):\n     \"\"\"\n@@ -1339,7 +1425,7 @@ class C(object):\n             pass\n \n         b = _ClassBuilder(\n-            C, None, True, True, False, False, False, False, False\n+            C, None, True, True, False, False, False, False, False, True\n         )\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n@@ -1353,7 +1439,7 @@ class C(object):\n             x = attr.ib()\n \n         b = _ClassBuilder(\n-            C, None, True, True, False, False, False, False, False\n+            C, None, True, True, False, False, False, False, False, True\n         )\n \n         cls = (\n@@ -1428,6 +1514,7 @@ class C(object):\n             is_exc=False,\n             kw_only=False,\n             cache_hash=False,\n+            collect_by_mro=True,\n         )\n         b._cls = {}  # no __module__; no __qualname__\n \ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -46,6 +46,7 @@ def simple_attr(\n     init=True,\n     converter=None,\n     kw_only=False,\n+    inherited=False,\n ):\n     \"\"\"\n     Return an attribute with a name and no other bells and whistles.\n@@ -60,7 +61,8 @@ def simple_attr(\n         hash=hash,\n         init=init,\n         converter=converter,\n-        kw_only=False,\n+        kw_only=kw_only,\n+        inherited=inherited,\n     )\n \n \n", "problem_statement": "MRO vs. inherited attributes\nThe way how attributes are collected from super classes is different comparing to how attributes and methods are searched by `getattr` (based on MRO for new-style classes).\r\n\r\nExample:\r\n```python\r\n@attr.s\r\nclass A(object):\r\n\r\n    x = attr.ib(10)\r\n\r\n    def xx(self):\r\n        return 10\r\n\r\n\r\n@attr.s\r\nclass B(A):\r\n    y = attr.ib(20)\r\n\r\n\r\n@attr.s\r\nclass C(A):\r\n    x = attr.ib(50)\r\n\r\n    def xx(self):\r\n        return 50\r\n\r\n\r\nclass D(B, C):\r\n    pass\r\n\r\n\r\nd = D()\r\nprint(d.x)  # prints 10\r\nprint(d.xx())  # prints 50\r\n```\r\n\r\nI think it would be great to the use the same approach for collecting attributes as used for searching methods and attributes. \r\n\r\nThe difference is caused by the fact that the function `_transform_attrs` in `attrs/_make.py` considers all attributes (own+inherited stored in `__attrs_attrs__`) and not only own attributes of super classes: https://github.com/python-attrs/attrs/blob/6a07b035b77ea8756408d65a36160f8670c66933/src/attr/_make.py#L367-L368\n", "hints_text": "Hm that\u2019s unfortunate and fixing it likely means breakage. :|\nSo this is interesting.\r\n\r\nThe underlying issue is that `attrs` always writes all methods optimized for the current class to avoid `super()` calls/traversal which means we have to simulate the `__mro__` ourselves when building the lists of attributes. FTR, dataclasses handle it the same way.\r\n\r\nAs such,  I was able to make your test case work by ignoring inherited attributes **iff** D is also decorated with `@attr.s` because _then_ attrs has the chance to intervene.\r\n\r\n---\r\n\r\nThere's another problem too: users expect the attributes to be ordered (in `__init__` parameter lists and reprs for example) in the order they are defined. E.g. if you have:\r\n\r\n```python\r\n        @attr.s\r\n        class C(object):\r\n            c = attr.ib(default=100)\r\n            x = attr.ib(default=1)\r\n            b = attr.ib(default=23)\r\n\r\n        @attr.s\r\n        class D(C):\r\n            a = attr.ib(default=42)\r\n            x = attr.ib(default=2)\r\n            d = attr.ib(default=3.14)\r\n```\r\n\r\nThe attribute order is c, b, a, x, d (N.B. that x changed position due to overwrite).\r\n\r\nIf I ignore inherited attributes and walk the mro, the order becomes a, x, d, c, b.\r\n\r\nI'm open to suggestions how to resolve this to make everyone happy but I banged my head against it for over an hour and didn't really come up with anything viable. :(\r\n\r\nI guess traversing it twice would work? Once for getting the order of the names right and then again to resolve them to the correct classes? \ud83e\udd14", "created_at": "2020-03-30T11:25:28Z"}
{"repo": "python-attrs/attrs", "pull_number": 620, "instance_id": "python-attrs__attrs-620", "issue_numbers": ["494"], "base_commit": "8c00f755f9d91c06fbdd9a20e24d2c4663e6339d", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -70,6 +70,31 @@ def __repr__(self):\n \"\"\"\n \n \n+class _CacheHashWrapper(int):\n+    \"\"\"\n+    An integer subclass that pickles / copies as None\n+\n+    This is used for non-slots classes with ``cache_hash=True``, to avoid\n+    serializing a potentially (even likely) invalid hash value. Since ``None``\n+    is the default value for uncalculated hashes, whenever this is copied,\n+    the copy's value for the hash should automatically reset.\n+\n+    See GH #613 for more details.\n+    \"\"\"\n+\n+    if PY2:\n+        # For some reason `type(None)` isn't callable in Python 2, but we don't\n+        # actually need a constructor for None objects, we just need any\n+        # available function that returns None.\n+        def __reduce__(self, _none_constructor=getattr, _args=(0, \"\", None)):\n+            return _none_constructor, _args\n+\n+    else:\n+\n+        def __reduce__(self, _none_constructor=type(None), _args=()):\n+            return _none_constructor, _args\n+\n+\n def attrib(\n     default=NOTHING,\n     validator=None,\n@@ -523,34 +548,6 @@ def _patch_original_class(self):\n         for name, value in self._cls_dict.items():\n             setattr(cls, name, value)\n \n-        # Attach __setstate__. This is necessary to clear the hash code\n-        # cache on deserialization. See issue\n-        # https://github.com/python-attrs/attrs/issues/482 .\n-        # Note that this code only handles setstate for dict classes.\n-        # For slotted classes, see similar code in _create_slots_class .\n-        if self._cache_hash:\n-            existing_set_state_method = getattr(cls, \"__setstate__\", None)\n-            if existing_set_state_method:\n-                raise NotImplementedError(\n-                    \"Currently you cannot use hash caching if \"\n-                    \"you specify your own __setstate__ method.\"\n-                    \"See https://github.com/python-attrs/attrs/issues/494 .\"\n-                )\n-\n-            # Clears the cached hash state on serialization; for frozen\n-            # classes we need to bypass the class's setattr method.\n-            if self._frozen:\n-\n-                def cache_hash_set_state(chss_self, _):\n-                    object.__setattr__(chss_self, _hash_cache_field, None)\n-\n-            else:\n-\n-                def cache_hash_set_state(chss_self, _):\n-                    setattr(chss_self, _hash_cache_field, None)\n-\n-            cls.__setstate__ = cache_hash_set_state\n-\n         return cls\n \n     def _create_slots_class(self):\n@@ -612,11 +609,10 @@ def slots_setstate(self, state):\n             __bound_setattr = _obj_setattr.__get__(self, Attribute)\n             for name, value in zip(state_attr_names, state):\n                 __bound_setattr(name, value)\n-            # Clearing the hash code cache on deserialization is needed\n-            # because hash codes can change from run to run. See issue\n-            # https://github.com/python-attrs/attrs/issues/482 .\n-            # Note that this code only handles setstate for slotted classes.\n-            # For dict classes, see similar code in _patch_original_class .\n+\n+            # The hash code cache is not included when the object is\n+            # serialized, but it still needs to be initialized to None to\n+            # indicate that the first call to __hash__ should be a cache miss.\n             if hash_caching_enabled:\n                 __bound_setattr(_hash_cache_field, None)\n \n@@ -1103,7 +1099,23 @@ def _make_hash(cls, attrs, frozen, cache_hash):\n     unique_filename = _generate_unique_filename(cls, \"hash\")\n     type_hash = hash(unique_filename)\n \n-    method_lines = [\"def __hash__(self):\"]\n+    hash_def = \"def __hash__(self\"\n+    hash_func = \"hash((\"\n+    closing_braces = \"))\"\n+    if not cache_hash:\n+        hash_def += \"):\"\n+    else:\n+        if not PY2:\n+            hash_def += \", *\"\n+\n+        hash_def += (\n+            \", _cache_wrapper=\"\n+            + \"__import__('attr._make')._make._CacheHashWrapper):\"\n+        )\n+        hash_func = \"_cache_wrapper(\" + hash_func\n+        closing_braces += \")\"\n+\n+    method_lines = [hash_def]\n \n     def append_hash_computation_lines(prefix, indent):\n         \"\"\"\n@@ -1111,14 +1123,18 @@ def append_hash_computation_lines(prefix, indent):\n         Below this will either be returned directly or used to compute\n         a value which is then cached, depending on the value of cache_hash\n         \"\"\"\n+\n         method_lines.extend(\n-            [indent + prefix + \"hash((\", indent + \"        %d,\" % (type_hash,)]\n+            [\n+                indent + prefix + hash_func,\n+                indent + \"        %d,\" % (type_hash,),\n+            ]\n         )\n \n         for a in attrs:\n             method_lines.append(indent + \"        self.%s,\" % a.name)\n \n-        method_lines.append(indent + \"    ))\")\n+        method_lines.append(indent + \"    \" + closing_braces)\n \n     if cache_hash:\n         method_lines.append(tab + \"if self.%s is None:\" % _hash_cache_field)\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -310,6 +310,33 @@ def test_str_no_repr(self):\n         ) == e.value.args[0]\n \n \n+# these are for use in TestAddHash.test_cache_hash_serialization\n+# they need to be out here so they can be un-pickled\n+@attr.attrs(hash=True, cache_hash=False)\n+class HashCacheSerializationTestUncached(object):\n+    foo_value = attr.ib()\n+\n+\n+@attr.attrs(hash=True, cache_hash=True)\n+class HashCacheSerializationTestCached(object):\n+    foo_value = attr.ib()\n+\n+\n+@attr.attrs(slots=True, hash=True, cache_hash=True)\n+class HashCacheSerializationTestCachedSlots(object):\n+    foo_value = attr.ib()\n+\n+\n+class IncrementingHasher(object):\n+    def __init__(self):\n+        self.hash_value = 100\n+\n+    def __hash__(self):\n+        rv = self.hash_value\n+        self.hash_value += 1\n+        return rv\n+\n+\n class TestAddHash(object):\n     \"\"\"\n     Tests for `_add_hash`.\n@@ -492,85 +519,87 @@ def __hash__(self):\n         assert 2 == uncached_instance.hash_counter.times_hash_called\n         assert 1 == cached_instance.hash_counter.times_hash_called\n \n-    def test_cache_hash_serialization(self):\n+    @pytest.mark.parametrize(\"cache_hash\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_copy_hash_cleared(self, cache_hash, frozen, slots):\n         \"\"\"\n-        Tests that the hash cache is cleared on deserialization to fix\n-        https://github.com/python-attrs/attrs/issues/482 .\n+        Test that the default hash is recalculated after a copy operation.\n         \"\"\"\n \n-        # First, check that our fix didn't break serialization without\n-        # hash caching.\n-        # We don't care about the result of this; we just want to make sure we\n-        # can do it without exceptions.\n-        hash(pickle.loads(pickle.dumps(HashCacheSerializationTestUncached)))\n-\n-        def assert_hash_code_not_cached_across_serialization(original):\n-            # Now check our fix for #482 for when hash caching is enabled.\n-            original_hash = hash(original)\n-            round_tripped = pickle.loads(pickle.dumps(original))\n-            # What we want to guard against is having a stale hash code\n-            # when a field's hash code differs in a new interpreter after\n-            # deserialization.  This is tricky to test because we are,\n-            # of course, still running in the same interpreter.  So\n-            # after deserialization we reach in and change the value of\n-            # a field to simulate the field changing its hash code. We then\n-            # check that the object's hash code changes, indicating that we\n-            # don't have a stale hash code.\n-            # This could fail in two ways: (1) pickle.loads could get the hash\n-            # code of the deserialized value (triggering it to cache) before\n-            # we alter the field value.  This doesn't happen in our tested\n-            # Python versions.  (2) \"foo\" and \"something different\" could\n-            # have a hash collision on this interpreter run.   But this is\n-            # extremely improbable and would just result in one buggy test run.\n-            round_tripped.foo_string = \"something different\"\n-            assert original_hash != hash(round_tripped)\n-\n-        # Slotted and dict classes implement __setstate__ differently,\n-        # so we need to test both cases.\n-        assert_hash_code_not_cached_across_serialization(\n-            HashCacheSerializationTestCached()\n-        )\n-        assert_hash_code_not_cached_across_serialization(\n-            HashCacheSerializationTestCachedSlots()\n-        )\n+        kwargs = dict(frozen=frozen, slots=slots, cache_hash=cache_hash,)\n+\n+        # Give it an explicit hash if we don't have an implicit one\n+        if not frozen:\n+            kwargs[\"hash\"] = True\n+\n+        @attr.s(**kwargs)\n+        class C(object):\n+            x = attr.ib()\n+\n+        a = C(IncrementingHasher())\n+        # Ensure that any hash cache would be calculated before copy\n+        orig_hash = hash(a)\n+        b = copy.deepcopy(a)\n \n-    def test_caching_and_custom_setstate(self):\n+        if kwargs[\"cache_hash\"]:\n+            # For cache_hash classes, this call is cached\n+            assert orig_hash == hash(a)\n+\n+        assert orig_hash != hash(b)\n+\n+    @pytest.mark.parametrize(\n+        \"klass,cached\",\n+        [\n+            (HashCacheSerializationTestUncached, False),\n+            (HashCacheSerializationTestCached, True),\n+            (HashCacheSerializationTestCachedSlots, True),\n+        ],\n+    )\n+    def test_cache_hash_serialization_hash_cleared(self, klass, cached):\n         \"\"\"\n-        The combination of a custom __setstate__ and cache_hash=True is caught\n-        with a helpful message.\n+        Tests that the hash cache is cleared on deserialization to fix\n+        https://github.com/python-attrs/attrs/issues/482 .\n \n-        This is needed because we handle clearing the cache after\n-        deserialization with a custom __setstate__. It is possible to make both\n-        work, but it requires some thought about how to go about it, so it has\n-        not yet been implemented.\n+        This test is intended to guard against a stale hash code surviving\n+        across serialization (which may cause problems when the hash value\n+        is different in different interpreters).\n         \"\"\"\n-        with pytest.raises(\n-            NotImplementedError,\n-            match=\"Currently you cannot use hash caching if you \"\n-            \"specify your own __setstate__ method.\",\n-        ):\n \n-            @attr.attrs(hash=True, cache_hash=True)\n-            class NoCacheHashAndCustomSetState(object):\n-                def __setstate__(self, state):\n-                    pass\n+        obj = klass(IncrementingHasher())\n+        original_hash = hash(obj)\n+        obj_rt = self._roundtrip_pickle(obj)\n \n+        if cached:\n+            assert original_hash == hash(obj)\n \n-# these are for use in TestAddHash.test_cache_hash_serialization\n-# they need to be out here so they can be un-pickled\n-@attr.attrs(hash=True, cache_hash=False)\n-class HashCacheSerializationTestUncached(object):\n-    foo_string = attr.ib(default=\"foo\")\n+        assert original_hash != hash(obj_rt)\n \n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_copy_two_arg_reduce(self, frozen):\n+        \"\"\"\n+        If __getstate__ returns None, the tuple returned by object.__reduce__\n+        won't contain the state dictionary; this test ensures that the custom\n+        __reduce__ generated when cache_hash=True works in that case.\n+        \"\"\"\n \n-@attr.attrs(hash=True, cache_hash=True)\n-class HashCacheSerializationTestCached(object):\n-    foo_string = attr.ib(default=\"foo\")\n+        @attr.s(frozen=frozen, cache_hash=True, hash=True)\n+        class C(object):\n+            x = attr.ib()\n \n+            def __getstate__(self):\n+                return None\n \n-@attr.attrs(slots=True, hash=True, cache_hash=True)\n-class HashCacheSerializationTestCachedSlots(object):\n-    foo_string = attr.ib(default=\"foo\")\n+        # By the nature of this test it doesn't really create an object that's\n+        # in a valid state - it basically does the equivalent of\n+        # `object.__new__(C)`, so it doesn't make much sense to assert anything\n+        # about the result of the copy. This test will just check that it\n+        # doesn't raise an *error*.\n+        copy.deepcopy(C(1))\n+\n+    def _roundtrip_pickle(self, obj):\n+        pickle_str = pickle.dumps(obj)\n+        return pickle.loads(pickle_str)\n \n \n class TestAddInit(object):\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1466,16 +1466,66 @@ class C2(C):\n \n         assert [C2] == C.__subclasses__()\n \n-    def test_cache_hash_with_frozen_serializes(self):\n+    def _get_copy_kwargs(include_slots=True):\n         \"\"\"\n-        Frozen classes with cache_hash should be serializable.\n+        Generate a list of compatible attr.s arguments for the `copy` tests.\n         \"\"\"\n+        options = [\"frozen\", \"hash\", \"cache_hash\"]\n \n-        @attr.s(cache_hash=True, frozen=True)\n+        if include_slots:\n+            options.extend([\"slots\", \"weakref_slot\"])\n+\n+        out_kwargs = []\n+        for args in itertools.product([True, False], repeat=len(options)):\n+            kwargs = dict(zip(options, args))\n+\n+            kwargs[\"hash\"] = kwargs[\"hash\"] or None\n+\n+            if kwargs[\"cache_hash\"] and not (\n+                kwargs[\"frozen\"] or kwargs[\"hash\"]\n+            ):\n+                continue\n+\n+            out_kwargs.append(kwargs)\n+\n+        return out_kwargs\n+\n+    @pytest.mark.parametrize(\"kwargs\", _get_copy_kwargs())\n+    def test_copy(self, kwargs):\n+        \"\"\"\n+        Ensure that an attrs class can be copied successfully.\n+        \"\"\"\n+\n+        @attr.s(eq=True, **kwargs)\n         class C(object):\n-            pass\n+            x = attr.ib()\n+\n+        a = C(1)\n+        b = copy.deepcopy(a)\n+\n+        assert a == b\n+\n+    @pytest.mark.parametrize(\"kwargs\", _get_copy_kwargs(include_slots=False))\n+    def test_copy_custom_setstate(self, kwargs):\n+        \"\"\"\n+        Ensure that non-slots classes respect a custom __setstate__.\n+        \"\"\"\n+\n+        @attr.s(eq=True, **kwargs)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __getstate__(self):\n+                return self.__dict__\n+\n+            def __setstate__(self, state):\n+                state[\"x\"] *= 5\n+                self.__dict__.update(state)\n+\n+        expected = C(25)\n+        actual = copy.copy(C(5))\n \n-        copy.deepcopy(C())\n+        assert actual == expected\n \n \n class TestMakeOrder:\n", "problem_statement": "Allow cache_hash=True to be used when a custom __setstate__ is present\nThis is not currently possible (as of the merge of #489 ) because when `cache_hash=True`, we solve #482 by adding a `__setstate__`  to all classes which clears the cached hash code.\r\n\r\nThis is a somewhat unusual combination of needs, so I imagine this is very low priority. This issue is just here as a marker for anyone who runs into this problem in the future.\n", "hints_text": "How about solving this (albeit mostly theoretical) issue by clearing the hash cache after invoking the custom `__setstate__`, like so (not including changes from #612 for simplicity, and there are lots of variations on how to implement this):\r\n\r\n```python\r\noriginal_setstate = getattr(cls, __setstate__, lambda s, _: None)\r\ndef cache_hash_set_state(chss_self, _):\r\n    original_setstate(chss_self, _)\r\n    setattr(chss_self, _hash_cache_field, None)\r\n```\r\n\r\nIf you consider the hash cache field to be an implementation detail owned by attrs, I think that likely the custom `__setstate__` shouldn't be touching it *anyway*, so this seems pretty safe. If you want a custom `__setstate__` that also has custom behavior involving the hash caching, you can implement a custom `__hash__` instead of using `cache_hash=True`.\n@pganssle : It has been a long time since I've touched this code, so I could be mistaken, but I believe your solution should work fine.  ", "created_at": "2020-01-27T18:44:43Z"}
{"repo": "python-attrs/attrs", "pull_number": 612, "instance_id": "python-attrs__attrs-612", "issue_numbers": ["611"], "base_commit": "ac541fbe556eb8c085a9cea26616f0ebad6ef632", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -537,9 +537,17 @@ def _patch_original_class(self):\n                     \"See https://github.com/python-attrs/attrs/issues/494 .\"\n                 )\n \n-            def cache_hash_set_state(chss_self, _):\n-                # clear hash code cache\n-                setattr(chss_self, _hash_cache_field, None)\n+            # Clears the cached hash state on serialization; for frozen\n+            # classes we need to bypass the class's setattr method.\n+            if self._frozen:\n+\n+                def cache_hash_set_state(chss_self, _):\n+                    object.__setattr__(chss_self, _hash_cache_field, None)\n+\n+            else:\n+\n+                def cache_hash_set_state(chss_self, _):\n+                    setattr(chss_self, _hash_cache_field, None)\n \n             cls.__setstate__ = cache_hash_set_state\n \n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1466,6 +1466,17 @@ class C2(C):\n \n         assert [C2] == C.__subclasses__()\n \n+    def test_cache_hash_with_frozen_serializes(self):\n+        \"\"\"\n+        Frozen classes with cache_hash should be serializable.\n+        \"\"\"\n+\n+        @attr.s(cache_hash=True, frozen=True)\n+        class C(object):\n+            pass\n+\n+        copy.deepcopy(C())\n+\n \n class TestMakeOrder:\n     \"\"\"\n", "problem_statement": "frozen=True incompatible with cache_hash=True as of 19.1.0\nPrior to #489, this used to work:\r\n\r\n```python\r\nimport attr\r\nimport copy\r\n\r\n@attr.s(frozen=True, cache_hash=True)\r\nclass FrozenWithCache:\r\n    pass\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    copy.deepcopy(FrozenWithCache())\r\n```\r\n\r\nThe issue is that `frozen` is implemented by throwing an error in `__setattr__`, and clearing the hash cache calls `setattr`. I think this can be solved by using [the same mechanism that `_make_hash` uses for frozen classes](https://github.com/python-attrs/attrs/blob/b6bd8c8d2bb0c53bbad0f11377df6083313d26c2/src/attr/_make.py#L1119), but I have not tried implementing this before.\r\n\r\nAnother option is to not clear the hash cache on serialization for frozen classes.\n", "hints_text": "", "created_at": "2020-01-07T23:15:37Z"}
{"repo": "python-attrs/attrs", "pull_number": 607, "instance_id": "python-attrs__attrs-607", "issue_numbers": ["324"], "base_commit": "94ad4f39172929a9696670eb03a9151feda63e03", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -218,7 +218,7 @@ def attrib(\n     .. deprecated:: 19.2.0 *cmp* Removal on or after 2021-06-01.\n     .. versionadded:: 19.2.0 *eq* and *order*\n     \"\"\"\n-    eq, order = _determine_eq_order(cmp, eq, order)\n+    eq, order = _determine_eq_order(cmp, eq, order, True)\n \n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n@@ -308,20 +308,32 @@ def _is_class_var(annot):\n     return str(annot).startswith(_classvar_prefixes)\n \n \n-def _get_annotations(cls):\n+def _has_own_attribute(cls, attrib_name):\n     \"\"\"\n-    Get annotations for *cls*.\n+    Check whether *cls* defines *attrib_name* (and doesn't just inherit it).\n+\n+    Requires Python 3.\n     \"\"\"\n-    anns = getattr(cls, \"__annotations__\", None)\n-    if anns is None:\n-        return {}\n+    attr = getattr(cls, attrib_name, _sentinel)\n+    if attr is _sentinel:\n+        return False\n \n-    # Verify that the annotations aren't merely inherited.\n     for base_cls in cls.__mro__[1:]:\n-        if anns is getattr(base_cls, \"__annotations__\", None):\n-            return {}\n+        a = getattr(base_cls, attrib_name, None)\n+        if attr is a:\n+            return False\n+\n+    return True\n+\n+\n+def _get_annotations(cls):\n+    \"\"\"\n+    Get annotations for *cls*.\n+    \"\"\"\n+    if _has_own_attribute(cls, \"__annotations__\"):\n+        return cls.__annotations__\n \n-    return anns\n+    return {}\n \n \n def _counter_getter(e):\n@@ -754,10 +766,10 @@ def _add_method_dunders(self, method):\n )\n \n \n-def _determine_eq_order(cmp, eq, order):\n+def _determine_eq_order(cmp, eq, order, default_eq):\n     \"\"\"\n     Validate the combination of *cmp*, *eq*, and *order*. Derive the effective\n-    values of eq and order.\n+    values of eq and order.  If *eq* is None, set it to *default_eq*.\n     \"\"\"\n     if cmp is not None and any((eq is not None, order is not None)):\n         raise ValueError(\"Don't mix `cmp` with `eq' and `order`.\")\n@@ -768,9 +780,10 @@ def _determine_eq_order(cmp, eq, order):\n \n         return cmp, cmp\n \n-    # If left None, equality is on and ordering mirrors equality.\n+    # If left None, equality is set to the specified default and ordering\n+    # mirrors equality.\n     if eq is None:\n-        eq = True\n+        eq = default_eq\n \n     if order is None:\n         order = eq\n@@ -781,14 +794,38 @@ def _determine_eq_order(cmp, eq, order):\n     return eq, order\n \n \n+def _determine_whether_to_implement(cls, flag, auto_detect, dunders):\n+    \"\"\"\n+    Check whether we should implement a set of methods for *cls*.\n+\n+    *flag* is the argument passed into @attr.s like 'init', *auto_detect* the\n+    same as passed into @attr.s and *dunders* is a tuple of attribute names\n+    whose presence signal that the user has implemented it themselves.\n+\n+    auto_detect must be False on Python 2.\n+    \"\"\"\n+    if flag is True or flag is None and auto_detect is False:\n+        return True\n+\n+    if flag is False:\n+        return False\n+\n+    # Logically, flag is None and auto_detect is True here.\n+    for dunder in dunders:\n+        if _has_own_attribute(cls, dunder):\n+            return False\n+\n+    return True\n+\n+\n def attrs(\n     maybe_cls=None,\n     these=None,\n     repr_ns=None,\n-    repr=True,\n+    repr=None,\n     cmp=None,\n     hash=None,\n-    init=True,\n+    init=None,\n     slots=False,\n     frozen=False,\n     weakref_slot=True,\n@@ -799,6 +836,7 @@ def attrs(\n     auto_exc=False,\n     eq=None,\n     order=None,\n+    auto_detect=False,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -823,6 +861,32 @@ def attrs(\n     :param str repr_ns: When using nested classes, there's no way in Python 2\n         to automatically detect that.  Therefore it's possible to set the\n         namespace explicitly for a more meaningful ``repr`` output.\n+    :param bool auto_detect: Instead of setting the *init*, *repr*, *eq*,\n+        *order*, and *hash* arguments explicitly, assume they are set to\n+        ``True`` **unless any** of the involved methods for one of the\n+        arguments is implemented in the *current* class (i.e. it is *not*\n+        inherited from some base class).\n+\n+        So for example by implementing ``__eq__`` on a class yourself,\n+        ``attrs`` will deduce ``eq=False`` and won't create *neither*\n+        ``__eq__`` *nor* ``__ne__`` (but Python classes come with a sensible\n+        ``__ne__`` by default, so it *should* be enough to only implement\n+        ``__eq__`` in most cases).\n+\n+        .. warning::\n+\n+           If you prevent ``attrs`` from creating the ordering methods for you\n+           (``order=False``, e.g. by implementing ``__le__``), it becomes\n+           *your* responsibility to make sure its ordering is sound. The best\n+           way is to use the `functools.total_ordering` decorator.\n+\n+\n+        Passing ``True`` or ``False`` to *init*, *repr*, *eq*, *order*,\n+        *cmp*, or *hash* overrides whatever *auto_detect* would determine.\n+\n+        *auto_detect* requires Python 3. Setting it ``True`` on Python 2 raises\n+        a `PythonTooOldError`.\n+\n     :param bool repr: Create a ``__repr__`` method with a human readable\n         representation of ``attrs`` attributes..\n     :param bool str: Create a ``__str__`` method that is identical to\n@@ -891,8 +955,8 @@ def attrs(\n \n     :param bool weakref_slot: Make instances weak-referenceable.  This has no\n         effect unless ``slots`` is also enabled.\n-    :param bool auto_attribs: If True, collect `PEP 526`_-annotated attributes\n-        (Python 3.6 and later only) from the class body.\n+    :param bool auto_attribs: If ``True``, collect `PEP 526`_-annotated\n+        attributes (Python 3.6 and later only) from the class body.\n \n         In this case, you **must** annotate every field.  If ``attrs``\n         encounters a field that is set to an `attr.ib` but lacks a type\n@@ -957,8 +1021,15 @@ def attrs(\n     .. versionadded:: 19.1.0 *auto_exc*\n     .. deprecated:: 19.2.0 *cmp* Removal on or after 2021-06-01.\n     .. versionadded:: 19.2.0 *eq* and *order*\n+    .. versionadded:: 20.1.0 *auto_detect*\n     \"\"\"\n-    eq, order = _determine_eq_order(cmp, eq, order)\n+    if auto_detect and PY2:\n+        raise PythonTooOldError(\n+            \"auto_detect only works on Python 3 and later.\"\n+        )\n+\n+    eq_, order_ = _determine_eq_order(cmp, eq, order, None)\n+    hash_ = hash  # workaround the lack of nonlocal\n \n     def wrap(cls):\n \n@@ -978,16 +1049,31 @@ def wrap(cls):\n             cache_hash,\n             is_exc,\n         )\n-\n-        if repr is True:\n+        if _determine_whether_to_implement(\n+            cls, repr, auto_detect, (\"__repr__\",)\n+        ):\n             builder.add_repr(repr_ns)\n         if str is True:\n             builder.add_str()\n-        if eq is True and not is_exc:\n+\n+        eq = _determine_whether_to_implement(\n+            cls, eq_, auto_detect, (\"__eq__\", \"__ne__\")\n+        )\n+        if not is_exc and eq is True:\n             builder.add_eq()\n-        if order is True and not is_exc:\n+        if not is_exc and _determine_whether_to_implement(\n+            cls, order_, auto_detect, (\"__lt__\", \"__le__\", \"__gt__\", \"__ge__\")\n+        ):\n             builder.add_order()\n \n+        if (\n+            hash_ is None\n+            and auto_detect is True\n+            and _has_own_attribute(cls, \"__hash__\")\n+        ):\n+            hash = False\n+        else:\n+            hash = hash_\n         if hash is not True and hash is not False and hash is not None:\n             # Can't use `hash in` because 1 == True for example.\n             raise TypeError(\n@@ -1015,7 +1101,9 @@ def wrap(cls):\n                 )\n             builder.make_unhashable()\n \n-        if init is True:\n+        if _determine_whether_to_implement(\n+            cls, init, auto_detect, (\"__init__\",)\n+        ):\n             builder.add_init()\n         else:\n             if cache_hash:\n@@ -1832,7 +1920,7 @@ def __init__(\n         eq=None,\n         order=None,\n     ):\n-        eq, order = _determine_eq_order(cmp, eq, order)\n+        eq, order = _determine_eq_order(cmp, eq, order, True)\n \n         # Cache this descriptor here to speed things up later.\n         bound_setattr = _obj_setattr.__get__(self, Attribute)\n@@ -2178,7 +2266,10 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n         attributes_arguments[\"eq\"],\n         attributes_arguments[\"order\"],\n     ) = _determine_eq_order(\n-        cmp, attributes_arguments.get(\"eq\"), attributes_arguments.get(\"order\")\n+        cmp,\n+        attributes_arguments.get(\"eq\"),\n+        attributes_arguments.get(\"order\"),\n+        True,\n     )\n \n     return _attrs(these=cls_dict, **attributes_arguments)(type_)\ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\n--- a/src/attr/exceptions.py\n+++ b/src/attr/exceptions.py\n@@ -51,7 +51,8 @@ class UnannotatedAttributeError(RuntimeError):\n \n class PythonTooOldError(RuntimeError):\n     \"\"\"\n-    An ``attrs`` feature requiring a more recent python version has been used.\n+    It was attempted to use an ``attrs`` feature that requires a newer Python\n+    version.\n \n     .. versionadded:: 18.2.0\n     \"\"\"\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -5,6 +5,7 @@\n from __future__ import absolute_import, division, print_function\n \n import copy\n+import functools\n import gc\n import inspect\n import itertools\n@@ -29,6 +30,7 @@\n     _ClassBuilder,\n     _CountingAttr,\n     _determine_eq_order,\n+    _determine_whether_to_implement,\n     _transform_attrs,\n     and_,\n     fields,\n@@ -1588,16 +1590,16 @@ class B(A):\n class TestDetermineEqOrder(object):\n     def test_default(self):\n         \"\"\"\n-        If all are set to None, do the default: True, True\n+        If all are set to None, set both eq and order to the passed default.\n         \"\"\"\n-        assert (True, True) == _determine_eq_order(None, None, None)\n+        assert (42, 42) == _determine_eq_order(None, None, None, 42)\n \n     @pytest.mark.parametrize(\"eq\", [True, False])\n     def test_order_mirrors_eq_by_default(self, eq):\n         \"\"\"\n         If order is None, it mirrors eq.\n         \"\"\"\n-        assert (eq, eq) == _determine_eq_order(None, eq, None)\n+        assert (eq, eq) == _determine_eq_order(None, eq, None, True)\n \n     def test_order_without_eq(self):\n         \"\"\"\n@@ -1606,7 +1608,7 @@ def test_order_without_eq(self):\n         with pytest.raises(\n             ValueError, match=\"`order` can only be True if `eq` is True too.\"\n         ):\n-            _determine_eq_order(None, False, True)\n+            _determine_eq_order(None, False, True, True)\n \n     @given(cmp=booleans(), eq=optional_bool, order=optional_bool)\n     def test_mix(self, cmp, eq, order):\n@@ -1618,7 +1620,7 @@ def test_mix(self, cmp, eq, order):\n         with pytest.raises(\n             ValueError, match=\"Don't mix `cmp` with `eq' and `order`.\"\n         ):\n-            _determine_eq_order(cmp, eq, order)\n+            _determine_eq_order(cmp, eq, order, True)\n \n     def test_cmp_deprecated(self):\n         \"\"\"\n@@ -1669,3 +1671,346 @@ class A(object):\n                 A.__qualname__\n             )\n             assert expected == method.__doc__\n+\n+\n+@pytest.mark.skipif(not PY2, reason=\"Needs to be only caught on Python 2.\")\n+def test_auto_detect_raises_on_py2():\n+    \"\"\"\n+    Trying to pass auto_detect=True to attr.s raises PythonTooOldError.\n+    \"\"\"\n+    with pytest.raises(PythonTooOldError):\n+        attr.s(auto_detect=True)\n+\n+\n+class BareC(object):\n+    pass\n+\n+\n+class BareSlottedC(object):\n+    __slots__ = ()\n+\n+\n+@pytest.mark.skipif(PY2, reason=\"Auto-detection is Python 3-only.\")\n+class TestAutoDetect:\n+    @pytest.mark.parametrize(\"C\", (BareC, BareSlottedC))\n+    def test_determine_detects_non_presence_correctly(self, C):\n+        \"\"\"\n+        On an empty class, nothing should be detected.\n+        \"\"\"\n+        assert True is _determine_whether_to_implement(\n+            C, None, True, (\"__init__\",)\n+        )\n+        assert True is _determine_whether_to_implement(\n+            C, None, True, (\"__repr__\",)\n+        )\n+        assert True is _determine_whether_to_implement(\n+            C, None, True, (\"__eq__\", \"__ne__\")\n+        )\n+        assert True is _determine_whether_to_implement(\n+            C, None, True, (\"__le__\", \"__lt__\", \"__ge__\", \"__gt__\")\n+        )\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_make_all_by_default(self, slots, frozen):\n+        \"\"\"\n+        If nothing is there to be detected, imply init=True, repr=True,\n+        hash=None, eq=True, order=True.\n+        \"\"\"\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+        i = C(1)\n+        o = object()\n+\n+        assert i.__init__ is not o.__init__\n+        assert i.__repr__ is not o.__repr__\n+        assert i.__eq__ is not o.__eq__\n+        assert i.__ne__ is not o.__ne__\n+        assert i.__le__ is not o.__le__\n+        assert i.__lt__ is not o.__lt__\n+        assert i.__ge__ is not o.__ge__\n+        assert i.__gt__ is not o.__gt__\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_detect_auto_init(self, slots, frozen):\n+        \"\"\"\n+        If auto_detect=True and an __init__ exists, don't write one.\n+        \"\"\"\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class CI(object):\n+            x = attr.ib()\n+\n+            def __init__(self):\n+                object.__setattr__(self, \"x\", 42)\n+\n+        assert 42 == CI().x\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_detect_auto_repr(self, slots, frozen):\n+        \"\"\"\n+        If auto_detect=True and an __repr__ exists, don't write one.\n+        \"\"\"\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __repr__(self):\n+                return \"hi\"\n+\n+        assert \"hi\" == repr(C(42))\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_detect_auto_hash(self, slots, frozen):\n+        \"\"\"\n+        If auto_detect=True and an __hash__ exists, don't write one.\n+        \"\"\"\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __hash__(self):\n+                return 0xC0FFEE\n+\n+        assert 0xC0FFEE == hash(C(42))\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_detect_auto_eq(self, slots, frozen):\n+        \"\"\"\n+        If auto_detect=True and an __eq__ or an __ne__, exist, don't write one.\n+        \"\"\"\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __eq__(self, o):\n+                raise ValueError(\"worked\")\n+\n+        with pytest.raises(ValueError, match=\"worked\"):\n+            C(1) == C(1)\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class D(object):\n+            x = attr.ib()\n+\n+            def __ne__(self, o):\n+                raise ValueError(\"worked\")\n+\n+        with pytest.raises(ValueError, match=\"worked\"):\n+            D(1) != D(1)\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_detect_auto_order(self, slots, frozen):\n+        \"\"\"\n+        If auto_detect=True and an __ge__, __gt__, __le__, or and __lt__ exist,\n+        don't write one.\n+\n+        It's surprisingly difficult to test this programmatically, so we do it\n+        by hand.\n+        \"\"\"\n+\n+        def assert_not_set(cls, ex, meth_name):\n+            __tracebackhide__ = True\n+\n+            a = getattr(cls, meth_name)\n+            if meth_name == ex:\n+                assert a == 42\n+            else:\n+                assert a is getattr(object, meth_name)\n+\n+        def assert_none_set(cls, ex):\n+            __tracebackhide__ = True\n+\n+            for m in (\"le\", \"lt\", \"ge\", \"gt\"):\n+                assert_not_set(cls, ex, \"__\" + m + \"__\")\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class LE(object):\n+            __le__ = 42\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class LT(object):\n+            __lt__ = 42\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class GE(object):\n+            __ge__ = 42\n+\n+        @attr.s(auto_detect=True, slots=slots, frozen=frozen)\n+        class GT(object):\n+            __gt__ = 42\n+\n+        assert_none_set(LE, \"__le__\")\n+        assert_none_set(LT, \"__lt__\")\n+        assert_none_set(GE, \"__ge__\")\n+        assert_none_set(GT, \"__gt__\")\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_override_init(self, slots, frozen):\n+        \"\"\"\n+        If init=True is passed, ignore __init__.\n+        \"\"\"\n+\n+        @attr.s(init=True, auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __init__(self):\n+                pytest.fail(\"should not be called\")\n+\n+        assert C(1) == C(1)\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_override_repr(self, slots, frozen):\n+        \"\"\"\n+        If repr=True is passed, ignore __repr__.\n+        \"\"\"\n+\n+        @attr.s(repr=True, auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __repr__(self):\n+                pytest.fail(\"should not be called\")\n+\n+        assert \"C(x=1)\" == repr(C(1))\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_override_hash(self, slots, frozen):\n+        \"\"\"\n+        If hash=True is passed, ignore __hash__.\n+        \"\"\"\n+\n+        @attr.s(hash=True, auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __hash__(self):\n+                pytest.fail(\"should not be called\")\n+\n+        assert hash(C(1))\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_override_eq(self, slots, frozen):\n+        \"\"\"\n+        If eq=True is passed, ignore __eq__ and __ne__.\n+        \"\"\"\n+\n+        @attr.s(eq=True, auto_detect=True, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __eq__(self, o):\n+                pytest.fail(\"should not be called\")\n+\n+            def __ne__(self, o):\n+                pytest.fail(\"should not be called\")\n+\n+        assert C(1) == C(1)\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    @pytest.mark.parametrize(\n+        \"eq,order,cmp\",\n+        [\n+            (True, None, None),\n+            (True, True, None),\n+            (None, True, None),\n+            (None, None, True),\n+        ],\n+    )\n+    def test_override_order(self, slots, frozen, eq, order, cmp, recwarn):\n+        \"\"\"\n+        If order=True is passed, ignore __le__, __lt__, __gt__, __ge__.\n+\n+        eq=True and cmp=True both imply order=True so test it too.\n+        \"\"\"\n+\n+        def meth(self, o):\n+            pytest.fail(\"should not be called\")\n+\n+        @attr.s(\n+            cmp=cmp,\n+            order=order,\n+            eq=eq,\n+            auto_detect=True,\n+            slots=slots,\n+            frozen=frozen,\n+        )\n+        class C(object):\n+            x = attr.ib()\n+            __le__ = __lt__ = __gt__ = __ge__ = meth\n+\n+        assert C(1) < C(2)\n+        assert C(1) <= C(2)\n+        assert C(2) > C(1)\n+        assert C(2) >= C(1)\n+\n+        if cmp:\n+            assert 1 == len(recwarn.list)\n+        else:\n+            assert 0 == len(recwarn.list)\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"first\", [True, False])\n+    def test_total_ordering(self, slots, first):\n+        \"\"\"\n+        functools.total_ordering works as expected if an order method and an eq\n+        method are detected.\n+\n+        Ensure the order doesn't matter.\n+        \"\"\"\n+\n+        class C(object):\n+            x = attr.ib()\n+            own_eq_called = attr.ib(default=False)\n+            own_le_called = attr.ib(default=False)\n+\n+            def __eq__(self, o):\n+                self.own_eq_called = True\n+                return self.x == o.x\n+\n+            def __le__(self, o):\n+                self.own_le_called = True\n+                return self.x <= o.x\n+\n+        if first:\n+            C = functools.total_ordering(\n+                attr.s(auto_detect=True, slots=slots)(C)\n+            )\n+        else:\n+            C = attr.s(auto_detect=True, slots=slots)(\n+                functools.total_ordering(C)\n+            )\n+\n+        c1, c2 = C(1), C(2)\n+\n+        assert c1 < c2\n+        assert c1.own_le_called\n+\n+        c1, c2 = C(1), C(2)\n+\n+        assert c2 > c1\n+        assert c2.own_le_called\n+\n+        c1, c2 = C(1), C(2)\n+\n+        assert c2 != c1\n+        assert c1 == c1\n+\n+        assert c1.own_eq_called\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -183,3 +183,13 @@ class WithCustomRepr:\n class OrderFlags:\n     a = attr.ib(eq=False, order=False)\n     b = attr.ib(eq=True, order=True)\n+\n+\n+# Auto-detect\n+# XXX: needs support in mypy\n+# @attr.s(auto_detect=True)\n+# class AutoDetect:\n+#     x: int\n+\n+#     def __init__(self, x: int):\n+#         self.x = x\n", "problem_statement": "Auto-detect user-written methods\nCurrently, if you want to implement a method yourself, you have to remember to do two things:\r\n\r\n```python\r\n@attr.s(repr=False)\r\nclass C:\r\n    def __repr__(self):\r\n        return \"whatever\"\r\n```\r\n\r\nI\u2019ve seen quite a few people be confused/frustrated by that.\r\n\r\n***\r\n\r\nI think unless `these` is set, it would be kind of cool if we detected that the current class (and not some super class) has a user-written method and set the flag to false automatically such that\r\n\r\n```python\r\n@attr.s\r\nclass C:\r\n    def __repr__(self):\r\n        return \"whatever\"\r\n```\r\n\r\ndoes what you\u2019d expect.\r\n\r\nOpinions?\n", "hints_text": "\ud83d\udc4d \nSame with `__init__`?  (I ask because the mypy plugin will have to deal with that too.)\nThe idea is to support it for all of them.  It gets a bit hairy when we get to comparison because it\u2019s several ones.  Would we stop completely?  Or just not replace one of them?\nWith comparison methods, perhaps [total_ordering](https://docs.python.org/3/library/functools.html#functools.total_ordering) could provide guidance; if you provide enough for `total_ordering` to work, we apply it or do something similar?\r\n\r\nIt's a bit of feature creep, but it feels in line with the developer doing as little work related to attributes as necessary and we take care of the rest.\nThe more I think about it the more I think we should just skip methods that have been defined and be done with it.  That allows people to customise their classes even better.", "created_at": "2020-01-03T13:24:16Z"}
{"repo": "python-attrs/attrs", "pull_number": 590, "instance_id": "python-attrs__attrs-590", "issue_numbers": ["589"], "base_commit": "4bd682709134155ec79c5077a748a8bd3ade39d9", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -641,8 +641,13 @@ def slots_setstate(self, state):\n             if not closure_cells:  # Catch None or the empty list.\n                 continue\n             for cell in closure_cells:\n-                if cell.cell_contents is self._cls:\n-                    set_closure_cell(cell, cls)\n+                try:\n+                    match = cell.cell_contents is self._cls\n+                except ValueError:  # ValueError: Cell is empty\n+                    pass\n+                else:\n+                    if match:\n+                        set_closure_cell(cell, cls)\n \n         return cls\n \n", "test_patch": "diff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -543,3 +543,28 @@ class C(object):\n     w = weakref.ref(c)\n \n     assert c is w()\n+\n+\n+def test_slots_empty_cell():\n+    \"\"\"\n+    Tests that no `ValueError: Cell is empty` exception is raised when\n+    closure cells are present with no contents in a `slots=True` class.\n+    (issue https://github.com/python-attrs/attrs/issues/589)\n+\n+    On Python 3, if a method mentions `__class__` or uses the no-arg `super()`,\n+    the compiler will bake a reference to the class in the method itself as\n+    `method.__closure__`. Since `attrs` replaces the class with a clone,\n+    `_ClassBuilder._create_slots_class(self)` will rewrite these references so\n+    it keeps working. This method was not properly covering the edge case where\n+    the closure cell was empty, we fixed it and this is the non-regression\n+    test.\n+    \"\"\"\n+\n+    @attr.s(slots=True)\n+    class C(object):\n+        field = attr.ib()\n+\n+        def f(self, a):\n+            super(C, self).__init__()\n+\n+    C(field=1)\n", "problem_statement": "ValueError: Cell is empty with very specific code\nConsider this horrible and useless code:\r\n\r\n```python\r\n@attr.s(slots=True)\r\nclass C(object):\r\n    field = attr.ib()\r\n\r\n    def f(self, a):\r\n        super(C, self).__init__()\r\n```\r\n\r\nYou get a nice error:\r\n\r\n```\r\n        # The following is a fix for\r\n        # https://github.com/python-attrs/attrs/issues/102.  On Python 3,\r\n        # if a method mentions `__class__` or uses the no-arg super(), the\r\n        # compiler will bake a reference to the class in the method itself\r\n        # as `method.__closure__`.  Since we replace the class with a\r\n        # clone, we rewrite these references so it keeps working.\r\n        for item in cls.__dict__.values():\r\n            if isinstance(item, (classmethod, staticmethod)):\r\n                # Class- and staticmethods hide their functions inside.\r\n                # These might need to be rewritten as well.\r\n                closure_cells = getattr(item.__func__, \"__closure__\", None)\r\n            else:\r\n                closure_cells = getattr(item, \"__closure__\", None)\r\n    \r\n            if not closure_cells:  # Catch None or the empty list.\r\n                continue\r\n            for cell in closure_cells:\r\n>               if cell.cell_contents is self._cls:\r\nE               ValueError: Cell is empty\r\n\r\n..\\src\\attr\\_make.py:639: ValueError\r\n```\r\n\r\nI'll push a PR right away\n", "hints_text": "", "created_at": "2019-10-21T15:59:12Z"}
{"repo": "python-attrs/attrs", "pull_number": 586, "instance_id": "python-attrs__attrs-586", "issue_numbers": ["585"], "base_commit": "3432df571117386cd7f58db3222ed1dd7fa35d7b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -509,7 +509,7 @@ def _patch_original_class(self):\n             for name in self._attr_names:\n                 if (\n                     name not in base_names\n-                    and getattr(cls, name, _sentinel) != _sentinel\n+                    and getattr(cls, name, _sentinel) is not _sentinel\n                 ):\n                     try:\n                         delattr(cls, name)\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -282,3 +282,18 @@ class C:\n \n         with pytest.raises(AttributeError):\n             C.y\n+\n+    def test_non_comparable_defaults(self):\n+        \"\"\"\n+        Regression test for #585: objects that are not directly comparable\n+        (for example numpy arrays) would cause a crash when used as\n+        default values of an attrs auto-attrib class.\n+        \"\"\"\n+\n+        class NonComparable:\n+            def __eq__(self, other):\n+                raise ValueError\n+\n+        @attr.s(auto_attribs=True)\n+        class C:\n+            x: typing.Any = NonComparable()\n", "problem_statement": "Couldn't use numpy arrays as defaults on attrs 19.2\nThe following code stops working when upgrading from attrs 19.1 to 19.2:\r\n\r\n```\r\n@attr.s(auto_attribs=True)\r\nclass NumParams:\r\n    N = 3\r\n    alpha = np.zeros((N, Ng))\r\n```\r\n\r\nSeems that change #556 requires that default attributes should implement `__eq__`, which is not the case for numpy arrays.\r\n\r\nTaceback is:\r\n```\r\n    @attr.s(auto_attribs=True)\r\n../../../../miniconda/envs/attests/lib/python3.6/site-packages/attr/_make.py:1010: in wrap\r\n    return builder.build_class()\r\n../../../../miniconda/envs/attests/lib/python3.6/site-packages/attr/_make.py:498: in build_class\r\n    return self._patch_original_class()\r\n../../../../miniconda/envs/attests/lib/python3.6/site-packages/attr/_make.py:512: in _patch_original_class\r\n    and getattr(cls, name, _sentinel) != _sentinel\r\nE   ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\r\n```\n", "hints_text": "the issue can be resolved by switching the sentinel check from equality to is", "created_at": "2019-10-14T19:58:16Z"}
{"repo": "python-attrs/attrs", "pull_number": 574, "instance_id": "python-attrs__attrs-574", "issue_numbers": ["170"], "base_commit": "6e7b9f2cfaeb95936edea53c5f5f67800aaa20ee", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -2,8 +2,6 @@\n \n import sys\n \n-import pytest\n-\n from hypothesis import HealthCheck, settings\n \n \n@@ -15,21 +13,6 @@ def pytest_configure(config):\n     settings.load_profile(\"patience\")\n \n \n-@pytest.fixture(scope=\"session\")\n-def C():\n-    \"\"\"\n-    Return a simple but fully featured attrs class with an x and a y attribute.\n-    \"\"\"\n-    import attr\n-\n-    @attr.s\n-    class C(object):\n-        x = attr.ib()\n-        y = attr.ib()\n-\n-    return C\n-\n-\n collect_ignore = []\n if sys.version_info[:2] < (3, 6):\n     collect_ignore.extend(\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -5,6 +5,7 @@\n import sys\n import threading\n import uuid\n+import warnings\n \n from operator import itemgetter\n \n@@ -73,7 +74,7 @@ def attrib(\n     default=NOTHING,\n     validator=None,\n     repr=True,\n-    cmp=True,\n+    cmp=None,\n     hash=None,\n     init=True,\n     metadata=None,\n@@ -81,6 +82,8 @@ def attrib(\n     converter=None,\n     factory=None,\n     kw_only=False,\n+    eq=None,\n+    order=None,\n ):\n     \"\"\"\n     Create a new attribute on a class.\n@@ -135,10 +138,15 @@ def attrib(\n         as-is, i.e. it will be used directly *instead* of calling ``repr()``\n         (the default).\n     :type repr: a ``bool`` or a ``callable`` to use a custom function.\n-    :param bool cmp: Include this attribute in the generated comparison methods\n-        (``__eq__`` et al).\n+    :param bool eq: If ``True`` (default), include this attribute in the\n+        generated ``__eq__`` and ``__ne__`` methods that check two instances\n+        for equality.\n+    :param bool order: If ``True`` (default), include this attributes in the\n+        generated ``__lt__``, ``__le__``, ``__gt__`` and ``__ge__`` methods.\n+    :param bool cmp: Setting to ``True`` is equivalent to setting ``eq=True,\n+        order=True``. Deprecated in favor of *eq* and *order*.\n     :param hash: Include this attribute in the generated ``__hash__``\n-        method.  If ``None`` (default), mirror *cmp*'s value.  This is the\n+        method.  If ``None`` (default), mirror *eq*'s value.  This is the\n         correct behavior according the Python spec.  Setting this value to\n         anything else than ``None`` is *discouraged*.\n     :type hash: ``bool`` or ``None``\n@@ -171,7 +179,7 @@ def attrib(\n     .. versionadded:: 16.3.0 *metadata*\n     .. versionchanged:: 17.1.0 *validator* can be a ``list`` now.\n     .. versionchanged:: 17.1.0\n-       *hash* is ``None`` and therefore mirrors *cmp* by default.\n+       *hash* is ``None`` and therefore mirrors *eq* by default.\n     .. versionadded:: 17.3.0 *type*\n     .. deprecated:: 17.4.0 *convert*\n     .. versionadded:: 17.4.0 *converter* as a replacement for the deprecated\n@@ -181,7 +189,11 @@ def attrib(\n     .. versionadded:: 18.2.0 *kw_only*\n     .. versionchanged:: 19.2.0 *convert* keyword argument removed\n     .. versionchanged:: 19.2.0 *repr* also accepts a custom callable.\n+    .. deprecated:: 19.2.0 *cmp* Removal on or after 2021-06-01.\n+    .. versionadded:: 19.2.0 *eq* and *order*\n     \"\"\"\n+    eq, order = _determine_eq_order(cmp, eq, order)\n+\n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n             \"Invalid value for hash.  Must be True, False, or None.\"\n@@ -204,13 +216,15 @@ def attrib(\n         default=default,\n         validator=validator,\n         repr=repr,\n-        cmp=cmp,\n+        cmp=None,\n         hash=hash,\n         init=init,\n         converter=converter,\n         metadata=metadata,\n         type=type,\n         kw_only=kw_only,\n+        eq=eq,\n+        order=order,\n     )\n \n \n@@ -678,14 +692,22 @@ def add_init(self):\n \n         return self\n \n-    def add_cmp(self):\n+    def add_eq(self):\n         cd = self._cls_dict\n \n-        cd[\"__eq__\"], cd[\"__ne__\"], cd[\"__lt__\"], cd[\"__le__\"], cd[\n-            \"__gt__\"\n-        ], cd[\"__ge__\"] = (\n+        cd[\"__eq__\"], cd[\"__ne__\"] = (\n             self._add_method_dunders(meth)\n-            for meth in _make_cmp(self._cls, self._attrs)\n+            for meth in _make_eq(self._cls, self._attrs)\n+        )\n+\n+        return self\n+\n+    def add_order(self):\n+        cd = self._cls_dict\n+\n+        cd[\"__lt__\"], cd[\"__le__\"], cd[\"__gt__\"], cd[\"__ge__\"] = (\n+            self._add_method_dunders(meth)\n+            for meth in _make_order(self._cls, self._attrs)\n         )\n \n         return self\n@@ -709,12 +731,45 @@ def _add_method_dunders(self, method):\n         return method\n \n \n+_CMP_DEPRECATION = (\n+    \"The usage of `cmp` is deprecated and will be removed on or after \"\n+    \"2021-06-01.  Please use `eq` and `order` instead.\"\n+)\n+\n+\n+def _determine_eq_order(cmp, eq, order):\n+    \"\"\"\n+    Validate the combination of *cmp*, *eq*, and *order*. Derive the effective\n+    values of eq and order.\n+    \"\"\"\n+    if cmp is not None and any((eq is not None, order is not None)):\n+        raise ValueError(\"Don't mix `cmp` with `eq' and `order`.\")\n+\n+    # cmp takes precedence due to bw-compatibility.\n+    if cmp is not None:\n+        warnings.warn(_CMP_DEPRECATION, DeprecationWarning, stacklevel=3)\n+\n+        return cmp, cmp\n+\n+    # If left None, equality is on and ordering mirrors equality.\n+    if eq is None:\n+        eq = True\n+\n+    if order is None:\n+        order = eq\n+\n+    if eq is False and order is True:\n+        raise ValueError(\"`order` can only be True if `eq` is True too.\")\n+\n+    return eq, order\n+\n+\n def attrs(\n     maybe_cls=None,\n     these=None,\n     repr_ns=None,\n     repr=True,\n-    cmp=True,\n+    cmp=None,\n     hash=None,\n     init=True,\n     slots=False,\n@@ -725,6 +780,8 @@ def attrs(\n     kw_only=False,\n     cache_hash=False,\n     auto_exc=False,\n+    eq=None,\n+    order=None,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -754,17 +811,28 @@ def attrs(\n     :param bool str: Create a ``__str__`` method that is identical to\n         ``__repr__``.  This is usually not necessary except for\n         `Exception`\\ s.\n-    :param bool cmp: Create ``__eq__``, ``__ne__``, ``__lt__``, ``__le__``,\n-        ``__gt__``, and ``__ge__`` methods that compare the class as if it were\n-        a tuple of its ``attrs`` attributes.  But the attributes are *only*\n-        compared, if the types of both classes are *identical*!\n+    :param bool eq: If ``True`` or ``None`` (default), add ``__eq__`` and\n+        ``__ne__`` methods that check two instances for equality.\n+\n+        They compare the instances as if they were tuples of their ``attrs``\n+        attributes, but only iff the types of both classes are *identical*!\n+    :type eq: `bool` or `None`\n+    :param bool order: If ``True``, add ``__lt__``, ``__le__``, ``__gt__``,\n+        and ``__ge__`` methods that behave like *eq* above and allow instances\n+        to be ordered. If ``None`` (default) mirror value of *eq*.\n+    :type order: `bool` or `None`\n+    :param cmp: Setting to ``True`` is equivalent to setting ``eq=True,\n+        order=True``. Deprecated in favor of *eq* and *order*, has precedence\n+        over them for backward-compatibility though. Must not be mixed with\n+        *eq* or *order*.\n+    :type cmp: `bool` or `None`\n     :param hash: If ``None`` (default), the ``__hash__`` method is generated\n-        according how *cmp* and *frozen* are set.\n+        according how *eq* and *frozen* are set.\n \n         1. If *both* are True, ``attrs`` will generate a ``__hash__`` for you.\n-        2. If *cmp* is True and *frozen* is False, ``__hash__`` will be set to\n+        2. If *eq* is True and *frozen* is False, ``__hash__`` will be set to\n            None, marking it unhashable (which it is).\n-        3. If *cmp* is False, ``__hash__`` will be left untouched meaning the\n+        3. If *eq* is False, ``__hash__`` will be left untouched meaning the\n            ``__hash__`` method of the base class will be used (if base class is\n            ``object``, this means it will fall back to id-based hashing.).\n \n@@ -838,10 +906,10 @@ def attrs(\n         following happens to behave like a well-behaved Python exceptions\n         class:\n \n-        - the values for *cmp* and *hash* are ignored and the instances compare\n-          and hash by the instance's ids (N.B. ``attrs`` will *not* remove\n-          existing implementations of ``__hash__`` or the equality methods. It\n-          just won't add own ones.),\n+        - the values for *eq*, *order*, and *hash* are ignored and the\n+          instances compare and hash by the instance's ids (N.B. ``attrs`` will\n+          *not* remove existing implementations of ``__hash__`` or the equality\n+          methods. It just won't add own ones.),\n         - all attributes that are either passed into ``__init__`` or have a\n           default value are additionally available as a tuple in the ``args``\n           attribute,\n@@ -869,7 +937,10 @@ def attrs(\n     .. versionadded:: 18.2.0 *kw_only*\n     .. versionadded:: 18.2.0 *cache_hash*\n     .. versionadded:: 19.1.0 *auto_exc*\n+    .. deprecated:: 19.2.0 *cmp* Removal on or after 2021-06-01.\n+    .. versionadded:: 19.2.0 *eq* and *order*\n     \"\"\"\n+    eq, order = _determine_eq_order(cmp, eq, order)\n \n     def wrap(cls):\n \n@@ -894,15 +965,17 @@ def wrap(cls):\n             builder.add_repr(repr_ns)\n         if str is True:\n             builder.add_str()\n-        if cmp is True and not is_exc:\n-            builder.add_cmp()\n+        if eq is True and not is_exc:\n+            builder.add_eq()\n+        if order is True and not is_exc:\n+            builder.add_order()\n \n         if hash is not True and hash is not False and hash is not None:\n             # Can't use `hash in` because 1 == True for example.\n             raise TypeError(\n                 \"Invalid value for hash.  Must be True, False, or None.\"\n             )\n-        elif hash is False or (hash is None and cmp is False) or is_exc:\n+        elif hash is False or (hash is None and eq is False) or is_exc:\n             # Don't do anything. Should fall back to __object__'s __hash__\n             # which is by id.\n             if cache_hash:\n@@ -911,7 +984,7 @@ def wrap(cls):\n                     \" hashing must be either explicitly or implicitly \"\n                     \"enabled.\"\n                 )\n-        elif hash is True or (hash is None and cmp is True and frozen is True):\n+        elif hash is True or (hash is None and eq is True and frozen is True):\n             # Build a __hash__ if told so, or if it's safe.\n             builder.add_hash()\n         else:\n@@ -1013,9 +1086,7 @@ def _generate_unique_filename(cls, func_name):\n \n def _make_hash(cls, attrs, frozen, cache_hash):\n     attrs = tuple(\n-        a\n-        for a in attrs\n-        if a.hash is True or (a.hash is None and a.cmp is True)\n+        a for a in attrs if a.hash is True or (a.hash is None and a.eq is True)\n     )\n \n     tab = \"        \"\n@@ -1093,8 +1164,8 @@ def __ne__(self, other):\n     return not result\n \n \n-def _make_cmp(cls, attrs):\n-    attrs = [a for a in attrs if a.cmp]\n+def _make_eq(cls, attrs):\n+    attrs = [a for a in attrs if a.eq]\n \n     unique_filename = _generate_unique_filename(cls, \"eq\")\n     lines = [\n@@ -1129,8 +1200,11 @@ def _make_cmp(cls, attrs):\n         script.splitlines(True),\n         unique_filename,\n     )\n-    eq = locs[\"__eq__\"]\n-    ne = __ne__\n+    return locs[\"__eq__\"], __ne__\n+\n+\n+def _make_order(cls, attrs):\n+    attrs = [a for a in attrs if a.order]\n \n     def attrs_to_tuple(obj):\n         \"\"\"\n@@ -1174,19 +1248,17 @@ def __ge__(self, other):\n \n         return NotImplemented\n \n-    return eq, ne, __lt__, __le__, __gt__, __ge__\n+    return __lt__, __le__, __gt__, __ge__\n \n \n-def _add_cmp(cls, attrs=None):\n+def _add_eq(cls, attrs=None):\n     \"\"\"\n-    Add comparison methods to *cls*.\n+    Add equality methods to *cls* with *attrs*.\n     \"\"\"\n     if attrs is None:\n         attrs = cls.__attrs_attrs__\n \n-    cls.__eq__, cls.__ne__, cls.__lt__, cls.__le__, cls.__gt__, cls.__ge__ = _make_cmp(  # noqa\n-        cls, attrs\n-    )\n+    cls.__eq__, cls.__ne__ = _make_eq(cls, attrs)\n \n     return cls\n \n@@ -1682,7 +1754,8 @@ class Attribute(object):\n         \"default\",\n         \"validator\",\n         \"repr\",\n-        \"cmp\",\n+        \"eq\",\n+        \"order\",\n         \"hash\",\n         \"init\",\n         \"metadata\",\n@@ -1697,14 +1770,18 @@ def __init__(\n         default,\n         validator,\n         repr,\n-        cmp,\n+        cmp,  # XXX: unused, remove along with other cmp code.\n         hash,\n         init,\n         metadata=None,\n         type=None,\n         converter=None,\n         kw_only=False,\n+        eq=None,\n+        order=None,\n     ):\n+        eq, order = _determine_eq_order(cmp, eq, order)\n+\n         # Cache this descriptor here to speed things up later.\n         bound_setattr = _obj_setattr.__get__(self, Attribute)\n \n@@ -1714,7 +1791,8 @@ def __init__(\n         bound_setattr(\"default\", default)\n         bound_setattr(\"validator\", validator)\n         bound_setattr(\"repr\", repr)\n-        bound_setattr(\"cmp\", cmp)\n+        bound_setattr(\"eq\", eq)\n+        bound_setattr(\"order\", order)\n         bound_setattr(\"hash\", hash)\n         bound_setattr(\"init\", init)\n         bound_setattr(\"converter\", converter)\n@@ -1757,9 +1835,19 @@ def from_counting_attr(cls, name, ca, type=None):\n             validator=ca._validator,\n             default=ca._default,\n             type=type,\n+            cmp=None,\n             **inst_dict\n         )\n \n+    @property\n+    def cmp(self):\n+        \"\"\"\n+        Simulate the presence of a cmp attribute and warn.\n+        \"\"\"\n+        warnings.warn(_CMP_DEPRECATION, DeprecationWarning, stacklevel=2)\n+\n+        return self.eq and self.order\n+\n     # Don't use attr.assoc since fields(Attribute) doesn't work\n     def _assoc(self, **changes):\n         \"\"\"\n@@ -1807,7 +1895,9 @@ def _setattrs(self, name_values_pairs):\n         default=NOTHING,\n         validator=None,\n         repr=True,\n-        cmp=True,\n+        cmp=None,\n+        eq=True,\n+        order=False,\n         hash=(name != \"metadata\"),\n         init=True,\n     )\n@@ -1815,7 +1905,7 @@ def _setattrs(self, name_values_pairs):\n ]\n \n Attribute = _add_hash(\n-    _add_cmp(_add_repr(Attribute, attrs=_a), attrs=_a),\n+    _add_eq(_add_repr(Attribute, attrs=_a), attrs=_a),\n     attrs=[a for a in _a if a.hash],\n )\n \n@@ -1833,7 +1923,8 @@ class _CountingAttr(object):\n         \"counter\",\n         \"_default\",\n         \"repr\",\n-        \"cmp\",\n+        \"eq\",\n+        \"order\",\n         \"hash\",\n         \"init\",\n         \"metadata\",\n@@ -1848,22 +1939,34 @@ class _CountingAttr(object):\n             default=NOTHING,\n             validator=None,\n             repr=True,\n-            cmp=True,\n+            cmp=None,\n             hash=True,\n             init=True,\n             kw_only=False,\n+            eq=True,\n+            order=False,\n+        )\n+        for name in (\n+            \"counter\",\n+            \"_default\",\n+            \"repr\",\n+            \"eq\",\n+            \"order\",\n+            \"hash\",\n+            \"init\",\n         )\n-        for name in (\"counter\", \"_default\", \"repr\", \"cmp\", \"hash\", \"init\")\n     ) + (\n         Attribute(\n             name=\"metadata\",\n             default=None,\n             validator=None,\n             repr=True,\n-            cmp=True,\n+            cmp=None,\n             hash=False,\n             init=True,\n             kw_only=False,\n+            eq=True,\n+            order=False,\n         ),\n     )\n     cls_counter = 0\n@@ -1873,13 +1976,15 @@ def __init__(\n         default,\n         validator,\n         repr,\n-        cmp,\n+        cmp,  # XXX: unused, remove along with cmp\n         hash,\n         init,\n         converter,\n         metadata,\n         type,\n         kw_only,\n+        eq,\n+        order,\n     ):\n         _CountingAttr.cls_counter += 1\n         self.counter = _CountingAttr.cls_counter\n@@ -1890,7 +1995,8 @@ def __init__(\n         else:\n             self._validator = validator\n         self.repr = repr\n-        self.cmp = cmp\n+        self.eq = eq\n+        self.order = order\n         self.hash = hash\n         self.init = init\n         self.converter = converter\n@@ -1930,7 +2036,7 @@ def default(self, meth):\n         return meth\n \n \n-_CountingAttr = _add_cmp(_add_repr(_CountingAttr))\n+_CountingAttr = _add_eq(_add_repr(_CountingAttr))\n \n \n @attrs(slots=True, init=False, hash=True)\n@@ -2011,6 +2117,14 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n     except (AttributeError, ValueError):\n         pass\n \n+    # We do it here for proper warnings with meaningful stacklevel.\n+    cmp = attributes_arguments.pop(\"cmp\", None)\n+    attributes_arguments[\"eq\"], attributes_arguments[\n+        \"order\"\n+    ] = _determine_eq_order(\n+        cmp, attributes_arguments.get(\"eq\"), attributes_arguments.get(\"order\")\n+    )\n+\n     return _attrs(these=cls_dict, **attributes_arguments)(type_)\n \n \n", "test_patch": "diff --git a/tests/strategies.py b/tests/strategies.py\n--- a/tests/strategies.py\n+++ b/tests/strategies.py\n@@ -14,6 +14,9 @@\n from .utils import make_class\n \n \n+optional_bool = st.one_of(st.none(), st.booleans())\n+\n+\n def gen_attr_names():\n     \"\"\"\n     Generate names for attributes, 'a'...'z', then 'aa'...'zz'.\n@@ -131,7 +134,8 @@ def simple_attrs_with_metadata(draw):\n         default=c_attr._default,\n         validator=c_attr._validator,\n         repr=c_attr.repr,\n-        cmp=c_attr.cmp,\n+        eq=c_attr.eq,\n+        order=c_attr.order,\n         hash=c_attr.hash,\n         init=c_attr.init,\n         metadata=metadata,\ndiff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -11,15 +11,17 @@\n import pytest\n import six\n \n-from hypothesis import given\n+from hypothesis import assume, given\n from hypothesis.strategies import booleans\n \n import attr\n \n-from attr._compat import TYPE\n+from attr._compat import PY2, TYPE\n from attr._make import NOTHING, Attribute\n from attr.exceptions import FrozenInstanceError\n \n+from .strategies import optional_bool\n+\n \n @attr.s\n class C1(object):\n@@ -124,7 +126,9 @@ def test_fields(self, cls):\n                 default=foo,\n                 validator=None,\n                 repr=True,\n-                cmp=True,\n+                cmp=None,\n+                eq=True,\n+                order=True,\n                 hash=None,\n                 init=True,\n             ),\n@@ -133,7 +137,9 @@ def test_fields(self, cls):\n                 default=attr.Factory(list),\n                 validator=None,\n                 repr=True,\n-                cmp=True,\n+                cmp=None,\n+                eq=True,\n+                order=True,\n                 hash=None,\n                 init=True,\n             ),\n@@ -181,13 +187,16 @@ def test_programmatic(self, slots, frozen):\n         `attr.make_class` works.\n         \"\"\"\n         PC = attr.make_class(\"PC\", [\"a\", \"b\"], slots=slots, frozen=frozen)\n+\n         assert (\n             Attribute(\n                 name=\"a\",\n                 default=NOTHING,\n                 validator=None,\n                 repr=True,\n-                cmp=True,\n+                cmp=None,\n+                eq=True,\n+                order=True,\n                 hash=None,\n                 init=True,\n             ),\n@@ -196,7 +205,9 @@ def test_programmatic(self, slots, frozen):\n                 default=NOTHING,\n                 validator=None,\n                 repr=True,\n-                cmp=True,\n+                cmp=None,\n+                eq=True,\n+                order=True,\n                 hash=None,\n                 init=True,\n             ),\n@@ -380,7 +391,7 @@ class HashByIDBackwardCompat(object):\n             HashByIDBackwardCompat(1)\n         )\n \n-        @attr.s(hash=False, cmp=False)\n+        @attr.s(hash=False, eq=False)\n         class HashByID(object):\n             x = attr.ib()\n \n@@ -412,10 +423,10 @@ class D(C):\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_hash_false_cmp_false(self, slots):\n         \"\"\"\n-        hash=False and cmp=False make a class hashable by ID.\n+        hash=False and eq=False make a class hashable by ID.\n         \"\"\"\n \n-        @attr.s(hash=False, cmp=False, slots=slots)\n+        @attr.s(hash=False, eq=False, slots=slots)\n         class C(object):\n             pass\n \n@@ -581,3 +592,76 @@ class FooError(Exception):\n             x = attr.ib()\n \n         FooError(1)\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_eq_only(self, slots, frozen):\n+        \"\"\"\n+        Classes with order=False cannot be ordered.\n+\n+        Python 3 throws a TypeError, in Python2 we have to check for the\n+        absence.\n+        \"\"\"\n+\n+        @attr.s(eq=True, order=False, slots=slots, frozen=frozen)\n+        class C(object):\n+            x = attr.ib()\n+\n+        if not PY2:\n+            possible_errors = (\n+                \"unorderable types: C() < C()\",\n+                \"'<' not supported between instances of 'C' and 'C'\",\n+                \"unorderable types: C < C\",  # old PyPy 3\n+            )\n+\n+            with pytest.raises(TypeError) as ei:\n+                C(5) < C(6)\n+\n+            assert ei.value.args[0] in possible_errors\n+        else:\n+            i = C(42)\n+            for m in (\"lt\", \"le\", \"gt\", \"ge\"):\n+                assert None is getattr(i, \"__%s__\" % (m,), None)\n+\n+    @given(cmp=optional_bool, eq=optional_bool, order=optional_bool)\n+    def test_cmp_deprecated_attribute(self, cmp, eq, order):\n+        \"\"\"\n+        Accessing Attribute.cmp raises a deprecation warning but returns True\n+        if cmp is True, or eq and order are *both* effectively True.\n+        \"\"\"\n+        # These cases are invalid and raise a ValueError.\n+        assume(cmp is None or (eq is None and order is None))\n+        assume(not (eq is False and order is True))\n+\n+        if cmp is not None:\n+            rv = cmp\n+        elif eq is True or eq is None:\n+            rv = order is None or order is True\n+        elif cmp is None and eq is None and order is None:\n+            rv = True\n+        elif cmp is None or eq is None:\n+            rv = False\n+        else:\n+            pytest.fail(\n+                \"Unexpected state: cmp=%r eq=%r order=%r\" % (cmp, eq, order)\n+            )\n+\n+        with pytest.deprecated_call() as dc:\n+\n+            @attr.s\n+            class C(object):\n+                x = attr.ib(cmp=cmp, eq=eq, order=order)\n+\n+            assert rv == attr.fields(C).x.cmp\n+\n+        if cmp is not None:\n+            # Remove warning from creating the attribute if cmp is not None.\n+            dc.pop()\n+\n+        w, = dc.list\n+\n+        assert (\n+            \"The usage of `cmp` is deprecated and will be removed on or after \"\n+            \"2021-06-01.  Please use `eq` and `order` instead.\"\n+            == w.message.args[0]\n+        )\ndiff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -29,8 +29,10 @@\n from .utils import simple_attr, simple_class\n \n \n-CmpC = simple_class(cmp=True)\n-CmpCSlots = simple_class(cmp=True, slots=True)\n+EqC = simple_class(eq=True)\n+EqCSlots = simple_class(eq=True, slots=True)\n+OrderC = simple_class(order=True)\n+OrderCSlots = simple_class(order=True, slots=True)\n ReprC = simple_class(repr=True)\n ReprCSlots = simple_class(repr=True, slots=True)\n \n@@ -38,10 +40,10 @@\n # implicitly.  The \"Cached\" versions are the same, except with hash code\n # caching enabled\n HashC = simple_class(hash=True)\n-HashCSlots = simple_class(hash=None, cmp=True, frozen=True, slots=True)\n+HashCSlots = simple_class(hash=None, eq=True, frozen=True, slots=True)\n HashCCached = simple_class(hash=True, cache_hash=True)\n HashCSlotsCached = simple_class(\n-    hash=None, cmp=True, frozen=True, slots=True, cache_hash=True\n+    hash=None, eq=True, frozen=True, slots=True, cache_hash=True\n )\n # the cached hash code is stored slightly differently in this case\n # so it needs to be tested separately\n@@ -77,23 +79,23 @@ class InitC(object):\n InitC = _add_init(InitC, False)\n \n \n-class TestAddCmp(object):\n+class TestEqOrder(object):\n     \"\"\"\n-    Tests for `_add_cmp`.\n+    Tests for eq and order related methods.\n     \"\"\"\n \n     @given(booleans())\n-    def test_cmp(self, slots):\n+    def test_eq_ignore_attrib(self, slots):\n         \"\"\"\n-        If `cmp` is False, ignore that attribute.\n+        If `eq` is False for an attribute, ignore that attribute.\n         \"\"\"\n         C = make_class(\n-            \"C\", {\"a\": attr.ib(cmp=False), \"b\": attr.ib()}, slots=slots\n+            \"C\", {\"a\": attr.ib(eq=False), \"b\": attr.ib()}, slots=slots\n         )\n \n         assert C(1, 2) == C(2, 2)\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [EqC, EqCSlots])\n     def test_equal(self, cls):\n         \"\"\"\n         Equal objects are detected as equal.\n@@ -101,7 +103,7 @@ def test_equal(self, cls):\n         assert cls(1, 2) == cls(1, 2)\n         assert not (cls(1, 2) != cls(1, 2))\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [EqC, EqCSlots])\n     def test_unequal_same_class(self, cls):\n         \"\"\"\n         Unequal objects of correct type are detected as unequal.\n@@ -109,21 +111,21 @@ def test_unequal_same_class(self, cls):\n         assert cls(1, 2) != cls(2, 1)\n         assert not (cls(1, 2) == cls(2, 1))\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [EqC, EqCSlots])\n     def test_unequal_different_class(self, cls):\n         \"\"\"\n         Unequal objects of different type are detected even if their attributes\n         match.\n         \"\"\"\n \n-        class NotCmpC(object):\n+        class NotEqC(object):\n             a = 1\n             b = 2\n \n-        assert cls(1, 2) != NotCmpC()\n-        assert not (cls(1, 2) == NotCmpC())\n+        assert cls(1, 2) != NotEqC()\n+        assert not (cls(1, 2) == NotEqC())\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_lt(self, cls):\n         \"\"\"\n         __lt__ compares objects as tuples of attribute values.\n@@ -135,14 +137,14 @@ def test_lt(self, cls):\n         ]:\n             assert cls(*a) < cls(*b)\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_lt_unordable(self, cls):\n         \"\"\"\n         __lt__ returns NotImplemented if classes differ.\n         \"\"\"\n         assert NotImplemented == (cls(1, 2).__lt__(42))\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_le(self, cls):\n         \"\"\"\n         __le__ compares objects as tuples of attribute values.\n@@ -156,14 +158,14 @@ def test_le(self, cls):\n         ]:\n             assert cls(*a) <= cls(*b)\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_le_unordable(self, cls):\n         \"\"\"\n         __le__ returns NotImplemented if classes differ.\n         \"\"\"\n         assert NotImplemented == (cls(1, 2).__le__(42))\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_gt(self, cls):\n         \"\"\"\n         __gt__ compares objects as tuples of attribute values.\n@@ -175,14 +177,14 @@ def test_gt(self, cls):\n         ]:\n             assert cls(*a) > cls(*b)\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_gt_unordable(self, cls):\n         \"\"\"\n         __gt__ returns NotImplemented if classes differ.\n         \"\"\"\n         assert NotImplemented == (cls(1, 2).__gt__(42))\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_ge(self, cls):\n         \"\"\"\n         __ge__ compares objects as tuples of attribute values.\n@@ -196,7 +198,7 @@ def test_ge(self, cls):\n         ]:\n             assert cls(*a) >= cls(*b)\n \n-    @pytest.mark.parametrize(\"cls\", [CmpC, CmpCSlots])\n+    @pytest.mark.parametrize(\"cls\", [OrderC, OrderCSlots])\n     def test_ge_unordable(self, cls):\n         \"\"\"\n         __ge__ returns NotImplemented if classes differ.\n@@ -347,7 +349,7 @@ def test_enforce_no_cache_hash_without_hash(self):\n         # unhashable case\n         with pytest.raises(TypeError) as e:\n             make_class(\n-                \"C\", {}, hash=None, cmp=True, frozen=False, cache_hash=True\n+                \"C\", {}, hash=None, eq=True, frozen=False, cache_hash=True\n             )\n         assert exc_args == e.value.args\n \n@@ -380,13 +382,13 @@ def test_hash_attribute(self, slots, cache_hash):\n         assert hash(C(1, 2)) == hash(C(2, 2))\n \n     @given(booleans())\n-    def test_hash_attribute_mirrors_cmp(self, cmp):\n+    def test_hash_attribute_mirrors_eq(self, eq):\n         \"\"\"\n-        If `hash` is None, the hash generation mirrors `cmp`.\n+        If `hash` is None, the hash generation mirrors `eq`.\n         \"\"\"\n-        C = make_class(\"C\", {\"a\": attr.ib(cmp=cmp)}, cmp=True, frozen=True)\n+        C = make_class(\"C\", {\"a\": attr.ib(eq=eq)}, eq=True, frozen=True)\n \n-        if cmp:\n+        if eq:\n             assert C(1) != C(2)\n             assert hash(C(1)) != hash(C(2))\n             assert hash(C(1)) == hash(C(1))\n@@ -395,18 +397,18 @@ def test_hash_attribute_mirrors_cmp(self, cmp):\n             assert hash(C(1)) == hash(C(2))\n \n     @given(booleans())\n-    def test_hash_mirrors_cmp(self, cmp):\n+    def test_hash_mirrors_eq(self, eq):\n         \"\"\"\n-        If `hash` is None, the hash generation mirrors `cmp`.\n+        If `hash` is None, the hash generation mirrors `eq`.\n         \"\"\"\n-        C = make_class(\"C\", {\"a\": attr.ib()}, cmp=cmp, frozen=True)\n+        C = make_class(\"C\", {\"a\": attr.ib()}, eq=eq, frozen=True)\n \n         i = C(1)\n \n         assert i == i\n         assert hash(i) == hash(i)\n \n-        if cmp:\n+        if eq:\n             assert C(1) == C(1)\n             assert hash(C(1)) == hash(C(1))\n         else:\n@@ -777,7 +779,7 @@ def test_eq(self):\n         assert 1 != _Nothing()\n \n \n-@attr.s(hash=True, cmp=True)\n+@attr.s(hash=True, order=True)\n class C(object):\n     pass\n \n@@ -786,7 +788,7 @@ class C(object):\n OriginalC = C\n \n \n-@attr.s(hash=True, cmp=True)\n+@attr.s(hash=True, order=True)\n class C(object):\n     pass\n \ndiff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -25,6 +25,21 @@\n SEQUENCE_TYPES = (list, tuple)\n \n \n+@pytest.fixture(scope=\"session\", name=\"C\")\n+def fixture_C():\n+    \"\"\"\n+    Return a simple but fully featured attrs class with an x and a y attribute.\n+    \"\"\"\n+    import attr\n+\n+    @attr.s\n+    class C(object):\n+        x = attr.ib()\n+        y = attr.ib()\n+\n+    return C\n+\n+\n class TestAsDict(object):\n     \"\"\"\n     Tests for `asdict`.\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -14,7 +14,7 @@\n \n import pytest\n \n-from hypothesis import given\n+from hypothesis import assume, given\n from hypothesis.strategies import booleans, integers, lists, sampled_from, text\n \n import attr\n@@ -28,6 +28,7 @@\n     _Attributes,\n     _ClassBuilder,\n     _CountingAttr,\n+    _determine_eq_order,\n     _transform_attrs,\n     and_,\n     fields,\n@@ -44,6 +45,7 @@\n from .strategies import (\n     gen_attr_names,\n     list_of_attrs,\n+    optional_bool,\n     simple_attrs,\n     simple_attrs_with_metadata,\n     simple_attrs_without_metadata,\n@@ -216,8 +218,9 @@ class C(object):\n             \"No mandatory attributes allowed after an attribute with a \"\n             \"default value or factory.  Attribute in question: Attribute\"\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n-            \"cmp=True, hash=None, init=True, metadata=mappingproxy({}), \"\n-            \"type=None, converter=None, kw_only=False)\",\n+            \"eq=True, order=True, hash=None, init=True, \"\n+            \"metadata=mappingproxy({}), type=None, converter=None, \"\n+            \"kw_only=False)\",\n         ) == e.value.args\n \n     def test_kw_only(self):\n@@ -411,21 +414,30 @@ class C(object):\n         \"arg_name, method_name\",\n         [\n             (\"repr\", \"__repr__\"),\n-            (\"cmp\", \"__eq__\"),\n+            (\"eq\", \"__eq__\"),\n+            (\"order\", \"__le__\"),\n             (\"hash\", \"__hash__\"),\n             (\"init\", \"__init__\"),\n         ],\n     )\n     def test_respects_add_arguments(self, arg_name, method_name):\n         \"\"\"\n-        If a certain `add_XXX` is `False`, `__XXX__` is not added to the class.\n+        If a certain `XXX` is `False`, `__XXX__` is not added to the class.\n         \"\"\"\n         # Set the method name to a sentinel and check whether it has been\n         # overwritten afterwards.\n         sentinel = object()\n \n-        am_args = {\"repr\": True, \"cmp\": True, \"hash\": True, \"init\": True}\n+        am_args = {\n+            \"repr\": True,\n+            \"eq\": True,\n+            \"order\": True,\n+            \"hash\": True,\n+            \"init\": True,\n+        }\n         am_args[arg_name] = False\n+        if arg_name == \"eq\":\n+            am_args[\"order\"] = False\n \n         class C(object):\n             x = attr.ib()\n@@ -918,16 +930,17 @@ class TestFields(object):\n     Tests for `fields`.\n     \"\"\"\n \n+    @given(simple_classes())\n     def test_instance(self, C):\n         \"\"\"\n         Raises `TypeError` on non-classes.\n         \"\"\"\n         with pytest.raises(TypeError) as e:\n-            fields(C(1, 2))\n+            fields(C())\n \n         assert \"Passed object must be a class.\" == e.value.args[0]\n \n-    def test_handler_non_attrs_class(self, C):\n+    def test_handler_non_attrs_class(self):\n         \"\"\"\n         Raises `ValueError` if passed a non-``attrs`` instance.\n         \"\"\"\n@@ -959,16 +972,17 @@ class TestFieldsDict(object):\n     Tests for `fields_dict`.\n     \"\"\"\n \n+    @given(simple_classes())\n     def test_instance(self, C):\n         \"\"\"\n         Raises `TypeError` on non-classes.\n         \"\"\"\n         with pytest.raises(TypeError) as e:\n-            fields_dict(C(1, 2))\n+            fields_dict(C())\n \n         assert \"Passed object must be a class.\" == e.value.args[0]\n \n-    def test_handler_non_attrs_class(self, C):\n+    def test_handler_non_attrs_class(self):\n         \"\"\"\n         Raises `ValueError` if passed a non-``attrs`` instance.\n         \"\"\"\n@@ -1341,7 +1355,8 @@ class C(object):\n         )\n \n         cls = (\n-            b.add_cmp()\n+            b.add_eq()\n+            .add_order()\n             .add_hash()\n             .add_init()\n             .add_repr(\"ns\")\n@@ -1427,7 +1442,7 @@ def test_weakref_setstate(self):\n         @attr.s(slots=True)\n         class C(object):\n             __weakref__ = attr.ib(\n-                init=False, hash=False, repr=False, cmp=False\n+                init=False, hash=False, repr=False, eq=False, order=False\n             )\n \n         assert C() == copy.deepcopy(C())\n@@ -1452,9 +1467,9 @@ class C2(C):\n         assert [C2] == C.__subclasses__()\n \n \n-class TestMakeCmp:\n+class TestMakeOrder:\n     \"\"\"\n-    Tests for _make_cmp().\n+    Tests for _make_order().\n     \"\"\"\n \n     def test_subclasses_cannot_be_compared(self):\n@@ -1500,3 +1515,57 @@ class B(A):\n \n             with pytest.raises(TypeError):\n                 a > b\n+\n+\n+class TestDetermineEqOrder(object):\n+    def test_default(self):\n+        \"\"\"\n+        If all are set to None, do the default: True, True\n+        \"\"\"\n+        assert (True, True) == _determine_eq_order(None, None, None)\n+\n+    @pytest.mark.parametrize(\"eq\", [True, False])\n+    def test_order_mirrors_eq_by_default(self, eq):\n+        \"\"\"\n+        If order is None, it mirrors eq.\n+        \"\"\"\n+        assert (eq, eq) == _determine_eq_order(None, eq, None)\n+\n+    def test_order_without_eq(self):\n+        \"\"\"\n+        eq=False, order=True raises a meaningful ValueError.\n+        \"\"\"\n+        with pytest.raises(\n+            ValueError, match=\"`order` can only be True if `eq` is True too.\"\n+        ):\n+            _determine_eq_order(None, False, True)\n+\n+    @given(cmp=booleans(), eq=optional_bool, order=optional_bool)\n+    def test_mix(self, cmp, eq, order):\n+        \"\"\"\n+        If cmp is not None, eq and order must be None and vice versa.\n+        \"\"\"\n+        assume(eq is not None or order is not None)\n+\n+        with pytest.raises(\n+            ValueError, match=\"Don't mix `cmp` with `eq' and `order`.\"\n+        ):\n+            _determine_eq_order(cmp, eq, order)\n+\n+    def test_cmp_deprecated(self):\n+        \"\"\"\n+        Passing a cmp that is not None raises a DeprecationWarning.\n+        \"\"\"\n+        with pytest.deprecated_call() as dc:\n+\n+            @attr.s(cmp=True)\n+            class C(object):\n+                pass\n+\n+        w, = dc.list\n+\n+        assert (\n+            \"The usage of `cmp` is deprecated and will be removed on or after \"\n+            \"2021-06-01.  Please use `eq` and `order` instead.\"\n+            == w.message.args[0]\n+        )\ndiff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -272,7 +272,9 @@ def test_bare_inheritance_from_slots():\n     Inheriting from a bare attrs slotted class works.\n     \"\"\"\n \n-    @attr.s(init=False, cmp=False, hash=False, repr=False, slots=True)\n+    @attr.s(\n+        init=False, eq=False, order=False, hash=False, repr=False, slots=True\n+    )\n     class C1BareSlots(object):\n         x = attr.ib(validator=attr.validators.instance_of(int))\n         y = attr.ib()\n@@ -288,7 +290,7 @@ def classmethod(cls):\n         def staticmethod():\n             return \"staticmethod\"\n \n-    @attr.s(init=False, cmp=False, hash=False, repr=False)\n+    @attr.s(init=False, eq=False, order=False, hash=False, repr=False)\n     class C1Bare(object):\n         x = attr.ib(validator=attr.validators.instance_of(int))\n         y = attr.ib()\n@@ -533,7 +535,9 @@ def tests_weakref_does_not_add_with_weakref_attribute():\n \n     @attr.s(slots=True, weakref_slot=True)\n     class C(object):\n-        __weakref__ = attr.ib(init=False, hash=False, repr=False, cmp=False)\n+        __weakref__ = attr.ib(\n+            init=False, hash=False, repr=False, eq=False, order=False\n+        )\n \n     c = C()\n     w = weakref.ref(c)\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -166,3 +166,10 @@ class WithCustomRepr:\n     b = attr.ib(repr=False)\n     c = attr.ib(repr=lambda value: \"c is for cookie\")\n     d = attr.ib(repr=str)\n+\n+\n+# Check some of our own types\n+@attr.s(eq=True, order=False)\n+class OrderFlags:\n+    a = attr.ib(eq=False, order=False)\n+    b = attr.ib(eq=True, order=True)\ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -9,7 +9,8 @@\n \n \n def simple_class(\n-    cmp=False,\n+    eq=False,\n+    order=False,\n     repr=False,\n     hash=False,\n     str=False,\n@@ -23,7 +24,8 @@ def simple_class(\n     return make_class(\n         \"C\",\n         [\"a\", \"b\"],\n-        cmp=cmp,\n+        eq=eq or order,\n+        order=order,\n         repr=repr,\n         hash=hash,\n         init=True,\n@@ -39,7 +41,7 @@ def simple_attr(\n     default=NOTHING,\n     validator=None,\n     repr=True,\n-    cmp=True,\n+    eq=True,\n     hash=None,\n     init=True,\n     converter=None,\n@@ -53,7 +55,8 @@ def simple_attr(\n         default=default,\n         validator=validator,\n         repr=repr,\n-        cmp=cmp,\n+        cmp=None,\n+        eq=eq,\n         hash=hash,\n         init=init,\n         converter=converter,\n", "problem_statement": "Suggestion: differentiate in cmp between (== , !=) and (>,>=, <, <=).\nThanks for a fantastic library!\r\n\r\nOne thing that surprised me at first was that I could not write an effective `__gt__()`-function for my attr-class. I found the `cmp`-init-parameter later (in the code), but I still wonder if it wouldn't be a good idea if I could have the option of keeping the tuple-based `__eq__` and `__ne__`-implementations, but override size-comparisons (maybe based on a single `__lt__`-function?).\n", "hints_text": "I agree with this suggestion, but for a different reason. I use `cmp=True` for 99% of my classes but only because I want `==` and `!=` to work. Virtually none of these classes I want to be orderable. So there are IMO two good reasons to decouple `__eq__` from ordering.\r\n\r\nNot really sure how to deal with backwards compatibility though. Introduce `eq` and `order` (or `ordering`, `ordered`?) arguments to `attr.s`, keeping `cmp` for a year and letting `cmp` override `eq` and `order` if explicitly specified. I would default `cmp` to true and `order` to false.\r\n\r\nI'm not sure about the use case where you define `__lt__`. This is already covered by https://docs.python.org/3/library/functools.html#functools.total_ordering, so you can just say:\r\n\r\n```\r\n@attr.s(eq=True, order=False)\r\n@total_ordering\r\nclass A:\r\n    a = attr.ib()\r\n\r\n    def __lt__(self, other):\r\n        ...\r\n```\r\n\r\nOr we could actually do this for you if we detect one of the methods.\r\n\r\n@hynek @glyph ?\nThis does seem like a good idea.\r\n\r\nI think backwards compatibility is reasonably easy; introduce just `eq`, no `order`.  I'd say `cmp=True` means full comparison (i.e.: ordering, since you can't have ordering without equality) and `eq=True` implies `cmp=False`; we can switch `cmp`'s default to be `NOTHING` so as to distinguish \"not passed\" from \"explicit `True`\".\n(Since `cmp` implies `eq`, passing both `eq` and `cmp` explicitly, regardless of their values, ought to be an error, I think.)\nI was thinking ideally `cmp` would start defaulting to false, and `eq` to true. This would be a compatibility break, no? In my mind very few classes require ordering. We can be better than namedtuple here :)\nFour things:\r\n\r\n1. I don't care, you'll have to hash it out yourselves. :)\r\n2. We break cmp/hash compat with the next release so this ought to be resolved before 17.1 lands.\r\n3. Do those proposal play well with the current state of cmp at all?\r\n4. We'll I *do* care a bit...are you sure implying a False by passing True to eq is a good, not confusing API? :-/\r\n\r\nAlso you should consult @njsmith; I'm not merging any changes to those parts without his approval. :)\nFTR, dataclasses seem to have a split between eq and cmp.\r\n\r\nI think it would be nice if an attrs-based back port would be possible and I think currently this is the only feature where attrs is not a superset.\r\n\r\n***\r\n\r\nIt also might be another case where my intention to move from bools to Enums makes a lot of sense.\nI'm interested in this, too. Otherwise, how could this be done elegantly: I have a Status class like this:\r\n```\r\n@attr.s(frozen=True, auto_attribs=True)\r\nclass Status:\r\n    weight: int = attr.ib(cmp=True)\r\n    message: str = attr.ib(\r\n        cmp=False,\r\n        converter=lambda value: str() if value is None else value,\r\n    )\r\n    code: str = attr.ib(\r\n        cmp=False,\r\n        converter=lambda value: str() if value is None else value,\r\n    )\r\n\r\n    @classmethod\r\n    def Debug(cls, message=None, code=None):\r\n        return cls(weight=0, message=message, code=code)\r\n\r\n    [...]\r\n\r\n    @classmethod\r\n    def Error(cls, message=None, code=None):\r\n        return cls(weight=6, message=message, code=code)\r\n```\r\nIt can be instantiated like this: `Status.Error(\"This and that is wrong etc.\", code=\"mismatched-something\")`. I want to test for equality of two instances using `weight` and `code`, but order only by `weight`.\nUnrelatedly:\r\n\r\n> `converter=lambda value: str() if value is None else value`\r\n\r\nI think what you want here is `default=\"\"`?\nI wish, the constructors pass in `None` for stuff and I want to never have a `None` object in there so I don't need to care about `AttributeError`s. I could do this in the constructors but didn't feel like copy-pasting the boilerplate :)\nAh\u2026hm\u2026you may get away with using `attr.NOTHING` instead of None in the class methods. :) I don\u2019t know if I should encourage that but it definitely will never stop working.", "created_at": "2019-09-16T12:13:24Z"}
{"repo": "python-attrs/attrs", "pull_number": 568, "instance_id": "python-attrs__attrs-568", "issue_numbers": ["212"], "base_commit": "daf2bc8182a681ed0c85271bafbd24c2ca5ea70b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -128,8 +128,14 @@ def attrib(\n \n     :type validator: ``callable`` or a ``list`` of ``callable``\\\\ s.\n \n-    :param bool repr: Include this attribute in the generated ``__repr__``\n-        method.\n+    :param repr: Include this attribute in the generated ``__repr__``\n+        method. If ``True``, include the attribute; if ``False``, omit it. By\n+        default, the built-in ``repr()`` function is used. To override how the\n+        attribute value is formatted, pass a ``callable`` that takes a single\n+        value and returns a string. Note that the resulting string is used\n+        as-is, i.e. it will be used directly *instead* of calling ``repr()``\n+        (the default).\n+    :type repr: a ``bool`` or a ``callable`` to use a custom function.\n     :param bool cmp: Include this attribute in the generated comparison methods\n         (``__eq__`` et al).\n     :param hash: Include this attribute in the generated ``__hash__``\n@@ -175,6 +181,7 @@ def attrib(\n        ``factory=f`` is syntactic sugar for ``default=attr.Factory(f)``.\n     .. versionadded:: 18.2.0 *kw_only*\n     .. versionchanged:: 19.2.0 *convert* keyword argument removed\n+    .. versionchanged:: 19.2.0 *repr* also accepts a custom callable.\n     \"\"\"\n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n@@ -1210,9 +1217,17 @@ def _add_cmp(cls, attrs=None):\n \n def _make_repr(attrs, ns):\n     \"\"\"\n-    Make a repr method for *attr_names* adding *ns* to the full name.\n+    Make a repr method that includes relevant *attrs*, adding *ns* to the full\n+    name.\n     \"\"\"\n-    attr_names = tuple(a.name for a in attrs if a.repr)\n+\n+    # Figure out which attributes to include, and which function to use to\n+    # format them. The a.repr value can be either bool or a custom callable.\n+    attr_names_with_reprs = tuple(\n+        (a.name, repr if a.repr is True else a.repr)\n+        for a in attrs\n+        if a.repr is not False\n+    )\n \n     def __repr__(self):\n         \"\"\"\n@@ -1244,12 +1259,14 @@ def __repr__(self):\n         try:\n             result = [class_name, \"(\"]\n             first = True\n-            for name in attr_names:\n+            for name, attr_repr in attr_names_with_reprs:\n                 if first:\n                     first = False\n                 else:\n                     result.append(\", \")\n-                result.extend((name, \"=\", repr(getattr(self, name, NOTHING))))\n+                result.extend(\n+                    (name, \"=\", attr_repr(getattr(self, name, NOTHING)))\n+                )\n             return \"\".join(result) + \")\"\n         finally:\n             working_set.remove(id(self))\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -227,6 +227,21 @@ def test_repr_works(self, cls):\n         \"\"\"\n         assert \"C(a=1, b=2)\" == repr(cls(1, 2))\n \n+    def test_custom_repr_works(self):\n+        \"\"\"\n+        repr returns a sensible value for attributes with a custom repr\n+        callable.\n+        \"\"\"\n+\n+        def custom_repr(value):\n+            return \"foo:\" + str(value)\n+\n+        @attr.s\n+        class C(object):\n+            a = attr.ib(repr=custom_repr)\n+\n+        assert \"C(a=foo:1)\" == repr(C(1))\n+\n     def test_infinite_recursion(self):\n         \"\"\"\n         In the presence of a cyclic graph, repr will emit an ellipsis and not\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -151,3 +151,12 @@ class Validated:\n             attr.validators.instance_of(C), attr.validators.instance_of(D)\n         ),\n     )\n+\n+\n+# Custom repr()\n+@attr.s\n+class WithCustomRepr:\n+    a = attr.ib(repr=True)\n+    b = attr.ib(repr=False)\n+    c = attr.ib(repr=lambda value: \"c is for cookie\")\n+    d = attr.ib(repr=str)\n", "problem_statement": "Allow repr (+ str?) to take callables\nIt would be useful to be able to pass in a callable to do `repr`'ing of attributes.\r\n\r\nFor me this happens if I want to present a value in the repr differently than just `repr(foo)`, which is sometimes useful, especially if the \"different way\" is to use e.g. `reprlib.repr` to do auto-truncation of long values.\r\n\r\nBeing able to pass in callables to the `repr` argument seems at first glance like a reasonably easy way to do that.\r\n\r\nE.g.\r\n\r\n`attr.ib(repr=reprlib.repr)`\r\n\r\nand\r\n\r\n`attr.ib(repr=lambda value: repr(value) * 12)`\r\n\r\nYou could preserve backwards compatibility by having True be equivalent to `repr`, and False be a sentinel (which you need anyways).\r\n\r\nI think this could also satisfy #41, if you do the same to `attr.s`, and then provide an `attr.simple_repr`, so you'd do `attr.s(repr=attr.simple_repr)` and get the normal bracket repr instead of the eval one.\n", "hints_text": "See https://github.com/python-attrs/attrs/issues/224#issuecomment-319078193 for a patch to support a callable with `repr`.\nThis is an interesting idea.\r\n\r\nI think our repr support can be improved in any case; we're doing more work in the method that is generally needed, so it can be sped up by eval-ing a tailored function. Part of this work can be changing the `Attribute.repr` type to essentially be `Union[bool, Callable[[], str]` (so, either a boolean or a callable) and applying the callable when `__repr__`-ing.\nAnother use case where this is useful are numbers which you'd like to show in hexadecimal (`modifiers = attr.ib(repr=lambda mod: hex(int(mod)))`, or PyQt (not Python) enum values where you want to get a human-readable value instead of an int.\nAnother use case I have is when you have  a list attribute and you'd like `__repr__` to print out only the list length (for example in cases where it is extremely large).\r\n\r\nWould be happy to know if there is another way to do it.\r\n\nI've created a small extension which provides callable reprs and allows titles to be overridden too (e.g. for the length case cited above): [attrs_flexible_reprs.py](https://gist.github.com/gimbo/19f1fede170090fdf029a4f3f5c7fece)\r\n\r\nInput/feedback welcomed.\n@gimbo I think your flexible repr doesn\u2019t take into account our recursion handler?\r\n\r\n***\r\n\r\nRe earlier comments, I wouldn\u2019t make this issue depend on transforming our repr generator to code generation. It would be nice to have, but not required for fixing this particular issue.\n@hynek I'm sure you're right - it's very simplistic, just the simplest thing I came up with that scratched the itch I had.\r\n\r\nI haven't delved into the code of `attrs` at all - when you say \"recursion handler\" I'm guessing you mean something to handle the case where a class `A` has a field also of type `A`? Certainly my code doesn't handle that gracefully, it seems. Perhaps I'll take a look at what `attrs` does by default and try to upgrade. :-) Thanks!\nGlyph has recently taught our repr to detect loops in definitions so it doesn\u2019t run into max recursion error. You'd have to look at the current code and shoehorn the callable thing into it.", "created_at": "2019-09-05T12:56:14Z"}
{"repo": "python-attrs/attrs", "pull_number": 563, "instance_id": "python-attrs__attrs-563", "issue_numbers": ["543"], "base_commit": "8174b03b962165278dd65508bf0f947c98a1190a", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -912,20 +912,20 @@ def wrap(cls):\n             raise TypeError(\n                 \"Invalid value for hash.  Must be True, False, or None.\"\n             )\n-        elif hash is False or (hash is None and cmp is False):\n+        elif hash is False or (hash is None and cmp is False) or is_exc:\n+            # Don't do anything. Should fall back to __object__'s __hash__\n+            # which is by id.\n             if cache_hash:\n                 raise TypeError(\n                     \"Invalid value for cache_hash.  To use hash caching,\"\n                     \" hashing must be either explicitly or implicitly \"\n                     \"enabled.\"\n                 )\n-        elif (\n-            hash is True\n-            or (hash is None and cmp is True and frozen is True)\n-            and is_exc is False\n-        ):\n+        elif hash is True or (hash is None and cmp is True and frozen is True):\n+            # Build a __hash__ if told so, or if it's safe.\n             builder.add_hash()\n         else:\n+            # Raise TypeError on attempts to hash.\n             if cache_hash:\n                 raise TypeError(\n                     \"Invalid value for cache_hash.  To use hash caching,\"\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -515,9 +515,8 @@ class C(object):\n     @pytest.mark.parametrize(\"frozen\", [True, False])\n     def test_auto_exc(self, slots, frozen):\n         \"\"\"\n-        Classes with auto_exc=True have a Exception-style __str__, are neither\n-        comparable nor hashable, and store the fields additionally in\n-        self.args.\n+        Classes with auto_exc=True have a Exception-style __str__, compare and\n+        hash by id, and store the fields additionally in self.args.\n         \"\"\"\n \n         @attr.s(auto_exc=True, slots=slots, frozen=frozen)\n@@ -545,21 +544,28 @@ class FooError(Exception):\n         assert FooErrorMade(1, \"foo\") != FooErrorMade(1, \"foo\")\n \n         for cls in (FooError, FooErrorMade):\n-            with pytest.raises(cls) as ei:\n+            with pytest.raises(cls) as ei1:\n                 raise cls(1, \"foo\")\n \n-            e = ei.value\n+            with pytest.raises(cls) as ei2:\n+                raise cls(1, \"foo\")\n+\n+            e1 = ei1.value\n+            e2 = ei2.value\n \n-            assert e is e\n-            assert e == e\n-            assert \"(1, 'foo')\" == str(e)\n-            assert (1, \"foo\") == e.args\n+            assert e1 is e1\n+            assert e1 == e1\n+            assert e2 == e2\n+            assert e1 != e2\n+            assert \"(1, 'foo')\" == str(e1) == str(e2)\n+            assert (1, \"foo\") == e1.args == e2.args\n \n-            with pytest.raises(TypeError):\n-                hash(e)\n+            hash(e1) == hash(e1)\n+            hash(e2) == hash(e2)\n \n             if not frozen:\n-                deepcopy(e)\n+                deepcopy(e1)\n+                deepcopy(e2)\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n     @pytest.mark.parametrize(\"frozen\", [True, False])\n", "problem_statement": "auto_exc's hashing behavior and its documentation do not match\nThe [documentation](https://github.com/python-attrs/attrs/blob/25a02bbc7b5309acebda20101125372d42c978db/src/attr/_make.py#L846) for `auto_exc` says:\r\n```\r\n  - the values for *cmp* and *hash* are ignored and the instances compare\r\n          and hash by the instance's ids (N.B. ``attrs`` will *not* remove\r\n          existing implementations of ``__hash__`` or the equality methods. It\r\n          just won't add own ones.),\r\n```\r\n\r\nHowever, the test for `auto_exc` [says](https://github.com/python-attrs/attrs/blob/25a02bbc7b5309acebda20101125372d42c978db/tests/test_dark_magic.py#L519):\r\n```\r\n    Classes with auto_exc=True have a Exception-style __str__, are neither\r\n        comparable nor hashable, and store the fields additionally in\r\n        self.args.\r\n```\r\n\r\nand [tests](https://github.com/python-attrs/attrs/blob/25a02bbc7b5309acebda20101125372d42c978db/tests/test_dark_magic.py#L558):\r\n\r\n```\r\n            with pytest.raises(TypeError):\r\n                hash(e)\r\n```\r\n\r\nThe documentation and the code should be made consistent.  I noticed this because `unittest` complained that the exception type was unhashable when thrown from a test and I see some [references to `logging` expecting hashable exceptions](https://github.com/schematics/schematics/issues/452), so the documented behavior is probably better than the implemented behavior.\n", "hints_text": "Oh god, are there any docs on Exception hashability? This looks bonkers:\r\n\r\n```python\r\nIn [7]: hash(Exception()) == hash(Exception())\r\nOut[7]: True\r\n\r\nIn [8]: hash(Exception(1)) == hash(Exception(1))\r\nOut[8]: True\r\n\r\nIn [9]: hash(Exception(1)) == hash(Exception(2))\r\nOut[9]: True\r\n\r\nIn [10]: hash(TypeError(1)) == hash(TypeError(2))\r\nOut[10]: True\r\n```\n@hynek: This confused me for quite a while, but I think I have tracked it down, helped by some further investigation by @berquist.\r\n\r\nNote you don't get the same error if you first assign the exceptions to variables before doing the comparison.  I think what is going on is:\r\n\r\n1. `Exception` and `TypeError` have hash and equality by `id()`.\r\n2.  The the first exception is created and its hash is taken from its memory location.  Then it is no longer referenced, so it is deleted from memory.  The second exception is created in the same memory location formerly occupied by the first exception and therefore has an identical `id()`.  See https://github.com/satwikkansal/wtfpython#-deep-down-were-all-the-same- .\r\n\r\nFor the life of me I can't find any documentation of the requirements or conventions for `__eq__` and `__hash__` with respect to exceptions.   There is definitely nothing about it in [the obvious](https://docs.python.org/3.7/tutorial/errors.html) [places](https://docs.python.org/3.7/library/exceptions.html) in the Python documentation.  This is unfortunately an extremely difficult thing to Google for, and I can't turn up anything else useful.  Also, what appears to be [the tests for the base exception classes in CPython](https://github.com/python/cpython/blob/8f4ef3b019ce380022018587571b0f970e668de3/Lib/test/test_exceptions.py) have no tests related to either hashing or equality. \r\n\r\nThe actual behavior of the built-in exceptions seems to match what the `attrs` documentation says it will do (hashing and equality by `id()`), so it seems reasonable to switch the implementation to match the documentation.\r\n", "created_at": "2019-08-18T06:46:16Z"}
{"repo": "python-attrs/attrs", "pull_number": 560, "instance_id": "python-attrs__attrs-560", "issue_numbers": ["558"], "base_commit": "ad33d87ca5bf3be54e65ca742997187ec3b8c1ed", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1,10 +1,10 @@\n from __future__ import absolute_import, division, print_function\n \n import copy\n-import hashlib\n import linecache\n import sys\n import threading\n+import uuid\n import warnings\n \n from operator import itemgetter\n@@ -665,7 +665,10 @@ def make_unhashable(self):\n     def add_hash(self):\n         self._cls_dict[\"__hash__\"] = self._add_method_dunders(\n             _make_hash(\n-                self._attrs, frozen=self._frozen, cache_hash=self._cache_hash\n+                self._cls,\n+                self._attrs,\n+                frozen=self._frozen,\n+                cache_hash=self._cache_hash,\n             )\n         )\n \n@@ -674,6 +677,7 @@ def add_hash(self):\n     def add_init(self):\n         self._cls_dict[\"__init__\"] = self._add_method_dunders(\n             _make_init(\n+                self._cls,\n                 self._attrs,\n                 self._has_post_init,\n                 self._frozen,\n@@ -692,7 +696,8 @@ def add_cmp(self):\n         cd[\"__eq__\"], cd[\"__ne__\"], cd[\"__lt__\"], cd[\"__le__\"], cd[\n             \"__gt__\"\n         ], cd[\"__ge__\"] = (\n-            self._add_method_dunders(meth) for meth in _make_cmp(self._attrs)\n+            self._add_method_dunders(meth)\n+            for meth in _make_cmp(self._cls, self._attrs)\n         )\n \n         return self\n@@ -986,7 +991,37 @@ def _attrs_to_tuple(obj, attrs):\n     return tuple(getattr(obj, a.name) for a in attrs)\n \n \n-def _make_hash(attrs, frozen, cache_hash):\n+def _generate_unique_filename(cls, func_name):\n+    \"\"\"\n+    Create a \"filename\" suitable for a function being generated.\n+    \"\"\"\n+    unique_id = uuid.uuid4()\n+    extra = \"\"\n+    count = 1\n+\n+    while True:\n+        unique_filename = \"<attrs generated {0} {1}.{2}{3}>\".format(\n+            func_name,\n+            cls.__module__,\n+            getattr(cls, \"__qualname__\", cls.__name__),\n+            extra,\n+        )\n+        # To handle concurrency we essentially \"reserve\" our spot in\n+        # the linecache with a dummy line.  The caller can then\n+        # set this value correctly.\n+        cache_line = (1, None, (str(unique_id),), unique_filename)\n+        if (\n+            linecache.cache.setdefault(unique_filename, cache_line)\n+            == cache_line\n+        ):\n+            return unique_filename\n+\n+        # Looks like this spot is taken. Try again.\n+        count += 1\n+        extra = \"-{0}\".format(count)\n+\n+\n+def _make_hash(cls, attrs, frozen, cache_hash):\n     attrs = tuple(\n         a\n         for a in attrs\n@@ -995,10 +1030,7 @@ def _make_hash(attrs, frozen, cache_hash):\n \n     tab = \"        \"\n \n-    # We cache the generated hash methods for the same kinds of attributes.\n-    sha1 = hashlib.sha1()\n-    sha1.update(repr(attrs).encode(\"utf-8\"))\n-    unique_filename = \"<attrs generated hash %s>\" % (sha1.hexdigest(),)\n+    unique_filename = _generate_unique_filename(cls, \"hash\")\n     type_hash = hash(unique_filename)\n \n     method_lines = [\"def __hash__(self):\"]\n@@ -1055,7 +1087,7 @@ def _add_hash(cls, attrs):\n     \"\"\"\n     Add a hash method to *cls*.\n     \"\"\"\n-    cls.__hash__ = _make_hash(attrs, frozen=False, cache_hash=False)\n+    cls.__hash__ = _make_hash(cls, attrs, frozen=False, cache_hash=False)\n     return cls\n \n \n@@ -1077,13 +1109,10 @@ def __ne__(self, other):\n )\n \n \n-def _make_cmp(attrs):\n+def _make_cmp(cls, attrs):\n     attrs = [a for a in attrs if a.cmp]\n \n-    # We cache the generated eq methods for the same kinds of attributes.\n-    sha1 = hashlib.sha1()\n-    sha1.update(repr(attrs).encode(\"utf-8\"))\n-    unique_filename = \"<attrs generated eq %s>\" % (sha1.hexdigest(),)\n+    unique_filename = _generate_unique_filename(cls, \"eq\")\n     lines = [\n         \"def __eq__(self, other):\",\n         \"    if other.__class__ is not self.__class__:\",\n@@ -1188,7 +1217,7 @@ def _add_cmp(cls, attrs=None):\n         attrs = cls.__attrs_attrs__\n \n     cls.__eq__, cls.__ne__, cls.__lt__, cls.__le__, cls.__gt__, cls.__ge__ = _make_cmp(  # noqa\n-        attrs\n+        cls, attrs\n     )\n \n     return cls\n@@ -1258,14 +1287,11 @@ def _add_repr(cls, ns=None, attrs=None):\n \n \n def _make_init(\n-    attrs, post_init, frozen, slots, cache_hash, base_attr_map, is_exc\n+    cls, attrs, post_init, frozen, slots, cache_hash, base_attr_map, is_exc\n ):\n     attrs = [a for a in attrs if a.init or a.default is not NOTHING]\n \n-    # We cache the generated init methods for the same kinds of attributes.\n-    sha1 = hashlib.sha1()\n-    sha1.update(repr(attrs).encode(\"utf-8\"))\n-    unique_filename = \"<attrs generated init {0}>\".format(sha1.hexdigest())\n+    unique_filename = _generate_unique_filename(cls, \"init\")\n \n     script, globs, annotations = _attrs_to_init_script(\n         attrs, frozen, slots, post_init, cache_hash, base_attr_map, is_exc\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -58,6 +58,7 @@ def _add_init(cls, frozen):\n     the tests for it are still useful to test the behavior of _make_init.\n     \"\"\"\n     cls.__init__ = _make_init(\n+        cls,\n         cls.__attrs_attrs__,\n         getattr(cls, \"__attrs_post_init__\", False),\n         frozen,\n@@ -759,3 +760,48 @@ def test_eq(self):\n         assert _Nothing() == _Nothing() == NOTHING\n         assert not (_Nothing() != _Nothing())\n         assert 1 != _Nothing()\n+\n+\n+@attr.s(hash=True, cmp=True)\n+class C(object):\n+    pass\n+\n+\n+# Store this class so that we recreate it.\n+OriginalC = C\n+\n+\n+@attr.s(hash=True, cmp=True)\n+class C(object):\n+    pass\n+\n+\n+class TestFilenames(object):\n+    def test_filenames(self):\n+        \"\"\"\n+        The created dunder methods have a \"consistent\" filename.\n+        \"\"\"\n+        assert (\n+            OriginalC.__init__.__code__.co_filename\n+            == \"<attrs generated init tests.test_dunders.C>\"\n+        )\n+        assert (\n+            OriginalC.__eq__.__code__.co_filename\n+            == \"<attrs generated eq tests.test_dunders.C>\"\n+        )\n+        assert (\n+            OriginalC.__hash__.__code__.co_filename\n+            == \"<attrs generated hash tests.test_dunders.C>\"\n+        )\n+        assert (\n+            C.__init__.__code__.co_filename\n+            == \"<attrs generated init tests.test_dunders.C-2>\"\n+        )\n+        assert (\n+            C.__eq__.__code__.co_filename\n+            == \"<attrs generated eq tests.test_dunders.C-2>\"\n+        )\n+        assert (\n+            C.__hash__.__code__.co_filename\n+            == \"<attrs generated hash tests.test_dunders.C-2>\"\n+        )\n", "problem_statement": "init unique_filename is problematic for exception aggregation\nWe had a case where a custom converter was often failing due to an app issue.  The traceback will include a line with a unique ID based on the initial attr values in the class:\r\n\r\n```\r\nFile \"<attrs generated init 81db48c8801f50d1c320ad1b8d1e0028320432b2>\", line 3, in __init__\r\n```\r\n\r\nHaving a unique ID in the traceback in turn causes problems for exception fingerprinting (e.g. by Sentry).  I'm not thrilled about doing custom traceback filtering for such cases, and would like to explore other options.\r\n\r\nI wonder what the full rationale is for ensuring the unique filename, and whether it could be made optional.\r\n\r\nIncluding a hash of the attribute values is essentially like dumping the values of all attributes of a class instance as part of the traceback whenever there is a constructor error regarding a single attribute-- which is less than precise error reporting.\r\n\r\nhttps://github.com/python-attrs/attrs/blob/dc1b5a01e98a9ba49d45ad07ba6ae0ee2d9c1b8e/src/attr/_make.py#L1268\n", "hints_text": "> I wonder what the full rationale is for ensuring the unique filename, and whether it could be made optional.\n\nThe rationale is that we need a unique but fake file name to feed into linecache so you you pdb step through the generated methods.  I\u2019m very much open to change some of this behavior (there\u2019s been a few related issues) but debuggability of generated methods is a non-negotiable property.\nTo clarify, this problem came up when using a lambda for an attrib converter, causing every program session to end up with a different hash.\r\n\r\nWhat exactly is the uniqueness requirement in this case?  The hash should ideally reflect the source code (i.e. static, deterministic) and not beyond.  Would using `cls.__module__` and `cls.__qualname__` be sufficient?\n\n> To clarify, this problem came up when using a lambda for an attrib converter, causing each program to end up with a different hash.\n> \nAre you sure it\u2019s the _same_ class? I can\u2019t check right now but the hash should be over the definition of the method so it _should_ be stable? I would like to make it nicer/human readable, I just didn\u2019t get around to it.\nI see this whenever our server restarts.  And I've been wondering what causes it.  \r\n\r\nSo it's the **same** class but it ends up with a different hash because of the ids of the functions used. Here's a minimal example:\r\n\r\n```\r\nimport attr\r\n\r\ndef to_int(x):\r\n    return int(x)\r\n\r\n@attr.dataclass\r\nclass Foo:\r\n    x: int = attr.ib(converter=to_int)\r\n\r\n    def __attrs_post_init__(self) -> None:\r\n        raise Exception(\"Foo\")\r\n\r\nFoo(6)\r\n```\r\n\r\nOn each run you get a different traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"foo.py\", line 16, in <module>\r\n    Foo(6)\r\n  File \"<attrs generated init ffbad27a615cd941c6e78e9521839574191a5a83>\", line 3, in __init__\r\n  File \"foo.py\", line 12, in __attrs_post_init__\r\n    raise Exception(\"Foo\")\r\nException: Foo\r\n```\r\n\r\nThe hash is generated from the `repr(attrs)` but in this case it changes:\r\n```\r\n[Attribute(name='x', default=NOTHING, validator=None, repr=True, cmp=True, hash=None, init=True, metadata=mappingproxy({}), type=<class 'int'>, converter=<function to_int at 0x1086cf0d0>, kw_only=False)]\r\n```\r\nAnd here's another run:\r\n```\r\n[Attribute(name='x', default=NOTHING, validator=None, repr=True, cmp=True, hash=None, init=True, metadata=mappingproxy({}), type=<class 'int'>, converter=<function to_int at 0x101f2f0d0>, kw_only=False)]\r\n```\r\n\r\n\r\n\r\n\nYeah should be definitely fixed then.\nI notice that in tracebacks the python interpreter will only show the names of functions, not the address.  Presumably Attribute repr needs to filter function values this way.\nSo just for posterity, this is the reason why we can't just use `__module__` and `__qualname__`:\r\n\r\n```python\r\nclass C:\r\n    pass\r\n\r\nD = C\r\n\r\nclass C:\r\n    pass\r\n\r\n\r\nprint(f\"{ D.__module__ }.{ D.__qualname__ }\")\r\nprint(f\"{ C.__module__ }.{ C.__qualname__ }\")\r\n```\r\n\r\nWhat we need is an id that is unequivocal per class, but stable over restarts. Removing the id from the function reprs doesn't help here, because of the same reason: it could be different functions with the same name.\r\n\r\nIdeas?\nWhich problem is worse: nondeterministic tracebacks, or some outlier case where all attrs are identical except for a function param with overloaded name, affecting pdb debugging?\nThat depends on your use-case. FWIW, one of the most common FUD arguments against `attrs` is/was that you can't properly debug generated code.\r\n\r\nI guess we could lower the probability by using qualnames/modules as part of the function repr?\nHere's a proposal:\r\n\r\nGenerate the filename from the qualified name (e.g. `__attrs__generated_{__module__}_{__qualname__}.py`. Check the `linecache` to see if that file exists.  If it does, then modify the filename (append a number e.g. \"`_2`\")  Repeat until you find an unused filename.\r\n\r\nTools like sentry might get confused if you rearrange this code.  But I believe having repeated classes like this might be rare enough that this is good enough.\r\n\r\nIf this sounds like a decent solution I can work on a PR.  \r\n\r\nOh and for the record it appears that sentry uses the following information to determine a \"fingerprint\"  \r\n\r\n>Depending on the information available, the following data can be used for each stack trace frame:\r\n> \r\n> * Module name\r\n> * Normalized filename (with revision hashes, etc. removed)\r\n> * Normalized context line (essentially a cleaned up version of the sourcecode of the affected line, if provided)\r\n\r\nFrom https://docs.sentry.io/data-management/rollups/?platform=python#grouping-by-stacktrace\r\n\nSounds great! I guess we have to take care about threadsafety here?\nI suspect `__qualname__` is sufficient for the common case-- and it's desirable for being the most readable and not subject to change when files are moved around in the project.\r\n\r\nPlease consider the variant where `__qualname__` is the default, and append `{__module__}_{n}` on collision.\nThat would lead to more unpredictable name churn though. I think it's quite common that you have the same classname in different packages/modules. Depending on import order and other randomness, the numbers could change wildly.\r\n\r\nMaking the module part of the file name is coherent with how it's work with non-attrs classes, so I think that's the best way forward overall.\nQuestion: What does this mean in the code:\r\n\r\n    # We cache the generated init methods for the same kinds of attributes.\r\n\r\nI can't find any cache aside from the linecache.  And we don't look up anything in that.\nI think it means the linecache, that it gets re-used for the identical class? I really want to get rid of all that crap, especially so we maybe can put the name of the class into the docstring.", "created_at": "2019-07-30T14:12:44Z"}
{"repo": "python-attrs/attrs", "pull_number": 556, "instance_id": "python-attrs__attrs-556", "issue_numbers": ["523"], "base_commit": "4a1b3a1436c375c72f80866c6ca145ff0e69086f", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -42,6 +42,9 @@\n \n _empty_metadata_singleton = metadata_proxy({})\n \n+# Unique object for unequivocal getattr() defaults.\n+_sentinel = object()\n+\n \n class _Nothing(object):\n     \"\"\"\n@@ -504,7 +507,7 @@ def _patch_original_class(self):\n             for name in self._attr_names:\n                 if (\n                     name not in base_names\n-                    and getattr(cls, name, None) is not None\n+                    and getattr(cls, name, _sentinel) != _sentinel\n                 ):\n                     try:\n                         delattr(cls, name)\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -265,3 +265,20 @@ class C(Base):\n             x: int\n \n         assert 1 == C(1).x\n+\n+    def test_removes_none_too(self):\n+        \"\"\"\n+        Regression test for #523: make sure defaults that are set to None are\n+        removed too.\n+        \"\"\"\n+\n+        @attr.s(auto_attribs=True)\n+        class C:\n+            x: int = 42\n+            y: typing.Any = None\n+\n+        with pytest.raises(AttributeError):\n+            C.x\n+\n+        with pytest.raises(AttributeError):\n+            C.y\n", "problem_statement": "Attrs deletes any non-None class attributes\nCurrently, `attrs` will delete any non-`None` class attributes when `_ClassBuilder._delete_attribs` is `True` (i.e. when attributes are specified via class attributes, not directly via `these` field).\r\nAccording to comment on [_make.py:502](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L502), this is intended to remove `attr.ib` instances from the class.\r\nBut it does not play well with attributes declared using PEP 484 type annotations and `auto_attribs=True` argument to `attr.s`, because any attribute with non-`None` default value specified will be pruned from the class, while attributes with `None` value are retained.\r\nThis leads to unexpected behaviour in many cases, in particular when generating documentation using `Sphinx` `autosummary` extension which relies on class introspection.\r\nI think we should remove only `attr.ib` instances, not any not-None fields. At least in `auto_attribs` mode. Or at least fix the comment.\r\n\r\nAttrs version checked: 19.1.0\r\nCode to reproduce:\r\n```\r\nimport attr\r\nimport typing\r\n\r\n@attr.s(auto_attribs=True)\r\nclass Foo:\r\n    bar: int = 42\r\n    baz: typing.Any = None\r\n\r\nprint([f for f in dir(Foo) if not f.startswith('_')])  # ['baz']\r\nprint(Foo.baz)  # 42\r\nprint(Foo.bar)  # AttributeError\r\n```\n", "hints_text": "Gosh I'm traveling but isn't the problem just that we need to use a proper/unique sentinel value instead of None here?!\nThere is totally a bug here, because None and non-None fields should obviously be treated differently.\r\n\r\nRemoving only `attr.ib`s would work, however the values those fields have are semantically supposed to be default values that get assigned on instantiation, not class variables. It gets even more complicated when we introduce default factories. We'd have to remove them too\u2026but that'd be highly inconsistent?\r\n\r\nSo the fix here is to remove `None` too.", "created_at": "2019-07-21T06:23:16Z"}
{"repo": "python-attrs/attrs", "pull_number": 539, "instance_id": "python-attrs__attrs-539", "issue_numbers": ["538"], "base_commit": "40d5c90ef6cf3a577e81e2b82de548b7ebc3b897", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -164,6 +164,8 @@ def force_x_to_be_a_cell():  # pragma: no cover\n         # Convert this code object to a code object that sets the\n         # function's first _freevar_ (not cellvar) to the argument.\n         args = [co.co_argcount]\n+        if sys.version_info >= (3, 8):\n+            args.append(co.co_posonlyargcount)\n         if not PY2:\n             args.append(co.co_kwonlyargcount)\n         args.extend(\n", "test_patch": "", "problem_statement": "New Python-only closure cell rewriting fails on Python 3.8-dev\nI need someone who understands the code better than I to tell me whether this is our problem or whether we should report this upstream.\r\n\r\nThe problem seems to be the instantiation of `types.CodeType(*args)`  because it throws an:\r\n\r\n```\r\nTypeError('an integer is required (got type bytes)')\r\n```\r\n\r\nThe contents of args is the following:\r\n\r\n```\r\n[1,\r\n 0,\r\n 2,\r\n 1,\r\n 19,\r\n b'|\\x00\\x89\\x00d\\x00S\\x00',\r\n (None,\r\n  <code object force_x_to_be_a_cell at 0x7fe71817fe70, file \"/Users/hynek/Projects/attrs/.tox/py38/lib/python3.8/site-packages/attr/_compat.py\", line 151>,\r\n  'make_set_closure_cell.<locals>.set_first_cellvar_to.<locals>.force_x_to_be_a_cell'),\r\n (),\r\n ('value', 'force_x_to_be_a_cell'),\r\n '/Users/hynek/Projects/attrs/.tox/py38/lib/python3.8/site-packages/attr/_compat.py',\r\n 'set_first_cellvar_to',\r\n 144,\r\n b'\\x00\\x01\\x04\\x01\\x04\\x05',\r\n ('x',),\r\n ()]\r\n```\r\n\r\nI suspect it's either ` b'|\\x00\\x89\\x00d\\x00S\\x00',` or ` b'\\x00\\x01\\x04\\x01\\x04\\x05',` or both. However, it's bytes on 3.7 too.\r\n\r\nHalp @oremanj?\n", "hints_text": "Sorry, I\u2019ve been out of town for a few days. Will try to look into this within the next day or two.\r\n\r\nMy unfounded suspicion is that the signature of CodeType changed in 3.8 to add a positional-only arguments count, and we just need to update our call to the CodeType constructor accordingly.", "created_at": "2019-06-04T05:35:48Z"}
{"repo": "python-attrs/attrs", "pull_number": 505, "instance_id": "python-attrs__attrs-505", "issue_numbers": ["503", "503"], "base_commit": "7b37354aa4c81ba299427972a20c55da848d5bfd", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -843,10 +843,10 @@ def attrs(\n     :param bool cache_hash: Ensure that the object's hash code is computed\n         only once and stored on the object.  If this is set to ``True``,\n         hashing must be either explicitly or implicitly enabled for this\n-        class.  If the hash code is cached, then no attributes of this\n-        class which participate in hash code computation may be mutated\n-        after object creation.\n-\n+        class.  If the hash code is cached, avoid any reassignments of\n+        fields involved in hash code computation or mutations of the objects\n+        those fields point to after object creation.  If such changes occur,\n+        the behavior of the object's hash code is undefined.\n \n     .. versionadded:: 16.0.0 *slots*\n     .. versionadded:: 16.1.0 *frozen*\n", "test_patch": "", "problem_statement": "Requirement for safety of cache_hash is stronger than documented\nThe documentation states:\r\n\r\n> `cache_hash` (`bool`) \u2013 Ensure that the object\u2019s hash code is computed only once and stored on the object. If this is set to True, hashing must be either explicitly or implicitly enabled for this class. If the hash code is cached, then no attributes of this class which participate in hash code computation may be mutated after object creation.\r\n\r\nA reader could read this as meaning that only the local fields of this object should not be assigned to and that using this on any `frozen` class is okay.  We should clarify that the object needs to be \"deeply immutable\" for this to be safe.\nRequirement for safety of cache_hash is stronger than documented\nThe documentation states:\r\n\r\n> `cache_hash` (`bool`) \u2013 Ensure that the object\u2019s hash code is computed only once and stored on the object. If this is set to True, hashing must be either explicitly or implicitly enabled for this class. If the hash code is cached, then no attributes of this class which participate in hash code computation may be mutated after object creation.\r\n\r\nA reader could read this as meaning that only the local fields of this object should not be assigned to and that using this on any `frozen` class is okay.  We should clarify that the object needs to be \"deeply immutable\" for this to be safe.\n", "hints_text": "\n", "created_at": "2019-02-14T16:20:34Z"}
{"repo": "python-attrs/attrs", "pull_number": 500, "instance_id": "python-attrs__attrs-500", "issue_numbers": ["368"], "base_commit": "a35d8fb4c4c057cc6778879f2d01ac7b9ac4b6ad", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -453,6 +453,7 @@ class _ClassBuilder(object):\n         \"_has_post_init\",\n         \"_delete_attribs\",\n         \"_base_attr_map\",\n+        \"_is_exc\",\n     )\n \n     def __init__(\n@@ -465,6 +466,7 @@ def __init__(\n         auto_attribs,\n         kw_only,\n         cache_hash,\n+        is_exc,\n     ):\n         attrs, base_attrs, base_map = _transform_attrs(\n             cls, these, auto_attribs, kw_only\n@@ -482,6 +484,7 @@ def __init__(\n         self._cache_hash = cache_hash\n         self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\n         self._delete_attribs = not bool(these)\n+        self._is_exc = is_exc\n \n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n \n@@ -688,6 +691,7 @@ def add_init(self):\n                 self._slots,\n                 self._cache_hash,\n                 self._base_attr_map,\n+                self._is_exc,\n             )\n         )\n \n@@ -738,6 +742,7 @@ def attrs(\n     auto_attribs=False,\n     kw_only=False,\n     cache_hash=False,\n+    auto_exc=False,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -847,6 +852,19 @@ def attrs(\n         fields involved in hash code computation or mutations of the objects\n         those fields point to after object creation.  If such changes occur,\n         the behavior of the object's hash code is undefined.\n+    :param bool auto_exc: If the class subclasses :class:`BaseException`\n+        (which implicitly includes any subclass of any exception), the\n+        following happens to behave like a well-behaved Python exceptions\n+        class:\n+\n+        - the values for *cmp* and *hash* are ignored and the instances compare\n+          and hash by the instance's ids (N.B. ``attrs`` will *not* remove\n+          existing implementations of ``__hash__`` or the equality methods. It\n+          just won't add own ones.),\n+        - all attributes that are either passed into ``__init__`` or have a\n+          default value are additionally available as a tuple in the ``args``\n+          attribute,\n+        - the value of *str* is ignored leaving ``__str__`` to base classes.\n \n     .. versionadded:: 16.0.0 *slots*\n     .. versionadded:: 16.1.0 *frozen*\n@@ -866,12 +884,16 @@ def attrs(\n        to each other.\n     .. versionadded:: 18.2.0 *kw_only*\n     .. versionadded:: 18.2.0 *cache_hash*\n+    .. versionadded:: 19.1.0 *auto_exc*\n     \"\"\"\n \n     def wrap(cls):\n+\n         if getattr(cls, \"__class__\", None) is None:\n             raise TypeError(\"attrs only works with new-style classes.\")\n \n+        is_exc = auto_exc is True and issubclass(cls, BaseException)\n+\n         builder = _ClassBuilder(\n             cls,\n             these,\n@@ -881,13 +903,14 @@ def wrap(cls):\n             auto_attribs,\n             kw_only,\n             cache_hash,\n+            is_exc,\n         )\n \n         if repr is True:\n             builder.add_repr(repr_ns)\n         if str is True:\n             builder.add_str()\n-        if cmp is True:\n+        if cmp is True and not is_exc:\n             builder.add_cmp()\n \n         if hash is not True and hash is not False and hash is not None:\n@@ -902,7 +925,11 @@ def wrap(cls):\n                     \" hashing must be either explicitly or implicitly \"\n                     \"enabled.\"\n                 )\n-        elif hash is True or (hash is None and cmp is True and frozen is True):\n+        elif (\n+            hash is True\n+            or (hash is None and cmp is True and frozen is True)\n+            and is_exc is False\n+        ):\n             builder.add_hash()\n         else:\n             if cache_hash:\n@@ -1241,7 +1268,9 @@ def _add_repr(cls, ns=None, attrs=None):\n     return cls\n \n \n-def _make_init(attrs, post_init, frozen, slots, cache_hash, base_attr_map):\n+def _make_init(\n+    attrs, post_init, frozen, slots, cache_hash, base_attr_map, is_exc\n+):\n     attrs = [a for a in attrs if a.init or a.default is not NOTHING]\n \n     # We cache the generated init methods for the same kinds of attributes.\n@@ -1250,16 +1279,18 @@ def _make_init(attrs, post_init, frozen, slots, cache_hash, base_attr_map):\n     unique_filename = \"<attrs generated init {0}>\".format(sha1.hexdigest())\n \n     script, globs, annotations = _attrs_to_init_script(\n-        attrs, frozen, slots, post_init, cache_hash, base_attr_map\n+        attrs, frozen, slots, post_init, cache_hash, base_attr_map, is_exc\n     )\n     locs = {}\n     bytecode = compile(script, unique_filename, \"exec\")\n     attr_dict = dict((a.name, a) for a in attrs)\n     globs.update({\"NOTHING\": NOTHING, \"attr_dict\": attr_dict})\n+\n     if frozen is True:\n         # Save the lookup overhead in __init__ if we need to circumvent\n         # immutability.\n         globs[\"_cached_setattr\"] = _obj_setattr\n+\n     eval(bytecode, globs, locs)\n \n     # In order of debuggers like PDB being able to step through the code,\n@@ -1273,6 +1304,7 @@ def _make_init(attrs, post_init, frozen, slots, cache_hash, base_attr_map):\n \n     __init__ = locs[\"__init__\"]\n     __init__.__annotations__ = annotations\n+\n     return __init__\n \n \n@@ -1287,6 +1319,7 @@ def _add_init(cls, frozen):\n         _is_slot_cls(cls),\n         cache_hash=False,\n         base_attr_map={},\n+        is_exc=False,\n     )\n     return cls\n \n@@ -1376,7 +1409,7 @@ def _is_slot_attr(a_name, base_attr_map):\n \n \n def _attrs_to_init_script(\n-    attrs, frozen, slots, post_init, cache_hash, base_attr_map\n+    attrs, frozen, slots, post_init, cache_hash, base_attr_map, is_exc\n ):\n     \"\"\"\n     Return a script of an initializer for *attrs* and a dict of globals.\n@@ -1625,6 +1658,13 @@ def fmt_setter_with_converter(attr_name, value_var):\n             init_hash_cache = \"self.%s = %s\"\n         lines.append(init_hash_cache % (_hash_cache_field, \"None\"))\n \n+    # For exceptions we rely on BaseException.__init__ for proper\n+    # initialization.\n+    if is_exc:\n+        vals = \",\".join(\"self.\" + a.name for a in attrs if a.init)\n+\n+        lines.append(\"BaseException.__init__(self, %s)\" % (vals,))\n+\n     args = \", \".join(args)\n     if kw_only_args:\n         if PY2:\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -6,6 +6,8 @@\n \n import pickle\n \n+from copy import deepcopy\n+\n import pytest\n import six\n \n@@ -508,3 +510,68 @@ class C(object):\n         assert \"property\" == attr.fields(C).property.name\n         assert \"itemgetter\" == attr.fields(C).itemgetter.name\n         assert \"x\" == attr.fields(C).x.name\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_auto_exc(self, slots, frozen):\n+        \"\"\"\n+        Classes with auto_exc=True have a Exception-style __str__, are neither\n+        comparable nor hashable, and store the fields additionally in\n+        self.args.\n+        \"\"\"\n+\n+        @attr.s(auto_exc=True, slots=slots, frozen=frozen)\n+        class FooError(Exception):\n+            x = attr.ib()\n+            y = attr.ib(init=False, default=42)\n+            z = attr.ib(init=False)\n+            a = attr.ib()\n+\n+        FooErrorMade = attr.make_class(\n+            \"FooErrorMade\",\n+            bases=(Exception,),\n+            attrs={\n+                \"x\": attr.ib(),\n+                \"y\": attr.ib(init=False, default=42),\n+                \"z\": attr.ib(init=False),\n+                \"a\": attr.ib(),\n+            },\n+            auto_exc=True,\n+            slots=slots,\n+            frozen=frozen,\n+        )\n+\n+        assert FooError(1, \"foo\") != FooError(1, \"foo\")\n+        assert FooErrorMade(1, \"foo\") != FooErrorMade(1, \"foo\")\n+\n+        for cls in (FooError, FooErrorMade):\n+            with pytest.raises(cls) as ei:\n+                raise cls(1, \"foo\")\n+\n+            e = ei.value\n+\n+            assert e is e\n+            assert e == e\n+            assert \"(1, 'foo')\" == str(e)\n+            assert (1, \"foo\") == e.args\n+\n+            with pytest.raises(TypeError):\n+                hash(e)\n+\n+            if not frozen:\n+                deepcopy(e)\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_auto_exc_one_attrib(self, slots, frozen):\n+        \"\"\"\n+        Having one attribute works with auto_exc=True.\n+\n+        Easy to get wrong with tuple literals.\n+        \"\"\"\n+\n+        @attr.s(auto_exc=True, slots=slots, frozen=frozen)\n+        class FooError(Exception):\n+            x = attr.ib()\n+\n+        FooError(1)\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1425,7 +1425,9 @@ def test_repr(self):\n         class C(object):\n             pass\n \n-        b = _ClassBuilder(C, None, True, True, False, False, False, False)\n+        b = _ClassBuilder(\n+            C, None, True, True, False, False, False, False, False\n+        )\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n \n@@ -1437,7 +1439,9 @@ def test_returns_self(self):\n         class C(object):\n             x = attr.ib()\n \n-        b = _ClassBuilder(C, None, True, True, False, False, False, False)\n+        b = _ClassBuilder(\n+            C, None, True, True, False, False, False, False, False\n+        )\n \n         cls = (\n             b.add_cmp()\n@@ -1500,6 +1504,7 @@ class C(object):\n             frozen=False,\n             weakref_slot=True,\n             auto_attribs=False,\n+            is_exc=False,\n             kw_only=False,\n             cache_hash=False,\n         )\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -80,6 +80,20 @@ class HH(DD, EE):\n c == cc\n \n \n+# Exceptions\n+@attr.s(auto_exc=True)\n+class Error(Exception):\n+    x = attr.ib()\n+\n+\n+try:\n+    raise Error(1)\n+except Error as e:\n+    e.x\n+    e.args\n+    str(e)\n+\n+\n # Converters\n # XXX: Currently converters can only be functions so none of this works\n # although the stubs should be correct.\n", "problem_statement": "Add a convenience flag for upcalling on Exception subclasses\nCurrently, these tests both fail on 2.7 and only the latter fails on 3.6.\r\n\r\n```python\r\n@attr.s\r\nclass E1(Exception):\r\n    x = attr.ib()\r\n    y = attr.ib()\r\n\r\n\r\ndef test_exception_init_called():\r\n    e = E1(1, 2)\r\n    assert e.args == (e.x, e.y) == (1, 2)\r\n\r\n\r\ndef test_exception_init_called_even_with_kw():\r\n    e = E1(y=3, x=4)\r\n    assert e.args == (e.x, e.y) == (4, 3)\r\n```\r\n\r\nIf attrs is overriding `__init__` then this makes sense; `args` is filled in by `__init__` in 2.x and `__new__` in 3.x, but only pulling from the `*args` and never `**kwargs`. I discussed this a bit with @markrwilliams but I'm not sure what the best way to handle an attrs-ified exception would be. Maybe it's okay to consider `args` vestigal.\r\n\r\nMostly I'm raising this on the issue tracker because there are some references to using attrs for exceptions, but only indirectly. It'd be nice to have some documentation on a suggested approach either way.\n", "hints_text": "Is `test_exception_init_called_even_with_kw` a valid test?\r\n\r\nThe `args` attribute on `Exception` is documented as \"The tuple of arguments given to the exception constructor.\"\r\n\r\nAnd `Exception` itself doesn't accept `kwargs`.  So I think the behavior in the case of `kwargs` to init with respect to what goes into the `args` attribute is\u2026 undefined.  So I'd have no expectation of that test passing on exception classes generically.\nI included it because of the usual attrs isomorphism:\r\n\r\n```python\r\nclass E1(Exception):\r\n    def __init__(self, x, y):\r\n        super(E1, self).__init__(x, y)\r\n        self.x = x\r\n        self.y = y\r\n```\r\n\r\nIt might not abide strictly by the documentation of `Exception` that you'd end up with `e.args == (e.x, e.y)` but I wasn't sure if a case could be made since this is how one would write the class without attrs.\nI guess what I'm saying is that it's not clear to me that when one calls the super init, that including the kwargs is a common practice.\r\n\r\nThat said, I find the `args` attribute's design to be severely lacking in clarity, basically a \"tuple of whatever rando stuff the caller threw in here\", so I'm rather sympathetic to the argument that it is vestigal.\r\n\r\nThe only reason to care about it as far as I'm aware is that it effects `str()`, and that's true even when using `attrs`, which leaves something to be desired:\r\n\r\n```console\r\n>>> str(C(1,2))\r\n'C(x=1, y=2)'\r\n>>> str(C(x=1,y=2))\r\n'C(x=1, y=2)'\r\n>>> str(E1(1,2))\r\n'(1, 2)'\r\n>>> str(E1(x=1,y=2))\r\n''\r\n```\r\n\r\nHere `E1` is defined as in your example, and `C` is the same as `E1`, but without inheriting from `Exception`.\r\n\nAfter running into #217 I came up with an `@attrs_exception` decorator that passes both of your tests on Python 2.7 (and probably 3.6):\r\n\r\n```python\r\nimport inspect\r\n\r\nimport attr\r\n\r\n\r\ndef attrs_exception(maybe_cls=None, *args, **kwargs):\r\n    r\"\"\"\r\n    A class decorator to eliminate boilerplate when creating Exceptions using\r\n    :func:`attr.s`.\r\n\r\n    Adds ``__str__`` (because Exceptions don't use ``__repr__``) and an\r\n    ``__attrs_post_init__`` that calls ``Exception.__init__`` with the class's\r\n    :func:`attr.ib`\\ s. Without this, instances cannot be deepcopied on Python 2.\r\n\r\n    ref: https://github.com/python-attrs/attrs/issues/217\r\n\r\n    :param args: additional positional arguments to be passed to :func:`attr.s`\r\n    :param kwargs: additional keyword arguments to be passed to :func:`attr.s`\r\n    \"\"\"\r\n    def wrap(cls):\r\n        def _attrs_post_init__(obj):\r\n            Exception.__init__(obj, *attr.astuple(obj))\r\n\r\n        existing_post_init = getattr(cls, '__attrs_post_init__', None)\r\n        if (\r\n            existing_post_init\r\n            and (\r\n                inspect.getsource(existing_post_init)\r\n                != inspect.getsource(_attrs_post_init__)\r\n            )\r\n        ):\r\n            raise TypeError(\r\n                \"'%s' already has an '__attrs_post_init__' method\" % (cls,),\r\n            )\r\n        if not issubclass(cls, Exception):\r\n            raise TypeError(\r\n                \"'%s' is not a subclass of Exception! Use 'attr.s' instead\" % (cls,),\r\n            )\r\n        cls.__attrs_post_init__ = _attrs_post_init__\r\n\r\n        kwargs['str'] = True\r\n        kwargs['slots'] = True\r\n        return attr.attributes(cls, *args, **kwargs)\r\n\r\n    # maybe_cls depends on the usage of the decorator. It's a class if it's\r\n    # used as @attrs_exception but None if it's used as @attrs_exception()\r\n    if maybe_cls is None:\r\n        return wrap\r\n    else:\r\n        return wrap(maybe_cls)\r\n```\r\n\r\nIf anyone is interested, I can probably put that (and its accompanying tests) on PyPI.\nSo, what we want here is basically:\r\n\r\n1. `@attr.s(str=True)`\r\n2.  All fields *additionally* put into `self.args`?\r\n3. Exceptions usually can\u2019t be compared \u2013 so maybe also `cmp=False`?\r\n\r\nI\u2019d be sympathetic to add something like `@attr.exc` since I use it quite often myself.\nJust hit this myself, blindly assuming Exceptions would work - `@attr.exc` (`@attr.err`?) would be very handy.", "created_at": "2019-02-10T16:13:44Z"}
{"repo": "python-attrs/attrs", "pull_number": 489, "instance_id": "python-attrs__attrs-489", "issue_numbers": ["482"], "base_commit": "1a90857109794f27e4cf5914bb9ae4617993e880", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -529,6 +529,26 @@ def _patch_original_class(self):\n         for name, value in self._cls_dict.items():\n             setattr(cls, name, value)\n \n+        # Attach __setstate__. This is necessary to clear the hash code\n+        # cache on deserialization. See issue\n+        # https://github.com/python-attrs/attrs/issues/482 .\n+        # Note that this code only handles setstate for dict classes.\n+        # For slotted classes, see similar code in _create_slots_class .\n+        if self._cache_hash:\n+            existing_set_state_method = getattr(cls, \"__setstate__\", None)\n+            if existing_set_state_method:\n+                raise NotImplementedError(\n+                    \"Currently you cannot use hash caching if \"\n+                    \"you specify your own __setstate__ method.\"\n+                    \"See https://github.com/python-attrs/attrs/issues/494 .\"\n+                )\n+\n+            def cache_hash_set_state(chss_self, _):\n+                # clear hash code cache\n+                setattr(chss_self, _hash_cache_field, None)\n+\n+            setattr(cls, \"__setstate__\", cache_hash_set_state)\n+\n         return cls\n \n     def _create_slots_class(self):\n@@ -581,6 +601,8 @@ def slots_getstate(self):\n             \"\"\"\n             return tuple(getattr(self, name) for name in state_attr_names)\n \n+        hash_caching_enabled = self._cache_hash\n+\n         def slots_setstate(self, state):\n             \"\"\"\n             Automatically created by attrs.\n@@ -588,6 +610,13 @@ def slots_setstate(self, state):\n             __bound_setattr = _obj_setattr.__get__(self, Attribute)\n             for name, value in zip(state_attr_names, state):\n                 __bound_setattr(name, value)\n+            # Clearing the hash code cache on deserialization is needed\n+            # because hash codes can change from run to run. See issue\n+            # https://github.com/python-attrs/attrs/issues/482 .\n+            # Note that this code only handles setstate for slotted classes.\n+            # For dict classes, see similar code in _patch_original_class .\n+            if hash_caching_enabled:\n+                __bound_setattr(_hash_cache_field, None)\n \n         # slots and frozen require __getstate__/__setstate__ to work\n         cd[\"__getstate__\"] = slots_getstate\n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -5,6 +5,7 @@\n from __future__ import absolute_import, division, print_function\n \n import copy\n+import pickle\n \n import pytest\n \n@@ -453,6 +454,83 @@ def __hash__(self):\n         assert 2 == uncached_instance.hash_counter.times_hash_called\n         assert 1 == cached_instance.hash_counter.times_hash_called\n \n+    def test_cache_hash_serialization(self):\n+        \"\"\"\n+        Tests that the hash cache is cleared on deserialization to fix\n+        https://github.com/python-attrs/attrs/issues/482 .\n+        \"\"\"\n+\n+        # First, check that our fix didn't break serialization without\n+        # hash caching.\n+        # We don't care about the result of this; we just want to make sure we\n+        # can do it without exceptions.\n+        hash(pickle.loads(pickle.dumps(HashCacheSerializationTestUncached)))\n+\n+        def assert_hash_code_not_cached_across_serialization(original):\n+            # Now check our fix for #482 for when hash caching is enabled.\n+            original_hash = hash(original)\n+            round_tripped = pickle.loads(pickle.dumps(original))\n+            # What we want to guard against is having a stale hash code\n+            # when a field's hash code differs in a new interpreter after\n+            # deserialization.  This is tricky to test because we are,\n+            # of course, still running in the same interpreter.  So\n+            # after deserialization we reach in and change the value of\n+            # a field to simulate the field changing its hash code. We then\n+            # check that the object's hash code changes, indicating that we\n+            # don't have a stale hash code.\n+            # This could fail in two ways: (1) pickle.loads could get the hash\n+            # code of the deserialized value (triggering it to cache) before\n+            # we alter the field value.  This doesn't happen in our tested\n+            # Python versions.  (2) \"foo\" and \"something different\" could\n+            # have a hash collision on this interpreter run.   But this is\n+            # extremely improbable and would just result in one buggy test run.\n+            round_tripped.foo_string = \"something different\"\n+            assert original_hash != hash(round_tripped)\n+\n+        # Slots and non-slots classes implement __setstate__ differently,\n+        # so we need to test both cases.\n+        assert_hash_code_not_cached_across_serialization(\n+            HashCacheSerializationTestCached()\n+        )\n+        assert_hash_code_not_cached_across_serialization(\n+            HashCacheSerializationTestCachedSlots()\n+        )\n+\n+        # Test that a custom __setstate__ is disallowed on a\n+        # cache_hash=True object.\n+        # This is needed because we handle clearing the cache after\n+        # deserialization with a custom __setstate__. It is possible\n+        # to make both work, but it requires some thought about how to go\n+        # about it, so it has not yet been implemented.\n+        with pytest.raises(\n+            NotImplementedError,\n+            message=\"Currently you cannot use hash caching if you \"\n+            \"specify your own __setstate__ method.  This is tracked\"\n+            \"by https://github.com/python-attrs/attrs/issues/494\",\n+        ):\n+\n+            @attr.attrs(hash=True, cache_hash=True)\n+            class NoCacheHashAndCustomSetState(object):\n+                def __setstate__(self, state):\n+                    pass\n+\n+\n+# these are for use in TestAddHash.test_cache_hash_serialization\n+# they need to be out here so they can be un-pickled\n+@attr.attrs(hash=True, cache_hash=False)\n+class HashCacheSerializationTestUncached(object):\n+    foo_string = attr.ib(default=\"foo\")\n+\n+\n+@attr.attrs(hash=True, cache_hash=True)\n+class HashCacheSerializationTestCached(object):\n+    foo_string = attr.ib(default=\"foo\")\n+\n+\n+@attr.attrs(slots=True, hash=True, cache_hash=True)\n+class HashCacheSerializationTestCachedSlots(object):\n+    foo_string = attr.ib(default=\"foo\")\n+\n \n class TestAddInit(object):\n     \"\"\"\n", "problem_statement": "cache_hash can give the wrong hash code for deserialized objects\nI just realized a bug in the code I wrote for hash code caching (#426).  Because the hash code cache field gets serialized and deserialized by Pickle, when you deserialize a `cache_hash=True` `attrs` object, the hashcode will be the hashcode the object had at serialization-time. However, if your object has fields with hash codes which are not deterministic between interpreter runs, then on a new interpreter run your deserialized object will have a hash code which differs from a newly created identical object.\r\n\r\nWe can fix this for `pickle` by recomputing the hash code in `__setstate__`.  Other serialization libraries which don't respect `__setstate__` will still have a problem, but I don't think we can do anything about that.  If the `__setstate__` solution sounds acceptable I will implement it next week.\n", "hints_text": "", "created_at": "2019-01-22T20:01:01Z"}
{"repo": "python-attrs/attrs", "pull_number": 459, "instance_id": "python-attrs__attrs-459", "issue_numbers": ["450"], "base_commit": "7bfd0e4061daee413a0cd1a3c78f1f3a98e0f32b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -409,12 +409,11 @@ def _transform_attrs(cls, these, auto_attribs, kw_only):\n             a.kw_only is False\n         ):\n             had_default = True\n-        if was_kw_only is True and a.kw_only is False:\n+        if was_kw_only is True and a.kw_only is False and a.init is True:\n             raise ValueError(\n                 \"Non keyword-only attributes are not allowed after a \"\n-                \"keyword-only attribute.  Attribute in question: {a!r}\".format(\n-                    a=a\n-                )\n+                \"keyword-only attribute (unless they are init=False).  \"\n+                \"Attribute in question: {a!r}\".format(a=a)\n             )\n         if was_kw_only is False and a.init is True and a.kw_only is True:\n             was_kw_only = True\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -705,7 +705,8 @@ class C(object):\n \n         assert (\n             \"Non keyword-only attributes are not allowed after a \"\n-            \"keyword-only attribute.  Attribute in question: Attribute\"\n+            \"keyword-only attribute (unless they are init=False).  \"\n+            \"Attribute in question: Attribute\"\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n             \"cmp=True, hash=None, init=True, metadata=mappingproxy({}), \"\n             \"type=None, converter=None, kw_only=False)\",\n@@ -771,6 +772,62 @@ class C(Base):\n         assert c.x == 0\n         assert c.y == 1\n \n+    def test_init_false_attribute_after_keyword_attribute(self):\n+        \"\"\"\n+        A positional attribute cannot follow a `kw_only` attribute,\n+        but an `init=False` attribute can because it won't appear\n+        in `__init__`\n+        \"\"\"\n+\n+        @attr.s\n+        class KwArgBeforeInitFalse:\n+            kwarg = attr.ib(kw_only=True)\n+            non_init_function_default = attr.ib(init=False)\n+            non_init_keyword_default = attr.ib(\n+                init=False, default=\"default-by-keyword\"\n+            )\n+\n+            @non_init_function_default.default\n+            def _init_to_init(self):\n+                return self.kwarg + \"b\"\n+\n+        c = KwArgBeforeInitFalse(kwarg=\"a\")\n+\n+        assert c.kwarg == \"a\"\n+        assert c.non_init_function_default == \"ab\"\n+        assert c.non_init_keyword_default == \"default-by-keyword\"\n+\n+    def test_init_false_attribute_after_keyword_attribute_with_inheritance(\n+        self\n+    ):\n+        \"\"\"\n+        A positional attribute cannot follow a `kw_only` attribute,\n+        but an `init=False` attribute can because it won't appear\n+        in `__init__`. This test checks that we allow this\n+        even when the `kw_only` attribute appears in a parent class\n+        \"\"\"\n+\n+        @attr.s\n+        class KwArgBeforeInitFalseParent:\n+            kwarg = attr.ib(kw_only=True)\n+\n+        @attr.s\n+        class KwArgBeforeInitFalseChild(KwArgBeforeInitFalseParent):\n+            non_init_function_default = attr.ib(init=False)\n+            non_init_keyword_default = attr.ib(\n+                init=False, default=\"default-by-keyword\"\n+            )\n+\n+            @non_init_function_default.default\n+            def _init_to_init(self):\n+                return self.kwarg + \"b\"\n+\n+        c = KwArgBeforeInitFalseChild(kwarg=\"a\")\n+\n+        assert c.kwarg == \"a\"\n+        assert c.non_init_function_default == \"ab\"\n+        assert c.non_init_keyword_default == \"default-by-keyword\"\n+\n \n @pytest.mark.skipif(not PY2, reason=\"PY2-specific keyword-only error behavior\")\n class TestKeywordOnlyAttributesOnPy2(object):\n", "problem_statement": "init=False attributes which depend on keyword-only attributes are impossible\nThe initialization of an `init=False` attribute cannot (straightforwardly) depend on a `kw_only=True` attribute because there is no legal ordering of these two attributes.\r\n\r\n```python\r\nfrom attr import attrs, attrib\r\n\r\n\r\n@attrs\r\nclass BrokenInitFirst:\r\n    _to_init: str  = attrib(init=False)\r\n    kwarg: str = attrib(kw_only=True)\r\n\r\n    @_to_init.default\r\n    def _init_to_init(self) -> str:\r\n        return self.kwarg + \"foo\"\r\n\r\n\r\nBrokenInitFirst(kwarg=\"meep\")\r\n```\r\n\r\nproduces:\r\n\r\n```python\r\nAttributeError: 'BrokenInitFirst' object has no attribute 'kwarg'\r\n```\r\n\r\nwhile\r\n\r\n```python\r\nfrom attr import attrs, attrib\r\n\r\n\r\n@attrs\r\nclass BrokenKwArgFirst:\r\n    kwarg: str = attrib(kw_only=True)\r\n    _to_init: str = attrib(init=False)\r\n\r\n    @_to_init.default\r\n    def _init_to_init(self) -> str:\r\n        return self.kwarg + \"foo\"\r\n\r\n\r\nBrokenKwArgFirst(kwarg=\"meep\")\r\n```\r\n\r\nproduces\r\n\r\n```\r\n  File \"/Users/gabbard/anaconda3/envs/cwc-event/lib/python3.6/site-packages/attr/_make.py\", line 904, in attrs\r\n    return wrap(maybe_cls)\r\n  File \"/Users/gabbard/anaconda3/envs/cwc-event/lib/python3.6/site-packages/attr/_make.py\", line 855, in wrap\r\n    cache_hash,\r\n  File \"/Users/gabbard/anaconda3/envs/cwc-event/lib/python3.6/site-packages/attr/_make.py\", line 471, in __init__\r\n    cls, these, auto_attribs, kw_only\r\n  File \"/Users/gabbard/anaconda3/envs/cwc-event/lib/python3.6/site-packages/attr/_make.py\", line 416, in _transform_attrs\r\n    a=a\r\nValueError: Non keyword-only attributes are not allowed after a keyword-only attribute.  Attribute in question: Attribute(name='_to_init', default=Factory(factory=<function BrokenKwArgFirst._init_to_init at 0x10830df28>, takes_self=True), validator=None, repr=True, cmp=True, hash=None, init=False, metadata=mappingproxy({}), type=<class 'str'>, converter=None, kw_only=False)\r\n```\r\n\r\nThese examples can also be found in https://github.com/rgabbard/attrs-kwonly-init-bug\r\n\r\nThis is related to https://github.com/python-attrs/attrs/issues/448 . Assuming there is some sort of internal ordering of attributes which also controls their initialization order, I think the solution here is to sort `kw_only=True` attributes after `kw_only=False`, and `init=False` last of all.\n", "hints_text": "At a quick glance it looks like performing the sort mentioned above (first `kw_only=False, init=True`, then `kw_only=True, init=True`, last `init=False`) around https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L378 should do the trick for both this and #448 .   @hynek , if this seems like the right strategy to you, I can make a PR with it.\n@hynek : bumping the question above, since I just ran into this problem again today.  If you can confirm you are happy with the proposed approach to a fix, I am happy to submit a PR with it.\nI\u2019m sorry you hit me in the middle of my vacation and I'm having a hard time to catch up with the more complex issues.\r\n\r\nAnd yes I agree that:\r\n\r\n1. `init=False attributes` should never cause a `Non keyword-only attributes\u2026` error\r\n1.  it\u2019s kinda weird that we don\u2019t allow kw_only attributes anywhere. someone should research why we chose that route. they are a lot more useful if you can sprinkle them anywhere.\r\n\r\nSo feel free to submit a PR if you manage to achieve that without breaking backward compatibility. Even in subclassing scenarios. I tend to think that it might be better to make the condition slightly more complicated instead of re-ordering them because that might have other unforeseen side effects.\n@hynek : After more thought I think you are correct that using a more complex condition is better.  I will poke at this as I have free time. :-)\n@hynek: I don't think you commented on the `BrokenInitFirst` case.  As with #448, it would introduce a (simpler) difference between the order of attributes at the order of arguments to `__init__`.  But the arguments for allowing them anywhere would be similar, no?\nI went through the [initial](https://github.com/python-attrs/attrs/pull/281) and [final](https://github.com/python-attrs/attrs/pull/411/files) PRs as well as the three related issues (#38 , #106 , #335 ).  It looks not allowing `kw_only` attributes anywhere was not a decision that was made very explicitly. The closest thing I see to a discussion of this is @hynek 's comment [here](https://github.com/python-attrs/attrs/pull/281#issuecomment-383271154) that \"I think it\u2019s fair to expect that a non-kw_only attribute must not come after a kw_only attribute\" and @Tinche 's [comment](https://github.com/python-attrs/attrs/issues/106#issuecomment-262722028):\r\n\r\n> Currently the definition order of attributes is the same as the order of the attributes in the generated `__init__`. This is strictly by @hynek's executive order and I personally agree with the rationale. If it wasn't intentional we would just sort the attributes and you wouldn't need to put arguments with defaults last. The order of definition is used in other places too: the `__repr__`, comparison methods, `attr.fields`.\r\n\r\nand subsequent discussion.\r\n\r\nI *think* the way forward is:\r\n* to maintain the current order of arguments (that is, declaration order) for purposes of `repr`, field initialization, etc.\r\n* to alter the condition to not thrown an exception if an `init=False` attribute follows a `kw_only` attribute\r\n* to float `kw_only` attributes to the end of the argument list when generating `__init__`\nI think that makes sense.  It doesn't address `BrokenInitFirst`, though, right?\n@wsanchez : I am a little uncertain whether `BrokenInitFirst` needs to be fixed, since the general rule seems to be that an `init=False` attribute with a default needs to come later in the attribute ordering than any fields it depends on (me calling it `Broken` was misleading - I was just trying to illustrate that no legal attribute ordering for this case existed; as long as we fix one of the two options then the particular problem I had in mind is solved). \r\n\nWhoops sorry, I glossed over the dependency there, but mostly wanted to be clear that this case wasn\u2019t addressed. I agree it shouldn\u2019t be. ", "created_at": "2018-10-31T23:56:58Z"}
{"repo": "python-attrs/attrs", "pull_number": 431, "instance_id": "python-attrs__attrs-431", "issue_numbers": ["427"], "base_commit": "7fe111cbe288603c730d777cb4f28dff4b8b921a", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -522,7 +522,13 @@ def _patch_original_class(self):\n                     name not in super_names\n                     and getattr(cls, name, None) is not None\n                 ):\n-                    delattr(cls, name)\n+                    try:\n+                        delattr(cls, name)\n+                    except AttributeError:\n+                        # This can happen if a superclass defines a class\n+                        # variable and we want to set an attribute with the\n+                        # same name by using only a type annotation.\n+                        pass\n \n         # Attach our dunder methods.\n         for name, value in self._cls_dict.items():\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -165,7 +165,7 @@ class C:\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_auto_attribs_subclassing(self, slots):\n         \"\"\"\n-        Attributes from super classes are inherited, it doesn't matter if the\n+        Attributes from superclasses are inherited, it doesn't matter if the\n         subclass has annotations or not.\n \n         Ref #291\n@@ -250,3 +250,18 @@ class C:\n \n         assert c.x == 0\n         assert c.y == 1\n+\n+    def test_super_class_variable(self):\n+        \"\"\"\n+        Superclass class variables can be overridden with an attribute\n+        without resorting to using an explicit `attr.ib()`.\n+        \"\"\"\n+\n+        class Base:\n+            x: int = 42\n+\n+        @attr.s(auto_attribs=True)\n+        class C(Base):\n+            x: int\n+\n+        assert 1 == C(1).x\ndiff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -421,7 +421,7 @@ class C(object):\n \n     def test_overwrite_super(self):\n         \"\"\"\n-        Super classes can overwrite each other and the attributes are added\n+        Superclasses can overwrite each other and the attributes are added\n         in the order they are defined.\n         \"\"\"\n \ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -323,7 +323,7 @@ class C(B):\n \n     def test_these(self):\n         \"\"\"\n-        If these is passed, use it and ignore body and super classes.\n+        If these is passed, use it and ignore body and superclasses.\n         \"\"\"\n \n         class Base(object):\n", "problem_statement": "attr.ib cleanup + auto_attribs + class vars from superclasses\nConsider the following:\r\n\r\n```python\r\nimport attr\r\n\r\nclass Base:\r\n    x = 0\r\n\r\n@attr.s(auto_attribs=True)\r\nclass C(Base):\r\n    x: int\r\n```\r\n\r\nThis raises an:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"t.py\", line 9, in <module>\r\n    class C(Base):\r\n  File \"/Users/hynek/Projects/attrs/src/attr/_make.py\", line 858, in wrap\r\n    return builder.build_class()\r\n  File \"/Users/hynek/Projects/attrs/src/attr/_make.py\", line 496, in build_class\r\n    return self._patch_original_class()\r\n  File \"/Users/hynek/Projects/attrs/src/attr/_make.py\", line 514, in _patch_original_class\r\n    delattr(cls, name)\r\nAttributeError: x\r\n```\r\n\r\n(interestingly `getattr(cls, name)` works but `delattr` does not)\r\n\r\nThis is actually quite common if you implement an ABC. The current code is:\r\n\r\n```python\r\n                if (\r\n                    name not in super_names\r\n                    and getattr(cls, name, None) is not None\r\n                ):\r\n                    delattr(cls, name)\r\n```\r\n\r\nMaybe we should change the check to `isinstance(getattr(cls, name, None), _CountingAttr)`?\n", "hints_text": "(Maybe wrapping in try/except would be better.)", "created_at": "2018-08-21T05:21:27Z"}
{"repo": "python-attrs/attrs", "pull_number": 430, "instance_id": "python-attrs__attrs-430", "issue_numbers": ["429"], "base_commit": "6a07b035b77ea8756408d65a36160f8670c66933", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -31,7 +31,9 @@\n _obj_setattr = object.__setattr__\n _init_converter_pat = \"__attr_converter_{}\"\n _init_factory_pat = \"__attr_factory_{}\"\n-_tuple_property_pat = \"    {attr_name} = property(itemgetter({index}))\"\n+_tuple_property_pat = (\n+    \"    {attr_name} = _attrs_property(_attrs_itemgetter({index}))\"\n+)\n _classvar_prefixes = (\"typing.ClassVar\", \"t.ClassVar\", \"ClassVar\")\n # we don't use a double-underscore prefix because that triggers\n # name mangling when trying to create a slot for the field\n@@ -243,8 +245,9 @@ class MyClassAttributes(tuple):\n             )\n     else:\n         attr_class_template.append(\"    pass\")\n-    globs = {\"itemgetter\": itemgetter}\n+    globs = {\"_attrs_itemgetter\": itemgetter, \"_attrs_property\": property}\n     eval(compile(\"\\n\".join(attr_class_template), \"\", \"exec\"), globs)\n+\n     return globs[attr_class_name]\n \n \n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -482,3 +482,18 @@ class Sub(Base):\n \n             with pytest.raises(FrozenInstanceError):\n                 i.b = \"3\"\n+\n+    def test_tuple_class_aliasing(self):\n+        \"\"\"\n+        itemgetter and property are legal attribute names.\n+        \"\"\"\n+\n+        @attr.s\n+        class C(object):\n+            property = attr.ib()\n+            itemgetter = attr.ib()\n+            x = attr.ib()\n+\n+        assert \"property\" == attr.fields(C).property.name\n+        assert \"itemgetter\" == attr.fields(C).itemgetter.name\n+        assert \"x\" == attr.fields(C).x.name\n", "problem_statement": "Exception when using auto_attribs and a attribute named property\nGiven a class like:\r\n\r\n```python\r\n@attr.s(auto_attribs=True)\r\nclass Foo:\r\n\r\n    property: str\r\n    other: str\r\n```\r\n\r\nAttrs is raising an exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"f.py\", line 13, in <module>\r\n    @attr.s(auto_attribs=True)\r\n  File \"/usr/local/lib/python3.6/site-packages/attr/_make.py\", line 729, in wrap\r\n    builder = _ClassBuilder(cls, these, slots, frozen, auto_attribs)\r\n  File \"/usr/local/lib/python3.6/site-packages/attr/_make.py\", line 409, in __init__\r\n    cls, these, auto_attribs\r\n  File \"/usr/local/lib/python3.6/site-packages/attr/_make.py\", line 354, in _transform_attrs\r\n    AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)\r\n  File \"/usr/local/lib/python3.6/site-packages/attr/_make.py\", line 220, in _make_attr_tuple_class\r\n    eval(compile(\"\\n\".join(attr_class_template), \"\", \"exec\"), globs)\r\n  File \"\", line 1, in <module>\r\n  File \"\", line 4, in BreaksAttributes\r\nTypeError: 'property' object is not callable\r\n```\r\n\r\nWhat's odd here, is that it works fine as long as property is the *last* item in the class, e.g.:\r\n\r\n```python\r\n@attr.s(auto_attribs=True)\r\nclass Foo:\r\n\r\n    other: str\r\n    property: str\r\n```\r\n\r\nthis works fine and doesn't raise an error.\n", "hints_text": "Upon further investigation, this doesn't appear to have anything to do with the ``auto_attribs=True``, as it also fails without that, using ``attr.ib()``.", "created_at": "2018-08-21T04:15:15Z"}
{"repo": "python-attrs/attrs", "pull_number": 414, "instance_id": "python-attrs__attrs-414", "issue_numbers": ["400"], "base_commit": "03b265d390e3fc1a713ca0ee36314047b8c2b1fc", "patch": "diff --git a/src/attr/converters.py b/src/attr/converters.py\n--- a/src/attr/converters.py\n+++ b/src/attr/converters.py\n@@ -4,6 +4,8 @@\n \n from __future__ import absolute_import, division, print_function\n \n+from ._make import NOTHING, Factory\n+\n \n def optional(converter):\n     \"\"\"\n@@ -13,7 +15,7 @@ def optional(converter):\n     :param callable converter: the converter that is used for non-``None``\n         values.\n \n-    ..  versionadded:: 17.1.0\n+    .. versionadded:: 17.1.0\n     \"\"\"\n \n     def optional_converter(val):\n@@ -22,3 +24,55 @@ def optional_converter(val):\n         return converter(val)\n \n     return optional_converter\n+\n+\n+def default_if_none(default=NOTHING, factory=None):\n+    \"\"\"\n+    A converter that allows to replace ``None`` values by *default* or the\n+    result of *factory*.\n+\n+    :param default: Value to be used if ``None`` is passed. Passing an instance\n+       of :class:`attr.Factory` is supported, however the ``takes_self`` option\n+       is *not*.\n+    :param callable factory: A callable that takes not parameters whose result\n+       is used if ``None`` is passed.\n+\n+    :raises TypeError: If **neither** *default* or *factory* is passed.\n+    :raises TypeError: If **both** *default* and *factory* are passed.\n+    :raises ValueError: If an instance of :class:`attr.Factory` is passed with\n+       ``takes_self=True``.\n+\n+    .. versionadded:: 18.2.0\n+    \"\"\"\n+    if default is NOTHING and factory is None:\n+        raise TypeError(\"Must pass either `default` or `factory`.\")\n+\n+    if default is not NOTHING and factory is not None:\n+        raise TypeError(\n+            \"Must pass either `default` or `factory` but not both.\"\n+        )\n+\n+    if factory is not None:\n+        default = Factory(factory)\n+\n+    if isinstance(default, Factory):\n+        if default.takes_self:\n+            raise ValueError(\n+                \"`takes_self` is not supported by default_if_none.\"\n+            )\n+\n+        def default_if_none_converter(val):\n+            if val is not None:\n+                return val\n+\n+            return default.factory()\n+\n+    else:\n+\n+        def default_if_none_converter(val):\n+            if val is not None:\n+                return val\n+\n+            return default\n+\n+    return default_if_none_converter\n", "test_patch": "diff --git a/tests/test_converters.py b/tests/test_converters.py\n--- a/tests/test_converters.py\n+++ b/tests/test_converters.py\n@@ -6,7 +6,8 @@\n \n import pytest\n \n-from attr.converters import optional\n+from attr import Factory\n+from attr.converters import default_if_none, optional\n \n \n class TestOptional(object):\n@@ -19,6 +20,7 @@ def test_success_with_type(self):\n         Wrapped converter is used as usual if value is not None.\n         \"\"\"\n         c = optional(int)\n+\n         assert c(\"42\") == 42\n \n     def test_success_with_none(self):\n@@ -26,6 +28,7 @@ def test_success_with_none(self):\n         Nothing happens if None.\n         \"\"\"\n         c = optional(int)\n+\n         assert c(None) is None\n \n     def test_fail(self):\n@@ -33,5 +36,62 @@ def test_fail(self):\n         Propagates the underlying conversion error when conversion fails.\n         \"\"\"\n         c = optional(int)\n+\n         with pytest.raises(ValueError):\n             c(\"not_an_int\")\n+\n+\n+class TestDefaultIfNone(object):\n+    def test_missing_default(self):\n+        \"\"\"\n+        Raises TypeError if neither default nor factory have been passed.\n+        \"\"\"\n+        with pytest.raises(TypeError, match=\"Must pass either\"):\n+            default_if_none()\n+\n+    def test_too_many_defaults(self):\n+        \"\"\"\n+        Raises TypeError if both default and factory are passed.\n+        \"\"\"\n+        with pytest.raises(TypeError, match=\"but not both\"):\n+            default_if_none(True, lambda: 42)\n+\n+    def test_factory_takes_self(self):\n+        \"\"\"\n+        Raises ValueError if passed Factory has takes_self=True.\n+        \"\"\"\n+        with pytest.raises(ValueError, match=\"takes_self\"):\n+            default_if_none(Factory(list, takes_self=True))\n+\n+    @pytest.mark.parametrize(\"val\", [1, 0, True, False, \"foo\", \"\", object()])\n+    def test_not_none(self, val):\n+        \"\"\"\n+        If a non-None value is passed, it's handed down.\n+        \"\"\"\n+        c = default_if_none(\"nope\")\n+\n+        assert val == c(val)\n+\n+        c = default_if_none(factory=list)\n+\n+        assert val == c(val)\n+\n+    def test_none_value(self):\n+        \"\"\"\n+        Default values are returned when a None is passed.\n+        \"\"\"\n+        c = default_if_none(42)\n+\n+        assert 42 == c(None)\n+\n+    def test_none_factory(self):\n+        \"\"\"\n+        Factories are used if None is passed.\n+        \"\"\"\n+        c = default_if_none(factory=list)\n+\n+        assert [] == c(None)\n+\n+        c = default_if_none(default=Factory(list))\n+\n+        assert [] == c(None)\ndiff --git a/tests/typing_example.py b/tests/typing_example.py\n--- a/tests/typing_example.py\n+++ b/tests/typing_example.py\n@@ -78,3 +78,25 @@ class HH(DD, EE):\n \n # same class\n c == cc\n+\n+\n+# Converters\n+# XXX: Currently converters can only be functions so none of this works\n+# although the stubs should be correct.\n+\n+# @attr.s\n+# class ConvCOptional:\n+#     x: Optional[int] = attr.ib(converter=attr.converters.optional(int))\n+\n+\n+# ConvCOptional(1)\n+# ConvCOptional(None)\n+\n+\n+# @attr.s\n+# class ConvCDefaultIfNone:\n+#     x: int = attr.ib(converter=attr.converters.default_if_none(42))\n+\n+\n+# ConvCDefaultIfNone(1)\n+# ConvCDefaultIfNone(None)\n", "problem_statement": "Most elegant way to avoid None objects in class?\n(continuing from https://github.com/python-attrs/attrs/issues/170 which I don't want to derail)\r\n\r\nI have a class like this:\r\n```python\r\n@attr.s(frozen=True, auto_attribs=True)\r\nclass Status:\r\n    weight: int = attr.ib(cmp=True)\r\n    message: str = attr.ib(\r\n        cmp=False,\r\n        converter=lambda value: str() if value is None else value,\r\n    )\r\n    code: str = attr.ib(\r\n        cmp=False,\r\n        converter=lambda value: str() if value is None else value,\r\n    )\r\n\r\n    @classmethod\r\n    def Debug(cls, message=None, code=None):\r\n        return cls(weight=0, message=message, code=code)\r\n\r\n    [...]\r\n\r\n    @classmethod\r\n    def Error(cls, message=None, code=None):\r\n        return cls(weight=6, message=message, code=code)\r\n```\r\nIt can be instantiated like this: `Status.Error(\"This and that is wrong etc.\", code=\"mismatched-something\")`. However, instantiating it like `Status.Error()` should result in `Status(weight=6, message=\"\", code=\"\")`, i.e. I want to avoid None objects. Python unfortunately makes it more tedious than it should be to give out non-None default arguments.\r\n\r\n@hynek noted that I may want to use `default=\"\"` and use `attr.NOTHING` as the default argument in the constructors, however:\r\n```\r\nIn [1]: import attr\r\n   ...: @attr.s\r\n   ...: class Status:\r\n   ...:     a = attr.ib(default=\"\")\r\n   ...:     @classmethod\r\n   ...:     def aaa(cls, a=attr.NOTHING):\r\n   ...:         return cls(a)\r\n   ...:\r\n\r\nIn [2]: Status.aaa()\r\nOut[2]: Status(a=NOTHING)\r\n\r\nIn [3]: Status.aaa(\"\")\r\nOut[3]: Status(a='')\r\n\r\nIn [4]: import attr\r\n   ...: @attr.s\r\n   ...: class Status:\r\n   ...:     a = attr.ib(default=\"\")\r\n   ...:     @classmethod\r\n   ...:     def aaa(cls, a=None):\r\n   ...:         return cls(a=a or attr.NOTHING)\r\n\r\nIn [5]: Status.aaa()\r\nOut[5]: Status(a=NOTHING)\r\n```\r\n\n", "hints_text": "(I suppose I can use `def aaa(cls, a=\"\"):` here because strings are immutable, but I'd like to know about a more general approach.)\nUgh right the NOTHING way doesn\u2019t work because attrs uses literal `\"\"` as default parameters if possible.\nI guess what could be done is some kind of `attr.converters.default_if_none(default=NOTHING, factory=None)` so you could write `attr.converters.default_if_none(default=\"\")` or ``attr.converters.default_if_none(factory=list)``. I *think* I had uses for that too before. \ud83e\udd14", "created_at": "2018-07-28T13:19:23Z"}
{"repo": "python-attrs/attrs", "pull_number": 411, "instance_id": "python-attrs__attrs-411", "issue_numbers": ["106", "38"], "base_commit": "3363bb35dc8680708bf82e2d87629d64dabc6c01", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1,5 +1,6 @@\n from __future__ import absolute_import, division, print_function\n \n+import copy\n import hashlib\n import linecache\n import sys\n@@ -21,6 +22,7 @@\n     DefaultAlreadySetError,\n     FrozenInstanceError,\n     NotAnAttrsClassError,\n+    PythonTooOldError,\n     UnannotatedAttributeError,\n )\n \n@@ -79,6 +81,7 @@ def attrib(\n     type=None,\n     converter=None,\n     factory=None,\n+    kw_only=False,\n ):\n     \"\"\"\n     Create a new attribute on a class.\n@@ -151,6 +154,9 @@ def attrib(\n         This argument is provided for backward compatibility.\n         Regardless of the approach used, the type will be stored on\n         ``Attribute.type``.\n+    :param kw_only: Make this attribute keyword-only (Python 3+)\n+        in the generated ``__init__`` (if ``init`` is ``False``, this\n+        parameter is ignored).\n \n     .. versionadded:: 15.2.0 *convert*\n     .. versionadded:: 16.3.0 *metadata*\n@@ -163,6 +169,7 @@ def attrib(\n        *convert* to achieve consistency with other noun-based arguments.\n     .. versionadded:: 18.1.0\n        ``factory=f`` is syntactic sugar for ``default=attr.Factory(f)``.\n+    .. versionadded:: 18.2.0 *kw_only*\n     \"\"\"\n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n@@ -206,6 +213,7 @@ def attrib(\n         converter=converter,\n         metadata=metadata,\n         type=type,\n+        kw_only=kw_only,\n     )\n \n \n@@ -285,7 +293,7 @@ def _counter_getter(e):\n     return e[1].counter\n \n \n-def _transform_attrs(cls, these, auto_attribs):\n+def _transform_attrs(cls, these, auto_attribs, kw_only):\n     \"\"\"\n     Transform all `_CountingAttr`s on a class into `Attribute`s.\n \n@@ -368,19 +376,22 @@ def _transform_attrs(cls, these, auto_attribs):\n \n     AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)\n \n-    attrs = AttrsClass(\n-        super_attrs\n-        + [\n-            Attribute.from_counting_attr(\n-                name=attr_name, ca=ca, type=anns.get(attr_name)\n-            )\n-            for attr_name, ca in ca_list\n-        ]\n-    )\n+    if kw_only:\n+        own_attrs = [a._assoc(kw_only=True) for a in own_attrs]\n+        super_attrs = [a._assoc(kw_only=True) for a in super_attrs]\n+\n+    attrs = AttrsClass(super_attrs + own_attrs)\n \n     had_default = False\n+    was_kw_only = False\n     for a in attrs:\n-        if had_default is True and a.default is NOTHING and a.init is True:\n+        if (\n+            was_kw_only is False\n+            and had_default is True\n+            and a.default is NOTHING\n+            and a.init is True\n+            and a.kw_only is False\n+        ):\n             raise ValueError(\n                 \"No mandatory attributes allowed after an attribute with a \"\n                 \"default value or factory.  Attribute in question: %r\" % (a,)\n@@ -389,8 +400,21 @@ def _transform_attrs(cls, these, auto_attribs):\n             had_default is False\n             and a.default is not NOTHING\n             and a.init is not False\n+            and\n+            # Keyword-only attributes without defaults can be specified\n+            # after keyword-only attributes with defaults.\n+            a.kw_only is False\n         ):\n             had_default = True\n+        if was_kw_only is True and a.kw_only is False:\n+            raise ValueError(\n+                \"Non keyword-only attributes are not allowed after a \"\n+                \"keyword-only attribute.  Attribute in question: {a!r}\".format(\n+                    a=a\n+                )\n+            )\n+        if was_kw_only is False and a.init is True and a.kw_only is True:\n+            was_kw_only = True\n \n     return _Attributes((attrs, super_attrs, super_attr_map))\n \n@@ -427,9 +451,9 @@ class _ClassBuilder(object):\n         \"_super_attr_map\",\n     )\n \n-    def __init__(self, cls, these, slots, frozen, auto_attribs):\n+    def __init__(self, cls, these, slots, frozen, auto_attribs, kw_only):\n         attrs, super_attrs, super_map = _transform_attrs(\n-            cls, these, auto_attribs\n+            cls, these, auto_attribs, kw_only\n         )\n \n         self._cls = cls\n@@ -639,6 +663,7 @@ def attrs(\n     frozen=False,\n     str=False,\n     auto_attribs=False,\n+    kw_only=False,\n ):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -736,6 +761,10 @@ def attrs(\n         Attributes annotated as :data:`typing.ClassVar` are **ignored**.\n \n         .. _`PEP 526`: https://www.python.org/dev/peps/pep-0526/\n+    :param bool kw_only: Make all attributes keyword-only (Python 3+)\n+        in the generated ``__init__`` (if ``init`` is ``False``, this\n+        parameter is ignored).\n+\n \n     .. versionadded:: 16.0.0 *slots*\n     .. versionadded:: 16.1.0 *frozen*\n@@ -752,13 +781,16 @@ def attrs(\n        :class:`DeprecationWarning` if the classes compared are subclasses of\n        each other. ``__eq`` and ``__ne__`` never tried to compared subclasses\n        to each other.\n+    .. versionadded:: 18.2.0 *kw_only*\n     \"\"\"\n \n     def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n             raise TypeError(\"attrs only works with new-style classes.\")\n \n-        builder = _ClassBuilder(cls, these, slots, frozen, auto_attribs)\n+        builder = _ClassBuilder(\n+            cls, these, slots, frozen, auto_attribs, kw_only\n+        )\n \n         if repr is True:\n             builder.add_repr(repr_ns)\n@@ -1298,6 +1330,7 @@ def fmt_setter_with_converter(attr_name, value_var):\n             }\n \n     args = []\n+    kw_only_args = []\n     attrs_to_validate = []\n \n     # This is a dictionary of names to validator and converter callables.\n@@ -1357,11 +1390,13 @@ def fmt_setter_with_converter(attr_name, value_var):\n                         )\n                     )\n         elif a.default is not NOTHING and not has_factory:\n-            args.append(\n-                \"{arg_name}=attr_dict['{attr_name}'].default\".format(\n-                    arg_name=arg_name, attr_name=attr_name\n-                )\n+            arg = \"{arg_name}=attr_dict['{attr_name}'].default\".format(\n+                arg_name=arg_name, attr_name=attr_name\n             )\n+            if a.kw_only:\n+                kw_only_args.append(arg)\n+            else:\n+                args.append(arg)\n             if a.converter is not None:\n                 lines.append(fmt_setter_with_converter(attr_name, arg_name))\n                 names_for_globals[\n@@ -1370,7 +1405,11 @@ def fmt_setter_with_converter(attr_name, value_var):\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name))\n         elif has_factory:\n-            args.append(\"{arg_name}=NOTHING\".format(arg_name=arg_name))\n+            arg = \"{arg_name}=NOTHING\".format(arg_name=arg_name)\n+            if a.kw_only:\n+                kw_only_args.append(arg)\n+            else:\n+                args.append(arg)\n             lines.append(\n                 \"if {arg_name} is not NOTHING:\".format(arg_name=arg_name)\n             )\n@@ -1402,7 +1441,10 @@ def fmt_setter_with_converter(attr_name, value_var):\n                 )\n             names_for_globals[init_factory_name] = a.default.factory\n         else:\n-            args.append(arg_name)\n+            if a.kw_only:\n+                kw_only_args.append(arg_name)\n+            else:\n+                args.append(arg_name)\n             if a.converter is not None:\n                 lines.append(fmt_setter_with_converter(attr_name, arg_name))\n                 names_for_globals[\n@@ -1428,13 +1470,23 @@ def fmt_setter_with_converter(attr_name, value_var):\n     if post_init:\n         lines.append(\"self.__attrs_post_init__()\")\n \n+    args = \", \".join(args)\n+    if kw_only_args:\n+        if PY2:\n+            raise PythonTooOldError(\n+                \"Keyword-only arguments only work on Python 3 and later.\"\n+            )\n+\n+        args += \"{leading_comma}*, {kw_only_args}\".format(\n+            leading_comma=\", \" if args else \"\",\n+            kw_only_args=\", \".join(kw_only_args),\n+        )\n     return (\n         \"\"\"\\\n def __init__(self, {args}):\n     {lines}\n \"\"\".format(\n-            args=\", \".join(args),\n-            lines=\"\\n    \".join(lines) if lines else \"pass\",\n+            args=args, lines=\"\\n    \".join(lines) if lines else \"pass\"\n         ),\n         names_for_globals,\n         annotations,\n@@ -1463,6 +1515,7 @@ class Attribute(object):\n         \"metadata\",\n         \"type\",\n         \"converter\",\n+        \"kw_only\",\n     )\n \n     def __init__(\n@@ -1478,6 +1531,7 @@ def __init__(\n         metadata=None,\n         type=None,\n         converter=None,\n+        kw_only=False,\n     ):\n         # Cache this descriptor here to speed things up later.\n         bound_setattr = _obj_setattr.__get__(self, Attribute)\n@@ -1515,6 +1569,7 @@ def __init__(\n             ),\n         )\n         bound_setattr(\"type\", type)\n+        bound_setattr(\"kw_only\", kw_only)\n \n     def __setattr__(self, name, value):\n         raise FrozenInstanceError()\n@@ -1558,6 +1613,17 @@ def from_counting_attr(cls, name, ca, type=None):\n             **inst_dict\n         )\n \n+    # Don't use attr.assoc since fields(Attribute) doesn't work\n+    def _assoc(self, **changes):\n+        \"\"\"\n+        Copy *self* and apply *changes*.\n+        \"\"\"\n+        new = copy.copy(self)\n+\n+        new._setattrs(changes.items())\n+\n+        return new\n+\n     # Don't use _add_pickle since fields(Attribute) doesn't work\n     def __getstate__(self):\n         \"\"\"\n@@ -1572,8 +1638,11 @@ def __setstate__(self, state):\n         \"\"\"\n         Play nice with pickle.\n         \"\"\"\n+        self._setattrs(zip(self.__slots__, state))\n+\n+    def _setattrs(self, name_values_pairs):\n         bound_setattr = _obj_setattr.__get__(self, Attribute)\n-        for name, value in zip(self.__slots__, state):\n+        for name, value in name_values_pairs:\n             if name != \"metadata\":\n                 bound_setattr(name, value)\n             else:\n@@ -1625,6 +1694,7 @@ class _CountingAttr(object):\n         \"_validator\",\n         \"converter\",\n         \"type\",\n+        \"kw_only\",\n     )\n     __attrs_attrs__ = tuple(\n         Attribute(\n@@ -1635,6 +1705,7 @@ class _CountingAttr(object):\n             cmp=True,\n             hash=True,\n             init=True,\n+            kw_only=False,\n         )\n         for name in (\"counter\", \"_default\", \"repr\", \"cmp\", \"hash\", \"init\")\n     ) + (\n@@ -1646,6 +1717,7 @@ class _CountingAttr(object):\n             cmp=True,\n             hash=False,\n             init=True,\n+            kw_only=False,\n         ),\n     )\n     cls_counter = 0\n@@ -1661,6 +1733,7 @@ def __init__(\n         converter,\n         metadata,\n         type,\n+        kw_only,\n     ):\n         _CountingAttr.cls_counter += 1\n         self.counter = _CountingAttr.cls_counter\n@@ -1677,6 +1750,7 @@ def __init__(\n         self.converter = converter\n         self.metadata = metadata\n         self.type = type\n+        self.kw_only = kw_only\n \n     def validator(self, meth):\n         \"\"\"\ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\n--- a/src/attr/exceptions.py\n+++ b/src/attr/exceptions.py\n@@ -47,3 +47,11 @@ class UnannotatedAttributeError(RuntimeError):\n \n     .. versionadded:: 17.3.0\n     \"\"\"\n+\n+\n+class PythonTooOldError(RuntimeError):\n+    \"\"\"\n+    An ``attrs`` feature requiring a more recent python version has been used.\n+\n+    .. versionadded:: 18.2.0\n+    \"\"\"\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -229,3 +229,24 @@ class C:\n             \"foo\": \"typing.Any\",\n             \"return\": None,\n         }\n+\n+    def test_keyword_only_auto_attribs(self):\n+        \"\"\"\n+        `kw_only` propagates to attributes defined via `auto_attribs`.\n+        \"\"\"\n+\n+        @attr.s(auto_attribs=True, kw_only=True)\n+        class C:\n+            x: int\n+            y: int\n+\n+        with pytest.raises(TypeError):\n+            C(0, 1)\n+\n+        with pytest.raises(TypeError):\n+            C(x=0)\n+\n+        c = C(x=0, y=1)\n+\n+        assert c.x == 0\n+        assert c.y == 1\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -35,7 +35,11 @@\n     make_class,\n     validate,\n )\n-from attr.exceptions import DefaultAlreadySetError, NotAnAttrsClassError\n+from attr.exceptions import (\n+    DefaultAlreadySetError,\n+    NotAnAttrsClassError,\n+    PythonTooOldError,\n+)\n \n from .strategies import (\n     gen_attr_names,\n@@ -229,7 +233,7 @@ def test_no_modifications(self):\n         Doesn't attach __attrs_attrs__ to the class anymore.\n         \"\"\"\n         C = make_tc()\n-        _transform_attrs(C, None, False)\n+        _transform_attrs(C, None, False, False)\n \n         assert None is getattr(C, \"__attrs_attrs__\", None)\n \n@@ -238,7 +242,7 @@ def test_normal(self):\n         Transforms every `_CountingAttr` and leaves others (a) be.\n         \"\"\"\n         C = make_tc()\n-        attrs, _, _ = _transform_attrs(C, None, False)\n+        attrs, _, _ = _transform_attrs(C, None, False, False)\n \n         assert [\"z\", \"y\", \"x\"] == [a.name for a in attrs]\n \n@@ -251,14 +255,16 @@ def test_empty(self):\n         class C(object):\n             pass\n \n-        assert _Attributes(((), [], {})) == _transform_attrs(C, None, False)\n+        assert _Attributes(((), [], {})) == _transform_attrs(\n+            C, None, False, False\n+        )\n \n     def test_transforms_to_attribute(self):\n         \"\"\"\n         All `_CountingAttr`s are transformed into `Attribute`s.\n         \"\"\"\n         C = make_tc()\n-        attrs, super_attrs, _ = _transform_attrs(C, None, False)\n+        attrs, super_attrs, _ = _transform_attrs(C, None, False, False)\n \n         assert [] == super_attrs\n         assert 3 == len(attrs)\n@@ -275,15 +281,46 @@ class C(object):\n             y = attr.ib()\n \n         with pytest.raises(ValueError) as e:\n-            _transform_attrs(C, None, False)\n+            _transform_attrs(C, None, False, False)\n         assert (\n             \"No mandatory attributes allowed after an attribute with a \"\n             \"default value or factory.  Attribute in question: Attribute\"\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n             \"cmp=True, hash=None, init=True, metadata=mappingproxy({}), \"\n-            \"type=None, converter=None)\",\n+            \"type=None, converter=None, kw_only=False)\",\n         ) == e.value.args\n \n+    def test_kw_only(self):\n+        \"\"\"\n+        Converts all attributes, including superclass attributes, if `kw_only`\n+        is provided. Therefore, `kw_only` allows attributes with defaults to\n+        preceed mandatory attributes.\n+\n+        Updates in the subclass *don't* affect the superclass attributes.\n+        \"\"\"\n+\n+        @attr.s\n+        class B(object):\n+            b = attr.ib()\n+\n+        for b_a in B.__attrs_attrs__:\n+            assert b_a.kw_only is False\n+\n+        class C(B):\n+            x = attr.ib(default=None)\n+            y = attr.ib()\n+\n+        attrs, super_attrs, _ = _transform_attrs(C, None, False, True)\n+\n+        assert len(attrs) == 3\n+        assert len(super_attrs) == 1\n+\n+        for a in attrs:\n+            assert a.kw_only is True\n+\n+        for b_a in B.__attrs_attrs__:\n+            assert b_a.kw_only is False\n+\n     def test_these(self):\n         \"\"\"\n         If these is passed, use it and ignore body and super classes.\n@@ -295,7 +332,9 @@ class Base(object):\n         class C(Base):\n             y = attr.ib()\n \n-        attrs, super_attrs, _ = _transform_attrs(C, {\"x\": attr.ib()}, False)\n+        attrs, super_attrs, _ = _transform_attrs(\n+            C, {\"x\": attr.ib()}, False, False\n+        )\n \n         assert [] == super_attrs\n         assert (simple_attr(\"x\"),) == attrs\n@@ -594,6 +633,182 @@ class C(object):\n                 x = attr.ib(factory=Factory(list))\n \n \n+@pytest.mark.skipif(PY2, reason=\"keyword-only arguments are PY3-only.\")\n+class TestKeywordOnlyAttributes(object):\n+    \"\"\"\n+    Tests for keyword-only attributes.\n+    \"\"\"\n+\n+    def test_adds_keyword_only_arguments(self):\n+        \"\"\"\n+        Attributes can be added as keyword-only.\n+        \"\"\"\n+\n+        @attr.s\n+        class C(object):\n+            a = attr.ib()\n+            b = attr.ib(default=2, kw_only=True)\n+            c = attr.ib(kw_only=True)\n+            d = attr.ib(default=attr.Factory(lambda: 4), kw_only=True)\n+\n+        c = C(1, c=3)\n+\n+        assert c.a == 1\n+        assert c.b == 2\n+        assert c.c == 3\n+        assert c.d == 4\n+\n+    def test_ignores_kw_only_when_init_is_false(self):\n+        \"\"\"\n+        Specifying ``kw_only=True`` when ``init=False`` is essentially a no-op.\n+        \"\"\"\n+\n+        @attr.s\n+        class C(object):\n+            x = attr.ib(init=False, default=0, kw_only=True)\n+            y = attr.ib()\n+\n+        c = C(1)\n+\n+        assert c.x == 0\n+        assert c.y == 1\n+\n+    def test_keyword_only_attributes_presence(self):\n+        \"\"\"\n+        Raises `TypeError` when keyword-only arguments are\n+        not specified.\n+        \"\"\"\n+\n+        @attr.s\n+        class C(object):\n+            x = attr.ib(kw_only=True)\n+\n+        with pytest.raises(TypeError) as e:\n+            C()\n+\n+        assert (\n+            \"missing 1 required keyword-only argument: 'x'\"\n+        ) in e.value.args[0]\n+\n+    def test_conflicting_keyword_only_attributes(self):\n+        \"\"\"\n+        Raises `ValueError` if keyword-only attributes are followed by\n+        regular (non keyword-only) attributes.\n+        \"\"\"\n+\n+        class C(object):\n+            x = attr.ib(kw_only=True)\n+            y = attr.ib()\n+\n+        with pytest.raises(ValueError) as e:\n+            _transform_attrs(C, None, False, False)\n+\n+        assert (\n+            \"Non keyword-only attributes are not allowed after a \"\n+            \"keyword-only attribute.  Attribute in question: Attribute\"\n+            \"(name='y', default=NOTHING, validator=None, repr=True, \"\n+            \"cmp=True, hash=None, init=True, metadata=mappingproxy({}), \"\n+            \"type=None, converter=None, kw_only=False)\",\n+        ) == e.value.args\n+\n+    def test_keyword_only_attributes_allow_subclassing(self):\n+        \"\"\"\n+        Subclass can define keyword-only attributed without defaults,\n+        when the base class has attributes with defaults.\n+        \"\"\"\n+\n+        @attr.s\n+        class Base(object):\n+            x = attr.ib(default=0)\n+\n+        @attr.s\n+        class C(Base):\n+            y = attr.ib(kw_only=True)\n+\n+        c = C(y=1)\n+\n+        assert c.x == 0\n+        assert c.y == 1\n+\n+    def test_keyword_only_class_level(self):\n+        \"\"\"\n+        `kw_only` can be provided at the attr.s level, converting all\n+        attributes to `kw_only.`\n+        \"\"\"\n+\n+        @attr.s(kw_only=True)\n+        class C:\n+            x = attr.ib()\n+            y = attr.ib(kw_only=True)\n+\n+        with pytest.raises(TypeError):\n+            C(0, y=1)\n+\n+        c = C(x=0, y=1)\n+\n+        assert c.x == 0\n+        assert c.y == 1\n+\n+    def test_keyword_only_class_level_subclassing(self):\n+        \"\"\"\n+        Subclass `kw_only` propagates to attrs inherited from the base,\n+        allowing non-default following default.\n+        \"\"\"\n+\n+        @attr.s\n+        class Base(object):\n+            x = attr.ib(default=0)\n+\n+        @attr.s(kw_only=True)\n+        class C(Base):\n+            y = attr.ib()\n+\n+        with pytest.raises(TypeError):\n+            C(1)\n+\n+        c = C(x=0, y=1)\n+\n+        assert c.x == 0\n+        assert c.y == 1\n+\n+\n+@pytest.mark.skipif(not PY2, reason=\"PY2-specific keyword-only error behavior\")\n+class TestKeywordOnlyAttributesOnPy2(object):\n+    \"\"\"\n+    Tests for keyword-only attribute behavior on py2.\n+    \"\"\"\n+\n+    def test_syntax_error(self):\n+        \"\"\"\n+        Keyword-only attributes raise Syntax error on ``__init__`` generation.\n+        \"\"\"\n+\n+        with pytest.raises(PythonTooOldError):\n+\n+            @attr.s(kw_only=True)\n+            class ClassLevel(object):\n+                a = attr.ib()\n+\n+        with pytest.raises(PythonTooOldError):\n+\n+            @attr.s()\n+            class AttrLevel(object):\n+                a = attr.ib(kw_only=True)\n+\n+    def test_no_init(self):\n+        \"\"\"\n+        Keyworld-only is a no-op, not any error, if ``init=false``.\n+        \"\"\"\n+\n+        @attr.s(kw_only=True, init=False)\n+        class ClassLevel(object):\n+            a = attr.ib()\n+\n+        @attr.s(init=False)\n+        class AttrLevel(object):\n+            a = attr.ib(kw_only=True)\n+\n+\n @attr.s\n class GC(object):\n     @attr.s\n@@ -1153,7 +1368,7 @@ def test_repr(self):\n         class C(object):\n             pass\n \n-        b = _ClassBuilder(C, None, True, True, False)\n+        b = _ClassBuilder(C, None, True, True, False, False)\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n \n@@ -1165,7 +1380,7 @@ def test_returns_self(self):\n         class C(object):\n             x = attr.ib()\n \n-        b = _ClassBuilder(C, None, True, True, False)\n+        b = _ClassBuilder(C, None, True, True, False, False)\n \n         cls = (\n             b.add_cmp()\n@@ -1222,7 +1437,12 @@ class C(object):\n             pass\n \n         b = _ClassBuilder(\n-            C, these=None, slots=False, frozen=False, auto_attribs=False\n+            C,\n+            these=None,\n+            slots=False,\n+            frozen=False,\n+            auto_attribs=False,\n+            kw_only=False,\n         )\n         b._cls = {}  # no __module__; no __qualname__\n \ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -36,6 +36,7 @@ def simple_attr(\n     hash=None,\n     init=True,\n     converter=None,\n+    kw_only=False,\n ):\n     \"\"\"\n     Return an attribute with a name and no other bells and whistles.\n@@ -49,6 +50,7 @@ def simple_attr(\n         hash=hash,\n         init=init,\n         converter=converter,\n+        kw_only=False,\n     )\n \n \n", "problem_statement": "Add support for keyword only arguments\nThere was a suggestion in #38 that there be an option to make arguments keyword only. The suggested API was to have something like:\n\n``` python\n    @attr.s\n    class A:\n        a = attr.ib()\n        b = attr.ib(init='kwonly')\n\n        # __init__ signature is:\n        # def __init__(self, a, *, b):\n        #    pass\n```\n\nWould support for this be accepted? What about\n\n``` python\n    @attr.s(kwonly=True)\n    class A:\n        a = attr.ib()\n        b = attr.ib()\n\n        # __init__ signature is:\n        # def __init__(self, *, a, b):\n        #    pass\n```\n\nwhich may be nicer when subclassing?\n\nsubclass with mandatory attribute cannot be created when the base class has a factory based one\nfailing example\n\n```\nimport attr\n\ndef test_example():\n\n    @attr.s\n    class Base(object):\n        attr = attr.ib(default=False)\n\n    @attr.s\n    class Sub(Base):\n        needed = attr.ib()\n```\n\n", "hints_text": "This functionality would be nice for the \"big bag of configuration\" use case.  I don't really want to be able to pass my 19 different configuration items positionally.  It would be totally unreadable.\r\n\r\nCurrently I have to make sure to carefully order my attribute definitions to avoid running into limitations about what can have a default and what cannot.  If everything were keyword-only, this would go away.\r\n\r\nThis use-case would be better served by an API like the latter suggested above (so the setting doesn't have to be repeated 19 times).  The existence of both of the proposed APIs wouldn't hurt this use case, though.\nI can already use keywords arguments to build `attrs` objects. Why do you need a parameter to enforce it ? (i/e : disable positionnal arguments)\nKwonly attributes would have to have defaults, no? How does that work with with the class decorator approach?\r\n\r\n> Currently I have to make sure to carefully order my attribute definitions to avoid running into limitations about what can have a default and what cannot. If everything were keyword-only, this would go away.\r\n\r\nIf kwonly attributes must have defaults, this wouldn't solve anything for you. You can set defaults today on everything and not care about ordering attributes.\r\n\r\n> I don't really want to be able to pass my 19 different configuration items positionally. It would be totally unreadable.\r\n\r\nNot sure what you mean here, could you clarify? You'd like to disable positional arguments on your `__init__` altogether? I mean, that's fine, but you don't actually have to use this feature.\r\n\r\nI thought you might be disagreeing with having to carefully position arguments to `__init__`, but that's not really the case currently, or `C(**attr.asdict(C()))` wouldn't work.\nI want to be able to write this:\r\n\r\n```\r\n    @attr.s\r\n    class A(object):\r\n        a = attr.ib(default=\"abc\")\r\n        b = attr.ib()\r\n```\r\n\r\nThis is not currently possible because:\r\n\r\n```\r\nValueError: No mandatory attributes allowed after an attribute with a default value or factory.  Attribute in question: Attribute(name='b', default=NOTHING, validator=None, repr=True, cmp=True, hash=True, init=True, convert=None)\r\n```\r\n\r\nAs a work-around, I can re-arrange the attributes on my class every time I add or remove a default - but I'd much rather just say something like `@attr.s(positional=False)` and not worry about the order.\n@Tinche No, keyword only is different to having a default.\r\nDefault argument:\r\n```\r\ndef a(a=1):\r\n    pass\r\n```\r\nis different to keyword only with default:\r\n```\r\ndef a(*, a=1):\r\n    pass\r\n```\r\nis different to keyword only\r\n```\r\ndef a(*, a):\r\n    pass\r\n```\r\n\r\nMy original question was what should the API be?\nHuh, guess I learned something today. None of the examples in the PEP 3102 show a kw-only argument without a default, but the text mentions it (I just skimmed the text :).\r\n\r\nAnyway, continuing the discussion. Currently the definition order of attributes is the same as the order of the attributes in the generated `__init__`. This is strictly by @hynek's executive order and I personally agree with the rationale. If it wasn't intentional we would just sort the attributes and you wouldn't need to put arguments with defaults last. The order of definition is used in other places too: the `__repr__`, comparison methods, `attr.fields`.\r\n\r\nKeeping with this design decision, if your attributes were a mix of normal and kwonly attributes, you'd still need to define your kwonly attributes after the normal ones.\r\n\r\n```\r\n@attr.s\r\nclass A:\r\n    a = attr.ib()\r\n    b = attr.ib(init='kwonly')\r\n```\r\n\r\nThe idea all attributes could be marked as kwonly is also being floated around:\r\n\r\n```\r\n@attr.s(init='kwonly')\r\nclass A:\r\n    a = attr.ib(default=0)\r\n    b = attr.ib()\r\n```\r\n\r\nThe attribute-level kwonly needs support from `attrs` core. The class level could be handled by an additional decorator (that you can write yourself):\r\n\r\n```\r\n@attr.s\r\n@kwonly\r\nclass A:\r\n    a = attr.ib(default=0)\r\n    b = attr.ib()\r\n```\r\n\r\nI think this is where we are with the proposals, currently.\nFirst of all: as long as I breathe, there won\u2019t be any strings part of any API. :)\r\n\r\nSecondly, I guess we *could* implement kw-only so mixing is possible by moving default values into ``__init__`` as it used to be in `characteristic` and simply set all attributes to `NOTHING`.  Adding a `*,` on Py3 is more of a nifty goodie.\r\n\r\nPrecondition is that it must not have any performance implications for common use cases.\r\n\r\nThirdly, I\u2019m totally _not_ implementing it. :)\n@hynek \r\n```\r\nfrom enum import Enum\r\n\r\nclass InitType(Enum):\r\n    PRESENT = True\r\n    ABSENT = False\r\n    KWONLY = \"kwonly\"\r\n\r\nattr.ib(init=True) === attr.ib(init=InitType.PRESENT)\r\nattr.ib(init='kwonly') === attr.ib(init=InitType.KWONLY)\r\n```\r\nIt's backward compatible, and supports not using the enum when you don't feel like it (i.e. the REPL or using timeit).\r\n\r\n> Secondly, I guess we could implement kw-only so mixing is possible by moving default values into __init__ as it used to be in characteristic and simply set all attributes to NOTHING. Adding a *, on Py3 is more of a nifty goodie.\r\n\r\nIs this a response to the issue of having to order the attributes so attributes with defaults are last? I think a separate issue should be created for commenting on this, since it's almost orthogonal to kwonly arguments. (We could implement kwonly args without touching the rule, or the rule could be changed without implementing kwonly args at all, and kwonly args would be useful even if we change the rule.)\nI feel like kwonly is a red herring.  I don\u2019t see *any* reason to add *any* complexity just so people can\u2019t pass argument by order.\r\n\r\nOTOH being able to mix default with non-defaults is an actual use case that *might* be mitigated by a kwonly design.  But focusing on the former seems backward to me.\nI've used kw-only arguments pretty regularly since their addition.  My main reasons for doing so:\r\n\r\n- **raising the difficulty of calling code incorrectly** (it's not impossible to say `Foo(should_be_bar=quux, should_be_quux=bar)`, but it's more obvious in coding and review that that's wrong than if you're allowed to write `Foo(quux, bar)`)\r\n- **faster failure in error cases** (`Foo(quux, bar)` fails on call with a nice error, rather than having some logic/type error occur several calls later).  (yes, `Foo(bar, quux)` is 'correct' and also fails with kw-only args, but the gains from fast failure and obvious code outweigh this, IMO)\r\n- **readability/explicitness**.  yep, it's more to type, but it's also faster to comprehend.  You don't *need* kw-only args to init classes with keywords, but if using keywords for code clarity is important to the project, you want some kind of enforcement.  You could try to enforce that when doing code review or with static analysis, but those are never going to be as reliable as language-level support.\r\n\r\nYou don't have to agree, of course, but since nobody else responded after you said you don't see *any* reason, I thought I'd list the ones I find compelling in the projects/teams I've been working on.\r\n\r\nThere's also [the official python reason for including them](https://www.python.org/dev/peps/pep-3102/#rationale) in the language, which I also appreciate from time to time for functions, and actually isn't about preventing people from passing arguments by order - it's about allowing people to specify arguments by keyword after using varargs:\r\n\r\n\r\n> The current Python function-calling paradigm allows arguments to be specified either by position or by keyword. An argument can be filled in either explicitly by name, or implicitly by position.\r\n> \r\n> There are often cases where it is desirable for a function to take a variable number of arguments. The Python language supports this using the 'varargs' syntax ( *name ), which specifies that any 'left over' arguments be passed into the varargs parameter as a tuple.\r\n> \r\n> One limitation on this is that currently, all of the regular argument slots must be filled before the vararg slot can be.\r\n> \r\n> This is not always desirable. One can easily envision a function which takes a variable number of arguments, but also takes one or more 'options' in the form of keyword arguments. Currently, the only way to do this is to define both a varargs argument, and a 'keywords' argument ( **kwargs ), and then manually extract the desired keywords from the dictionary.\r\n\r\nWhile I appreciate that use case from time to time for functions... I don't know that I've ever actually wanted to do keywords after varargs in a class init, but `\u00af\\_(\u30c4)_/\u00af`.  \nFWIW there\u2019s two levels to it:\r\n\r\n1. are we gonna allow the user to make certain args kwonly and others not?  I find this introduces too much complexity for too little gain and we\u2019d regret it later.\r\n2. `@attr.s(init_kwonly=True)` that only works on Python 3 by adding a `*` after `self` is something I could get behind.  Although that leads to weirdness if you want to write cross-platform code.  So we\u2019d have to change the signature to `__init__(self, **kw)` and extract the arguments within __init__ which is also kind of tedious.  :|  I might merge a good PR for this one but I\u2019m not gonna write it.\nfwiw, a trick for py2 (who uses that anyway nowadays?) is to add a `_please_use_kwargs=None` arg as the first arg after `self`. i have seen this in the wild but cannot recall where.\nwhile one might think the extra \"marker arg\" is ugly, it actually gives much better info in `help()` output (and sphinx autoclass docs) than `**kwargs` does.\nI think I could live with such an hack on Python 2.\nI'm in favor of the class-wide `@attr.s(kwonly=True)` option for reasons similar to @exarkun.  I don't want reordering of attributes to be an API-incompatible change, but I have no good way to prevent called for using them positionally.\r\n\r\nThe per-attribute constraint seems like it might add more complexity than it's worth, but that may be simply because it's not a use case I have at the moment\u2026 perhaps as a compatibility thing where you have an existing class and you want all new attributes to be kwarg-only?\r\n\r\nBut I'd love to see the class-level constraint.\nI'd love to see this, too. And, while the granularity of the per-`attr.ib()` `kwonly` specification would be nice to have, the class-wide option would still be tremendously useful.\nThis has been reported before and I\u2019m not sure what to do about it.  putting mandatory always before optionals?  iow reordering?\n\nthey can always be given as keyword\n\nthe order should stay the same\n\nit should be possible to give them as keyword instead of a positional argument\n\nonce inheritance is involved it seems sensible to go towards keywords in any case\n\nbasically all mandatory arguments after a optional one can be primary keyword based\n\nbtw, i do in fact use them as keywords, but putting in a default of None seems the wrong way\n\nI kind of agree, but what\u2019s better?  having a sentinel and explode on it?\n\nnot quite sure what you mean by the sentinel\n\nfor the code in the example i posted i think that `Sub(needed='foo')` should work since all mandatory arguments where given\n\nwhat you sketched it results in\n\n``` python\ndef __init__(self, attr=False, needed):\n    pass\n```\n\nwhich is a syntax error.\n\nSo we need some default value for needed here.\n\ni see what you mean, in python3 its  `*,` and valid, for python2 there is need for a workaround in form of a sentinel object and exploding then\n\nI accidentally opened up a duplicate of this.\n\nMy personal opinion\u2122 is that we should just allow users to mark attributes as `init='kwonly'`. That will allow users to fix the problem themselves on Python 3 and consider upgrading on Python 2. \ud83d\ude3d\n\nFull example:\n\n```\n@attr.s\nclass A:\n    a = attr.ib()\n    b = attr.ib(init='kwonly', default=1)\n\n    # __init__ signature is:\n    def __init__(self, a, *, b=1):\n        pass\n\n@attr.s\nclass B(A):\n    c = attr.ib()\n\n    # __init__ signature is:\n    def __init__(self, a, c, *, b=1):\n        pass\n```\n\nAlso, in the case of the error we have now, a helpful error message can direct users to use `kwonly`.\n\nI ran into this problem as well and I have a slightly different take on it that I wanted to submit. A more natural solution to me would be to write something like:\r\n\r\n\timport attr\r\n\t\r\n\tdef test_example():\r\n\t\r\n\t    @attr.s\r\n\t    class Base(object):\r\n\t        attr = attr.ib(default=False)\r\n\t\r\n\t    @attr.s\r\n\t    class Sub(Base):\r\n\t        needed = attr.ib()\r\n\t        attr = attr.ib(default=False)\r\n\t        \r\nAt the cost of a very minor repetition of code, this lets the programmer explicitly control the order in which the attributes should appear for representation purposes or when converting to a tuple. However what I wrote obviously doesn't work in the current version of attr: because of the way inheritance is implemented, Sub receives two 'attr' attributes, which happens to break the \\_\\_init\\_\\_ method among other things. I do have a bit of beef with that and was both curious about why attributes don't get overridden in subclasses, and willing to do something about it -then I saw this issue and thought that would be a good starting point for my comment.\nhow about this: \r\n- add optional class-level var that defines the order of arguments (as list of strings?)\r\n- if some required argument encountered in the child, fail with error, requesting explicit order of attributes specified?\r\n- users can use required arguments in children but must provide order themselves explicitly\r\n\nsince this is starting to turn into a mirad of dozens and dozens of options i believe this should either not be supported for the sake of simplicity or be supported only by disabling positional constructor arguments in the complete inheritance tree\nI tend to agree.  I\u2019m thinking about an option to `@attr.s` that changes the mode of `__init__` from building a proper signature to `def __init__(x=NOTHING, y=NOTHING, z=42, a=NOTHING)` and so forth.  Then it checks at the beginning if there\u2019s a `NOTHING` in mandatory attributes.  It\u2019s slower but only for people who insist to subclass (I would add electro shocks if I could ;)).\nYea I run into this issue a lot when I have some common optional attributes that I want to share across many classes. e.g.\r\n\r\n```\r\n@attr.s()\r\nclass SmallOptions(object):\r\n    verbose = attr.ib(default=None)\r\n    other_option = attr.ib(default=None)\r\n\r\n@attr.s()\r\nclass Main(SmallOptions):\r\n     required = attr.ib()\r\n```\r\n\r\nI'm kinda inspired by go's embedded struct types:\r\n https://www.goinggo.net/2014/05/methods-interfaces-and-embedded-types.html\r\nhttp://www.hydrogen18.com/blog/golang-embedding.html\r\n which I'd like to replicate that same sort of composability here. Instead of inheriting from SmallOptions, I'd want class Main to 'embed' SmallOptions instance. Maybe it would look something like so.\r\n\r\n```\r\n@attr.s()\r\nclass Main(object):\r\n     required = attr.ib()\r\n     __attrs_embedded__ = {'options': SmallOptions}\r\n```\r\n\r\nwith some __getattr__ generated functionality. There would be a SmallOptions instance embedded within Main instance that would be proxied, and can be accessed directly by Main().options as well. \r\n\r\n\nor like this\r\n```\r\n@attr.s()\r\nclass Main(object):\r\n     required = attr.ib()\r\n     options = attr.embed(SmallOptions)\r\n```", "created_at": "2018-07-24T08:36:30Z"}
{"repo": "python-attrs/attrs", "pull_number": 410, "instance_id": "python-attrs__attrs-410", "issue_numbers": ["407", "407"], "base_commit": "6f3f4904bed568795c96c07579a7a6ebf9ca9062", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -493,7 +493,7 @@ def _create_slots_class(self):\n         cd = {\n             k: v\n             for k, v in iteritems(self._cls_dict)\n-            if k not in tuple(self._attr_names) + (\"__dict__\",)\n+            if k not in tuple(self._attr_names) + (\"__dict__\", \"__weakref__\")\n         }\n \n         # We only add the names of attributes that aren't inherited.\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -5,6 +5,7 @@\n from __future__ import absolute_import, division, print_function\n \n import copy\n+import gc\n import inspect\n import itertools\n import sys\n@@ -1250,6 +1251,25 @@ class C(object):\n \n         assert C() == copy.deepcopy(C())\n \n+    def test_no_references_to_original(self):\n+        \"\"\"\n+        When subclassing a slots class, there are no stray references to the\n+        original class.\n+        \"\"\"\n+\n+        @attr.s(slots=True)\n+        class C(object):\n+            pass\n+\n+        @attr.s(slots=True)\n+        class C2(C):\n+            pass\n+\n+        # The original C2 is in a reference cycle, so force a collect:\n+        gc.collect()\n+\n+        assert [C2] == C.__subclasses__()\n+\n \n class TestMakeCmp:\n     \"\"\"\n", "problem_statement": "Slots class holding a reference to the original version\nI have a class hierarchy implemented with slots enabled, like this:\r\n\r\nimport attr\r\n\r\n```python\r\n@attr.s(slots=True)\r\nclass BaseClass(object):\r\n    foo = attr.ib(default='foo')\r\n\r\n@attr.s(slots=True)\r\nclass SubClass(BaseClass):\r\n    bar = attr.ib(default='bar')\r\n```\r\n\r\nThis works fine until I wanted to introspect the class hierarchy:\r\n\r\n```python\r\nBaseClass.__subclasses__()  # returns [<class '__main__.SubClass'>, <class '__main__.SubClass'>]\r\n```\r\n\r\nOne of these is the original class, and the other is the new one created and returned by `attr.s`. This behavior manifests on both Python 3 and Python 2 (3.7.0 and 2.7.14, to be specific).\r\n\r\nMy understanding was that classes kept weak references to their subclasses to allow the `__subclasses__` method to work, and I know that attrs creates and returns a new class when `slots=True`, but it's not clear to me why the old class stays around. I don't see any obvious place where a strong reference to it is held.\r\n\r\nI guessed that there might be a reference cycle somewhere, so I tried adding a call to `gc.collect()` and checking `gc.garbage`, but that turned out to be incorrect.\r\n\r\nBecause I didn't see that the reference-counting mentioned [in this comment](https://github.com/python-attrs/attrs/issues/102#issuecomment-252526692) was ever addressed, I also guessed that this might be a leak due to the `__class__` closure cell fixup. I decided that this isn't the cause, either, because Python 2 does not have the `__class__` closure cell.\r\n\nSlots class holding a reference to the original version\nI have a class hierarchy implemented with slots enabled, like this:\r\n\r\nimport attr\r\n\r\n```python\r\n@attr.s(slots=True)\r\nclass BaseClass(object):\r\n    foo = attr.ib(default='foo')\r\n\r\n@attr.s(slots=True)\r\nclass SubClass(BaseClass):\r\n    bar = attr.ib(default='bar')\r\n```\r\n\r\nThis works fine until I wanted to introspect the class hierarchy:\r\n\r\n```python\r\nBaseClass.__subclasses__()  # returns [<class '__main__.SubClass'>, <class '__main__.SubClass'>]\r\n```\r\n\r\nOne of these is the original class, and the other is the new one created and returned by `attr.s`. This behavior manifests on both Python 3 and Python 2 (3.7.0 and 2.7.14, to be specific).\r\n\r\nMy understanding was that classes kept weak references to their subclasses to allow the `__subclasses__` method to work, and I know that attrs creates and returns a new class when `slots=True`, but it's not clear to me why the old class stays around. I don't see any obvious place where a strong reference to it is held.\r\n\r\nI guessed that there might be a reference cycle somewhere, so I tried adding a call to `gc.collect()` and checking `gc.garbage`, but that turned out to be incorrect.\r\n\r\nBecause I didn't see that the reference-counting mentioned [in this comment](https://github.com/python-attrs/attrs/issues/102#issuecomment-252526692) was ever addressed, I also guessed that this might be a leak due to the `__class__` closure cell fixup. I decided that this isn't the cause, either, because Python 2 does not have the `__class__` closure cell.\r\n\n", "hints_text": "When replacing the class in `slots=True` attrs has to make sure that the class hierarchy remains intact, therefore the returned class is a subclass of the original one. Does that answer your question?\nThat would answer the question, but I'm not convinced that it's true...\r\n\r\n```pycon\r\nPython 3.6.6 (default, Jun 27 2018, 13:11:40)\r\n[GCC 8.1.1 20180531] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import attr\r\n>>> @attr.s(slots=True)\r\n... class Foo: pass\r\n...\r\n>>> class Bar(Foo): pass\r\n...\r\n>>> AttrsBar = attr.s(slots=True)(Bar)\r\n>>> issubclass(AttrsBar, Bar)\r\nFalse\r\n```\nHm that might be due to how we create the class (by calling `type()` IIRC). Because OTOH:\r\n\r\n```pycon\r\n>>> import attr\r\n\r\n>>> class C: pass\r\n\r\n>>> C2 = attr.s(slots=True)(C)\r\n\r\n>>> C2.__mro__\r\n(<class '__main__.C'>, <class 'object'>)\r\n```\r\n\r\nSo the class is definitely there, it\u2019s just that Python subclass machinery doesn\u2019t know about it.\nI think you're being misled by the fact that the class generated by attrs still thinks its name is `C` despite being bound to `C2`:\r\n\r\n```pycon\r\n>>> import attr\r\n>>> class C: pass\r\n...\r\n>>> C2 = attr.s(slots=True)(C)\r\n>>> C2\r\n<class '__main__.C'>\r\n>>> C2.__mro__[0] is C\r\nFalse\r\n>>> C2.__mro__[0] is C2\r\nTrue\r\n```\r\n\r\nWhen the class [is created](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L533), it's using the original classes bases as the new bases, and I didn't see anywhere that the bases get modified...\nAh you\u2019re right, turns out we\u2019re more elaborate than I remembered:\r\n\r\nhttps://github.com/python-attrs/attrs/blob/35f7745ac22dab8ccfd82d7728623e9fdd5b76eb/src/attr/_make.py#L533\r\n\r\nSo I guess if we have a leak, `_ClassBuilder._create_slots_class()` would be the place to look? Have you tried something like https://mg.pov.lt/objgraph/?\nAh, no I hadn't thought of that...\r\n\r\n![attrs_slots_subclasses](https://user-images.githubusercontent.com/238853/42822571-5da1b2b8-89a9-11e8-926b-39917332edc2.png)\r\n\r\nI think that means the correct fix is to add `__weakref__` to the exception list here: https://github.com/python-attrs/attrs/blob/35f7745ac22dab8ccfd82d7728623e9fdd5b76eb/src/attr/_make.py#L493-L497\r\n\r\nWith that:\r\n\r\n```pycon\r\n>>> import attr\r\n>>> @attr.s(slots=True)\r\n... class C: pass\r\n...\r\n>>> @attr.s(slots=True)\r\n... class C2(C): pass\r\n...\r\n>>> import gc\r\n>>> gc.collect()\r\n11\r\n>>> C.__subclasses__()\r\n[<class '__main__.C2'>]\r\n```\r\n\r\nThe original class is left as a cyclic isolate when `attr.s` returns. I think that's as far as the attrs project needs to go to fix this; I'll call `gc.collect()` from my application. I'll write a test and open a PR today or tomorrow.\nWhen replacing the class in `slots=True` attrs has to make sure that the class hierarchy remains intact, therefore the returned class is a subclass of the original one. Does that answer your question?\nThat would answer the question, but I'm not convinced that it's true...\r\n\r\n```pycon\r\nPython 3.6.6 (default, Jun 27 2018, 13:11:40)\r\n[GCC 8.1.1 20180531] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import attr\r\n>>> @attr.s(slots=True)\r\n... class Foo: pass\r\n...\r\n>>> class Bar(Foo): pass\r\n...\r\n>>> AttrsBar = attr.s(slots=True)(Bar)\r\n>>> issubclass(AttrsBar, Bar)\r\nFalse\r\n```\nHm that might be due to how we create the class (by calling `type()` IIRC). Because OTOH:\r\n\r\n```pycon\r\n>>> import attr\r\n\r\n>>> class C: pass\r\n\r\n>>> C2 = attr.s(slots=True)(C)\r\n\r\n>>> C2.__mro__\r\n(<class '__main__.C'>, <class 'object'>)\r\n```\r\n\r\nSo the class is definitely there, it\u2019s just that Python subclass machinery doesn\u2019t know about it.\nI think you're being misled by the fact that the class generated by attrs still thinks its name is `C` despite being bound to `C2`:\r\n\r\n```pycon\r\n>>> import attr\r\n>>> class C: pass\r\n...\r\n>>> C2 = attr.s(slots=True)(C)\r\n>>> C2\r\n<class '__main__.C'>\r\n>>> C2.__mro__[0] is C\r\nFalse\r\n>>> C2.__mro__[0] is C2\r\nTrue\r\n```\r\n\r\nWhen the class [is created](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L533), it's using the original classes bases as the new bases, and I didn't see anywhere that the bases get modified...\nAh you\u2019re right, turns out we\u2019re more elaborate than I remembered:\r\n\r\nhttps://github.com/python-attrs/attrs/blob/35f7745ac22dab8ccfd82d7728623e9fdd5b76eb/src/attr/_make.py#L533\r\n\r\nSo I guess if we have a leak, `_ClassBuilder._create_slots_class()` would be the place to look? Have you tried something like https://mg.pov.lt/objgraph/?\nAh, no I hadn't thought of that...\r\n\r\n![attrs_slots_subclasses](https://user-images.githubusercontent.com/238853/42822571-5da1b2b8-89a9-11e8-926b-39917332edc2.png)\r\n\r\nI think that means the correct fix is to add `__weakref__` to the exception list here: https://github.com/python-attrs/attrs/blob/35f7745ac22dab8ccfd82d7728623e9fdd5b76eb/src/attr/_make.py#L493-L497\r\n\r\nWith that:\r\n\r\n```pycon\r\n>>> import attr\r\n>>> @attr.s(slots=True)\r\n... class C: pass\r\n...\r\n>>> @attr.s(slots=True)\r\n... class C2(C): pass\r\n...\r\n>>> import gc\r\n>>> gc.collect()\r\n11\r\n>>> C.__subclasses__()\r\n[<class '__main__.C2'>]\r\n```\r\n\r\nThe original class is left as a cyclic isolate when `attr.s` returns. I think that's as far as the attrs project needs to go to fix this; I'll call `gc.collect()` from my application. I'll write a test and open a PR today or tomorrow.", "created_at": "2018-07-18T00:08:38Z"}
{"repo": "python-attrs/attrs", "pull_number": 396, "instance_id": "python-attrs__attrs-396", "issue_numbers": ["364"], "base_commit": "908cb018f21beb4c139160c3d8a85db330e87cee", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -4,6 +4,16 @@\n \n import pytest\n \n+from hypothesis import HealthCheck, settings\n+\n+\n+def pytest_configure(config):\n+    # HealthCheck.too_slow causes more trouble than good -- especially in CIs.\n+    settings.register_profile(\n+        \"patience\", settings(suppress_health_check=[HealthCheck.too_slow])\n+    )\n+    settings.load_profile(\"patience\")\n+\n \n @pytest.fixture(scope=\"session\")\n def C():\n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -8,7 +8,7 @@\n \n import pytest\n \n-from hypothesis import HealthCheck, assume, given, settings\n+from hypothesis import assume, given\n from hypothesis import strategies as st\n \n import attr\n@@ -67,7 +67,6 @@ def test_nested_dicts(self, C):\n         assert {\"x\": {1: {2: {\"x\": 1, \"y\": 2}}}, \"y\": None} == asdict(outer)\n \n     @given(nested_classes, st.sampled_from(MAPPING_TYPES))\n-    @settings(suppress_health_check=[HealthCheck.too_slow])\n     def test_recurse_property(self, cls, dict_class):\n         \"\"\"\n         Property tests for recursive asdict.\n@@ -196,7 +195,6 @@ def test_recurse(self, C, tuple_factory):\n         ) == astuple(C(C(1, 2), C(3, 4)), tuple_factory=tuple_factory)\n \n     @given(nested_classes, st.sampled_from(SEQUENCE_TYPES))\n-    @settings(suppress_health_check=[HealthCheck.too_slow])\n     def test_recurse_property(self, cls, tuple_class):\n         \"\"\"\n         Property tests for recursive astuple.\n@@ -215,7 +213,6 @@ def assert_proper_tuple_class(obj, obj_tuple):\n         assert_proper_tuple_class(obj, obj_tuple)\n \n     @given(nested_classes, st.sampled_from(SEQUENCE_TYPES))\n-    @settings(suppress_health_check=[HealthCheck.too_slow])\n     def test_recurse_retain(self, cls, tuple_class):\n         \"\"\"\n         Property tests for asserting collection types are retained.\n", "problem_statement": "Suppress HealthCheck.too_slow for test_not_none_metadata\nOn very slow hardware, these may time out.\r\n\r\nBug: https://bugs.gentoo.org/651794\n", "hints_text": "# [Codecov](https://codecov.io/gh/python-attrs/attrs/pull/364?src=pr&el=h1) Report\n> Merging [#364](https://codecov.io/gh/python-attrs/attrs/pull/364?src=pr&el=desc) into [master](https://codecov.io/gh/python-attrs/attrs/commit/8274c9fdbc1513c87272340f92cd51dfea27c2ab?src=pr&el=desc) will **not change** coverage.\n> The diff coverage is `n/a`.\n\n[![Impacted file tree graph](https://codecov.io/gh/python-attrs/attrs/pull/364/graphs/tree.svg?token=BxTJx0Ibv7&src=pr&height=150&width=650)](https://codecov.io/gh/python-attrs/attrs/pull/364?src=pr&el=tree)\n\n```diff\n@@          Coverage Diff          @@\n##           master   #364   +/-   ##\n=====================================\n  Coverage     100%   100%           \n=====================================\n  Files           9      9           \n  Lines         831    831           \n  Branches      174    174           \n=====================================\n  Hits          831    831\n```\n\n\n\n------\n\n[Continue to review full report at Codecov](https://codecov.io/gh/python-attrs/attrs/pull/364?src=pr&el=continue).\n> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n> `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n> Powered by [Codecov](https://codecov.io/gh/python-attrs/attrs/pull/364?src=pr&el=footer). Last update [8274c9f...720dd35](https://codecov.io/gh/python-attrs/attrs/pull/364?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n\nIt might be better to have a global thing like:\r\n\r\n```python\r\nsettings.register_profile(\r\n    \"patience\", settings(suppress_health_check=[HealthCheck.too_slow])\r\n)\r\nsettings.load_profile(\"patience\")\r\n```\r\n\r\nAnd make the `load_profile` call conditional on an environment variable, rather than trying to suppress this for specific tests.  (All tests will time out on slow enough hardware.)\nYeah I think I agree with @wsanchez here. Trying to suppress only certain tests is a game of whac-a-mole. It should be all or none.\nThen push the relevant changes please?\n@hynek: Should we suppress these all the time or try to limit that to CI environments (eg. \"CI\" env var is set)?  I kinda lean towards the former; wall-clock timeouts like these aren't my favorite.\r\n\nHm ISTM that it\u2019s kind of a feature in local dev that some tests are not optimal.\r\n\r\nSo I\u2019d tend to an env var.  But would like  input from @Tinche and @DRMacIver on it.", "created_at": "2018-06-17T06:11:05Z"}
{"repo": "python-attrs/attrs", "pull_number": 394, "instance_id": "python-attrs__attrs-394", "issue_numbers": ["387"], "base_commit": "9c414702bd26c2793386250c4442d48864e3e0b9", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -671,7 +671,7 @@ def attrs(\n     :param bool cmp: Create ``__eq__``, ``__ne__``, ``__lt__``, ``__le__``,\n         ``__gt__``, and ``__ge__`` methods that compare the class as if it were\n         a tuple of its ``attrs`` attributes.  But the attributes are *only*\n-        compared, if the type of both classes is *identical*!\n+        compared, if the types of both classes are *identical*!\n     :param hash: If ``None`` (default), the ``__hash__`` method is generated\n         according how *cmp* and *frozen* are set.\n \n@@ -747,6 +747,11 @@ def attrs(\n     .. versionchanged:: 18.1.0\n        If *these* is passed, no attributes are deleted from the class body.\n     .. versionchanged:: 18.1.0 If *these* is ordered, the order is retained.\n+    .. deprecated:: 18.2.0\n+       ``__lt__``, ``__le__``, ``__gt__``, and ``__ge__`` now raise a\n+       :class:`DeprecationWarning` if the classes compared are subclasses of\n+       each other. ``__eq`` and ``__ne__`` never tried to compared subclasses\n+       to each other.\n     \"\"\"\n \n     def wrap(cls):\n@@ -885,6 +890,12 @@ def __ne__(self, other):\n     return not result\n \n \n+WARNING_CMP_ISINSTANCE = (\n+    \"Comparision of subclasses using __%s__ is deprecated and will be removed \"\n+    \"in 2019.\"\n+)\n+\n+\n def _make_cmp(attrs):\n     attrs = [a for a in attrs if a.cmp]\n \n@@ -938,6 +949,10 @@ def __lt__(self, other):\n         Automatically created by attrs.\n         \"\"\"\n         if isinstance(other, self.__class__):\n+            if other.__class__ is not self.__class__:\n+                warnings.warn(\n+                    WARNING_CMP_ISINSTANCE % (\"lt\",), DeprecationWarning\n+                )\n             return attrs_to_tuple(self) < attrs_to_tuple(other)\n         else:\n             return NotImplemented\n@@ -947,6 +962,10 @@ def __le__(self, other):\n         Automatically created by attrs.\n         \"\"\"\n         if isinstance(other, self.__class__):\n+            if other.__class__ is not self.__class__:\n+                warnings.warn(\n+                    WARNING_CMP_ISINSTANCE % (\"le\",), DeprecationWarning\n+                )\n             return attrs_to_tuple(self) <= attrs_to_tuple(other)\n         else:\n             return NotImplemented\n@@ -956,6 +975,10 @@ def __gt__(self, other):\n         Automatically created by attrs.\n         \"\"\"\n         if isinstance(other, self.__class__):\n+            if other.__class__ is not self.__class__:\n+                warnings.warn(\n+                    WARNING_CMP_ISINSTANCE % (\"gt\",), DeprecationWarning\n+                )\n             return attrs_to_tuple(self) > attrs_to_tuple(other)\n         else:\n             return NotImplemented\n@@ -965,6 +988,10 @@ def __ge__(self, other):\n         Automatically created by attrs.\n         \"\"\"\n         if isinstance(other, self.__class__):\n+            if other.__class__ is not self.__class__:\n+                warnings.warn(\n+                    WARNING_CMP_ISINSTANCE % (\"ge\",), DeprecationWarning\n+                )\n             return attrs_to_tuple(self) >= attrs_to_tuple(other)\n         else:\n             return NotImplemented\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1249,3 +1249,42 @@ class C(object):\n             )\n \n         assert C() == copy.deepcopy(C())\n+\n+\n+class TestMakeCmp:\n+    \"\"\"\n+    Tests for _make_cmp().\n+    \"\"\"\n+\n+    @pytest.mark.parametrize(\n+        \"op\", [\"__%s__\" % (op,) for op in (\"lt\", \"le\", \"gt\", \"ge\")]\n+    )\n+    def test_subclasses_deprecated(self, recwarn, op):\n+        \"\"\"\n+        Calling comparison methods on subclasses raises a deprecation warning;\n+        calling them on identical classes does not..\n+        \"\"\"\n+\n+        @attr.s\n+        class A(object):\n+            a = attr.ib()\n+\n+        @attr.s\n+        class B(A):\n+            pass\n+\n+        getattr(A(42), op)(A(42))\n+        getattr(B(42), op)(B(42))\n+\n+        assert [] == recwarn.list\n+\n+        getattr(A(42), op)(B(42))\n+\n+        w = recwarn.pop()\n+\n+        assert [] == recwarn.list\n+        assert isinstance(w.message, DeprecationWarning)\n+        assert (\n+            \"Comparision of subclasses using %s is deprecated and will be \"\n+            \"removed in 2019.\" % (op,)\n+        ) == w.message.args[0]\n", "problem_statement": "attrs._make should document why it is more restrictive with __eq__ than other comparisons\nThe type check in `__eq__` for generated classes is different than in other comparison methods.\r\n\r\nFor all other methods, `isinstance(other, self.__class__)` is used, which means subclasses will participate in the \"happy\" branch of the comparison.\r\n\r\nFor `__eq__` though, [`other.__class__ is self.__class__`](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L867) is used, so a trivial subclass will *not* compare equal, leading to the quite confusing:\r\n\r\n```\r\n>>> import attr; Parent = attr.make_class(\"Parent\", dict(foo=attr.ib())); Child = type(\"Child\", (Parent,), {}); print (Parent(foo=1) == Parent(foo=1), Parent(foo=1) == Child(foo=1), Parent(foo=1) < Parent(foo=2), Child(foo=1) < Parent(foo=2))\r\n(True, False, True, True)\r\n```\r\n\r\nThis strikes me as a bug (the incongruity), and that `__eq__` should use the same check, but even if it isn't, it likely bears mentioning that there's a difference.\r\n\r\nIt even seems like dataclasses have even done something [oddly similar](https://www.youtube.com/watch?v=T-TwcmT6Rcw#t=24m09s), maybe just straight copying the code here?\r\n\r\nhttps://github.com/python-attrs/attrs/commit/d134ce45fc98323576a19f03e39669dce615c4e1 looks like it's the commit that originally made the change (though since then `__eq__` now is hand-generated).\n", "hints_text": "Agreed; a reasonable developer would be surprised by the asymmetry described.\r\n\r\n(FWIW I am; though I try not to subclass, so hadn't noticed this.)\nWell yeah same, I think `attrs` should even have a `attr.s(..., allow_subclassing=True|False)` and default it to false :P, but that's a different story.\nAgree on all counts.\r\n\r\nAnd while it may be a bit off topic, I just wanted to echo a similar thought (experiment), that inheritance might be somewhat redeemed in a world where most types aren't open to extension by default. Not sure how deep attrs wants to dip into metaclasses.\nI suggest we start with some understanding about why this difference exists at all; without that, it's not obvious to me that it's even intentional.  (Though I want to assume that it is.)\nWell yeah, this one even made it to LWN: https://lwn.net/Articles/740153/\r\n\r\nThe question is in what direction we want to go. I find it hard to come to terms that two objects can be equal if they have different types. So my gut feeling would be to add a warning if someone compares instances that have different types and remove it in a year.\r\n\r\nBonus points for an option to allow to configure the behavior for both?\n> Well yeah, this one even made it to LWN: https://lwn.net/Articles/740153/\r\n\r\nFun :)\r\n\r\n> So my gut feeling would be to add a warning if someone compares instances that have different types and remove it in a year.\r\n\r\n+1\r\n\r\n> Bonus points for an option to allow to configure the behavior for both?\r\n\r\nIf I steal my own idea about `repr`, one could support this by having `attr.s(cmp=lambda self, other: isinstance(other, self.__class__))` (vs `cmp=lambda self, other: self.__class__ is other.__class__`, or `lambda self, other: False` / `True`), though I'm not inventive enough at the minute to think of any reason someone would want something other than those four options.\n@hynek I think I'm hearing that the existing difference is, in fact, accidental?  Anyway, I like the idea of warning/deprecating the `isinstance` behavior in the default comparators.\r\n\r\nI like the @Julian's idea of `cmp` accepting a callable, and have be thinking about that for a while\u2026 but  I'd like to consider other uses than the type precondition.  For example, I'd like to be able to change the compared data from the default of calling `attrs_to_tuple` on each object.  In my case I've wanted to change the order of the attributes, or have one of them sorted the other direction than the default (\"descending\"), and right now I have to implement my own comparators in order to do that.  More generally, one might want `cmp` to accept a callable like  Python 2's [`__cmp__`](https://docs.python.org/2/reference/datamodel.html?highlight=__cmp__#object.__cmp__) operator function\u2026\nIf you want to swap out the whole implementation wouldn't you just use `cmp=False`?\nWell, it's a lot more\u2026 boilerplate to implement all of the `__foo__` methods than it is to provide an alternative to `attrs_to_tuple`.\r\n\r\nProbably I should fess up and show an example.  I [did this as a mix-in](https://github.com/burningmantech/ranger-ims-server/blob/master/src/ims/model/_cmp.py#L31) such that all I need to do in classes that inherit from the mix-in is implement `_cmpValue`.  [Here's a simple example](https://github.com/burningmantech/ranger-ims-server/blob/master/src/ims/model/_address.py#L105) in which all I do is change the order of the compared values because I want `description` to be factored in last.  [Here's another](https://github.com/burningmantech/ranger-ims-server/blob/master/src/ims/model/_entry.py#L62) when I just invert one of the values.  This is a lot easier than implementing all of the dunders in each class.\r\n\r\nSorry if this is a tangent; it probably should be a separate ticket, but it effects this if we want to overload `cmp`, so just trying to get ahead of that.\r\n\nI'm not quite sure which way this thread is leaning at this point.  `is` or `isinstance()`?  If configurable, then which default?\n@wsanchez ah I see, well, I guess if we're dragging tangents into things I am pretty strongly against the way the current implementation combines equality with ordering, which is at least partially relevant for what you're doing there. Possibly yet a third ticket (or maybe it exists already I forget) though.\n@altendky My read of @hynek's comment is that we'd prefer `is` as the default, we should deprecate the current use of `isinstance`, and configurability is a bonus.  (And I agree with all that.)\n@Julian yeah, I agree that combining the two is problematic.  Th reason I think it's relevant here is that I suspect any configuration option we pick here (if we do) could make fixing that problem harder.\nI guess I don't follow how `is` would be expected behavior when inheriting.  I get tending away from inheritance (more or less strongly) but trivially inheriting a class shouldn't make it not equal, should it?  Wouldn't LSP encourage `isinstance()`?  I'm split between thinking I'm missing something and thinking that a dislike of inheritance is going to result in breaking it for those that use it.\r\n\r\nNote: I don't think I've inherited from an attrs class yet so I'm not arguing because of any direct effect I expect it to have on me.\n@altendky It's a fair point, because it's really non-obvious and I don't know of a settled best practice here, but the `is` check is simply being conservative, because the parent class' implementation of, say `__eq__` can't be sure that a subclass is equal any more than it can of a rando object.\r\n\r\nIf the subclass adds a field (certainly not uncommon), that field\u2026 wait\u2026 yes?\u2026 that field is not factored into the equality test.  (I hesitate because I'm looking at [`attrs_to_tuple`](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L902) and it's a closure that uses the same `attrs` for both `self` and `other`, but I'm not super familiar with that code.)\r\n\r\nThe thing is that the default implementation provided by `attrs` doesn't know what a subclass considers equal, so returning `NotImplemented` is just saying \"I dunno\".\r\n\r\nIt would be nice if one could explicitly declare a subclass as considering its instances equal to those of the parent class with equal field values, but I'm a little wary of an implementation that assumes this is true.\nI need to get a better understanding of LSP.  It seems to be part of 'proper' inheritance, but it also seems to hog tie subclasses.\nRandom thought: isinstance also means that if you compare a and b and b is a subclass of a, you get different results for a == b and b == a. \nNot sure now I'm following the last few comments --\r\n\r\nthe two options though would have to be `is`, or `isinstance` *plus* a field length check, because a subclass that adds fields seems pretty clearly like it shouldn't be `==` according to anyone, so you can't use *just* `isinstance`.\r\n\r\nBut in the latter case (`isinstance` + field length check) you get associativity and transitivity, so not sure I follow there, maybe I'm missing something.\r\n\r\nAnd if I didn't mention it earlier, yeah personally I'd lean towards that one, but since I am in the \"don't use inheritance\" camp I wouldn't argue heavily for it :P\nI guess comparisons are a well known exception to LSP?  Or LSP is just considered not relevant anymore?\r\n\r\nI still need to study it...\nNo your argument is good IMHO :)\nThen even `isinstance(other, type(self))` is too restrictive because a trivial child will reject a parent with matching attribute values.  Unless LSP is only about full substitution of all instances to the sun type and not about mixing parent and child instances.  I'd think this would agree with both other languages where a parent comparison method wouldn't even be aware of any new attributes on a child class as well as aligning with duck typing in Python.\n> Then even isinstance(other, type(self)) is too restrictive because a trivial child will reject a parent with matching attribute values.\r\n\r\nThis is what I meant in https://github.com/python-attrs/attrs/issues/387#issuecomment-395295204 btw. I guess we\u2019d have to check both ways and that is kind of getting silly.\r\n\r\nThe more I think about it, the more I\u2019m convinced we should go the `is` route and only add more options if there\u2019s enough people complaining.\nWhat about using `super()`?  If that passes and `isinstance(other, type(self))` then extra attributes of the subclass are compared.  I think that would pass.  I think that to satisfy LSP that any attributes added in a subclass would have to have defaults.\nThat won't work when the parent is on the left of the comparison -- it would call super, and not return `NotImplemented`, and then proceed to only compare to a subset of the subclass's fields.\r\n\r\nThough again I must not be following because this is the one option that I think *shouldn't* be on the table -- the only reasonable option that uses `isinstance` is returning `NotImplemented` for `not isinstance(other, self.__class__) or attr.fields(self) != attr.fields(other)`, just using the first part of the conditional there I think definitely produces nonsense for subclasses that add extra fields.\n@Julian I'll try an example and see what I see.  It does seem odd though that we are talking about inheritance and the one thing to not consider using is `super()`.\nFor what it's worth, there's also:\r\n\r\n```python\r\n@attr.s\r\nclass Rectangle(object):\r\n    width: float\r\n    height: float\r\n\r\n    def area(self) \u279c float:\r\n        return self.width * self.height\r\n\r\n@attr.s\r\nclass RedRectangle(object):\r\n    pass\r\n\r\n@attr.s\r\nclass BlueRectangle(object):\r\n    pass\r\n```\r\n\r\nIn which case, one might `assert RedRectangle(1,2) != BlueRectangle(1,2)` and perhaps even `assert RedRectangle(1,2) != Rectangle(1,2)`.  This is obviously contrived, but I don't think one can really just assume that subclasses with the same fields are equal.\r\n\r\nAlso: I see the auto-correct typo above, but Python really should accept `\u279c` as equivalent to `->`.\nJust my two cents here.\r\n\r\nThe most accurate definition of LSP I've ever found is this one:\r\n\r\n> Objects of subtypes should behave like those of supertypes if used via supertype methods.\r\n\r\nFor me it is essentially *the same* than duck typing. And the important point here is the \"if used via supertype methods\" part.\r\n\r\nThis has nothing to do with which fields do the subtypes have. So taking into account the _fields_ in the comparison would go in the wrong direction in respect to LSP... but, does this really have to do with LSP at all? I don't think so, but I'm also not so sure as to make an statement. \r\n\r\nWhat I'm sure of (and I hope anyone seriously following this thread) is that **Identity** is not a simple problem, but a really complex one because it involves what **you** mean by **Identity**. It depends on what you give \"relevance\" to and what you \"filter out\" of the comparison.\r\n\r\nSo what to do in cases like this one? When in doubt, I tend to apply the Fail-soon principle: implement by default the most restrictive code, the one that will throw an error sooner than others (in this case, the `is` comparison) so one will hit the problem the first time \"**it just doesn't work as I thought it worked**\". \r\n\r\nAnd then let me implement a different comparison method by my own when I have a more clear idea of what _equal_ means **for me** (which is already possible with `attrs`). In case of using inheritance, you will have to do this just once at the base class, so it is not a big deal anyway.\r\n\n@xgid I think I agree with almost all of that -- the only issue here is that there is no \"failure\" here -- Python doesn't throw errors when things don't implement equality, it coerces to a value no matter what.\r\n\r\nSo you do need to carefully pick the better of the two options.\nEhm. *Your* EOL Python maybe. \ud83d\ude43\r\n\r\n*Edit* oh wait you wrote equality...well that one is already strict so that can\u2019t be changed anyways. \n@hynek your shiny one too.\r\n\r\n```\r\n\u2299  python3 -c '                                                                                                                                                                                                                                                                                                                                           Julian@Macnetic \u25cf\r\nquote> class Foo(object):\r\nquote>     def __eq__(self, other):\r\nquote>         return NotImplemented\r\nquote> print(Foo() == Foo())'\r\nFalse\r\n```\r\n\r\nThe only thing it fixed there was the comparison operators I believe. Equality ones still always coerce.\n@Julian Sorry, I was not explicit enough regarding the `__eq__` implementation I'm proposing. \r\n\r\nI mean just:\r\n\r\n```python\r\ndef __eq__(self, other):\r\n    return  id(self) == id(other)\r\n```\r\n\r\nWhen I said \"_the one that will throw an error sooner than others_\" I was not meaning to return `NotImplemented` nor an exception. Just that the more restrictive implementation shown above will give you a comparison error in your code whenever you expect that something \"equivalent\"(1) to this will work:\r\n\r\n```python\r\nassert Foo(1,2) == Foo(1,2)\r\n```\r\ninstead of succeeding. \r\n\r\nIf it succeeds, you may not find the (logical) \"bug\" in your code until much much later. It's a kind of \"defensive programming\", but just for those \"corner cases where things may get dangerous if you are not aware of the real implications\", like this one.\r\n\r\n(1) By \"equivalent\" above I mean that this may be a _simple_ `if a == b` in your code for which you expect that the comparison will be successful.\r\n\r\n**Edit**: Just now I see that I made a mess talking about \"the `is` comparison\" at my first comment. Don't know what I was thinking about... \ud83d\ude33 \n@xgid That's just the `object` provided `==` isn't it?  So suggesting that is basically suggesting not implementing `__eq__` at all from an attrs perspective?\r\n\r\nAfter chatting with @Julian and reading around a bit more I think I see what I was missing.  It seems that the basic issue is a contention between satisfying both mathematical properties and Liskov.  The desire to use `==` as a way to access the equality check which should satisfy mathematical constraints brings in the inheritance factor and therefor Liskov.  So, don't use `__eq__`...  :]  My guess is that isn't an option we are looking to consider here but this does make me feel that any solution is going to be a compromise of some principal.  I haven't analyzed the situation carefully but `OrderedDict` is a 'classic' example of this issue and a solution that is tending towards the Liskov side over the math side of correctness.\r\n\r\nThere were suggestions that the reason for `is` type checking making sense is that equality is a type of equivalence relation and that they are defined on members of a set.  An `__eq__` method on a class that can be inherited may be applied to things that we can't include in the set we are considering when writing the `__eq__` because the subclasses haven't even been written yet.  At least by considering only the same type for a `True` result you have restricted the set of things that might be equal.  A bit of a helpful explanation for me at least.\r\n\r\nPerhaps there are some options here.  Default to no `__eq__` method (IOW `id()` checking from `object` iirc) and force people to...  implement their own?  pick between a pre-existing set of options that satisfy either math or Liskov?  It encourages them to check the docs and get a brief explanation of the dilemma and at least they have made the decision.\r\n\r\nI'm really not sure what I think should happen anymore but I at least better understand the issue with where I was going.  FWIW, I made a little implementation and set of tests while exploring my approach.\r\n\r\nhttps://repl.it/@altendky/LSP-and-eq-1\r\n\n@altendky \r\n\r\n> That's just the object provided == isn't it? So suggesting that is basically suggesting not implementing __eq__ at all from an attrs perspective?\r\n\r\nExactly! And for the exact same reasons you have explained better than me in your comment. The final goal is precisely that \"_It encourages them to check the docs and get a brief explanation of the dilemma_\" before they choose anything \"meaninful\" for them.\r\n\r\nIf I can also easily \"pick between a pre-existing set of options\", that would be even better, of course! I was talking only about the **default implementation**.\r\n\n> @xgid That's just the object provided == isn't it? So suggesting that is basically suggesting not implementing __eq__ at all from an attrs perspective?\r\n\r\nReturning `NotImplemented` allows the other object implement a comparator, so explicitly implementing an identity test in a class defeats the design of how Python implements these operators, no?\n@wsanchez I'm not sure what your comment means in regards to that quote.  That if someone were considering not implementing `__eq__` that they should instead implement it and `return NotImplemented`?  By 'object provided ==' I was referring to the `__eq__` provided by the type `object` that we all inherit from.\nWhat I mean is that the way `__eq__` works is that if you don't want to implement it, then don't add the method, or return `NotImplemented` when you don't know.  If you implement it as simply `return  id(self) == id(other)` (which is, I think, more simply written as `self is other`) then you are forcing an identity test to be used, instead of allowing such a test to be a fallback in the absence of, say, the other object implementing a comparator.\nAh, implementing `__eq__` as `self is other` is not the same as leaving it to `object`'s implementation because of other getting a chance in the latter case.  I see the connection.\nJFTR I\u2019ve just noticed that the docs were always very clear on this matter: `But the attributes are only compared, if the type of both classes is identical!`\r\n\r\nSo technically we could even get away without a deprecation period but let\u2019s do it anyways.", "created_at": "2018-06-16T05:59:11Z"}
{"repo": "python-attrs/attrs", "pull_number": 383, "instance_id": "python-attrs__attrs-383", "issue_numbers": ["382"], "base_commit": "8274c9fdbc1513c87272340f92cd51dfea27c2ab", "patch": "diff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -135,7 +135,12 @@ class _InValidator(object):\n     options = attrib()\n \n     def __call__(self, inst, attr, value):\n-        if value not in self.options:\n+        try:\n+            in_options = value in self.options\n+        except TypeError as e:  # e.g. `1 in \"abc\"`\n+            in_options = False\n+\n+        if not in_options:\n             raise ValueError(\n                 \"'{name}' must be in {options!r} (got {value!r})\"\n                 .format(name=attr.name, options=self.options, value=value)\n", "test_patch": "diff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -243,6 +243,19 @@ def test_fail(self):\n             \"'test' must be in [1, 2, 3] (got None)\",\n         ) == e.value.args\n \n+    def test_fail_with_string(self):\n+        \"\"\"\n+        Raise ValueError if the value is outside our options when the\n+        options are specified as a string and the value is not a string.\n+        \"\"\"\n+        v = in_(\"abc\")\n+        a = simple_attr(\"test\")\n+        with pytest.raises(ValueError) as e:\n+            v(None, a, None)\n+        assert (\n+            \"'test' must be in 'abc' (got None)\",\n+        ) == e.value.args\n+\n     def test_repr(self):\n         \"\"\"\n         Returned validator has a useful `__repr__`.\n", "problem_statement": "Poor error message/type for validators.in_ with a string\n```python\r\nimport attr\r\n\r\n@attr.s\r\nclass C:\r\n   s = attr.ib(validator=attr.validators.in_('abc'))\r\n\r\nC(s=1)  # TypeError: 'in <string>' requires string as left operand, not int\r\n```\r\n\r\n`__contains__` behaves a little weirdly for strings, but I still think this error could be improved.\r\n\r\nObvious options would be to catch exceptions and re-raise something with a clearer error message, and/or to deprecate use of strings as the collection here.\r\n\r\nFound in attrs=18.1.0 while working on HypothesisWorks/hypothesis#954.\n", "hints_text": "What is the actual problem here? I don't think it's fair to expect in_ to also type check?\r\n\r\nI think you want\r\n\r\n```python\r\ns = attr.ib(validator=[attr.validators.instance_of(str), attr.validators.in_('abc')])\r\n```\r\n\r\n?\nI think the request is for something like:\r\n\r\n```python\r\n    def __call__(self, inst, attr, value):\r\n        if value not in self.options:\r\n            try:\r\n                raise ValueError(\r\n                    \"'{name}' must be in {options!r} (got {value!r})\"\r\n                    .format(name=attr.name, options=self.options, value=value)\r\n                )\r\n            except Exception as e:\r\n                raise AssertionError(\r\n                    \"in_ validator for attribute {attr} raised exception for value {value}: {error}\"\r\n                    .format(attr=attr, value=value, error=e)\r\n                )\r\n```\r\n\nAlmost - the idea is that if `value in self.options` raises an exception instead of returning a bool, we should still raise a ValueError (not e.g. TypeError), and preferably one with a useful and consistent message.\r\n\r\nI'd write this as follows, and would be happy to open a PR if that would be helpful \ud83d\ude04 \r\n\r\n```python\r\ndef __call__(self, inst, attr, value):\r\n\ttry:\r\n\t\tif value not in self.options:\r\n\t\t\traise ValueError(\r\n\t\t\t\t\"'{name}' must be in {options!r} (got {value!r})\"\r\n\t\t\t\t.format(name=attr.name, options=self.options, value=value)\r\n\t\t\t)\r\n\texcept Exception:\r\n\t\traise ValueError(\r\n\t\t\t\"'{name}' must be in {options!r} \"\r\n\t\t\t\"(got {value!r}, which caused an internal error)\"\r\n\t\t\t.format(name=attr.name, options=self.options, value=value)\r\n\t\t)\r\n```\nThe contract for validators isn't super clear in the docs, but I don't see anything that says that `ValueError` is the only acceptable sort of exception to raise.  That probably should be clarified, but I would think `TypeError` is a valid exception to raise in the case where data of the wrong type is given, as in this example.\r\n\r\nI do agree that the a better error message would be useful, but I'd definitely include the original exception text.\nUh yeah there is absolutely no contract about what kind of exceptions are raised by validators and I\u2019d even argue that changing it could be backward incompatible. \ud83e\udd14\nI think it might make some sense for us to advise that certain exceptions are used, but I wouldn't go farther than that.  Otherwise, every validator would have to wrap a try/except around it's body, which could be a best practice, but seems like a lame thing to require.\r\n\r\nWhich leaves us with: should we do better than the above error message.  I notice I wrapped the try/except in my example around the wrong code (oops).\r\n\r\nLemme try again with a different suggestion:\r\n\r\n```python\r\n    def __call__(self, inst, attr, value):\r\n        try:\r\n            in_options = value in self.options\r\n        except TypeError as e:\r\n            in_options = False\r\n\r\n        if not in_options:\r\n            raise ValueError(\r\n                \"'{name}' must be in {options!r} (got {value!r})\"\r\n                .format(name=attr.name, options=self.options, value=value)\r\n            )\r\n```\r\n\r\nI don't think trying to catch all exceptions is necessarily more correct, but we can definitely say that a non-string object isn't in the provide bucket (that happens to be a string) of options.  Since that bucket isn't required to contain objects of a homogenous type, I returning `False` is more appropriate (or consistent with, say a `list`) than raising a `TypeError`.\r\n\nI guess I would accept a PR in this case.", "created_at": "2018-05-23T13:16:10Z"}
{"repo": "python-attrs/attrs", "pull_number": 375, "instance_id": "python-attrs__attrs-375", "issue_numbers": ["351"], "base_commit": "7a80d57d1cfe241ff47ed8241893f40d2c7b639f", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -106,7 +106,7 @@ def attrib(default=NOTHING, validator=None,\n \n         The validator can also be set using decorator notation as shown below.\n \n-    :type validator: ``callable`` or a ``list`` of ``callable``\\ s.\n+    :type validator: ``callable`` or a ``list`` of ``callable``\\\\ s.\n \n     :param bool repr: Include this attribute in the generated ``__repr__``\n         method.\n@@ -1125,7 +1125,7 @@ def fields_dict(cls):\n         class.\n \n     :rtype: an ordered dict where keys are attribute names and values are\n-        :class:`attr.Attribute`\\ s. This will be a :class:`dict` if it's\n+        :class:`attr.Attribute`\\\\ s. This will be a :class:`dict` if it's\n         naturally ordered like on Python 3.6+ or an\n         :class:`~collections.OrderedDict` otherwise.\n \ndiff --git a/src/attr/filters.py b/src/attr/filters.py\n--- a/src/attr/filters.py\n+++ b/src/attr/filters.py\n@@ -23,7 +23,7 @@ def include(*what):\n     Whitelist *what*.\n \n     :param what: What to whitelist.\n-    :type what: :class:`list` of :class:`type` or :class:`attr.Attribute`\\ s\n+    :type what: :class:`list` of :class:`type` or :class:`attr.Attribute`\\\\ s\n \n     :rtype: :class:`callable`\n     \"\"\"\n@@ -40,7 +40,7 @@ def exclude(*what):\n     Blacklist *what*.\n \n     :param what: What to blacklist.\n-    :type what: :class:`list` of classes or :class:`attr.Attribute`\\ s.\n+    :type what: :class:`list` of classes or :class:`attr.Attribute`\\\\ s.\n \n     :rtype: :class:`callable`\n     \"\"\"\n", "test_patch": "", "problem_statement": "Fix warning from py3 regarding \"improper regex escapes\"\npy3 emits warnings about strings which contain improper character escapes. This silences one of those warnings, while keeping the desired documentation output.\r\n\n", "hints_text": "I\u2019m kind of baffled I haven\u2019t caught that warning before. :|. But this doesn\u2019t work. I think the correct the approach is to make the string raw?", "created_at": "2018-04-28T21:21:37Z"}
{"repo": "python-attrs/attrs", "pull_number": 367, "instance_id": "python-attrs__attrs-367", "issue_numbers": ["361"], "base_commit": "57817b2c0e9cf98a2d974e8e845e8f6a1a1be89a", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -23,6 +23,8 @@\n _init_converter_pat = \"__attr_converter_{}\"\n _init_factory_pat = \"__attr_factory_{}\"\n _tuple_property_pat = \"    {attr_name} = property(itemgetter({index}))\"\n+_classvar_prefixes = (\"typing.ClassVar\", \"t.ClassVar\", \"ClassVar\")\n+\n _empty_metadata_singleton = metadata_proxy({})\n \n \n@@ -232,10 +234,11 @@ def _is_class_var(annot):\n     \"\"\"\n     Check whether *annot* is a typing.ClassVar.\n \n-    The implementation is gross but importing `typing` is slow and there are\n-    discussions to remove it from the stdlib alltogether.\n+    The string comparison hack is used to avoid evaluating all string\n+    annotations which would put attrs-based classes at a performance\n+    disadvantage compared to plain old classes.\n     \"\"\"\n-    return str(annot).startswith(\"typing.ClassVar\")\n+    return str(annot).startswith(_classvar_prefixes)\n \n \n def _get_annotations(cls):\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -11,6 +11,7 @@\n \n import attr\n \n+from attr._make import _classvar_prefixes\n from attr.exceptions import UnannotatedAttributeError\n \n \n@@ -204,13 +205,14 @@ class A:\n         assert A.__init__.__annotations__ == {'return': None}\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n-    def test_annotations_strings(self, slots):\n+    @pytest.mark.parametrize(\"classvar\", _classvar_prefixes)\n+    def test_annotations_strings(self, slots, classvar):\n         \"\"\"\n         String annotations are passed into __init__ as is.\n         \"\"\"\n         @attr.s(auto_attribs=True, slots=slots)\n         class C:\n-            cls_var: 'typing.ClassVar[int]' = 23\n+            cls_var: classvar + '[int]' = 23\n             a: 'int'\n             x: 'typing.List[int]' = attr.Factory(list)\n             y: 'int' = 2\n", "problem_statement": "Support ClassVar string annotations\nThe following doesn't work in Python 3.7\r\n\r\n```\r\nfrom __future__ import annotations\r\nimport attr\r\nfrom typing import ClassVar\r\n\r\n@attr.dataclass\r\nclass A:\r\n    x: ClassVar[int]\r\n\r\na = A()\r\n```\r\n\r\nBecause `ClassVar[int]` will be `'ClassVar[int]` in `A.__annotations__` and so `return str(annot).startswith(\"typing.ClassVar\")` returns `False`.\r\n\r\nYou can repro without 3.7 using this:\r\n\r\n```\r\nimport attr\r\nfrom typing import ClassVar\r\n\r\n@attr.dataclass\r\nclass A:\r\n    x: 'ClassVar[int]'\r\n\r\na = A()\r\n```\r\n\r\nNote: It's weird I'm not giving it a value but if I do then attrs will think it's a default value and the code won't error out.\r\n\r\nOh and the following works fine:\r\n```\r\nimport attr\r\nimport typing\r\n\r\n@attr.dataclass\r\nclass A:\r\n    x: 'typing.ClassVar[int]'\r\n\r\na = A()\r\n```\r\n\n", "hints_text": "Oh god more string comparisons. \ud83d\ude48\nThis is the last blocker for the next release. Any ideas how to solve this save expanding the comparison to just ClassVar and call it a day?\nI believe these are our only viable options:\r\n\r\n1. `eval` the first part (up to the first `[`) of every string annotation.  \r\n* If it raises, move on, if you get something check if it's a ClassVar.\r\n* Pros:  Catches every possible invocation, `from typing import ClassVar as MyClassVar`\r\n* Cons: I imagine this is prohibitively slow but it could be tested.\r\n  \r\n2. Just check for `.startswith('ClassVar')` also and move on.\r\n* Pros: Fast.\r\n* Cons: This will miss `as` imports.  And will also ignore situations in which you didn't import ClassVar correctly or at all.  e.g.\r\n```\r\n@attr.s(auto_attrib=True)\r\nclass a:\r\n    a: 'ClassVar'\r\n```\r\n(Though any good linter would catch that)\r\n\nCan I haz a non-terrible third option? :'(\nThe non-gross option is to import typing and use `get_type_hints()`. I thought you're already doing that for resolving regular fields but apparently not.\r\n\r\nHow about this: if user code *is* using annotations *and* that annotation is a string, *then* we import typing and use `get_type_hints()` like grown-ups? In all likelihood if the code was already using annotations, it was importing typing somewhere anyway so there's no danger of slowing anybody down. Plus, since user code is already using annotations, we know it's Python 3 so `typing` is there?\r\n\r\nLet me create a pull request to that effect.\nOK, so I tried the above and it seems it's a nuclear option since it forces all annotations to be evaluated. This is what I wanted to avoid with `from __future__ import annotations`.\r\n\r\nMaking it more intelligent would be possible with `typing.ForwardRef` and its `_evaluate()` method but those are only available on 3.7+ (PEP 560).\r\n\r\nI looked what `dataclasses` do in this case and they also don't work with `from __future__ import annotations` which I need to fix before Python 3.7 beta4.\r\n\r\nSo my pull request is going with Euresti's Option 2. This is going to be enough for 99.9% users.", "created_at": "2018-04-11T08:32:48Z"}
{"repo": "python-attrs/attrs", "pull_number": 363, "instance_id": "python-attrs__attrs-363", "issue_numbers": ["249"], "base_commit": "c2fef8c6973ad4ce57b0a2f41a46b97b26dde2de", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1034,7 +1034,7 @@ def _make_init(attrs, post_init, frozen, slots, super_attr_map):\n         sha1.hexdigest()\n     )\n \n-    script, globs = _attrs_to_init_script(\n+    script, globs, annotations = _attrs_to_init_script(\n         attrs,\n         frozen,\n         slots,\n@@ -1063,7 +1063,9 @@ def _make_init(attrs, post_init, frozen, slots, super_attr_map):\n         unique_filename,\n     )\n \n-    return locs[\"__init__\"]\n+    __init__ = locs[\"__init__\"]\n+    __init__.__annotations__ = annotations\n+    return __init__\n \n \n def _add_init(cls, frozen):\n@@ -1259,6 +1261,7 @@ def fmt_setter_with_converter(attr_name, value_var):\n     # This is a dictionary of names to validator and converter callables.\n     # Injecting this into __init__ globals lets us avoid lookups.\n     names_for_globals = {}\n+    annotations = {'return': None}\n \n     for a in attrs:\n         if a.validator:\n@@ -1349,6 +1352,9 @@ def fmt_setter_with_converter(attr_name, value_var):\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name))\n \n+        if a.init is True and a.converter is None and a.type is not None:\n+            annotations[arg_name] = a.type\n+\n     if attrs_to_validate:  # we can skip this if there are no validators.\n         names_for_globals[\"_config\"] = _config\n         lines.append(\"if _config._run_validators is True:\")\n@@ -1368,7 +1374,7 @@ def __init__(self, {args}):\n \"\"\".format(\n         args=\", \".join(args),\n         lines=\"\\n    \".join(lines) if lines else \"pass\",\n-    ), names_for_globals\n+    ), names_for_globals, annotations\n \n \n class Attribute(object):\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -32,6 +32,11 @@ class C:\n         assert int is attr.fields(C).x.type\n         assert str is attr.fields(C).y.type\n         assert None is attr.fields(C).z.type\n+        assert C.__init__.__annotations__ == {\n+            'x': int,\n+            'y': str,\n+            'return': None,\n+        }\n \n     def test_catches_basic_type_conflict(self):\n         \"\"\"\n@@ -57,6 +62,11 @@ class C:\n \n         assert typing.List[int] is attr.fields(C).x.type\n         assert typing.Optional[str] is attr.fields(C).y.type\n+        assert C.__init__.__annotations__ == {\n+            'x': typing.List[int],\n+            'y': typing.Optional[str],\n+            'return': None,\n+        }\n \n     def test_only_attrs_annotations_collected(self):\n         \"\"\"\n@@ -68,6 +78,10 @@ class C:\n             y: int\n \n         assert 1 == len(attr.fields(C))\n+        assert C.__init__.__annotations__ == {\n+            'x': typing.List[int],\n+            'return': None,\n+        }\n \n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_auto_attribs(self, slots):\n@@ -115,6 +129,15 @@ class C:\n             i.y = 23\n             assert 23 == i.y\n \n+        assert C.__init__.__annotations__ == {\n+            'a': int,\n+            'x': typing.List[int],\n+            'y': int,\n+            'z': int,\n+            'foo': typing.Any,\n+            'return': None,\n+        }\n+\n     @pytest.mark.parametrize(\"slots\", [True, False])\n     def test_auto_attribs_unannotated(self, slots):\n         \"\"\"\n@@ -154,3 +177,51 @@ class C(A):\n \n         assert \"B(a=1, b=2)\" == repr(B())\n         assert \"C(a=1)\" == repr(C())\n+\n+        assert A.__init__.__annotations__ == {\n+            'a': int,\n+            'return': None,\n+        }\n+        assert B.__init__.__annotations__ == {\n+            'a': int,\n+            'b': int,\n+            'return': None,\n+        }\n+        assert C.__init__.__annotations__ == {\n+            'a': int,\n+            'return': None,\n+        }\n+\n+    def test_converter_annotations(self):\n+        \"\"\"\n+        Attributes with converters don't have annotations.\n+        \"\"\"\n+\n+        @attr.s(auto_attribs=True)\n+        class A:\n+            a: int = attr.ib(converter=int)\n+\n+        assert A.__init__.__annotations__ == {'return': None}\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_annotations_strings(self, slots):\n+        \"\"\"\n+        String annotations are passed into __init__ as is.\n+        \"\"\"\n+        @attr.s(auto_attribs=True, slots=slots)\n+        class C:\n+            cls_var: 'typing.ClassVar[int]' = 23\n+            a: 'int'\n+            x: 'typing.List[int]' = attr.Factory(list)\n+            y: 'int' = 2\n+            z: 'int' = attr.ib(default=3)\n+            foo: 'typing.Any' = None\n+\n+        assert C.__init__.__annotations__ == {\n+            'a': 'int',\n+            'x': 'typing.List[int]',\n+            'y': 'int',\n+            'z': 'int',\n+            'foo': 'typing.Any',\n+            'return': None,\n+        }\n", "problem_statement": "Annotate __init__ with type hints?\nSo I'm not sure this makes 100% sense, but technically we could start adding type hints to the signature of our `__init__`.\r\n\r\nI guess there would be some runtime introspection benefits?\n", "hints_text": "Ooh, yes please - [Hypothesis](HypothesisWorks/hypothesis-python) does runtime introspection of type hints to work out how to call things when the user didn't supply all the required arguments for an example object to test.  We'd like deeper integration with attrs on our end at some point, but adding type hints would be a great start - and also work for other projects doing similar things \ud83d\ude04 \n+1 for this. I'm trying to use attrs with [injector](https://github.com/alecthomas/injector), and currently it does not work because `__init__` generated by attrs \"looses\" annotations:\r\n\r\n```\r\n>>> class Inner: pass\r\n... \r\n>>> @attr.s\r\n... class Outer:\r\n...     inner: Inner = attr.ib()\r\n... \r\n>>> Outer.__init__.__annotations__\r\n{}\r\n```\nI came here specifically to see about adding support for annotation of `__init__`. My use case is exactly the same as @haizaar except that I plan to use `auto_attribs`.\r\n\r\nI'd do it myself, but the code isn't particularly beginner-friendly.\r\n\r\nOne approach would be to simply add a block inside `_ClassBuilder.add_init` where we get the annotations off the decorated class and put them on the generated init method. Possibly by doing something like:\r\n\r\n```\r\ninit = self._cls_dict['__init__']\r\nannotations = get_type_hints(self._cls)\r\ninit_arg_list = init.__code__.co_varnames\r\nfor annotation_key, annotation_value in annotations \r\n    if annotation_key in init_arg_list:\r\n        add_annotation(init, annotation_key, annotation_value)\r\n        remove_annotation(self._cls, annotation_key)\r\n```\r\n\r\nalthough i suspect this is extremely unportable (on the other hand, it appears that it could work in pypy3).\r\n\r\nAlso, there is a great deal of stuff I don't really understand (and which is not related to my use case) involving super-attrs and whatnot. I don't understand what those are, so I can't tell if they would affect a solution like the one I sketched.\nI wouldn't use `get_type_hints` in this case - from 3.7 Python is moving towards lazy evaluation of type annotations, and forcing them from string to object form in attrs could break people's code (shouldn't, but could) and would almost certainly have a substantial performance hit for some users.\r\n\r\nInstead, I'd just copy keys out of the `__annotations__` dict, or `inspect.getfullargspec(...).annotations`\n@Zac-HD I don't know enough about the current discussion around python types direction to comment specifically on the stability of the approach, but the fact that there's ambiguity suggests that we (possibly \"you\"; i'm not a contributor) should add a little layer of abstraction here (possibly just `get_type_annotations_for_the_attrs_pkg()`).\r\n\r\nI'm currently collecting the above into a little package to allow a user to write\r\n\r\n```\r\n@inject_attr.s\r\nclass Thing:\r\n    field: KlassA\r\n    other_field: KlassB\r\n```\r\n\r\nAlthough since it's basically just for me, not all python users everywhere, I'm not going to be worrying too much about the fwd-compatibility of the annotations stuff.\r\n\r\nBy the way, you wouldn't happen to know if there's a way to delete specific type annotations from an object? It's not a big deal, but in the attrs-context, `field` and `other_field` are args to the ctor, and I can copy their annotations to `Thing.__init__`, but the annotations still remain as annotations for (i _think_) non-existent class variables on `Thing`.\n@haizaar in the meantime, you could try my shitty new [inject-attrs](https://github.com/dradetsky/inject-attrs) package (or something like it).\r\n\r\n@hynek you might take into consideration the fact that I've been motivated to make this.\nI was going to say that almost all my FOSS time goes to Hypothesis (currently working on a major release), but after that it *would* start to address HypothesisWorks/hypothesis-python#954 ...  So maybe, we'll see :smile: \nI think adding the annotations to `__init__` is great idea.  And what @Zac-HD recommends is definitely the way to do it.\r\n\r\nHowever, I don't think think removing the annotation is necessary because\r\n```\r\nclass Thing:\r\n    field: KlassA\r\n    other_field: KlassB\r\n```\r\nmeans that `field` is an instance variable of type `KlassA`.  If you wanted a class variable you'd use `ClassVar[KlassA]`\r\n", "created_at": "2018-03-26T14:12:16Z"}
{"repo": "python-attrs/attrs", "pull_number": 358, "instance_id": "python-attrs__attrs-358", "issue_numbers": ["95"], "base_commit": "780e1e5e1ea9d712e4df59f17fa1c8d4d3febcd5", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -3,6 +3,7 @@\n import hashlib\n import linecache\n import sys\n+import threading\n import warnings\n \n from operator import itemgetter\n@@ -953,6 +954,9 @@ def _add_cmp(cls, attrs=None):\n     return cls\n \n \n+_already_repring = threading.local()\n+\n+\n def _make_repr(attrs, ns):\n     \"\"\"\n     Make a repr method for *attr_names* adding *ns* to the full name.\n@@ -967,6 +971,14 @@ def __repr__(self):\n         \"\"\"\n         Automatically created by attrs.\n         \"\"\"\n+        try:\n+            working_set = _already_repring.working_set\n+        except AttributeError:\n+            working_set = set()\n+            _already_repring.working_set = working_set\n+\n+        if id(self) in working_set:\n+            return \"...\"\n         real_cls = self.__class__\n         if ns is None:\n             qualname = getattr(real_cls, \"__qualname__\", None)\n@@ -977,13 +989,23 @@ def __repr__(self):\n         else:\n             class_name = ns + \".\" + real_cls.__name__\n \n-        return \"{0}({1})\".format(\n-            class_name,\n-            \", \".join(\n-                name + \"=\" + repr(getattr(self, name, NOTHING))\n-                for name in attr_names\n-            )\n-        )\n+        # Since 'self' remains on the stack (i.e.: strongly referenced) for the\n+        # duration of this call, it's safe to depend on id(...) stability, and\n+        # not need to track the instance and therefore worry about properties\n+        # like weakref- or hash-ability.\n+        working_set.add(id(self))\n+        try:\n+            result = [class_name, \"(\"]\n+            first = True\n+            for name in attr_names:\n+                if first:\n+                    first = False\n+                else:\n+                    result.append(\", \")\n+                result.extend((name, \"=\", repr(getattr(self, name, NOTHING))))\n+            return \"\".join(result) + \")\"\n+        finally:\n+            working_set.remove(id(self))\n     return __repr__\n \n \n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -187,6 +187,20 @@ def test_repr_works(self, cls):\n         \"\"\"\n         assert \"C(a=1, b=2)\" == repr(cls(1, 2))\n \n+    def test_infinite_recursion(self):\n+        \"\"\"\n+        In the presence of a cyclic graph, repr will emit an ellipsis and not\n+        raise an exception.\n+        \"\"\"\n+        @attr.s\n+        class Cycle(object):\n+            value = attr.ib(default=7)\n+            cycle = attr.ib(default=None)\n+\n+        cycle = Cycle()\n+        cycle.cycle = cycle\n+        assert \"Cycle(value=7, cycle=...)\" == repr(cycle)\n+\n     def test_underscores(self):\n         \"\"\"\n         repr does not strip underscores.\n", "problem_statement": "Infinite Recursion in repr with bi-directional relationships\nTake a fairly trivial example (which has obviously been simplified to the point of absurdity):\n\n``` python\nimport attr\n\n@attr.s\nclass Test():\n    attr = attr.ib(default=None)\n\ntest = Test()\nother = Test()\ntest.attr = other\nother.attr = test\n\nprint(repr(test))\n```\n\nThis will result in infinite recursion. This can be worked around by setting `repr=False` in the attr.s decorator.\n\nI've sat on this bug for a week trying to come up with a good solution, and I can't think of anything good. I'm starting to think the best solution is to add a warning to the documentation of this behavior and calling it good.\n\n", "hints_text": "How do lists handle this?  (Where does list.__repr__ store state?)\n\n```\nPython 3.5.2 (default, Jul  2 2016, 07:15:59) \n[GCC 4.2.1 Compatible FreeBSD Clang 3.4.1 (tags/RELEASE_34/dot1-final 208032)] on freebsd10\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import attr\n>>> @attr.s\n... class A:\n...     a = attr.ib(default=None)\n... \n>>> L = []\n>>> L.append([A(L)])\n>>> L\n[[A(a=[...])]]\n```\n\nThis seems relavent:\nhttps://github.com/python/cpython/blob/8285672c6e174601589cc55cbe71d301488d3767/Objects/listobject.c#L369\n\nIt looks like they test the call for the recursion error and somewhere below that they replace it with ... .\n\nI don't think attrs could easily use the same strategy without handling all RuntimeErrors.  I think it would be better to do what you first suggested: note in the docs, but don't handle it.\n\nIf someone needs to handle it for a specific class, they can replace the generated __repr__, and can probably do a better job.\n\nYeah, that's kinda what I though too.\n\nUsually I solve this kinda thing by using a `set` to track which objects are currently being `repr`ed, if `self` is already in the set, return `...` instead of the usual value, when done, remove `self` from the set.  The only tricky part is figuring out how best to pass the set from one object to the next, since `__repr__` doesn't take an argument.  Probably would need a helper method that `__repr__` calls, that can explicitly pass a set.\n\nYes I thought about something like that too.\n\nThe problem is you have no place to store that state (the set), so it ends up being mutable global state.  I suspect the problems caused by that will be worse than \"<unprintable ... object>\" and RuntimeError(\"maximum recursion depth exceeded\").  At least for the default behavior, and remembering the vast majority of uses will not be cycles.\n\n(List cheats by not storing state and handling the exception instead.  However, list does it slightly differently than we could in pure Python, and it would be complicated to emulate that.  AFAICT, please correct.)\n\nIt wouldn't have to be mutable global state, attrs could generate it's own __attrs_repr__ (or similar) that takes an argument of a set or list (I don't think it would really matter since I think you'd need to call __contains__ at each step), you'd just call down the chain passing the instance until __contains__ came back true, then you'd just print \"...\"; and the attrs generated __repr__ would call __attrs_repr__. Unless I've completely overlooked something?\n\nOf course, that would require adding another method and some overhead to the __repr__ method.\n\nYou can't ensure __attrs_repr__ exists on all attributes of a class, in order to pass that parameter.  Here, A's repr calls list's repr which calls A's repr, but the cycle could be arbitrarily deeper or longer.\n\n```\n@attr.s\nclass A:\n  x = attr.ib()\na = A([])\na.x.append(a)\n```\n\nThe bulitins at least do the right thing in that case (set, list, dict).  Your example would resolve to 'A(x=[A(x=[...])])', for example (at least on python 3.5, maybe this doesn't work on python 2?).\n\nWhat about this? (obviously this is incomplete, it only handles the bits relevant to the stack)\n\n``` python\ndef __attr_repr__(self, stack=None)\n    stack = stack or []\n\n    if self in stack:\n        return '...'\n\n    stack.append(self)\n\n    try:\n        r = child.__attr_repr__(stack)\n    except AttributeError:\n        try:\n            r = child.__repr__()\n        except RecurssionError:\n            r = '...'\n    # XXX: might need to handle a RecursionError here too, since one could\n    # create a chain that big? If they did the assert below would fail\n\n    assert stack[-1] is self\n    del stack[-1]\n\n    return r\n```\n\nThis only place I could see this doing something less than ideal would be for classes that implement their own __repr__ method that does recursion, but in that case it should be replaced with \"...\"; it wouldn't be perfect but better than raising an exception like it does now, and that wouldn't be a problem for attr to solve anyway.\n\n[RecursionError](https://docs.python.org/3/library/exceptions.html#RecursionError) didn't exist prior to Python 3.5 (I made the same mistake in an edited earlier comment here); a RuntimeError was used previously. Even with the special exception class in 3.5, I'm leery of hiding a true error as a \"...\" string (when cycles are involved, a recursion limit exception could easily be unintentional), though there is no need for the stack at all if that's what you want.\n\n> it wouldn't be perfect but better than raising an exception like it does now\n\nWould it be better than raising an exception? I think the exception is better in general for this case, compared to trying to handle an uncommon or rare case in an unsurprising, on-by-default, one-size-fits-all hack.  Your code above still doesn't handle:\n\n```\n@attr.s\nclass A:\n    x = attr.ib()\na = A([])\na.x.append(a)\n```\n\nBecause list doesn't have the special repr method and the exception is caught \"inside\" the call chain.  For example, your code is equivalent (AFAICT, please correct) to:\n\n```\n>>> def f():\n...     try:\n...         return \"x\" + f()\n...     except RecursionError:\n...         return \"-\"\n... \n>>> print(f())\nxxx[...]xxx-\n```\n\nRather than \"x-\" or \"-\" for the last line, which is what we desire here. (Desire \"A(...)\" not \"A(A(A([...]A(...)[...])))\".)\n\n`threading.local` (sorry/not sorry)", "created_at": "2018-03-16T18:35:32Z"}
{"repo": "python-attrs/attrs", "pull_number": 356, "instance_id": "python-attrs__attrs-356", "issue_numbers": ["178"], "base_commit": "16e65835f4fbecd1ef8fabf5a208bf90be4efcd0", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -58,7 +58,8 @@ def __hash__(self):\n \n def attrib(default=NOTHING, validator=None,\n            repr=True, cmp=True, hash=None, init=True,\n-           convert=None, metadata=None, type=None, converter=None):\n+           convert=None, metadata=None, type=None, converter=None,\n+           factory=None):\n     \"\"\"\n     Create a new attribute on a class.\n \n@@ -83,6 +84,9 @@ def attrib(default=NOTHING, validator=None,\n \n     :type default: Any value.\n \n+    :param callable factory: Syntactic sugar for\n+        ``default=attr.Factory(callable)``.\n+\n     :param validator: :func:`callable` that is called by ``attrs``-generated\n         ``__init__`` methods after the instance has been initialized.  They\n         receive the initialized instance, the :class:`Attribute`, and the\n@@ -137,6 +141,8 @@ def attrib(default=NOTHING, validator=None,\n     .. deprecated:: 17.4.0 *convert*\n     .. versionadded:: 17.4.0 *converter* as a replacement for the deprecated\n        *convert* to achieve consistency with other noun-based arguments.\n+    .. versionadded:: 18.1.0\n+       ``factory=f`` is syntactic sugar for ``default=attr.Factory(f)``.\n     \"\"\"\n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n@@ -156,6 +162,18 @@ def attrib(default=NOTHING, validator=None,\n         )\n         converter = convert\n \n+    if factory is not None:\n+        if default is not NOTHING:\n+            raise ValueError(\n+                \"The `default` and `factory` arguments are mutually \"\n+                \"exclusive.\"\n+            )\n+        if not callable(factory):\n+            raise ValueError(\n+                \"The `factory` argument must be a callable.\"\n+            )\n+        default = Factory(factory)\n+\n     if metadata is None:\n         metadata = {}\n \n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -525,6 +525,35 @@ class C(object):\n \n         assert not isinstance(x, _CountingAttr)\n \n+    def test_factory_sugar(self):\n+        \"\"\"\n+        Passing factory=f is syntactic sugar for passing default=Factory(f).\n+        \"\"\"\n+        @attr.s\n+        class C(object):\n+            x = attr.ib(factory=list)\n+\n+        assert Factory(list) == attr.fields(C).x.default\n+\n+    def test_sugar_factory_mutex(self):\n+        \"\"\"\n+        Passing both default and factory raises ValueError.\n+        \"\"\"\n+        with pytest.raises(ValueError, match=\"mutually exclusive\"):\n+            @attr.s\n+            class C(object):\n+                x = attr.ib(factory=list, default=Factory(list))\n+\n+    def test_sugar_callable(self):\n+        \"\"\"\n+        Factory has to be a callable to prevent people from passing Factory\n+        into it.\n+        \"\"\"\n+        with pytest.raises(ValueError, match=\"must be a callable\"):\n+            @attr.s\n+            class C(object):\n+                x = attr.ib(factory=Factory(list))\n+\n \n @attr.s\n class GC(object):\n", "problem_statement": "attr.Factory is a little wordy\nattrs is a huge net win on an object like this:\r\n\r\n```python\r\n@attr.s\r\nclass Point(object):\r\n    def __init__(self, x, y, z):\r\n        self.x = x\r\n        self.y = y\r\n        self.z = z\r\n\r\nimport attr\r\n@attr.s\r\nclass Point(object):\r\n    x = attr.ib()\r\n    y = attr.ib()\r\n    z = attr.ib()\r\n```\r\n\r\nbut it's a lot less clear when you have something like this:\r\n\r\n```python\r\nclass Cache(object):\r\n    def __init__(self):\r\n        self._stored = []\r\n        self._by_name = {}\r\n        self._by_id = {}\r\n```\r\n\r\nwhich becomes\r\n\r\n```python\r\n@attr.s\r\nclass Cache(object):\r\n    _stored = attr.ib(default=attr.Factory(list))\r\n    _by_name = attr.ib(default=attr.Factory(dict))\r\n    _by_id = attr.ib(default=attr.Factory(dict))\r\n```\r\n\r\nI think an alias for this behavior, like:\r\n\r\n```python\r\n@attr.s\r\nclass Cache(object):\r\n    _stored = attr.ib(new=list)\r\n    _by_name = attr.ib(new=dict)\r\n    _by_id = attr.ib(new=dict)\r\n```\r\n\r\ncould make initializing these types of mutable objects a lot less verbose.\n", "hints_text": "Don't really have a strong opinion here, but I've been finding myself really needing factories that take `self` lately. (I'm getting along with using `__attrs_post_init__` but it's kind of a workaround...)\r\n\r\nIf we're changing the design it'd be nice for the new design to elegantly accommodate these kinds of callables too.\nI think it should *at least* be `factory` if anything.  But I have to admit that the reason it\u2019s wordy is that I wanted to avoid mutually exclusive arguments.\r\n\r\nSadly, that ship has sailed *long* ago so keeping it up doesn\u2019t make a lot of sense anymore.\r\n\r\n***\r\n\r\nI guess passing a half-initialized self into the factory would make a lot of people happy\u2026\nI also think that attr could make it easier to set default mutable attribute values. IMHO having to explicitly create a Factory object is too wordy and not very discoverable.  Thus I like this proposal. In fact I proposed something similar to Hynek via email, although I suggested \"factory\" rather than \"new\" for the keyword argument. I think using \"factory\" rather than \"new\" would make it more clear than a factory is introduced automatically.\r\n\r\nThat being said, I think that while this would be nice it would only be a partial solution. It would not make it easy enough to set an attribute default value to a non empty list. To do that currently you need to use a Factory and a lambda:\r\n\r\n~~~Python\r\n@attr.s\r\nclass Player(object):\r\n    position = attr.ib(default=attr.Factory(lambda: [0, 0, 0]))\r\n~~~\r\n\r\nIMHO that is way too verbose, complex and obscure for such as common use case. With this new proposal you would do:\r\n\r\n~~~Python\r\n@attr.s\r\nclass Player(object):\r\n    position = attr.ib(factory=lambda: [0, 0, 0])\r\n~~~\r\n\r\nwhich is better, but still a bit obscure.\r\n\r\nInstead, or perhaps in addition to the \"factory\" parameter there should be a simple way to set an attribute default value to a mutable, non empty value. For example there could be a new \"mdefault\" attribute  (or perhaps \"new\", if we use \"factory\" for the previous use case) which would both add the Factory and the lambda for you:\r\n\r\n~~~Python\r\n@attr.s\r\nclass Player(object):\r\n    position = attr.ib(new=[0, 0, 0])\r\n~~~\r\n\r\nIdeally attr may be smart enough to detect when the value is immutable and skip the lambda when not needed.\r\n\nHm, I see @hynek 's point. I don't actually need `self`, but I do need the values of other arguments (post-convert, ideally post-validation). There's already an issue for this over at https://github.com/python-attrs/attrs/issues/165.\r\n\r\nFirst of all, I like `attr.ib(factory=<callable>)`. Second, we could run with this and inspect the callable arguments. For every argument, inject the value of the attribute with the same name. No arguments - just call the callable.\r\n\r\n```\r\n@attr.s\r\nclass A:\r\n    a = attr.ib(convert=int)\r\n    b = attr.ib(factory=lambda a: a+1)\r\n\r\n\r\n# Generated __init__ equivalent:\r\ndef __init__(self, a, b):\r\n    self.a = int(a)\r\n    self.b = (lambda a: a+1)(self.a)\r\n```\r\n\r\nA small problem with this is runtime errors:\r\n\r\n```\r\n@attr.s\r\nclass A:\r\n    a = attr.ib()\r\n    b = attr.ib(factory=lambda c: c+1)\r\n    c = attr.ib()\r\n```\r\n\r\nThis should be an error. But we kinda already do this by throwing errors if attributes with default aren't listed last.\nOn the one hand, I love this because it is incredibly precise and doesn't carry the structural risk of \"here's half a `self` I found lying around in the garbage, do stuff to it, I'm sure it's fine\" that you have with `__init__`.\r\n\r\nOn the other hand, wow, what terrifying magic.  Where did `a` come from???\r\n\r\nFinally though - there's no problem with putting `c` into `b`'s arg list, as long as there are no cycles in the graph, we can just topologically sort all attributes by their dependencies and then set them in reverse dependency order in the generated `__init__` \ud83d\ude08 \nHave you guys lost your minds? \ud83d\ude31\n> Have you guys lost your minds? \ud83d\ude31\r\n\r\nYou're right, if brevity is the goal, a kwarg is probably not sufficiently terse to be worthwhile.  How about this:\r\n\r\n```python\r\n@attr.s\r\nclass X:\r\n    a = attr.ib() | None # -> `default=`\r\n    b = attr.ib() ^ list # -> `default=Factory(list)`\r\n    c = attr.ib() & [] # -> `default=Factory(lambda shared_list=[]: copy.deepcopy(shared_list))\r\n```\r\n\r\nThoughts?\nOh wait, perhaps I missed the obvious here:\n```python\r\n@attr.s\r\nclass X:\r\n    a = attr.ib() + None # -> `default=None`\r\n    b = attr.ib() * list # -> `default=Factory(list)`\r\n    c = attr.ib() ** [] # -> `default=Factory(lambda shared_list=[]: copy.deepcopy(shared_list))\r\n```\r\n\nSilliness aside, if we\u2019d want to pass optionally a half-initialized self, we\u2019d have to distinguish between methods whose only argument happens to be `self` and functions that take a self.  So I guess we need to use a unique name? `half_initialized_self`? \ud83d\ude02\r\n\r\nSeems fragile and implicit though\u2026\nDid we kind of agree on `attr.ib(default=attr.Factory(list)) == attr.ib(factory=list)`?\n(if you need `self`, you can always use the `@x.default` decorator)\nA lot of people really dislike the word \"factory\"; it has some baggage.  How do you feel about something even briefer, like `attr.ib(new=list)`?\nI appreciate the marketing angle but we really want to add a second name for the same concept --  a name that doesn't really make a lot of sense? :-/\r\n\r\nDon't get me wrong: I'd love to call it `new` I just have a very hard time to reconcile/rationalize it.\nFactory is a pattern for an object with methods that produces other objects with methods.  But the more general concept of making a new thing, or creating something, is far more general than a factory.  For me it makes sense that `Factory` would be the class, but that the non-`Factory` way of specifying it would be under a different name.\nglyph has a far tighter definition of \"factory\" than I've ever heard. I think that name is fine, FWIW.\r\n\r\nThough oddly, I associate \"new\" with other languages (Java) and totally think of that as a thing that produces an object with methods.  But then\u2026 isn't everything an object with methods in Python?  `SIGLOOP`\n[There's some debate](https://en.wikipedia.org/wiki/Factory_(object-oriented_programming)); it's certainly used in other ways too.  I didn't mean to say that my definition was precisely technically correct, just that the term has more of a technical connotation due to the design-patterns literature.\n1. For me, a factory is something that poops out instances and isn\u2019t a constructor/initializer.\r\n2. I have no problem to associate `new` with creating new objects \u2013 you guys are forgetting the \u201cdefault\u201d part of it. :)  To that end, factory isn\u2019t great either I have to concede. `default_new` would probably be best I think \u2013 but y\u2019all are too lazy to type that, aren\u2019t you? :-|\r\n\r\nWhat I\u2019m thinking about right now is that someone who isn\u2019t intimate with attrs comes to a code base and `new` seems like something _super_ confusing.  And being hard on code readers has always been a popular point to bash attrs for so I would prefer to not fuel that any more.\r\n\r\nWould it kill y\u2019all to have:\r\n\r\n```\r\ndef clever_factory(inst):\r\n    ...\r\n    return value\r\n\r\n@attr.s\r\nclass C:\r\n    x = attr.ib(default_new=list)\r\n    y = attr.ib(default_new(attr.takes_self(clever_factory))\r\n    z = attr.ib(default=42)\r\n```\r\n\r\n?\r\n\r\nTo *me*, this seems like a sweet spot for consistency, brevity, and clarity.  Comments? \ud83d\ude48\nFor the middle one, what about `attr.ib(default=Factory(clever_factory, pass_self=True))`?\nThat\u2019s a *great* idea @glyph!  I love the idea so much that I built a time machine and implemented it in the past, so it can be in [17.1](http://www.attrs.org/en/stable/api.html#attr.Factory)! :D\r\n\r\n(but good you made me re-look it up; it\u2019s takes_self not pass_self).\nAt this point I feel like the easiest way of solving this is just changing the docs to:\r\n\r\n```\r\nfrom attr import Factory as new\r\n\r\n@attr.s\r\nclass C:\r\n    x = attr.ib(default=new(list))\r\n    y = attr.ib(default=new(clever_factory, takes_self=True))\r\n    z = attr.ib(default=42)\r\n```\r\n\r\n\ud83d\ude0e\n@Tinche\u2026 uh\u2026 dammit that's too easy!\r\n\nThis is actually what I do in my own code :).\nSo um after typing `attr.ib(default=attr.Factory(list))` 8x for a single class\u2026am I the only one having weird feelings about `new=`?  Suddenly I\u2019m sympathetic but I don\u2019t want to make decisions out of recent pain.\ngive in to your anger\nOK but I just can\u2019t get over the inconsistency of new/factory.   That would bother me until my death.\r\n\r\nWould you consider `attr.ib(factory=list)` a sufficiently significant improvement?\n@Tinche's example is pretty concise, even if you type `Factory` instead of `new`, so this seems unnecessary\u2026  I agree with your desire to void mutually exclusive arguments.\r\n\nWell, we could go as far as adding a factory for Factory called `new`. \ud83e\udd23\nI do own factoryfactoryfactory.com\n`attr.ib(factory=list)` is certainly a step up!\r\n\r\n`attr.ib(default=new(list))` looks quite nice too, but `new` has a lot of baggage in Python speak.\nfor \"correctness\" sake `attr.ib(default=attr.OciousParameterFreeDataFactory(list))` **hides**\n> Don't really have a strong opinion here, but I've been finding myself really needing factories that take self lately. (I'm getting along with using __attrs_post_init__ but it's kind of a workaround...)\r\n\r\nWanted to also confirm this. I've run into this very often, e.g. setting one attr with other attr as a default value. Writing out\r\n\r\n```python\r\n    y = attr.ib(default=attr.Factory(lambda self: self.x, takes_self=True))\r\n```\r\n\r\nis a bit too heavy though.\r\n\r\nWondering if `takes_self` could automatically be set to `True` if the factory argument is a callable whose signature is exactly one argument named `self`, as a shortcut? This introduces no ambiguity since a \"normal factory\" isn't expected to accept any arguments anyway. So the above could be just:\r\n\r\n```python\r\n    y = attr.ib(factory=lambda self: self.x)\r\n```\r\n\nAs a working proof of concept:\r\n\r\n```python\r\nfrom inspect import Signature, Parameter, signature\r\n\r\nclass Factory(attr.Factory):\r\n    def __init__(self, func, takes_self=None):\r\n        if takes_self is None:\r\n            takes_self = signature(func) == Signature(\r\n                [Parameter('self', Parameter.POSITIONAL_OR_KEYWORD)]\r\n            )\r\n        super().__init__(func, takes_self=takes_self)\r\n        \r\ndef attrib(*args, factory=None, **kwargs):\r\n    if factory is not None:\r\n        kwargs['default'] = Factory(factory)\r\n    return attr.ib(*args, **kwargs)\r\n\r\n@attr.s\r\nclass Bar:\r\n    x = attrib()\r\n    y = attrib(factory=lambda self: self.x)\r\n```\r\n\r\n```python\r\n>>> Bar(42)\r\nBar(x=42, y=42)\r\n```\n@glyph: The [current state of things](https://github.com/python-attrs/attrs/blob/master/docs/examples.rst#types) is pretty good, yo:\r\n\r\n```python\r\n@attr.s(auto_attribs=True)\r\nclass Cache(object):\r\n    _stored: list = Factory(list)\r\n    _by_name: dict = Factory(dict)\r\n    _by_id: dict = Factory(dict)\r\n```\r\n\nmakes me wonder if a `auto_factory` would be a neat thing to have\nWhat would `auto_factory` mean?\r\n\r\nAnyway, I'd assert that the above syntax addresses this ticket.\nOops didn't mean to close\nSince this thread has already fans on Twitter and I got annoyed by the wordiness a few times myself, here\u2019s my final offer:\r\n\r\n`attr.ib(factory=list)` as syntactic sugar for `attr.ib(default=attr.Factory(list, pass_self=False))`\r\n\r\nNo magic, no nothing. If you need more power: there\u2019s two other ways for it.\nSounds cool!", "created_at": "2018-03-14T16:04:05Z"}
{"repo": "python-attrs/attrs", "pull_number": 349, "instance_id": "python-attrs__attrs-349", "issue_numbers": ["290"], "base_commit": "f5298627e6d2bd4fd2afa11140dffd508af74c9d", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -6,7 +6,8 @@\n from ._config import get_run_validators, set_run_validators\n from ._funcs import asdict, assoc, astuple, evolve, has\n from ._make import (\n-    NOTHING, Attribute, Factory, attrib, attrs, fields, make_class, validate\n+    NOTHING, Attribute, Factory, attrib, attrs, fields, fields_dict,\n+    make_class, validate\n )\n \n \n@@ -43,6 +44,7 @@\n     \"evolve\",\n     \"exceptions\",\n     \"fields\",\n+    \"fields_dict\",\n     \"filters\",\n     \"get_run_validators\",\n     \"has\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1042,7 +1042,7 @@ def _add_init(cls, frozen):\n \n def fields(cls):\n     \"\"\"\n-    Returns the tuple of ``attrs`` attributes for a class.\n+    Return the tuple of ``attrs`` attributes for a class.\n \n     The tuple also allows accessing the fields by their names (see below for\n     examples).\n@@ -1068,6 +1068,34 @@ def fields(cls):\n     return attrs\n \n \n+def fields_dict(cls):\n+    \"\"\"\n+    Return an ordered dictionary of ``attrs`` attributes for a class, whose\n+    keys are the attribute names.\n+\n+    :param type cls: Class to introspect.\n+\n+    :raise TypeError: If *cls* is not a class.\n+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+        class.\n+\n+    :rtype: an ordered dict where keys are attribute names and values are\n+        :class:`attr.Attribute`\\ s. This will be a :class:`dict` if it's\n+        naturally ordered like on Python 3.6+ or an\n+        :class:`~collections.OrderedDict` otherwise.\n+\n+    .. versionadded:: 18.1.0\n+    \"\"\"\n+    if not isclass(cls):\n+        raise TypeError(\"Passed object must be a class.\")\n+    attrs = getattr(cls, \"__attrs_attrs__\", None)\n+    if attrs is None:\n+        raise NotAnAttrsClassError(\n+            \"{cls!r} is not an attrs-decorated class.\".format(cls=cls)\n+        )\n+    return ordered_dict(((a.name, a) for a in attrs))\n+\n+\n def validate(inst):\n     \"\"\"\n     Validate all attributes on *inst* that have a validator.\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -22,7 +22,8 @@\n from attr._compat import PY2, ordered_dict\n from attr._make import (\n     Attribute, Factory, _AndValidator, _Attributes, _ClassBuilder,\n-    _CountingAttr, _transform_attrs, and_, fields, make_class, validate\n+    _CountingAttr, _transform_attrs, and_, fields, fields_dict, make_class,\n+    validate\n )\n from attr.exceptions import DefaultAlreadySetError, NotAnAttrsClassError\n \n@@ -656,6 +657,7 @@ def test_handler_non_attrs_class(self, C):\n         \"\"\"\n         with pytest.raises(NotAnAttrsClassError) as e:\n             fields(object)\n+\n         assert (\n             \"{o!r} is not an attrs-decorated class.\".format(o=object)\n         ) == e.value.args[0]\n@@ -676,6 +678,42 @@ def test_fields_properties(self, C):\n             assert getattr(fields(C), attribute.name) is attribute\n \n \n+class TestFieldsDict(object):\n+    \"\"\"\n+    Tests for `fields_dict`.\n+    \"\"\"\n+    def test_instance(self, C):\n+        \"\"\"\n+        Raises `TypeError` on non-classes.\n+        \"\"\"\n+        with pytest.raises(TypeError) as e:\n+            fields_dict(C(1, 2))\n+\n+        assert \"Passed object must be a class.\" == e.value.args[0]\n+\n+    def test_handler_non_attrs_class(self, C):\n+        \"\"\"\n+        Raises `ValueError` if passed a non-``attrs`` instance.\n+        \"\"\"\n+        with pytest.raises(NotAnAttrsClassError) as e:\n+            fields_dict(object)\n+\n+        assert (\n+            \"{o!r} is not an attrs-decorated class.\".format(o=object)\n+        ) == e.value.args[0]\n+\n+    @given(simple_classes())\n+    def test_fields_dict(self, C):\n+        \"\"\"\n+        Returns an ordered dict of ``{attribute_name: Attribute}``.\n+        \"\"\"\n+        d = fields_dict(C)\n+\n+        assert isinstance(d, ordered_dict)\n+        assert list(fields(C)) == list(d.values())\n+        assert [a.name for a in fields(C)] == [field_name for field_name in d]\n+\n+\n class TestConverter(object):\n     \"\"\"\n     Tests for attribute conversion.\n", "problem_statement": "Possible to add a \"field_names\" helper function?\nIn a specific use case, I need to get all field names that are defined in an attrs class, which is as simple as\r\n```\r\n[f.name for f in attr.fields(MyClass)]\r\n```\r\nDo you think it's OK to add a public API for this?\n", "hints_text": "Hm, I was rather thinking about exposing fields as a dict, because I needed string access to attributes.\r\n\r\nThat would give us:\r\n\r\n- `attr.fields_dict(MyClass)[name]` for me\r\n- and `attr.fields_dict(MyClass).keys()` for you\nThat sounds good to me.", "created_at": "2018-02-27T07:43:38Z"}
{"repo": "python-attrs/attrs", "pull_number": 343, "instance_id": "python-attrs__attrs-343", "issue_numbers": ["300"], "base_commit": "93eb1e4d21b5cc5c88da61e8182a42bb41cab557", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -10,6 +10,13 @@\n PYPY = platform.python_implementation() == \"PyPy\"\n \n \n+if PYPY or sys.version_info[:2] >= (3, 6):\n+    ordered_dict = dict\n+else:\n+    from collections import OrderedDict\n+    ordered_dict = OrderedDict\n+\n+\n if PY2:\n     from UserDict import IterableUserDict\n \ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -8,7 +8,9 @@\n from operator import itemgetter\n \n from . import _config\n-from ._compat import PY2, isclass, iteritems, metadata_proxy, set_closure_cell\n+from ._compat import (\n+    PY2, isclass, iteritems, metadata_proxy, ordered_dict, set_closure_cell\n+)\n from .exceptions import (\n     DefaultAlreadySetError, FrozenInstanceError, NotAnAttrsClassError,\n     UnannotatedAttributeError\n@@ -233,6 +235,13 @@ def _get_annotations(cls):\n     return anns\n \n \n+def _counter_getter(e):\n+    \"\"\"\n+    Key function for sorting to avoid re-creating a lambda for every class.\n+    \"\"\"\n+    return e[1].counter\n+\n+\n def _transform_attrs(cls, these, auto_attribs):\n     \"\"\"\n     Transform all `_CountingAttr`s on a class into `Attribute`s.\n@@ -245,11 +254,14 @@ def _transform_attrs(cls, these, auto_attribs):\n     anns = _get_annotations(cls)\n \n     if these is not None:\n-        ca_list = sorted((\n+        ca_list = [\n             (name, ca)\n             for name, ca\n             in iteritems(these)\n-        ), key=lambda e: e[1].counter)\n+        ]\n+\n+        if not isinstance(these, ordered_dict):\n+            ca_list.sort(key=_counter_getter)\n     elif auto_attribs is True:\n         ca_names = {\n             name\n@@ -593,6 +605,11 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n         If *these* is not ``None``, ``attrs`` will *not* search the class body\n         for attributes and will *not* remove any attributes from it.\n \n+        If *these* is an ordered dict (:class:`dict` on Python 3.6+,\n+        :class:`collections.OrderedDict` otherwise), the order is deduced from\n+        the order of the attributes inside *these*.  Otherwise the order\n+        of the definition of the attributes is used.\n+\n     :type these: :class:`dict` of :class:`str` to :func:`attr.ib`\n \n     :param str repr_ns: When using nested classes, there's no way in Python 2\n@@ -681,6 +698,7 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n     .. versionadded:: 17.3.0 *auto_attribs*\n     .. versionchanged:: 18.1.0\n        If *these* is passed, no attributes are deleted from the class body.\n+    .. versionchanged:: 18.1.0 If *these* is ordered, the order is retained.\n     \"\"\"\n     def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n@@ -1513,6 +1531,11 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n \n     :param attrs: A list of names or a dictionary of mappings of names to\n         attributes.\n+\n+        If *attrs* is a list or an ordered dict (:class:`dict` on Python 3.6+,\n+        :class:`collections.OrderedDict` otherwise), the order is deduced from\n+        the order of the names or attributes inside *attrs*.  Otherwise the\n+        order of the definition of the attributes is used.\n     :type attrs: :class:`list` or :class:`dict`\n \n     :param tuple bases: Classes that the new class will subclass.\n@@ -1522,7 +1545,8 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n     :return: A new class with *attrs*.\n     :rtype: type\n \n-    ..  versionadded:: 17.1.0 *bases*\n+    .. versionadded:: 17.1.0 *bases*\n+    .. versionchanged:: 18.1.0 If *attrs* is ordered, the order is retained.\n     \"\"\"\n     if isinstance(attrs, dict):\n         cls_dict = attrs\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -19,7 +19,7 @@\n import attr\n \n from attr import _config\n-from attr._compat import PY2\n+from attr._compat import PY2, ordered_dict\n from attr._make import (\n     Attribute, Factory, _AndValidator, _Attributes, _ClassBuilder,\n     _CountingAttr, _transform_attrs, and_, fields, make_class, validate\n@@ -281,6 +281,20 @@ class C(object):\n         assert 5 == C().x\n         assert \"C(x=5)\" == repr(C())\n \n+    def test_these_ordered(self):\n+        \"\"\"\n+        If these is passed ordered attrs, their order respect instead of the\n+        counter.\n+        \"\"\"\n+        b = attr.ib(default=2)\n+        a = attr.ib(default=1)\n+\n+        @attr.s(these=ordered_dict([(\"a\", a), (\"b\", b)]))\n+        class C(object):\n+            pass\n+\n+        assert \"C(a=1, b=2)\" == repr(C())\n+\n     def test_multiple_inheritance(self):\n         \"\"\"\n         Order of attributes doesn't get mixed up by multiple inheritance.\n@@ -610,6 +624,18 @@ def test_missing_sys_getframe(self, monkeypatch):\n \n         assert 1 == len(C.__attrs_attrs__)\n \n+    def test_make_class_ordered(self):\n+        \"\"\"\n+        If `make_class()` is passed ordered attrs, their order is respected\n+        instead of the counter.\n+        \"\"\"\n+        b = attr.ib(default=2)\n+        a = attr.ib(default=1)\n+\n+        C = attr.make_class(\"C\", ordered_dict([(\"a\", a), (\"b\", b)]))\n+\n+        assert \"C(a=1, b=2)\" == repr(C())\n+\n \n class TestFields(object):\n     \"\"\"\n@@ -686,13 +712,14 @@ def test_convert_factory_property(self, val, init):\n         \"\"\"\n         Property tests for attributes with convert, and a factory default.\n         \"\"\"\n-        C = make_class(\"C\", {\n-            \"y\": attr.ib(),\n-            \"x\": attr.ib(\n+        C = make_class(\"C\", ordered_dict([\n+            (\"y\", attr.ib()),\n+            (\"x\", attr.ib(\n                 init=init,\n                 default=Factory(lambda: val),\n-                converter=lambda v: v + 1),\n-        })\n+                converter=lambda v: v + 1\n+            )),\n+        ]))\n         c = C(2)\n \n         assert c.x == val + 1\n", "problem_statement": "Allow overwriting order inferred from _CountingAttr.counter when passing ordered `these`\nattrs classes can be constructed dynamically using `attr.s(maybe_cls=A, these=some_dict)`.\r\nUsually `some_dict` will be a standard (unordered) python dictionary and the order of attributes has to be inferred from `_CountingAttr.counter`.\r\n\r\nWhat about allowing the user to overwrite the `_CountingAttr.counter` by passing an `OrderedDict` as argument to `these`?\n", "hints_text": "I think @Julian would like this?\nYep! Would love to see what this looks like.", "created_at": "2018-02-05T09:39:46Z"}
{"repo": "python-attrs/attrs", "pull_number": 334, "instance_id": "python-attrs__attrs-334", "issue_numbers": ["321"], "base_commit": "825de4f008fddf2585fef1a31a2b925b0df8131d", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -87,15 +87,12 @@ def metadata_proxy(d):\n         return types.MappingProxyType(dict(d))\n \n \n-def import_ctypes():  # pragma: nocover\n+def import_ctypes():\n     \"\"\"\n     Moved into a function for testability.\n     \"\"\"\n-    try:\n-        import ctypes\n-        return ctypes\n-    except ImportError:\n-        return None\n+    import ctypes\n+    return ctypes\n \n \n if not PY2:\n@@ -126,12 +123,15 @@ def make_set_closure_cell():\n         def set_closure_cell(cell, value):\n             cell.__setstate__((value,))\n     else:\n-        ctypes = import_ctypes()\n-        if ctypes is not None:\n+        try:\n+            ctypes = import_ctypes()\n+\n             set_closure_cell = ctypes.pythonapi.PyCell_Set\n             set_closure_cell.argtypes = (ctypes.py_object, ctypes.py_object)\n             set_closure_cell.restype = ctypes.c_int\n-        else:\n+        except Exception:\n+            # We try best effort to set the cell, but sometimes it's not\n+            # possible.  For example on Jython or on GAE.\n             set_closure_cell = just_warn\n     return set_closure_cell\n \n", "test_patch": "", "problem_statement": "Jython compatibility\nHello.\r\n\r\nI've tried to use attrs module with Jython but it seems to be unsupported. I have an empty docker container based on Fedora 27 and Jython 2.7.1 (latest stable) installed from Fedora repository and attrs installed from PyPI.\r\n\r\nSteps to reproduce:\r\n```\r\n$ jython -m ensurepip\r\nCollecting setuptools\r\nCollecting pip\r\nInstalling collected packages: setuptools, pip\r\nSuccessfully installed pip-9.0.1 setuptools-28.8.0\r\n$ jython -m pip install attrs\r\nCollecting attrs\r\n  Downloading attrs-17.4.0-py2.py3-none-any.whl\r\nInstalling collected packages: attrs\r\nSuccessfully installed attrs-17.4.0\r\n$ jython \r\nJython 2.7.1 (, Sep 29 2017, 12:00:52) \r\n[OpenJDK 64-Bit Server VM (Oracle Corporation)] on java1.8.0_151\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import attr\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/share/jython/Lib/site-packages/attr/__init__.py\", line 5, in <module>\r\n    from . import converters, exceptions, filters, validators\r\n  File \"/usr/share/jython/Lib/site-packages/attr/filters.py\", line 7, in <module>\r\n    from ._compat import isclass\r\n  File \"/usr/share/jython/Lib/site-packages/attr/_compat.py\", line 139, in <module>\r\n    set_closure_cell = make_set_closure_cell()\r\n  File \"/usr/share/jython/Lib/site-packages/attr/_compat.py\", line 131, in make_set_closure_cell\r\n    set_closure_cell = ctypes.pythonapi.PyCell_Set\r\nAttributeError: 'module' object has no attribute 'pythonapi'\r\n```\r\n\r\nIs there any chance, that attrs would support Jython? I am asking because pytest is considered supported on Jython but depends on attrs so pytest also doesn't work.\r\n\r\nThank you and have a nice day!\n", "hints_text": "Looks like the related code was added in #226 for #102 (cc @Tinche)\nWe could add Jython as a special case. Does Jython support changing closure cell contents a different way?\n@Tinche Sorry, I don't know Jython enough to answer your question. \n@jeff5 should know more details\nJython is Python 2-only, so we can just not set a closure cell and be done with it.\n@RonnyPfannschmidt : not really. As far as I can tell, any use of ``ctypes`` in our tests is guarded by a skip-if-jython. It exists as a module, but maybe just to satisfy imports or some very limited uses.\r\n\r\nI haven't fully understood what you're doing with ``ctypes.pythonapi``. Obviously you can't expect the low-level C-API of CPython to work in a Java implementation. ``cell`` is an exposed type, of course, and my naive attempts to write its ``ob_ref`` member (which is public) are thwarted by coercion. I got most of the way with:\r\n```\r\n>>> c = g.func_closure[0]\r\n>>> ref = java.lang.Class.getField(org.python.core.PyCell, \"ob_ref\")\r\n>>> ref.get(c)\r\n5\r\n```\r\nwhere ``g`` is a function defined in an inner scope, but in ``ref.set(c, 6)`` the 6 is coerced to a ``java.lang.Integer`` so cannot be assigned.\r\n\r\nAny ideas @jimbaker ?\nWhat we\u2019re doing is enabling things like bare supers and __class__ to work.   AFAICT there\u2019s no downside to skip this on Python 2, so we could add a case for Jython.\r\n\r\nSadly, I have no way to test it because pyenv just exploded when trying to install it.\r\n\r\nSomeone just has to add a case to https://github.com/python-attrs/attrs/blob/1f0d85199666cfa881385c31314a6b2d39f6c36e/src/attr/_compat.py#L121 making set_closure_cell a NOP.", "created_at": "2018-01-27T19:38:44Z"}
{"repo": "python-attrs/attrs", "pull_number": 332, "instance_id": "python-attrs__attrs-332", "issue_numbers": ["331"], "base_commit": "75cdf8fe919c11ea94d443301b097cf165a1597b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -45,7 +45,7 @@ def __repr__(self):\n         return \"NOTHING\"\n \n     def __hash__(self):\n-        return 0xdeadbeef\n+        return 0xc0ffee\n \n \n NOTHING = _Nothing()\n", "test_patch": "", "problem_statement": "Hashing NOTHING in CPython is 60% slower than it should be on 32 bit builds\n```\r\nclass DeadBeef:\r\n    def __hash__(self):\r\n        return 0xdeadbeef\r\n\r\nclass LeetBeef:\r\n    def __hash__(self):\r\n        return 0x5eadbef0\r\n\r\na = Timer('hash(self)', 'from __main__ import DeadBeef;self=DeadBeef()')\r\nb = Timer('hash(self)', 'from __main__ import LeetBeef;self=LeetBeef()')\r\n\r\nprint('Dead:', hex(hash(DeadBeef())), min(a.repeat()))\r\nprint('Leet:', hex(hash(LeetBeef())), min(b.repeat()))\r\n\r\n```\r\n\r\nDon't know how/want to learn how to contribute to projects on here, but I would feel bad if I didn't at least mention on here an oversight of this magnitude.\n", "hints_text": "I assume this is about the fact that 0xdeadbeef is larger than (2^32/2-1)?", "created_at": "2018-01-26T10:26:35Z"}
{"repo": "python-attrs/attrs", "pull_number": 326, "instance_id": "python-attrs__attrs-326", "issue_numbers": ["311"], "base_commit": "1f0d85199666cfa881385c31314a6b2d39f6c36e", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -443,20 +443,26 @@ def _create_slots_class(self):\n         if qualname is not None:\n             cd[\"__qualname__\"] = qualname\n \n-        attr_names = tuple(self._attr_names)\n+        # __weakref__ is not writable.\n+        state_attr_names = tuple(\n+            an for an in self._attr_names if an != \"__weakref__\"\n+        )\n \n         def slots_getstate(self):\n             \"\"\"\n             Automatically created by attrs.\n             \"\"\"\n-            return tuple(getattr(self, name) for name in attr_names)\n+            return tuple(\n+                getattr(self, name)\n+                for name in state_attr_names\n+            )\n \n         def slots_setstate(self, state):\n             \"\"\"\n             Automatically created by attrs.\n             \"\"\"\n             __bound_setattr = _obj_setattr.__get__(self, Attribute)\n-            for name, value in zip(attr_names, state):\n+            for name, value in zip(state_attr_names, state):\n                 __bound_setattr(name, value)\n \n         # slots and frozen require __getstate__/__setstate__ to work\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -4,6 +4,7 @@\n \n from __future__ import absolute_import, division, print_function\n \n+import copy\n import inspect\n import itertools\n import sys\n@@ -1054,3 +1055,16 @@ def fake_meth(self):\n \n         assert \"42\" == rv.__module__ == fake_meth.__module__\n         assert \"23\" == rv.__qualname__ == fake_meth.__qualname__\n+\n+    def test_weakref_setstate(self):\n+        \"\"\"\n+        __weakref__ is not set on in setstate because it's not writable in\n+        slots classes.\n+        \"\"\"\n+        @attr.s(slots=True)\n+        class C(object):\n+            __weakref__ = attr.ib(\n+                init=False, hash=False, repr=False, cmp=False\n+            )\n+\n+        assert C() == copy.deepcopy(C())\n", "problem_statement": "deepcopy stopped working with slots=True and __weakref__ after updating to 17.3.0\n```Python 2.7.12 (default, Nov 20 2017, 18:23:56) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import attr\r\n>>> attr.__version__\r\n'17.3.0'\r\n>>> from copy import deepcopy\r\n>>> @attr.s(slots=True)\r\n... class Han(object):\r\n...     __weakref__ = attr.ib(init=False, hash=False, repr=False, cmp=False)\r\n... \r\n>>> h = Han()\r\n>>> o = deepcopy(h)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/copy.py\", line 190, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/usr/lib/python2.7/copy.py\", line 336, in _reconstruct\r\n    y.__setstate__(state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/attr/_make.py\", line 432, in slots_setstate\r\n    __bound_setattr(name, value)\r\nAttributeError: attribute '__weakref__' of 'Han' objects is not writable\r\n```\n", "hints_text": "Hm. I'll take a look soonish.\nAny update Tin?\nUhh totally forgot about this. Will take a look tomorrow.\nPlot twist, the above code works on OS X, CPython 3.6.1. But I remember looking at this at home on Linux and it didn't work.\nIt doesn\u2019t work for me on macOS High Sierra and 3.6.3.  Could you maybe have forgotten the decorator?  Happened to me too while checking.\r\n\r\nI also think I know what\u2019s happening: attrs deletes `__weakref__` because it\u2019s an attribute.\r\n\r\nWe\u2019ll have to create a blacklist of things that shouldn\u2019t be deleted.\nRunning Python docker images on OS X, 2.7.14 and 3.6.4 seem to work?\r\n\r\n```\r\nroot@ec456701d792:~# cat d.py\r\nimport attr\r\nfrom copy import deepcopy\r\n\r\n\r\n@attr.s(slots=True)\r\nclass Han(object):\r\n    __weakref__ = attr.ib(init=False, hash=False, repr=False, cmp=False)\r\n\r\n\r\nh = Han()\r\n\r\no = deepcopy(h)\r\n```\nThis is against master, btw.\n> I also think I know what\u2019s happening: attrs deletes __weakref__ because it\u2019s an attribute.\r\n\r\nWe don't do that for slot classes, right?\n```python\r\nTraceback (most recent call last):\r\n  File \"t2.py\", line 12, in <module>\r\n    o = deepcopy(h)\r\n  File \"/Users/hynek/.virtualenvs/attrs/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"/Users/hynek/.virtualenvs/attrs/lib/python3.6/copy.py\", line 282, in _reconstruct\r\n    y.__setstate__(state)\r\n  File \"/Users/hynek/Projects/attrs/src/attr/_make.py\", line 460, in slots_setstate\r\n    __bound_setattr(name, value)\r\nAttributeError: attribute '__weakref__' of 'Han' objects is not writable\r\n```\n> We don't do that for slot classes, right?\r\n\r\nOh yeah right.  So the bug seems to be in `slots_setstate` \u2013 I\u2019ve just had a look and it doesn\u2019t seem to check for init=False? \ud83e\udd14\nI still can't repro this. 3.6.3 you say?\r\n\r\n```\r\nttvrtkovic@NANOZAGDEV019 ~/p/attrs> docker run --rm -ti -v (pwd):/root python:3.6.3 /bin/bash\r\nUnable to find image 'python:3.6.3' locally\r\n3.6.3: Pulling from library/python\r\nf49cf87b52c1: Already exists\r\n7b491c575b06: Already exists\r\nb313b08bab3b: Already exists\r\n51d6678c3f0e: Already exists\r\n09f35bd58db2: Already exists\r\n1bda3d37eead: Pull complete\r\n9f47966d4de2: Pull complete\r\n9fd775bfe531: Pull complete\r\nDigest: sha256:cdef88d8625cf50ca705b7abfe99e8eb33b889652a9389b017eb46a6d2f1aaf3\r\nStatus: Downloaded newer image for python:3.6.3\r\nroot@83388638cbc3:/# cd root\r\nroot@83388638cbc3:~# pip install -e .\r\nObtaining file:///root\r\nInstalling collected packages: attrs\r\n  Running setup.py develop for attrs\r\nSuccessfully installed attrs\r\nroot@83388638cbc3:~# python -V\r\nPython 3.6.3\r\nroot@83388638cbc3:~# cat d.py\r\nimport attr\r\nfrom copy import deepcopy\r\n\r\n\r\n@attr.s(slots=True)\r\nclass Han(object):\r\n    __weakref__ = attr.ib(init=False, hash=False, repr=False, cmp=False)\r\n\r\n\r\nh = Han()\r\n\r\no = deepcopy(h)\r\nroot@83388638cbc3:~# python d.py\r\nroot@83388638cbc3:~#\r\n```\r\nSomething fishy going on.\nI'm an idiot, I wasn't actually on master.\n(replaced the last comment with this one)\r\n\r\nYeah, I can repro now. I think our `__setstate__` implementation is interacting badly with, well, Python. Consider this:\r\n\r\n```\r\nclass D:\r\n    __slots__ = ('__weakref__')\r\n\r\n>>> d = D()\r\n>>> d.__weakref__ = None\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: attribute '__weakref__' of 'D' objects is not writable\r\n```\r\nWhy isn't weakref writable? No idea, but it just isn't. So I guess we can't treat it like a normal attribute.\nThe question now is whether we add some duct tape or add proper weakref support that has been asked for by many people.\r\n\r\nAs you may suspect, I\u2019m for the latter. :)\nYeah, that'd be for the best probably. Ideas for the API?\nPaging @njsmith who asked for this feature before. :)\r\n\r\n(I think I\u2019ll also additionally add duct tape, that seems to be trivial to fix)", "created_at": "2018-01-17T11:07:36Z"}
{"repo": "python-attrs/attrs", "pull_number": 323, "instance_id": "python-attrs__attrs-323", "issue_numbers": ["322"], "base_commit": "9af773bdf388125af7e469e7817c79e491679300", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -128,13 +128,13 @@ def attrib(default=NOTHING, validator=None,\n \n     .. versionadded:: 15.2.0 *convert*\n     .. versionadded:: 16.3.0 *metadata*\n-    ..  versionchanged:: 17.1.0 *validator* can be a ``list`` now.\n-    ..  versionchanged:: 17.1.0\n-        *hash* is ``None`` and therefore mirrors *cmp* by default.\n-    ..  versionadded:: 17.3.0 *type*\n-    ..  deprecated:: 17.4.0 *convert*\n-    ..  versionadded:: 17.4.0 *converter* as a replacement for the deprecated\n-        *convert* to achieve consistency with other noun-based arguments.\n+    .. versionchanged:: 17.1.0 *validator* can be a ``list`` now.\n+    .. versionchanged:: 17.1.0\n+       *hash* is ``None`` and therefore mirrors *cmp* by default.\n+    .. versionadded:: 17.3.0 *type*\n+    .. deprecated:: 17.4.0 *convert*\n+    .. versionadded:: 17.4.0 *converter* as a replacement for the deprecated\n+       *convert* to achieve consistency with other noun-based arguments.\n     \"\"\"\n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n@@ -364,7 +364,7 @@ class _ClassBuilder(object):\n     \"\"\"\n     __slots__ = (\n         \"_cls\", \"_cls_dict\", \"_attrs\", \"_super_names\", \"_attr_names\", \"_slots\",\n-        \"_frozen\", \"_has_post_init\",\n+        \"_frozen\", \"_has_post_init\", \"_delete_attribs\",\n     )\n \n     def __init__(self, cls, these, slots, frozen, auto_attribs):\n@@ -378,6 +378,7 @@ def __init__(self, cls, these, slots, frozen, auto_attribs):\n         self._slots = slots\n         self._frozen = frozen or _has_frozen_superclass(cls)\n         self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\n+        self._delete_attribs = not bool(these)\n \n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n \n@@ -407,10 +408,11 @@ def _patch_original_class(self):\n         super_names = self._super_names\n \n         # Clean class of attribute definitions (`attr.ib()`s).\n-        for name in self._attr_names:\n-            if name not in super_names and \\\n-                    getattr(cls, name, None) is not None:\n-                delattr(cls, name)\n+        if self._delete_attribs:\n+            for name in self._attr_names:\n+                if name not in super_names and \\\n+                        getattr(cls, name, None) is not None:\n+                    delattr(cls, name)\n \n         # Attach our dunder methods.\n         for name, value in self._cls_dict.items():\n@@ -575,7 +577,7 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n         Django models) or don't want to.\n \n         If *these* is not ``None``, ``attrs`` will *not* search the class body\n-        for attributes.\n+        for attributes and will *not* remove any attributes from it.\n \n     :type these: :class:`dict` of :class:`str` to :func:`attr.ib`\n \n@@ -656,13 +658,15 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n \n         .. _`PEP 526`: https://www.python.org/dev/peps/pep-0526/\n \n-    ..  versionadded:: 16.0.0 *slots*\n-    ..  versionadded:: 16.1.0 *frozen*\n-    ..  versionadded:: 16.3.0 *str*, and support for ``__attrs_post_init__``.\n-    ..  versionchanged::\n-            17.1.0 *hash* supports ``None`` as value which is also the default\n-            now.\n+    .. versionadded:: 16.0.0 *slots*\n+    .. versionadded:: 16.1.0 *frozen*\n+    .. versionadded:: 16.3.0 *str*\n+    .. versionadded:: 16.3.0 Support for ``__attrs_post_init__``.\n+    .. versionchanged:: 17.1.0\n+       *hash* supports ``None`` as value which is also the default now.\n     .. versionadded:: 17.3.0 *auto_attribs*\n+    .. versionchanged:: 18.1.0\n+       If *these* is passed, no attributes are deleted from the class body.\n     \"\"\"\n     def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -269,6 +269,17 @@ class C(Base):\n             simple_attr(\"x\"),\n         ) == attrs\n \n+    def test_these_leave_body(self):\n+        \"\"\"\n+        If these is passed, no attributes are removed from the body.\n+        \"\"\"\n+        @attr.s(init=False, these={\"x\": attr.ib()})\n+        class C(object):\n+            x = 5\n+\n+        assert 5 == C().x\n+        assert \"C(x=5)\" == repr(C())\n+\n     def test_multiple_inheritance(self):\n         \"\"\"\n         Order of attributes doesn't get mixed up by multiple inheritance.\n", "problem_statement": "Don't delete class attributes specified in attrs(these=...)\nIn previous versions of `attrs` (verified in 16.3.0), you could get class attributes included in the auto-generated methods (`__repr__`, `__eq__`, et cetera) by setting `these` in the `attrs` decorator to the names of the attributes (with `init=False`).  As of version 17.3.0, the attributes listed in `these` are simply deleted from the class definition, eliminating the whole reason for specifying them via `these` instead of in the class body, or automatically via type annotations.  Attributes should only be deleted from the class definition if the attribute is an instance of whatever `attr.ib` returns, or at the very least, an option to not delete class attributes should be provided.\r\n\r\n\r\n    from attr import s, ib\r\n\r\n    @s(these=dict(something=ib(init=False)))\r\n    class test(object):\r\n\t    something = 'xyzzy'\r\n\r\n    print(test())\r\n\r\n\n", "hints_text": "Eh yeah, the whole point of `these` is to leave the class body alone.  \ud83d\ude48", "created_at": "2018-01-16T12:25:27Z"}
{"repo": "python-attrs/attrs", "pull_number": 316, "instance_id": "python-attrs__attrs-316", "issue_numbers": ["309"], "base_commit": "bc0b437e58cf5a9c60143909c93cb0d727b15300", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -491,17 +491,22 @@ def slots_setstate(self, state):\n         return cls\n \n     def add_repr(self, ns):\n-        self._cls_dict[\"__repr__\"] = _make_repr(self._attrs, ns=ns)\n+        self._cls_dict[\"__repr__\"] = self._add_method_dunders(\n+            _make_repr(self._attrs, ns=ns)\n+        )\n         return self\n \n     def add_str(self):\n-        repr_ = self._cls_dict.get(\"__repr__\")\n-        if repr_ is None:\n+        repr = self._cls_dict.get(\"__repr__\")\n+        if repr is None:\n             raise ValueError(\n                 \"__str__ can only be generated if a __repr__ exists.\"\n             )\n \n-        self._cls_dict[\"__str__\"] = repr_\n+        def __str__(self):\n+            return self.__repr__()\n+\n+        self._cls_dict[\"__str__\"] = self._add_method_dunders(__str__)\n         return self\n \n     def make_unhashable(self):\n@@ -509,25 +514,52 @@ def make_unhashable(self):\n         return self\n \n     def add_hash(self):\n-        self._cls_dict[\"__hash__\"] = _make_hash(self._attrs)\n+        self._cls_dict[\"__hash__\"] = self._add_method_dunders(\n+            _make_hash(self._attrs)\n+        )\n+\n         return self\n \n     def add_init(self):\n-        self._cls_dict[\"__init__\"] = _make_init(\n-            self._attrs,\n-            self._has_post_init,\n-            self._frozen,\n+        self._cls_dict[\"__init__\"] = self._add_method_dunders(\n+            _make_init(\n+                self._attrs,\n+                self._has_post_init,\n+                self._frozen,\n+            )\n         )\n+\n         return self\n \n     def add_cmp(self):\n         cd = self._cls_dict\n \n         cd[\"__eq__\"], cd[\"__ne__\"], cd[\"__lt__\"], cd[\"__le__\"], cd[\"__gt__\"], \\\n-            cd[\"__ge__\"] = _make_cmp(self._attrs)\n+            cd[\"__ge__\"] = (\n+                self._add_method_dunders(meth)\n+                for meth in _make_cmp(self._attrs)\n+            )\n \n         return self\n \n+    def _add_method_dunders(self, method):\n+        \"\"\"\n+        Add __module__ and __qualname__ to a *method* if possible.\n+        \"\"\"\n+        try:\n+            method.__module__ = self._cls.__module__\n+        except AttributeError:\n+            pass\n+\n+        try:\n+            method.__qualname__ = \".\".join(\n+                (self._cls.__qualname__, method.__name__,)\n+            )\n+        except AttributeError:\n+            pass\n+\n+        return method\n+\n \n def attrs(maybe_cls=None, these=None, repr_ns=None,\n           repr=True, cmp=True, hash=None, init=True,\n@@ -753,7 +785,7 @@ def _add_hash(cls, attrs):\n     return cls\n \n \n-def _ne(self, other):\n+def __ne__(self, other):\n     \"\"\"\n     Check equality and either forward a NotImplemented or return the result\n     negated.\n@@ -807,7 +839,7 @@ def _make_cmp(attrs):\n         unique_filename,\n     )\n     eq = locs[\"__eq__\"]\n-    ne = _ne\n+    ne = __ne__\n \n     def attrs_to_tuple(obj):\n         \"\"\"\n@@ -815,7 +847,7 @@ def attrs_to_tuple(obj):\n         \"\"\"\n         return _attrs_to_tuple(obj, attrs)\n \n-    def lt(self, other):\n+    def __lt__(self, other):\n         \"\"\"\n         Automatically created by attrs.\n         \"\"\"\n@@ -824,7 +856,7 @@ def lt(self, other):\n         else:\n             return NotImplemented\n \n-    def le(self, other):\n+    def __le__(self, other):\n         \"\"\"\n         Automatically created by attrs.\n         \"\"\"\n@@ -833,7 +865,7 @@ def le(self, other):\n         else:\n             return NotImplemented\n \n-    def gt(self, other):\n+    def __gt__(self, other):\n         \"\"\"\n         Automatically created by attrs.\n         \"\"\"\n@@ -842,7 +874,7 @@ def gt(self, other):\n         else:\n             return NotImplemented\n \n-    def ge(self, other):\n+    def __ge__(self, other):\n         \"\"\"\n         Automatically created by attrs.\n         \"\"\"\n@@ -851,7 +883,7 @@ def ge(self, other):\n         else:\n             return NotImplemented\n \n-    return eq, ne, lt, le, gt, ge\n+    return eq, ne, __lt__, __le__, __gt__, __ge__\n \n \n def _add_cmp(cls, attrs=None):\n@@ -877,7 +909,7 @@ def _make_repr(attrs, ns):\n         if a.repr\n     )\n \n-    def repr_(self):\n+    def __repr__(self):\n         \"\"\"\n         Automatically created by attrs.\n         \"\"\"\n@@ -898,7 +930,7 @@ def repr_(self):\n                 for name in attr_names\n             )\n         )\n-    return repr_\n+    return __repr__\n \n \n def _add_repr(cls, ns=None, attrs=None):\n@@ -908,8 +940,7 @@ def _add_repr(cls, ns=None, attrs=None):\n     if attrs is None:\n         attrs = cls.__attrs_attrs__\n \n-    repr_ = _make_repr(attrs, ns)\n-    cls.__repr__ = repr_\n+    cls.__repr__ = _make_repr(attrs, ns)\n     return cls\n \n \n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -997,3 +997,49 @@ class C(object):\n             .build_class()\n \n         assert \"ns.C(x=1)\" == repr(cls(1))\n+\n+    @pytest.mark.parametrize(\"meth_name\", [\n+        \"__init__\", \"__hash__\", \"__repr__\", \"__str__\",\n+        \"__eq__\", \"__ne__\", \"__lt__\", \"__le__\", \"__gt__\", \"__ge__\",\n+    ])\n+    def test_attaches_meta_dunders(self, meth_name):\n+        \"\"\"\n+        Generated methods have correct __module__, __name__, and __qualname__\n+        attributes.\n+        \"\"\"\n+        @attr.s(hash=True, str=True)\n+        class C(object):\n+            def organic(self):\n+                pass\n+\n+        meth = getattr(C, meth_name)\n+\n+        assert meth_name == meth.__name__\n+        assert C.organic.__module__ == meth.__module__\n+        if not PY2:\n+            organic_prefix = C.organic.__qualname__.rsplit(\".\", 1)[0]\n+            assert organic_prefix + \".\" + meth_name == meth.__qualname__\n+\n+    def test_handles_missing_meta_on_class(self):\n+        \"\"\"\n+        If the class hasn't a __module__ or __qualname__, the method hasn't\n+        either.\n+        \"\"\"\n+        class C(object):\n+            pass\n+\n+        b = _ClassBuilder(\n+            C, these=None, slots=False, frozen=False, auto_attribs=False,\n+        )\n+        b._cls = {}  # no __module__; no __qualname__\n+\n+        def fake_meth(self):\n+            pass\n+\n+        fake_meth.__module__ = \"42\"\n+        fake_meth.__qualname__ = \"23\"\n+\n+        rv = b._add_method_dunders(fake_meth)\n+\n+        assert \"42\" == rv.__module__ == fake_meth.__module__\n+        assert \"23\" == rv.__qualname__ == fake_meth.__qualname__\n", "problem_statement": "Generated methods like __init__ lack the __module__ attribute\nThis issue was initially reported in https://github.com/Stewori/pytypes/issues/18.\r\nApplying ``__module__`` on e.g. the ``__init__`` function generated by attrs raises a ``KeyError``. For more information please refer to the link above.\r\n\r\nBeing able to retrieve the module for a given function/method is relevant to locate the function or method in the class hierarchy from perspective of a decorator or profiler. Searching a module top-down for a function/method is often the only way to access its enclosing class, including nesting structure of classes.\r\n\r\nA workaround that sometimes worked but not in this case is to get the module via ``__code__.co_filename``. However, any valid approach for identifying the corresponding module and/or location in class hierarchy for a generated function would be fine.\r\n\r\nPlease apologize if I should overlook some approach that is already viable.\n", "hints_text": "We probably should try to set it to the module where the class is defined?\r\n\r\nThis problem will also appear with `__eq__` and `__hash__` with the next release.\n> We probably should try to set it to the module where the class is defined?\r\n\r\nYes that's right.\r\nDoes the generated method show up as member of a class if the class is inspected using ``dir`` or the ``inspect`` module or ``__dict__``? If not, it would be good to insert ``__qualname__`` as well, if that's not already done. (Sorry I don't know attrs well, so apologize if the ``__qualname__`` thing is already resolved. I'm just trying to early-prevent then next issue on this path...)\n@hynek Already spent a good amount of time learning how _make fits together.  With make.py:_make_init could add a 4th argument (cls) and then inside copy cls.__module__ to globs.  Either there or just setattr after  _make_init?\r\n\r\ncode reference\r\nhttps://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L905", "created_at": "2017-12-17T17:41:27Z"}
{"repo": "python-attrs/attrs", "pull_number": 315, "instance_id": "python-attrs__attrs-315", "issue_numbers": ["307"], "base_commit": "b3861d109bd7ad779877a230927d6a4e34d8a7e7", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -3,6 +3,7 @@\n import hashlib\n import linecache\n import sys\n+import warnings\n \n from operator import itemgetter\n \n@@ -16,7 +17,7 @@\n \n # This is used at least twice, so cache it here.\n _obj_setattr = object.__setattr__\n-_init_convert_pat = \"__attr_convert_{}\"\n+_init_converter_pat = \"__attr_converter_{}\"\n _init_factory_pat = \"__attr_factory_{}\"\n _tuple_property_pat = \"    {attr_name} = property(itemgetter({index}))\"\n _empty_metadata_singleton = metadata_proxy({})\n@@ -55,7 +56,7 @@ def __hash__(self):\n \n def attrib(default=NOTHING, validator=None,\n            repr=True, cmp=True, hash=None, init=True,\n-           convert=None, metadata=None, type=None):\n+           convert=None, metadata=None, type=None, converter=None):\n     \"\"\"\n     Create a new attribute on a class.\n \n@@ -111,8 +112,8 @@ def attrib(default=NOTHING, validator=None,\n         method.  It is possible to set this to ``False`` and set a default\n         value.  In that case this attributed is unconditionally initialized\n         with the specified default value or factory.\n-    :param callable convert: :func:`callable` that is called by\n-        ``attrs``-generated ``__init__`` methods to convert attribute's value\n+    :param callable converter: :func:`callable` that is called by\n+        ``attrs``-generated ``__init__`` methods to converter attribute's value\n         to the desired format.  It is given the passed-in value, and the\n         returned value will be used as the new value of the attribute.  The\n         value is converted before being passed to the validator, if any.\n@@ -125,17 +126,37 @@ def attrib(default=NOTHING, validator=None,\n         Regardless of the approach used, the type will be stored on\n         ``Attribute.type``.\n \n+    .. versionadded:: 15.2.0 *convert*\n+    .. versionadded:: 16.3.0 *metadata*\n     ..  versionchanged:: 17.1.0 *validator* can be a ``list`` now.\n     ..  versionchanged:: 17.1.0\n         *hash* is ``None`` and therefore mirrors *cmp* by default.\n     ..  versionadded:: 17.3.0 *type*\n+    ..  deprecated:: 17.4.0 *convert*\n+    ..  versionadded:: 17.4.0 *converter* as a replacement for the deprecated\n+        *convert* to achieve consistency with other noun-based arguments.\n     \"\"\"\n     if hash is not None and hash is not True and hash is not False:\n         raise TypeError(\n             \"Invalid value for hash.  Must be True, False, or None.\"\n         )\n+\n+    if convert is not None:\n+        if converter is not None:\n+            raise RuntimeError(\n+                \"Can't pass both `convert` and `converter`.  \"\n+                \"Please use `converter` only.\"\n+            )\n+        warnings.warn(\n+            \"The `convert` argument is deprecated in favor of `converter`.  \"\n+            \"It will be removed after 2019/01.\",\n+            DeprecationWarning, stacklevel=2\n+        )\n+        converter = convert\n+\n     if metadata is None:\n         metadata = {}\n+\n     return _CountingAttr(\n         default=default,\n         validator=validator,\n@@ -143,7 +164,7 @@ def attrib(default=NOTHING, validator=None,\n         cmp=cmp,\n         hash=hash,\n         init=init,\n-        convert=convert,\n+        converter=converter,\n         metadata=metadata,\n         type=type,\n     )\n@@ -1017,7 +1038,7 @@ def fmt_setter(attr_name, value_var):\n             }\n \n         def fmt_setter_with_converter(attr_name, value_var):\n-            conv_name = _init_convert_pat.format(attr_name)\n+            conv_name = _init_converter_pat.format(attr_name)\n             return \"_setattr('%(attr_name)s', %(conv)s(%(value_var)s))\" % {\n                 \"attr_name\": attr_name,\n                 \"value_var\": value_var,\n@@ -1031,7 +1052,7 @@ def fmt_setter(attr_name, value):\n             }\n \n         def fmt_setter_with_converter(attr_name, value_var):\n-            conv_name = _init_convert_pat.format(attr_name)\n+            conv_name = _init_converter_pat.format(attr_name)\n             return \"self.%(attr_name)s = %(conv)s(%(value_var)s)\" % {\n                 \"attr_name\": attr_name,\n                 \"value_var\": value_var,\n@@ -1058,12 +1079,12 @@ def fmt_setter_with_converter(attr_name, value_var):\n         if a.init is False:\n             if has_factory:\n                 init_factory_name = _init_factory_pat.format(a.name)\n-                if a.convert is not None:\n+                if a.converter is not None:\n                     lines.append(fmt_setter_with_converter(\n                         attr_name,\n                         init_factory_name + \"({0})\".format(maybe_self)))\n-                    conv_name = _init_convert_pat.format(a.name)\n-                    names_for_globals[conv_name] = a.convert\n+                    conv_name = _init_converter_pat.format(a.name)\n+                    names_for_globals[conv_name] = a.converter\n                 else:\n                     lines.append(fmt_setter(\n                         attr_name,\n@@ -1071,14 +1092,14 @@ def fmt_setter_with_converter(attr_name, value_var):\n                     ))\n                 names_for_globals[init_factory_name] = a.default.factory\n             else:\n-                if a.convert is not None:\n+                if a.converter is not None:\n                     lines.append(fmt_setter_with_converter(\n                         attr_name,\n                         \"attr_dict['{attr_name}'].default\"\n                         .format(attr_name=attr_name)\n                     ))\n-                    conv_name = _init_convert_pat.format(a.name)\n-                    names_for_globals[conv_name] = a.convert\n+                    conv_name = _init_converter_pat.format(a.name)\n+                    names_for_globals[conv_name] = a.converter\n                 else:\n                     lines.append(fmt_setter(\n                         attr_name,\n@@ -1092,9 +1113,11 @@ def fmt_setter_with_converter(attr_name, value_var):\n                     attr_name=attr_name,\n                 )\n             )\n-            if a.convert is not None:\n+            if a.converter is not None:\n                 lines.append(fmt_setter_with_converter(attr_name, arg_name))\n-                names_for_globals[_init_convert_pat.format(a.name)] = a.convert\n+                names_for_globals[_init_converter_pat.format(a.name)] = (\n+                    a.converter\n+                )\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name))\n         elif has_factory:\n@@ -1102,15 +1125,18 @@ def fmt_setter_with_converter(attr_name, value_var):\n             lines.append(\"if {arg_name} is not NOTHING:\"\n                          .format(arg_name=arg_name))\n             init_factory_name = _init_factory_pat.format(a.name)\n-            if a.convert is not None:\n-                lines.append(\"    \" + fmt_setter_with_converter(attr_name,\n-                                                                arg_name))\n+            if a.converter is not None:\n+                lines.append(\"    \" + fmt_setter_with_converter(\n+                    attr_name, arg_name\n+                ))\n                 lines.append(\"else:\")\n                 lines.append(\"    \" + fmt_setter_with_converter(\n                     attr_name,\n                     init_factory_name + \"({0})\".format(maybe_self)\n                 ))\n-                names_for_globals[_init_convert_pat.format(a.name)] = a.convert\n+                names_for_globals[_init_converter_pat.format(a.name)] = (\n+                    a.converter\n+                )\n             else:\n                 lines.append(\"    \" + fmt_setter(attr_name, arg_name))\n                 lines.append(\"else:\")\n@@ -1121,9 +1147,11 @@ def fmt_setter_with_converter(attr_name, value_var):\n             names_for_globals[init_factory_name] = a.default.factory\n         else:\n             args.append(arg_name)\n-            if a.convert is not None:\n+            if a.converter is not None:\n                 lines.append(fmt_setter_with_converter(attr_name, arg_name))\n-                names_for_globals[_init_convert_pat.format(a.name)] = a.convert\n+                names_for_globals[_init_converter_pat.format(a.name)] = (\n+                    a.converter\n+                )\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name))\n \n@@ -1156,17 +1184,34 @@ class Attribute(object):\n     :attribute name: The name of the attribute.\n \n     Plus *all* arguments of :func:`attr.ib`.\n+\n+    For the version history of the fields, see :func:`attr.ib`.\n     \"\"\"\n     __slots__ = (\n         \"name\", \"default\", \"validator\", \"repr\", \"cmp\", \"hash\", \"init\",\n-        \"convert\", \"metadata\", \"type\"\n+        \"metadata\", \"type\", \"converter\",\n     )\n \n     def __init__(self, name, default, validator, repr, cmp, hash, init,\n-                 convert=None, metadata=None, type=None):\n+                 convert=None, metadata=None, type=None, converter=None):\n         # Cache this descriptor here to speed things up later.\n         bound_setattr = _obj_setattr.__get__(self, Attribute)\n \n+        # Despite the big red warning, people *do* instantiate `Attribute`\n+        # themselves.\n+        if convert is not None:\n+            if converter is not None:\n+                raise RuntimeError(\n+                    \"Can't pass both `convert` and `converter`.  \"\n+                    \"Please use `converter` only.\"\n+                )\n+            warnings.warn(\n+                \"The `convert` argument is deprecated in favor of `converter`.\"\n+                \"  It will be removed after 2019/01.\",\n+                DeprecationWarning, stacklevel=2\n+            )\n+            converter = convert\n+\n         bound_setattr(\"name\", name)\n         bound_setattr(\"default\", default)\n         bound_setattr(\"validator\", validator)\n@@ -1174,14 +1219,25 @@ def __init__(self, name, default, validator, repr, cmp, hash, init,\n         bound_setattr(\"cmp\", cmp)\n         bound_setattr(\"hash\", hash)\n         bound_setattr(\"init\", init)\n-        bound_setattr(\"convert\", convert)\n-        bound_setattr(\"metadata\", (metadata_proxy(metadata) if metadata\n-                                   else _empty_metadata_singleton))\n+        bound_setattr(\"converter\", converter)\n+        bound_setattr(\"metadata\", (\n+            metadata_proxy(metadata) if metadata\n+            else _empty_metadata_singleton\n+        ))\n         bound_setattr(\"type\", type)\n \n     def __setattr__(self, name, value):\n         raise FrozenInstanceError()\n \n+    @property\n+    def convert(self):\n+        warnings.warn(\n+            \"The `convert` attribute is deprecated in favor of `converter`.  \"\n+            \"It will be removed after 2019/01.\",\n+            DeprecationWarning, stacklevel=2,\n+        )\n+        return self.converter\n+\n     @classmethod\n     def from_counting_attr(cls, name, ca, type=None):\n         # type holds the annotated value. deal with conflicts:\n@@ -1196,11 +1252,13 @@ def from_counting_attr(cls, name, ca, type=None):\n             for k\n             in Attribute.__slots__\n             if k not in (\n-                \"name\", \"validator\", \"default\", \"type\"\n-            )  # exclude methods\n+                \"name\", \"validator\", \"default\", \"type\", \"convert\",\n+            )  # exclude methods and deprecated alias\n         }\n-        return cls(name=name, validator=ca._validator, default=ca._default,\n-                   type=type, **inst_dict)\n+        return cls(\n+            name=name, validator=ca._validator, default=ca._default, type=type,\n+            **inst_dict\n+        )\n \n     # Don't use _add_pickle since fields(Attribute) doesn't work\n     def __getstate__(self):\n@@ -1224,9 +1282,12 @@ def __setstate__(self, state):\n                               _empty_metadata_singleton)\n \n \n-_a = [Attribute(name=name, default=NOTHING, validator=None,\n-                repr=True, cmp=True, hash=(name != \"metadata\"), init=True)\n-      for name in Attribute.__slots__]\n+_a = [\n+    Attribute(name=name, default=NOTHING, validator=None,\n+              repr=True, cmp=True, hash=(name != \"metadata\"), init=True)\n+    for name in Attribute.__slots__\n+    if name != \"convert\"  # XXX: remove once `convert` is gone\n+]\n \n Attribute = _add_hash(\n     _add_cmp(_add_repr(Attribute, attrs=_a), attrs=_a),\n@@ -1243,7 +1304,7 @@ class _CountingAttr(object):\n     likely the result of a bug like a forgotten `@attr.s` decorator.\n     \"\"\"\n     __slots__ = (\"counter\", \"_default\", \"repr\", \"cmp\", \"hash\", \"init\",\n-                 \"metadata\", \"_validator\", \"convert\", \"type\")\n+                 \"metadata\", \"_validator\", \"converter\", \"type\")\n     __attrs_attrs__ = tuple(\n         Attribute(name=name, default=NOTHING, validator=None,\n                   repr=True, cmp=True, hash=True, init=True)\n@@ -1255,7 +1316,7 @@ class _CountingAttr(object):\n     )\n     cls_counter = 0\n \n-    def __init__(self, default, validator, repr, cmp, hash, init, convert,\n+    def __init__(self, default, validator, repr, cmp, hash, init, converter,\n                  metadata, type):\n         _CountingAttr.cls_counter += 1\n         self.counter = _CountingAttr.cls_counter\n@@ -1269,7 +1330,7 @@ def __init__(self, default, validator, repr, cmp, hash, init, convert,\n         self.cmp = cmp\n         self.hash = hash\n         self.init = init\n-        self.convert = convert\n+        self.converter = converter\n         self.metadata = metadata\n         self.type = type\n \n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -121,6 +121,66 @@ def f(self):\n         assert Factory(f, True) == a._default\n \n \n+class TestAttribute(object):\n+    \"\"\"\n+    Tests for `attr.Attribute`.\n+    \"\"\"\n+    def test_deprecated_convert_argument(self):\n+        \"\"\"\n+        Using *convert* raises a DeprecationWarning and sets the converter\n+        field.\n+        \"\"\"\n+        def conv(v):\n+            return v\n+\n+        with pytest.warns(DeprecationWarning) as wi:\n+            a = Attribute(\n+                \"a\", True, True, True, True, True, True, convert=conv\n+            )\n+        w = wi.pop()\n+\n+        assert conv == a.converter\n+        assert (\n+            \"The `convert` argument is deprecated in favor of `converter`.  \"\n+            \"It will be removed after 2019/01.\",\n+        ) == w.message.args\n+        assert __file__ == w.filename\n+\n+    def test_deprecated_convert_attribute(self):\n+        \"\"\"\n+        If Attribute.convert is accessed, a DeprecationWarning is raised.\n+        \"\"\"\n+        def conv(v):\n+            return v\n+\n+        a = simple_attr(\"a\", converter=conv)\n+        with pytest.warns(DeprecationWarning) as wi:\n+            convert = a.convert\n+        w = wi.pop()\n+\n+        assert conv is convert is a.converter\n+        assert (\n+            \"The `convert` attribute is deprecated in favor of `converter`.  \"\n+            \"It will be removed after 2019/01.\",\n+        ) == w.message.args\n+        assert __file__ == w.filename\n+\n+    def test_convert_converter(self):\n+        \"\"\"\n+        A TypeError is raised if both *convert* and *converter* are passed.\n+        \"\"\"\n+        with pytest.raises(RuntimeError) as ei:\n+            Attribute(\n+                \"a\", True, True, True, True, True, True,\n+                convert=lambda v: v, converter=lambda v: v,\n+            )\n+\n+        assert (\n+            \"Can't pass both `convert` and `converter`.  \"\n+            \"Please use `converter` only.\",\n+        ) == ei.value.args\n+\n+\n def make_tc():\n     class TransformC(object):\n         z = attr.ib()\n@@ -188,8 +248,8 @@ class C(object):\n             \"No mandatory attributes allowed after an attribute with a \"\n             \"default value or factory.  Attribute in question: Attribute\"\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n-            \"cmp=True, hash=None, init=True, convert=None, \"\n-            \"metadata=mappingproxy({}), type=None)\",\n+            \"cmp=True, hash=None, init=True, metadata=mappingproxy({}), \"\n+            \"type=None, converter=None)\",\n         ) == e.value.args\n \n     def test_these(self):\n@@ -578,16 +638,16 @@ def test_fields_properties(self, C):\n             assert getattr(fields(C), attribute.name) is attribute\n \n \n-class TestConvert(object):\n+class TestConverter(object):\n     \"\"\"\n     Tests for attribute conversion.\n     \"\"\"\n     def test_convert(self):\n         \"\"\"\n-        Return value of convert is used as the attribute's value.\n+        Return value of converter is used as the attribute's value.\n         \"\"\"\n         C = make_class(\"C\", {\n-            \"x\": attr.ib(convert=lambda v: v + 1),\n+            \"x\": attr.ib(converter=lambda v: v + 1),\n             \"y\": attr.ib(),\n         })\n         c = C(1, 2)\n@@ -602,7 +662,7 @@ def test_convert_property(self, val, init):\n         \"\"\"\n         C = make_class(\"C\", {\n             \"y\": attr.ib(),\n-            \"x\": attr.ib(init=init, default=val, convert=lambda v: v + 1),\n+            \"x\": attr.ib(init=init, default=val, converter=lambda v: v + 1),\n         })\n         c = C(2)\n \n@@ -619,7 +679,7 @@ def test_convert_factory_property(self, val, init):\n             \"x\": attr.ib(\n                 init=init,\n                 default=Factory(lambda: val),\n-                convert=lambda v: v + 1),\n+                converter=lambda v: v + 1),\n         })\n         c = C(2)\n \n@@ -654,7 +714,7 @@ def validator(inst, attr, val):\n             raise RuntimeError(\"foo\")\n         C = make_class(\n             \"C\", {\n-                \"x\": attr.ib(validator=validator, convert=lambda v: 1 / 0),\n+                \"x\": attr.ib(validator=validator, converter=lambda v: 1 / 0),\n                 \"y\": attr.ib(),\n             })\n         with pytest.raises(ZeroDivisionError):\n@@ -665,10 +725,49 @@ def test_frozen(self):\n         Converters circumvent immutability.\n         \"\"\"\n         C = make_class(\"C\", {\n-            \"x\": attr.ib(convert=lambda v: int(v)),\n+            \"x\": attr.ib(converter=lambda v: int(v)),\n         }, frozen=True)\n         C(\"1\")\n \n+    def test_deprecated_convert(self):\n+        \"\"\"\n+        Using *convert* raises a DeprecationWarning and sets the converter\n+        field.\n+        \"\"\"\n+        def conv(v):\n+            return v\n+\n+        with pytest.warns(DeprecationWarning) as wi:\n+            @attr.s\n+            class C(object):\n+                x = attr.ib(convert=conv)\n+\n+            convert = fields(C).x.convert\n+\n+        assert 2 == len(wi.list)\n+        w = wi.pop()\n+\n+        assert conv == fields(C).x.converter == convert\n+        assert (\n+            \"The `convert` argument is deprecated in favor of `converter`.  \"\n+            \"It will be removed after 2019/01.\",\n+        ) == w.message.args\n+        assert __file__ == w.filename\n+\n+    def test_convert_converter(self):\n+        \"\"\"\n+        A TypeError is raised if both *convert* and *converter* are passed.\n+        \"\"\"\n+        with pytest.raises(RuntimeError) as ei:\n+            @attr.s\n+            class C(object):\n+                x = attr.ib(convert=lambda v: v, converter=lambda v: v)\n+\n+        assert (\n+            \"Can't pass both `convert` and `converter`.  \"\n+            \"Please use `converter` only.\",\n+        ) == ei.value.args\n+\n \n class TestValidate(object):\n     \"\"\"\ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -30,13 +30,13 @@ def simple_class(cmp=False, repr=False, hash=False, str=False, slots=False,\n \n \n def simple_attr(name, default=NOTHING, validator=None, repr=True,\n-                cmp=True, hash=None, init=True):\n+                cmp=True, hash=None, init=True, converter=None):\n     \"\"\"\n     Return an attribute with a name and no other bells and whistles.\n     \"\"\"\n     return Attribute(\n         name=name, default=default, validator=validator, repr=repr,\n-        cmp=cmp, hash=hash, init=init\n+        cmp=cmp, hash=hash, init=init, converter=converter,\n     )\n \n \n@@ -167,9 +167,17 @@ def simple_attrs_with_metadata(draw):\n     metadata = draw(st.dictionaries(\n         keys=keys, values=vals, min_size=1, max_size=5))\n \n-    return attr.ib(c_attr._default, c_attr._validator, c_attr.repr,\n-                   c_attr.cmp, c_attr.hash, c_attr.init, c_attr.convert,\n-                   metadata)\n+    return attr.ib(\n+        default=c_attr._default,\n+        validator=c_attr._validator,\n+        repr=c_attr.repr,\n+        cmp=c_attr.cmp,\n+        hash=c_attr.hash,\n+        init=c_attr.init,\n+        metadata=metadata,\n+        type=None,\n+        converter=c_attr.converter,\n+    )\n \n \n simple_attrs = simple_attrs_without_metadata | simple_attrs_with_metadata()\n", "problem_statement": "convert should be converter\nWe use proper nouns everywhere else too and this is kind of a sore thumb to me.  `attr.ib(convert=int)` should be deprecated and replaced by `attr.ib(converter=int)`.\n", "hints_text": "", "created_at": "2017-12-16T07:00:42Z"}
{"repo": "python-attrs/attrs", "pull_number": 304, "instance_id": "python-attrs__attrs-304", "issue_numbers": ["298"], "base_commit": "2c20c0f199bc3d4b52bf478e00417ea41111f30a", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -264,7 +264,7 @@ def _transform_attrs(cls, these, auto_attribs):\n             if isinstance(attr, _CountingAttr)\n         ), key=lambda e: e[1].counter)\n \n-    non_super_attrs = [\n+    own_attrs = [\n         Attribute.from_counting_attr(\n             name=attr_name,\n             ca=ca,\n@@ -274,34 +274,22 @@ def _transform_attrs(cls, these, auto_attribs):\n         in ca_list\n     ]\n \n-    # Walk *down* the MRO for attributes.  While doing so, we collect the names\n-    # of attributes we've seen in `take_attr_names` and ignore their\n-    # redefinitions deeper in the hierarchy.\n     super_attrs = []\n-    taken_attr_names = {a.name: a for a in non_super_attrs}\n+    taken_attr_names = {a.name: a for a in own_attrs}\n+\n+    # Traverse the MRO and collect attributes.\n     for super_cls in cls.__mro__[1:-1]:\n         sub_attrs = getattr(super_cls, \"__attrs_attrs__\", None)\n         if sub_attrs is not None:\n-            # We iterate over sub_attrs backwards so we can reverse the whole\n-            # list in the end and get all attributes in the order they have\n-            # been defined.\n-            for a in reversed(sub_attrs):\n+            for a in sub_attrs:\n                 prev_a = taken_attr_names.get(a.name)\n+                # Only add an attribute if it hasn't been defined before.  This\n+                # allows for overwriting attribute definitions by subclassing.\n                 if prev_a is None:\n                     super_attrs.append(a)\n                     taken_attr_names[a.name] = a\n-                elif prev_a == a:\n-                    # This happens thru multiple inheritance.  We don't want\n-                    # to favor attributes that are further down in the tree\n-                    # so we move them to the back.\n-                    super_attrs.remove(a)\n-                    super_attrs.append(a)\n-\n-    # Now reverse the list, such that the attributes are sorted by *descending*\n-    # age.  IOW: the oldest attribute definition is at the head of the list.\n-    super_attrs.reverse()\n \n-    attr_names = [a.name for a in super_attrs + non_super_attrs]\n+    attr_names = [a.name for a in super_attrs + own_attrs]\n \n     AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)\n \n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -235,7 +235,7 @@ class D(A):\n             d2 = attr.ib(default=\"d2\")\n \n         @attr.s\n-        class E(D, C):\n+        class E(C, D):\n             e1 = attr.ib(default=\"e1\")\n             e2 = attr.ib(default=\"e2\")\n \n", "problem_statement": "order of attributes is 'backwards' in case of multiple inheritance\nconsider following code.  I also added a dummy method `m` to show that precedence is \"correct\"ly follows for a basic method\r\n\r\n```python\r\nfrom attr import attributes, attr\r\n\r\n@attributes\r\nclass A(object):\r\n    a = attr()\r\n    def m(self):\r\n        print(\"A.m\")\r\n\r\n@attributes\r\nclass B(object):\r\n    b = attr()\r\n    def m(self):\r\n        print(\"B.m\")\r\n\r\n@attributes\r\nclass C(A, B):\r\n    c = attr()\r\n\r\n    def m(self):\r\n        super(C, self).m()\r\n\r\n    @classmethod\r\n    def supers(cls):\r\n        return cls.__bases__\r\n\r\nc = C(1, 2, 3)\r\n\r\nprint(c)\r\nc.m()\r\nprint(\"supers=%s\" % str(c.supers()))\r\n```\r\nrunning it results in \r\n```\r\nC(b=1, a=2, c=3)\r\nA.m\r\nsupers=(<class '__main__.A'>, <class '__main__.B'>)\r\n```\r\nso the first argument is (IMHO) incorrectly assigned to attribute b not a, and then 2nd one to a...\r\n\r\nBefore recent 3040bdabbc627fc6a4d151a9cb2e6f9d4177b6f2  quick and dirty (and possibly incomplete) fix was to remove `reversed` around mro within src/attr/_make.py  but neither I have looked yet into how logic should be adjusted in the current state of affairs, nor I analyzed for why reversed was needed to start with\n", "hints_text": "Sorry I didn't get around this any earlier, but I wanted to have a weekend so I can wrap my head around it.\r\n\r\nYou\u2019re right, we\u2019ve been traversing the MRO wrongly until recently.  I have a fix similar to yours, I\u2019m just not 100% sure how to proceed.  It seems that this bug is rather old and fixing it is technically breaking backward compatibility.\r\n\r\nI\u2019m tending to rip of the bandaid tho, since it\u2019s clearly behaving wrongly.", "created_at": "2017-12-03T07:19:36Z"}
{"repo": "python-attrs/attrs", "pull_number": 302, "instance_id": "python-attrs__attrs-302", "issue_numbers": ["265"], "base_commit": "3c9830f340535b663f2ceaca2d52d363bbf70df6", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -14,6 +14,7 @@\n     fields,\n     fields_dict,\n     make_class,\n+    resolve_types,\n     validate,\n )\n from ._version_info import VersionInfo\n@@ -61,6 +62,7 @@\n     \"has\",\n     \"ib\",\n     \"make_class\",\n+    \"resolve_types\",\n     \"s\",\n     \"set_run_validators\",\n     \"setters\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -1707,6 +1707,45 @@ def fields_dict(cls):\n     return ordered_dict(((a.name, a) for a in attrs))\n \n \n+def resolve_types(cls, globalns=None, localns=None):\n+    \"\"\"\n+    Resolve any strings and forward annotations in type annotations.\n+\n+    With no arguments, names will be looked up in the module in which the class\n+    was created.  If this is incorrect, e.g. if the name only exists inside a\n+    method, you may pass globalns or localns to specify other dictionaries in\n+    which to look up these names. See the docs of `typing.get_type_hints` for\n+    more details.\n+\n+    :param type cls: Class to resolve.\n+    :param globalns: Dictionary containing global variables, if needed.\n+    :param localns: Dictionary containing local variables, if needed.\n+\n+    :raise TypeError: If *cls* is not a class.\n+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``\n+        class.\n+    :raise NameError: If types cannot be resolved because of missing variables.\n+\n+    ..  versionadded:: 19.4.0\n+    \"\"\"\n+    try:\n+        # Since calling get_type_hints is expensive we cache whether we've\n+        # done it already.\n+        cls.__attrs_types_resolved__\n+    except AttributeError:\n+        import typing\n+\n+        hints = typing.get_type_hints(cls, globalns=globalns, localns=localns)\n+        for field in fields(cls):\n+            if field.name in hints:\n+                # Since fields have been frozen we must work around it.\n+                _obj_setattr(field, \"type\", hints[field.name])\n+        cls.__attrs_types_resolved__ = True\n+\n+    # Return the class so you can use it as a decorator too.\n+    return cls\n+\n+\n def validate(inst):\n     \"\"\"\n     Validate all attributes on *inst* that have a validator.\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -297,3 +297,107 @@ def __eq__(self, other):\n         @attr.s(auto_attribs=True)\n         class C:\n             x: typing.Any = NonComparable()\n+\n+    def test_basic_resolve(self):\n+        \"\"\"\n+        Resolve the `Attribute.type` attr from basic type annotations.\n+        Unannotated types are ignored.\n+        \"\"\"\n+\n+        @attr.s\n+        class C:\n+            x: \"int\" = attr.ib()\n+            y = attr.ib(type=str)\n+            z = attr.ib()\n+\n+        assert \"int\" == attr.fields(C).x.type\n+        assert str is attr.fields(C).y.type\n+        assert None is attr.fields(C).z.type\n+\n+        attr.resolve_types(C)\n+\n+        assert int is attr.fields(C).x.type\n+        assert str is attr.fields(C).y.type\n+        assert None is attr.fields(C).z.type\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_resolve_types_auto_attrib(self, slots):\n+        \"\"\"\n+        Types can be resolved even when strings are involved.\n+        \"\"\"\n+\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class A:\n+            a: typing.List[int]\n+            b: typing.List[\"int\"]\n+            c: \"typing.List[int]\"\n+\n+        assert typing.List[int] == attr.fields(A).a.type\n+        assert typing.List[\"int\"] == attr.fields(A).b.type\n+        assert \"typing.List[int]\" == attr.fields(A).c.type\n+\n+        # Note: I don't have to pass globals and locals here because\n+        # int is a builtin and will be available in any scope.\n+        attr.resolve_types(A)\n+\n+        assert typing.List[int] == attr.fields(A).a.type\n+        assert typing.List[int] == attr.fields(A).b.type\n+        assert typing.List[int] == attr.fields(A).c.type\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_resolve_types_decorator(self, slots):\n+        \"\"\"\n+        Types can be resolved using it as a decorator.\n+        \"\"\"\n+\n+        @attr.resolve_types\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class A:\n+            a: typing.List[int]\n+            b: typing.List[\"int\"]\n+            c: \"typing.List[int]\"\n+\n+        assert typing.List[int] == attr.fields(A).a.type\n+        assert typing.List[int] == attr.fields(A).b.type\n+        assert typing.List[int] == attr.fields(A).c.type\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_self_reference(self, slots):\n+        \"\"\"\n+        References to self class using quotes can be resolved.\n+        \"\"\"\n+\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class A:\n+            a: \"A\"\n+            b: typing.Optional[\"A\"]  # noqa: will resolve below\n+\n+        assert \"A\" == attr.fields(A).a.type\n+        assert typing.Optional[\"A\"] == attr.fields(A).b.type\n+\n+        attr.resolve_types(A, globals(), locals())\n+\n+        assert A == attr.fields(A).a.type\n+        assert typing.Optional[A] == attr.fields(A).b.type\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_forward_reference(self, slots):\n+        \"\"\"\n+        Forward references can be resolved.\n+        \"\"\"\n+\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class A:\n+            a: typing.List[\"B\"]  # noqa: will resolve below\n+\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class B:\n+            a: A\n+\n+        assert typing.List[\"B\"] == attr.fields(A).a.type\n+        assert A == attr.fields(B).a.type\n+\n+        attr.resolve_types(A, globals(), locals())\n+\n+        assert typing.List[B] == attr.fields(A).a.type\n+        assert A == attr.fields(B).a.type\n", "problem_statement": "Forward references\nHello, there's some food for thought. Imagine a class referencing itself.\r\n\r\n```\r\n@attr.s\r\nclass A:\r\n    a: 'A' = attr.ib()\r\n```\r\n\r\nThis is the proper way of doing this as per mypy. In the case of attrs though:\r\n\r\n```\r\n>>> attr.fields(A).a\r\nAttribute(name='a', default=NOTHING, validator=None, repr=True, cmp=True, hash=None, init=True, convert=None, metadata=mappingproxy({}), type='A')\r\n```\r\n\r\nThe string just gets copied into the type attribute. `A.__annotations__` has the same problem. Ideally the type would be the actual class object. Mypy deals with this by having more than one pass when parsing.\r\n\r\nThe first question to answer if whether we should deal with this here, in attrs, or let code making use of the type attribute deal with it. Maybe instead of expecting higher levels to deal with this, Python itself should handle it (although good luck waiting for this :). I think it's worth trying to deal with this problem in attrs, to make it easier for others.\r\n\r\nDealing with just a class referencing itself is very doable. Now imagine circular references.\r\n\r\n```\r\n@attr.s\r\nclass A:\r\n    b: 'B' = attr.ib()\r\n\r\n@attr.s\r\nclass B:\r\n    a: A = attr.ib()\r\n```\r\n\r\nNot really sure what to do here.\n", "hints_text": "This issue was initially motivated by https://github.com/Tinche/cattrs/issues/13.\nGitHub doesn't have enough Emojis for this one.", "created_at": "2017-11-29T21:18:26Z"}
{"repo": "python-attrs/attrs", "pull_number": 296, "instance_id": "python-attrs__attrs-296", "issue_numbers": ["295"], "base_commit": "ef9a062022c3057e03c7790fc67f15aabddf72c3", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -701,13 +701,37 @@ def _make_hash(attrs):\n         if a.hash is True or (a.hash is None and a.cmp is True)\n     )\n \n-    def hash_(self):\n-        \"\"\"\n-        Automatically created by attrs.\n-        \"\"\"\n-        return hash(_attrs_to_tuple(self, attrs))\n+    # We cache the generated init methods for the same kinds of attributes.\n+    sha1 = hashlib.sha1()\n+    sha1.update(repr(attrs).encode(\"utf-8\"))\n+    unique_filename = \"<attrs generated hash %s>\" % (sha1.hexdigest(),)\n+    type_hash = hash(unique_filename)\n+    lines = [\n+        \"def __hash__(self):\",\n+        \"    return hash((\",\n+        \"        %d,\" % (type_hash,),\n+    ]\n+    for a in attrs:\n+        lines.append(\"        self.%s,\" % (a.name))\n+\n+    lines.append(\"    ))\")\n+\n+    script = \"\\n\".join(lines)\n+    globs = {}\n+    locs = {}\n+    bytecode = compile(script, unique_filename, \"exec\")\n+    eval(bytecode, globs, locs)\n+\n+    # In order of debuggers like PDB being able to step through the code,\n+    # we add a fake linecache entry.\n+    linecache.cache[unique_filename] = (\n+        len(script),\n+        None,\n+        script.splitlines(True),\n+        unique_filename,\n+    )\n \n-    return hash_\n+    return locs[\"__hash__\"]\n \n \n def _add_hash(cls, attrs):\n@@ -858,7 +882,7 @@ def _make_init(attrs, post_init, frozen):\n         sha1.hexdigest()\n     )\n \n-    script, globs = _attrs_to_script(\n+    script, globs = _attrs_to_init_script(\n         attrs,\n         frozen,\n         post_init,\n@@ -875,7 +899,6 @@ def _make_init(attrs, post_init, frozen):\n         # immutability.\n         globs[\"_cached_setattr\"] = _obj_setattr\n     eval(bytecode, globs, locs)\n-    init = locs[\"__init__\"]\n \n     # In order of debuggers like PDB being able to step through the code,\n     # we add a fake linecache entry.\n@@ -883,10 +906,10 @@ def _make_init(attrs, post_init, frozen):\n         len(script),\n         None,\n         script.splitlines(True),\n-        unique_filename\n+        unique_filename,\n     )\n \n-    return init\n+    return locs[\"__init__\"]\n \n \n def _add_init(cls, frozen):\n@@ -946,7 +969,7 @@ def validate(inst):\n             v(inst, a, getattr(inst, a.name))\n \n \n-def _attrs_to_script(attrs, frozen, post_init):\n+def _attrs_to_init_script(attrs, frozen, post_init):\n     \"\"\"\n     Return a script of an initializer for *attrs* and a dict of globals.\n \n", "test_patch": "", "problem_statement": "__hash__ works only on attribute values\nCurrently our `__hash__` methods returns the hash of a tuple with all attribute values but without taking type information into account:\r\n\r\n```pycon\r\n>>> @attr.s(hash=True)\r\n... class C:\r\n...     x = attr.ib()\r\n>>> hash(C(1)) == hash((1,))\r\nTrue\r\n```\r\n\r\nOopsies!\n", "hints_text": "", "created_at": "2017-11-18T14:38:39Z"}
{"repo": "python-attrs/attrs", "pull_number": 292, "instance_id": "python-attrs__attrs-292", "issue_numbers": ["291"], "base_commit": "a84a36d45f34a82a1bb3180a33d5842f7718cdef", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -201,6 +201,22 @@ def _is_class_var(annot):\n     return str(annot).startswith(\"typing.ClassVar\")\n \n \n+def _get_annotations(cls):\n+    \"\"\"\n+    Get annotations for *cls*.\n+    \"\"\"\n+    anns = getattr(cls, \"__annotations__\", None)\n+    if anns is None:\n+        return {}\n+\n+    # Verify that the annotations aren't merely inherited.\n+    for super_cls in cls.__mro__[1:]:\n+        if anns is getattr(super_cls, \"__annotations__\", None):\n+            return {}\n+\n+    return anns\n+\n+\n def _transform_attrs(cls, these, auto_attribs):\n     \"\"\"\n     Transform all `_CountingAttr`s on a class into `Attribute`s.\n@@ -210,16 +226,15 @@ def _transform_attrs(cls, these, auto_attribs):\n     Return an `_Attributes`.\n     \"\"\"\n     cd = cls.__dict__\n-    anns = getattr(cls, \"__annotations__\", {})\n+    anns = _get_annotations(cls)\n \n-    if these is None and auto_attribs is False:\n+    if these is not None:\n         ca_list = sorted((\n-            (name, attr)\n-            for name, attr\n-            in cd.items()\n-            if isinstance(attr, _CountingAttr)\n+            (name, ca)\n+            for name, ca\n+            in iteritems(these)\n         ), key=lambda e: e[1].counter)\n-    elif these is None and auto_attribs is True:\n+    elif auto_attribs is True:\n         ca_names = {\n             name\n             for name, attr\n@@ -251,9 +266,10 @@ def _transform_attrs(cls, these, auto_attribs):\n             )\n     else:\n         ca_list = sorted((\n-            (name, ca)\n-            for name, ca\n-            in iteritems(these)\n+            (name, attr)\n+            for name, attr\n+            in cd.items()\n+            if isinstance(attr, _CountingAttr)\n         ), key=lambda e: e[1].counter)\n \n     non_super_attrs = [\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -131,3 +131,26 @@ class C:\n         assert (\n             \"The following `attr.ib`s lack a type annotation: v, y.\",\n         ) == e.value.args\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_auto_attribs_subclassing(self, slots):\n+        \"\"\"\n+        Attributes from super classes are inherited, it doesn't matter if the\n+        subclass has annotations or not.\n+\n+        Ref #291\n+        \"\"\"\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class A:\n+            a: int = 1\n+\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class B(A):\n+            b: int = 2\n+\n+        @attr.s(slots=slots, auto_attribs=True)\n+        class C(A):\n+            pass\n+\n+        assert \"B(a=1, b=2)\" == repr(B())\n+        assert \"C(a=1)\" == repr(C())\n", "problem_statement": "Type hint defaults don't work with inheritance\nConsider\r\n\r\n```\r\nIn [12]: @attr.s(auto_attribs=True)\r\n    ...: class A:\r\n    ...:     a: int = 10\r\n    ...:\r\n\r\nIn [13]: @attr.s(auto_attribs=True)\r\n    ...: class B(A):\r\n    ...:     pass\r\n    ...:\r\n\r\nIn [14]: A()\r\nOut[14]: A(a=10)\r\n\r\nIn [15]: B()\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-15-1c5ecc61f85b> in <module>()\r\n----> 1 B()\r\n\r\nTypeError: __init__() missing 1 required positional argument: 'a'\r\n\r\n```\r\n\r\nThis should work, given that the following works:\r\n\r\n```\r\nIn [16]: @attr.s()\r\n    ...: class A:\r\n    ...:     a = attr.ib(default=10)\r\n    ...:\r\n\r\nIn [17]: @attr.s()\r\n    ...: class B(A):\r\n    ...:     pass\r\n    ...:\r\n\r\nIn [18]: A()\r\nOut[18]: A(a=10)\r\n\r\nIn [19]: B()\r\nOut[19]: B(a=10)\r\n\r\n```\n", "hints_text": "Ugh so it\u2019s not inheritance, it\u2019s inheritance + no new annotations.  The problem is that `__annotations__` gets inherited:\r\n\r\n```pycon\r\n>>> import attr\r\n\r\n>>> @attr.s(auto_attribs=True)\r\n... class A:\r\n...     a: int = 10\r\n\r\n>>> @attr.s(auto_attribs=True)\r\n... class B(A):\r\n...     pass\r\n\r\n>>> A.__annotations__\r\n{'a': <class 'int'>}\r\n\r\n>>> B.__annotations__\r\n{'a': <class 'int'>}\r\n\r\n>>> A.__annotations__ is B.__annotations__\r\nTrue\r\n\r\n>>> @attr.s(auto_attribs=True)\r\n... class C(A):\r\n...     c: float = 20.0\r\n\r\n>>> C()\r\nC(a=10, c=20.0)\r\n```", "created_at": "2017-11-11T07:04:59Z"}
{"repo": "python-attrs/attrs", "pull_number": 287, "instance_id": "python-attrs__attrs-287", "issue_numbers": ["285"], "base_commit": "1e6627c9ad64988c3d547606fd379eb1dd32d80b", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -270,7 +270,7 @@ def _transform_attrs(cls, these, auto_attribs):\n     # of attributes we've seen in `take_attr_names` and ignore their\n     # redefinitions deeper in the hierarchy.\n     super_attrs = []\n-    taken_attr_names = set(a.name for a in non_super_attrs)\n+    taken_attr_names = {a.name: a for a in non_super_attrs}\n     for super_cls in cls.__mro__[1:-1]:\n         sub_attrs = getattr(super_cls, \"__attrs_attrs__\", None)\n         if sub_attrs is not None:\n@@ -278,9 +278,16 @@ def _transform_attrs(cls, these, auto_attribs):\n             # list in the end and get all attributes in the order they have\n             # been defined.\n             for a in reversed(sub_attrs):\n-                if a.name not in taken_attr_names:\n+                prev_a = taken_attr_names.get(a.name)\n+                if prev_a is None:\n+                    super_attrs.append(a)\n+                    taken_attr_names[a.name] = a\n+                elif prev_a == a:\n+                    # This happens thru multiple inheritance.  We don't want\n+                    # to favor attributes that are further down in the tree\n+                    # so we move them to the back.\n+                    super_attrs.remove(a)\n                     super_attrs.append(a)\n-                    taken_attr_names.add(a.name)\n \n     # Now reverse the list, such that the attributes are sorted by *descending*\n     # age.  IOW: the oldest attribute definition is at the head of the list.\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -214,6 +214,42 @@ class C(Base):\n             simple_attr(\"x\"),\n         ) == attrs\n \n+    def test_multiple_inheritance(self):\n+        \"\"\"\n+        Order of attributes doesn't get mixed up by multiple inheritance.\n+\n+        See #285\n+        \"\"\"\n+        @attr.s\n+        class A(object):\n+            a1 = attr.ib(default=\"a1\")\n+            a2 = attr.ib(default=\"a2\")\n+\n+        @attr.s\n+        class B(A):\n+            b1 = attr.ib(default=\"b1\")\n+            b2 = attr.ib(default=\"b2\")\n+\n+        @attr.s\n+        class C(B, A):\n+            c1 = attr.ib(default=\"c1\")\n+            c2 = attr.ib(default=\"c2\")\n+\n+        @attr.s\n+        class D(A):\n+            d1 = attr.ib(default=\"d1\")\n+            d2 = attr.ib(default=\"d2\")\n+\n+        @attr.s\n+        class E(D, C):\n+            e1 = attr.ib(default=\"e1\")\n+            e2 = attr.ib(default=\"e2\")\n+\n+        assert (\n+            \"E(a1='a1', a2='a2', b1='b1', b2='b2', c1='c1', c2='c2', d1='d1', \"\n+            \"d2='d2', e1='e1', e2='e2')\"\n+        ) == repr(E())\n+\n \n class TestAttributes(object):\n     \"\"\"\n", "problem_statement": "17.3.0 changes the order how inherited class attributes are defined if they have the same base class\nMinimal working example:\r\n```\r\nimport attr\r\n\r\n@attr.s()\r\nclass A:\r\n    name = attr.ib()\r\n    cookie = attr.ib(default=\"Cookie\")\r\n\r\n@attr.s()\r\nclass B:\r\n    cake = attr.ib(default=\"Cake\")\r\n    cereal = attr.ib(default=\"Cereal\")\r\n\r\n@attr.s()\r\nclass C(B, A):\r\n    breakfast = attr.ib(default=\"All\")\r\n\r\n@attr.s()\r\nclass D(A):\r\n    food = attr.ib(default=\"food\")\r\n    melon = attr.ib(default=\"melon\")\r\n\r\n@attr.s()\r\nclass E(D, C):\r\n    apple = attr.ib(default=\"apple\")\r\n```\r\nThis works with attrs==17.2.0 and breaks with attrs==17.3.0. In 17.3.0 the list of non_super_names in base.py: `['cake', 'cereal', 'breakfast', 'name', 'cookie', 'food', 'melon', 'apple']` breaks because attr is trying to create a non-default attribute in between default attributes. \n", "hints_text": "When looking at what ``_transform_attrs`` is doing for class E, we see what's going wrong. The MRO for E is E, D, C, B, A.\r\nIt first collects all (not just locally defined) attributes from ``D.__attrs_attrs__`` in reverse order: ``melon``, ``food``, ``cookie``, ``name``. Then it looks at ``C.__attrs_attrs__`` and collects the attributes which are not yet defined: ``breakfast``, ``cereal``, ``cake``.\r\nWhen reversing this again,  ``cake``, ``cereal``and ``breakfast`` end up before the ``name`` attribute.\r\nIt seems that this should work if it only looked at the locally defined attributes when iterating over the MRO, as ``A.name`` would be processed last.\nAs a minimal workaround, this change fixes the order for our usecase:\r\n``` diff\r\n@@ -278,7 +278,9 @@\r\n             # list in the end and get all attributes in the order they have\r\n             # been defined.\r\n             for a in reversed(sub_attrs):\r\n-                if a.name not in taken_attr_names:\r\n+                if a.name in super_cls.__super_names__:\r\n+                    continue\r\n+                elif a.name not in taken_attr_names:\r\n                     super_attrs.append(a)\r\n                     taken_attr_names.add(a.name)\r\n \r\n@@ -354,6 +356,7 @@\r\n         self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\r\n \r\n         self._cls_dict[\"__attrs_attrs__\"] = self._attrs\r\n+        self._cls_dict[\"__super_names__\"] = self._super_names\r\n \r\n         if frozen:\r\n             self._cls_dict[\"__setattr__\"] = _frozen_setattrs\r\n```\r\nThe downside is obviously cluttering the generated classes with the ``__super_names__`` attribute. Perhaps each Attribute could keep a reference to the class where it was defined.\r\nThat would allow ``_transform_attrs`` to filter out those defined on other super classes and only handle them later where they were actually defined.", "created_at": "2017-11-09T11:55:51Z"}
{"repo": "python-attrs/attrs", "pull_number": 286, "instance_id": "python-attrs__attrs-286", "issue_numbers": ["284"], "base_commit": "7501cecf0f4313c3b2597d03ac0853cca1659065", "patch": "diff --git a/src/attr/_compat.py b/src/attr/_compat.py\n--- a/src/attr/_compat.py\n+++ b/src/attr/_compat.py\n@@ -3,6 +3,7 @@\n import platform\n import sys\n import types\n+import warnings\n \n \n PY2 = sys.version_info[0] == 2\n@@ -85,11 +86,54 @@ def iteritems(d):\n     def metadata_proxy(d):\n         return types.MappingProxyType(dict(d))\n \n-if PYPY:  # pragma: no cover\n-    def set_closure_cell(cell, value):\n-        cell.__setstate__((value,))\n+\n+def import_ctypes():  # pragma: nocover\n+    \"\"\"\n+    Moved into a function for testability.\n+    \"\"\"\n+    try:\n+        import ctypes\n+        return ctypes\n+    except ImportError:\n+        return None\n+\n+\n+if not PY2:\n+    def just_warn(*args, **kw):\n+        \"\"\"\n+        We only warn on Python 3 because we are not aware of any concrete\n+        consequences of not setting the cell on Python 2.\n+        \"\"\"\n+        warnings.warn(\n+            \"Missing ctypes.  Some features like bare super() or accessing \"\n+            \"__class__ will not work with slots classes.\",\n+            RuntimeWarning,\n+            stacklevel=2,\n+        )\n else:\n-    import ctypes\n-    set_closure_cell = ctypes.pythonapi.PyCell_Set\n-    set_closure_cell.argtypes = (ctypes.py_object, ctypes.py_object)\n-    set_closure_cell.restype = ctypes.c_int\n+    def just_warn(*args, **kw):  # pragma: nocover\n+        \"\"\"\n+        We only warn on Python 3 because we are not aware of any concrete\n+        consequences of not setting the cell on Python 2.\n+        \"\"\"\n+\n+\n+def make_set_closure_cell():\n+    \"\"\"\n+    Moved into a function for testability.\n+    \"\"\"\n+    if PYPY:  # pragma: no cover\n+        def set_closure_cell(cell, value):\n+            cell.__setstate__((value,))\n+    else:\n+        ctypes = import_ctypes()\n+        if ctypes is not None:\n+            set_closure_cell = ctypes.pythonapi.PyCell_Set\n+            set_closure_cell.argtypes = (ctypes.py_object, ctypes.py_object)\n+            set_closure_cell.restype = ctypes.c_int\n+        else:\n+            set_closure_cell = just_warn\n+    return set_closure_cell\n+\n+\n+set_closure_cell = make_set_closure_cell()\n", "test_patch": "diff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -13,7 +13,7 @@\n \n import attr\n \n-from attr._compat import PY2\n+from attr._compat import PY2, PYPY, just_warn, make_set_closure_cell\n \n \n @attr.s\n@@ -325,76 +325,98 @@ class C2(C1Bare):\n \n \n @pytest.mark.skipif(PY2, reason=\"closure cell rewriting is PY3-only.\")\n-def test_closure_cell_rewriting():\n-    \"\"\"\n-    Slot classes support proper closure cell rewriting.\n-\n-    This affects features like `__class__` and the no-arg super().\n-    \"\"\"\n-    non_slot_instance = C1(x=1, y=\"test\")\n-    slot_instance = C1Slots(x=1, y=\"test\")\n-\n-    assert non_slot_instance.my_class() is C1\n-    assert slot_instance.my_class() is C1Slots\n-\n-    # Just assert they return something, and not an exception.\n-    assert non_slot_instance.my_super()\n-    assert slot_instance.my_super()\n-\n-\n-@pytest.mark.skipif(PY2, reason=\"closure cell rewriting is PY3-only.\")\n-def test_closure_cell_rewriting_inheritance():\n-    \"\"\"\n-    Slot classes support proper closure cell rewriting when inheriting.\n-\n-    This affects features like `__class__` and the no-arg super().\n-    \"\"\"\n-    @attr.s\n-    class C2(C1):\n-        def my_subclass(self):\n-            return __class__  # NOQA: F821\n-\n-    @attr.s\n-    class C2Slots(C1Slots):\n-        def my_subclass(self):\n-            return __class__  # NOQA: F821\n-\n-    non_slot_instance = C2(x=1, y=\"test\")\n-    slot_instance = C2Slots(x=1, y=\"test\")\n-\n-    assert non_slot_instance.my_class() is C1\n-    assert slot_instance.my_class() is C1Slots\n-\n-    # Just assert they return something, and not an exception.\n-    assert non_slot_instance.my_super()\n-    assert slot_instance.my_super()\n-\n-    assert non_slot_instance.my_subclass() is C2\n-    assert slot_instance.my_subclass() is C2Slots\n-\n-\n-@pytest.mark.skipif(PY2, reason=\"closure cell rewriting is PY3-only.\")\n-@pytest.mark.parametrize(\"slots\", [True, False])\n-def test_closure_cell_rewriting_cls_static(slots):\n-    \"\"\"\n-    Slot classes support proper closure cell rewriting for class- and static\n-    methods.\n-    \"\"\"\n-    # Python can reuse closure cells, so we create new classes just for\n-    # this test.\n-\n-    @attr.s(slots=slots)\n-    class C:\n-        @classmethod\n-        def clsmethod(cls):\n-            return __class__  # noqa: F821\n-\n-    assert C.clsmethod() is C\n-\n-    @attr.s(slots=slots)\n-    class D:\n-        @staticmethod\n-        def statmethod():\n-            return __class__  # noqa: F821\n-\n-    assert D.statmethod() is D\n+class TestClosureCellRewriting(object):\n+    def test_closure_cell_rewriting(self):\n+        \"\"\"\n+        Slot classes support proper closure cell rewriting.\n+\n+        This affects features like `__class__` and the no-arg super().\n+        \"\"\"\n+        non_slot_instance = C1(x=1, y=\"test\")\n+        slot_instance = C1Slots(x=1, y=\"test\")\n+\n+        assert non_slot_instance.my_class() is C1\n+        assert slot_instance.my_class() is C1Slots\n+\n+        # Just assert they return something, and not an exception.\n+        assert non_slot_instance.my_super()\n+        assert slot_instance.my_super()\n+\n+    def test_inheritance(self):\n+        \"\"\"\n+        Slot classes support proper closure cell rewriting when inheriting.\n+\n+        This affects features like `__class__` and the no-arg super().\n+        \"\"\"\n+        @attr.s\n+        class C2(C1):\n+            def my_subclass(self):\n+                return __class__  # NOQA: F821\n+\n+        @attr.s\n+        class C2Slots(C1Slots):\n+            def my_subclass(self):\n+                return __class__  # NOQA: F821\n+\n+        non_slot_instance = C2(x=1, y=\"test\")\n+        slot_instance = C2Slots(x=1, y=\"test\")\n+\n+        assert non_slot_instance.my_class() is C1\n+        assert slot_instance.my_class() is C1Slots\n+\n+        # Just assert they return something, and not an exception.\n+        assert non_slot_instance.my_super()\n+        assert slot_instance.my_super()\n+\n+        assert non_slot_instance.my_subclass() is C2\n+        assert slot_instance.my_subclass() is C2Slots\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_cls_static(self, slots):\n+        \"\"\"\n+        Slot classes support proper closure cell rewriting for class- and\n+        static methods.\n+        \"\"\"\n+        # Python can reuse closure cells, so we create new classes just for\n+        # this test.\n+\n+        @attr.s(slots=slots)\n+        class C:\n+            @classmethod\n+            def clsmethod(cls):\n+                return __class__  # noqa: F821\n+\n+        assert C.clsmethod() is C\n+\n+        @attr.s(slots=slots)\n+        class D:\n+            @staticmethod\n+            def statmethod():\n+                return __class__  # noqa: F821\n+\n+        assert D.statmethod() is D\n+\n+    @pytest.mark.skipif(\n+        PYPY,\n+        reason=\"ctypes are used only on CPython\"\n+    )\n+    def test_missing_ctypes(self, monkeypatch):\n+        \"\"\"\n+        Keeps working if ctypes is missing.\n+\n+        A warning is emitted that points to the actual code.\n+        \"\"\"\n+        monkeypatch.setattr(attr._compat, \"import_ctypes\", lambda: None)\n+        func = make_set_closure_cell()\n+\n+        with pytest.warns(RuntimeWarning) as wr:\n+            func()\n+\n+        w = wr.pop()\n+        assert __file__ == w.filename\n+        assert (\n+            \"Missing ctypes.  Some features like bare super() or accessing \"\n+            \"__class__ will not work with slots classes.\",\n+        ) == w.message.args\n+\n+        assert just_warn is func\n", "problem_statement": "Allow using attrs without ctypes\n#226 introduced the use of `ctypes`. I use attrs in a Google App Engine application. The app runs in a sandbox which limits the use of certain modules. `ctypes` is one of those libraries.\r\n\r\nI can peg my app to use only attrs 17.2.0, but it would be nice to have a fail-gently approach where, if ctypes is unavailable, attrs keeps working, though the behavior allowed by #226 of course would not work.\n", "hints_text": "Now, that\u2019s unfortunate!  Making the support unconditional is gonna be easy, the big question is how to document/communicate the behavior it to the user. \ud83e\udd14\nProbably log a warning? Hopefully in a way that's visible.\nAlso, we won't need ctypes in CPython 3.7 right?", "created_at": "2017-11-09T10:33:37Z"}
{"repo": "python-attrs/attrs", "pull_number": 277, "instance_id": "python-attrs__attrs-277", "issue_numbers": ["262"], "base_commit": "2a50c4b93002a0f4f4355051759beae5e0324497", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -1,5 +1,7 @@\n from __future__ import absolute_import, division, print_function\n \n+from functools import partial\n+\n from ._funcs import (\n     asdict,\n     assoc,\n@@ -43,6 +45,7 @@\n \n s = attributes = attrs\n ib = attr = attrib\n+dataclass = partial(attrs, auto_attribs=True)  # happy Easter ;)\n \n __all__ = [\n     \"Attribute\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -18,6 +18,7 @@\n     DefaultAlreadySetError,\n     FrozenInstanceError,\n     NotAnAttrsClassError,\n+    UnannotatedAttributeError,\n )\n \n \n@@ -190,7 +191,17 @@ class MyClassAttributes(tuple):\n ])\n \n \n-def _transform_attrs(cls, these):\n+def _is_class_var(annot):\n+    \"\"\"\n+    Check whether *annot* is a typing.ClassVar.\n+\n+    The implementation is gross but importing `typing` is slow and there are\n+    discussions to remove it from the stdlib alltogether.\n+    \"\"\"\n+    return str(annot).startswith(\"typing.ClassVar\")\n+\n+\n+def _transform_attrs(cls, these, auto_attribs):\n     \"\"\"\n     Transform all `_CountingAttr`s on a class into `Attribute`s.\n \n@@ -198,24 +209,58 @@ def _transform_attrs(cls, these):\n \n     Return an `_Attributes`.\n     \"\"\"\n-    if these is None:\n-        ca_list = [(name, attr)\n-                   for name, attr\n-                   in cls.__dict__.items()\n-                   if isinstance(attr, _CountingAttr)]\n+    cd = cls.__dict__\n+    anns = getattr(cls, \"__annotations__\", {})\n+\n+    if these is None and auto_attribs is False:\n+        ca_list = sorted((\n+            (name, attr)\n+            for name, attr\n+            in cd.items()\n+            if isinstance(attr, _CountingAttr)\n+        ), key=lambda e: e[1].counter)\n+    elif these is None and auto_attribs is True:\n+        ca_names = {\n+            name\n+            for name, attr\n+            in cd.items()\n+            if isinstance(attr, _CountingAttr)\n+        }\n+        ca_list = []\n+        annot_names = set()\n+        for attr_name, type in anns.items():\n+            if _is_class_var(type):\n+                continue\n+            annot_names.add(attr_name)\n+            a = cd.get(attr_name, NOTHING)\n+            if not isinstance(a, _CountingAttr):\n+                if a is NOTHING:\n+                    a = attrib()\n+                else:\n+                    a = attrib(default=a)\n+            ca_list.append((attr_name, a))\n+\n+        unannotated = ca_names - annot_names\n+        if len(unannotated) > 0:\n+            raise UnannotatedAttributeError(\n+                \"The following `attr.ib`s lack a type annotation: \" +\n+                \", \".join(sorted(\n+                    unannotated,\n+                    key=lambda n: cd.get(n).counter\n+                )) + \".\"\n+            )\n     else:\n-        ca_list = [(name, ca)\n-                   for name, ca\n-                   in iteritems(these)]\n-    ca_list = sorted(ca_list, key=lambda e: e[1].counter)\n-\n-    ann = getattr(cls, \"__annotations__\", {})\n+        ca_list = sorted((\n+            (name, ca)\n+            for name, ca\n+            in iteritems(these)\n+        ), key=lambda e: e[1].counter)\n \n     non_super_attrs = [\n         Attribute.from_counting_attr(\n             name=attr_name,\n             ca=ca,\n-            type=ann.get(attr_name),\n+            type=anns.get(attr_name),\n         )\n         for attr_name, ca\n         in ca_list\n@@ -250,7 +295,7 @@ def _transform_attrs(cls, these):\n             Attribute.from_counting_attr(\n                 name=attr_name,\n                 ca=ca,\n-                type=ann.get(attr_name)\n+                type=anns.get(attr_name)\n             )\n             for attr_name, ca\n             in ca_list\n@@ -296,8 +341,8 @@ class _ClassBuilder(object):\n         \"_frozen\", \"_has_post_init\",\n     )\n \n-    def __init__(self, cls, these, slots, frozen):\n-        attrs, super_attrs = _transform_attrs(cls, these)\n+    def __init__(self, cls, these, slots, frozen, auto_attribs):\n+        attrs, super_attrs = _transform_attrs(cls, these, auto_attribs)\n \n         self._cls = cls\n         self._cls_dict = dict(cls.__dict__) if slots else {}\n@@ -460,7 +505,7 @@ def add_cmp(self):\n \n def attrs(maybe_cls=None, these=None, repr_ns=None,\n           repr=True, cmp=True, hash=None, init=True,\n-          slots=False, frozen=False, str=False):\n+          slots=False, frozen=False, str=False, auto_attribs=False):\n     r\"\"\"\n     A class decorator that adds `dunder\n     <https://wiki.python.org/moin/DunderAlias>`_\\ -methods according to the\n@@ -535,6 +580,23 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n                ``object.__setattr__(self, \"attribute_name\", value)``.\n \n         ..  _slots: https://docs.python.org/3/reference/datamodel.html#slots\n+    :param bool auto_attribs: If True, collect `PEP 526`_-annotated attributes\n+        (Python 3.6 and later only) from the class body.\n+\n+        In this case, you **must** annotate every field.  If ``attrs``\n+        encounters a field that is set to an :func:`attr.ib` but lacks a type\n+        annotation, an :exc:`attr.exceptions.UnannotatedAttributeError` is\n+        raised.  Use ``field_name: typing.Any = attr.ib(...)`` if you don't\n+        want to set a type.\n+\n+        If you assign a value to those attributes (e.g. ``x: int = 42``), that\n+        value becomes the default value like if it were passed using\n+        ``attr.ib(default=42)``.  Passing an instance of :class:`Factory` also\n+        works as expected.\n+\n+        Attributes annotated as :class:`typing.ClassVar` are **ignored**.\n+\n+        .. _`PEP 526`: https://www.python.org/dev/peps/pep-0526/\n \n     ..  versionadded:: 16.0.0 *slots*\n     ..  versionadded:: 16.1.0 *frozen*\n@@ -542,12 +604,13 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n     ..  versionchanged::\n             17.1.0 *hash* supports ``None`` as value which is also the default\n             now.\n+    .. versionadded:: 17.3.0 *auto_attribs*\n     \"\"\"\n     def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n             raise TypeError(\"attrs only works with new-style classes.\")\n \n-        builder = _ClassBuilder(cls, these, slots, frozen)\n+        builder = _ClassBuilder(cls, these, slots, frozen, auto_attribs)\n \n         if repr is True:\n             builder.add_repr(repr_ns)\ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\n--- a/src/attr/exceptions.py\n+++ b/src/attr/exceptions.py\n@@ -37,3 +37,12 @@ class DefaultAlreadySetError(RuntimeError):\n \n     .. versionadded:: 17.1.0\n     \"\"\"\n+\n+\n+class UnannotatedAttributeError(RuntimeError):\n+    \"\"\"\n+    A class with ``auto_attribs=True`` has an ``attr.ib()`` without a type\n+    annotation.\n+\n+    .. versionadded:: 17.3.0\n+    \"\"\"\n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -4,12 +4,15 @@\n Python 3.6+ only.\n \"\"\"\n \n+import types\n import typing\n \n import pytest\n \n import attr\n \n+from attr.exceptions import UnannotatedAttributeError\n+\n \n class TestAnnotations:\n     \"\"\"\n@@ -65,3 +68,66 @@ class C:\n             y: int\n \n         assert 1 == len(attr.fields(C))\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_auto_attribs(self, slots):\n+        \"\"\"\n+        If *auto_attribs* is True, bare annotations are collected too.\n+        Defaults work and class variables are ignored.\n+        \"\"\"\n+        @attr.s(auto_attribs=True, slots=slots)\n+        class C:\n+            cls_var: typing.ClassVar[int] = 23\n+            a: int\n+            x: typing.List[int] = attr.Factory(list)\n+            y: int = 2\n+            z: int = attr.ib(default=3)\n+            foo: typing.Any = None\n+\n+        i = C(42)\n+        assert \"C(a=42, x=[], y=2, z=3, foo=None)\" == repr(i)\n+\n+        attr_names = set(a.name for a in C.__attrs_attrs__)\n+        assert \"a\" in attr_names  # just double check that the set works\n+        assert \"cls_var\" not in attr_names\n+\n+        assert int == attr.fields(C).a.type\n+\n+        assert attr.Factory(list) == attr.fields(C).x.default\n+        assert typing.List[int] == attr.fields(C).x.type\n+\n+        assert int == attr.fields(C).y.type\n+        assert 2 == attr.fields(C).y.default\n+\n+        assert int == attr.fields(C).z.type\n+\n+        assert typing.Any == attr.fields(C).foo.type\n+\n+        # Class body is clean.\n+        if slots is False:\n+            with pytest.raises(AttributeError):\n+                C.y\n+\n+            assert 2 == i.y\n+        else:\n+            assert isinstance(C.y, types.MemberDescriptorType)\n+\n+            i.y = 23\n+            assert 23 == i.y\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_auto_attribs_unannotated(self, slots):\n+        \"\"\"\n+        Unannotated `attr.ib`s raise an error.\n+        \"\"\"\n+        with pytest.raises(UnannotatedAttributeError) as e:\n+            @attr.s(slots=slots, auto_attribs=True)\n+            class C:\n+                v = attr.ib()\n+                x: int\n+                y = attr.ib()\n+                z: str\n+\n+        assert (\n+            \"The following `attr.ib`s lack a type annotation: v, y.\",\n+        ) == e.value.args\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -144,7 +144,7 @@ def test_no_modifications(self):\n         Doesn't attach __attrs_attrs__ to the class anymore.\n         \"\"\"\n         C = make_tc()\n-        _transform_attrs(C, None)\n+        _transform_attrs(C, None, False)\n \n         assert None is getattr(C, \"__attrs_attrs__\", None)\n \n@@ -153,7 +153,7 @@ def test_normal(self):\n         Transforms every `_CountingAttr` and leaves others (a) be.\n         \"\"\"\n         C = make_tc()\n-        attrs, _, = _transform_attrs(C, None)\n+        attrs, _, = _transform_attrs(C, None, False)\n \n         assert [\"z\", \"y\", \"x\"] == [a.name for a in attrs]\n \n@@ -165,14 +165,14 @@ def test_empty(self):\n         class C(object):\n             pass\n \n-        assert _Attributes(((), [])) == _transform_attrs(C, None)\n+        assert _Attributes(((), [])) == _transform_attrs(C, None, False)\n \n     def test_transforms_to_attribute(self):\n         \"\"\"\n         All `_CountingAttr`s are transformed into `Attribute`s.\n         \"\"\"\n         C = make_tc()\n-        attrs, super_attrs = _transform_attrs(C, None)\n+        attrs, super_attrs = _transform_attrs(C, None, False)\n \n         assert [] == super_attrs\n         assert 3 == len(attrs)\n@@ -188,7 +188,7 @@ class C(object):\n             y = attr.ib()\n \n         with pytest.raises(ValueError) as e:\n-            _transform_attrs(C, None)\n+            _transform_attrs(C, None, False)\n         assert (\n             \"No mandatory attributes allowed after an attribute with a \"\n             \"default value or factory.  Attribute in question: Attribute\"\n@@ -207,7 +207,7 @@ class Base(object):\n         class C(Base):\n             y = attr.ib()\n \n-        attrs, super_attrs = _transform_attrs(C, {\"x\": attr.ib()})\n+        attrs, super_attrs = _transform_attrs(C, {\"x\": attr.ib()}, False)\n \n         assert [] == super_attrs\n         assert (\n@@ -817,7 +817,7 @@ def test_repr(self):\n         class C(object):\n             pass\n \n-        b = _ClassBuilder(C, None, True, True)\n+        b = _ClassBuilder(C, None, True, True, False)\n \n         assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n \n@@ -828,7 +828,7 @@ def test_returns_self(self):\n         class C(object):\n             x = attr.ib()\n \n-        b = _ClassBuilder(C, None, True, True)\n+        b = _ClassBuilder(C, None, True, True, False)\n \n         cls = b.add_cmp().add_hash().add_init().add_repr(\"ns\").add_str() \\\n             .build_class()\n", "problem_statement": "Add option to collect annotated fields\nSince I\u2019m sick of hearing that \u201c[PEP 557](https://www.python.org/dev/peps/pep-0557/) is like attrs, but using variable annotations for field declarations\u201d, I\u2019d like to have an option to collect annotated fields that have no attr.ib definition.\r\n\r\nie.\r\n\r\n```python\r\n@attr.s(collect_bare=True)\r\nclass C:\r\n    x: int\r\n```\r\n\r\nshould be equivalent to:\r\n\r\n```python\r\n@attr.s\r\nclass C:\r\n    x: int = attr.ib()\r\n```\r\n\r\nI\u2019m open to better/shorter names.\r\n\r\nVolunteers?  @chadrik maybe? :)\n", "hints_text": "Hm I'd actually be ok with doing this by default?\nA turn off switch would be nice, just default collect_bare to true? Is this a compatibility issue?\nI\u2019d love to but that is technically backward incompatible.\nDurn it.\nWe could run it thru a deprecation cycle I guess?\n`s/collect_bare/automatic_attributes/`\r\n\nMaybe just `auto_attribs`?\nSo I gave this a lackluster shot and I\u2019ve run into a problem:\r\n\r\n```python\r\n    def test_auto_attribs(self):\r\n        \"\"\"\r\n        If *auto_attribs* is True, bare annotations are collected too.\r\n        \"\"\"\r\n        @attr.s(auto_attribs=True)\r\n        class C:\r\n            x: typing.List[int]\r\n            b = attr.ib()\r\n            y: int\r\n\r\n        assert \"C(x=1, b=2, y=3)\" == repr(C(1, 2, 3))\r\n```\r\n\r\n`x` and `y` are defined in `__annotations__` while `b` is defined in `__dict__`.  It there a way to determine their order?\r\n\r\n***\r\n\r\nTo me it looks like all we can do is to allow either 100% annotations or 100% `attr.ib`s which only makes sense once we have something like this:\r\n\r\n```python\r\n@attr.s(auto_attribs=True, check_types=True)\r\nclass Point:\r\n    x: float\r\n    y: float\r\n```\r\n\r\nor am I missing something?  (since we can\u2019t attach any more meta data to the fields, this has to be something that happens in `@attr.s`)\r\n\r\nThis kind of smells like a `record = attr.s(auto_attribs=True, check_types=True, frozen=True, slots=True)` which is certainly useful\r\n\r\n***\r\n\r\nOr am I missing something?.\nAh OK: we just have to enforce that all fields are annotated.  That\u2019s not that bad.", "created_at": "2017-10-27T08:03:24Z"}
{"repo": "python-attrs/attrs", "pull_number": 272, "instance_id": "python-attrs__attrs-272", "issue_numbers": ["269"], "base_commit": "5c5677b72b385753a189b8a3d2d769c5d6a454e9", "patch": "diff --git a/conftest.py b/conftest.py\n--- a/conftest.py\n+++ b/conftest.py\n@@ -21,4 +21,7 @@ class C(object):\n \n collect_ignore = []\n if sys.version_info[:2] < (3, 6):\n-    collect_ignore.append(\"tests/test_annotations.py\")\n+    collect_ignore.extend([\n+        \"tests/test_annotations.py\",\n+        \"tests/test_init_subclass.py\",\n+    ])\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -181,22 +181,27 @@ class MyClassAttributes(tuple):\n     return globs[attr_class_name]\n \n \n+# Tuple class for extracted attributes from a class definition.\n+# `super_attrs` is a subset of `attrs`.\n+_Attributes = _make_attr_tuple_class(\"_Attributes\", [\n+    \"attrs\",        # all attributes to build dunder methods for\n+    \"super_attrs\",  # attributes that have been inherited from super classes\n+])\n+\n+\n def _transform_attrs(cls, these):\n     \"\"\"\n-    Transform all `_CountingAttr`s on a class into `Attribute`s and save the\n-    list in `__attrs_attrs__` while potentially deleting them from *cls*.\n+    Transform all `_CountingAttr`s on a class into `Attribute`s.\n \n     If *these* is passed, use that and don't look for them on the class.\n \n-    Return a list of tuples of (attribute name, attribute).\n+    Return an `_Attributes`.\n     \"\"\"\n     if these is None:\n         ca_list = [(name, attr)\n                    for name, attr\n                    in cls.__dict__.items()\n                    if isinstance(attr, _CountingAttr)]\n-        for name, _ in ca_list:\n-            delattr(cls, name)\n     else:\n         ca_list = [(name, ca)\n                    for name, ca\n@@ -206,35 +211,53 @@ def _transform_attrs(cls, these):\n     ann = getattr(cls, \"__annotations__\", {})\n \n     non_super_attrs = [\n-        Attribute.from_counting_attr(name=attr_name, ca=ca,\n-                                     type=ann.get(attr_name))\n+        Attribute.from_counting_attr(\n+            name=attr_name,\n+            ca=ca,\n+            type=ann.get(attr_name),\n+        )\n         for attr_name, ca\n         in ca_list\n     ]\n \n-    super_cls = []\n-    non_super_names = set(a.name for a in non_super_attrs)\n-    for c in reversed(cls.__mro__[1:-1]):\n-        sub_attrs = getattr(c, \"__attrs_attrs__\", None)\n+    # Walk *down* the MRO for attributes.  While doing so, we collect the names\n+    # of attributes we've seen in `take_attr_names` and ignore their\n+    # redefinitions deeper in the hierarchy.\n+    super_attrs = []\n+    taken_attr_names = set(a.name for a in non_super_attrs)\n+    for super_cls in cls.__mro__[1:-1]:\n+        sub_attrs = getattr(super_cls, \"__attrs_attrs__\", None)\n         if sub_attrs is not None:\n-            super_cls.extend(\n-                a for a in sub_attrs\n-                if a not in super_cls and a.name not in non_super_names\n-            )\n+            # We iterate over sub_attrs backwards so we can reverse the whole\n+            # list in the end and get all attributes in the order they have\n+            # been defined.\n+            for a in reversed(sub_attrs):\n+                if a.name not in taken_attr_names:\n+                    super_attrs.append(a)\n+                    taken_attr_names.add(a.name)\n \n-    attr_names = [a.name for a in super_cls + non_super_attrs]\n+    # Now reverse the list, such that the attributes are sorted by *descending*\n+    # age.  IOW: the oldest attribute definition is at the head of the list.\n+    super_attrs.reverse()\n+\n+    attr_names = [a.name for a in super_attrs + non_super_attrs]\n \n     AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)\n \n-    cls.__attrs_attrs__ = AttrsClass(super_cls + [\n-        Attribute.from_counting_attr(name=attr_name, ca=ca,\n-                                     type=ann.get(attr_name))\n-        for attr_name, ca\n-        in ca_list\n-    ])\n+    attrs = AttrsClass(\n+        super_attrs + [\n+            Attribute.from_counting_attr(\n+                name=attr_name,\n+                ca=ca,\n+                type=ann.get(attr_name)\n+            )\n+            for attr_name, ca\n+            in ca_list\n+        ]\n+    )\n \n     had_default = False\n-    for a in cls.__attrs_attrs__:\n+    for a in attrs:\n         if had_default is True and a.default is NOTHING and a.init is True:\n             raise ValueError(\n                 \"No mandatory attributes allowed after an attribute with a \"\n@@ -246,7 +269,7 @@ def _transform_attrs(cls, these):\n                 a.init is not False:\n             had_default = True\n \n-    return ca_list\n+    return _Attributes((attrs, super_attrs))\n \n \n def _frozen_setattrs(self, name, value):\n@@ -263,6 +286,177 @@ def _frozen_delattrs(self, name):\n     raise FrozenInstanceError()\n \n \n+class _ClassBuilder(object):\n+    \"\"\"\n+    Iteratively build *one* class.\n+    \"\"\"\n+    __slots__ = (\n+        \"_cls\", \"_cls_dict\", \"_attrs\", \"_super_names\", \"_attr_names\", \"_slots\",\n+        \"_frozen\", \"_has_post_init\",\n+    )\n+\n+    def __init__(self, cls, these, slots, frozen):\n+        attrs, super_attrs = _transform_attrs(cls, these)\n+\n+        self._cls = cls\n+        self._cls_dict = dict(cls.__dict__) if slots else {}\n+        self._attrs = attrs\n+        self._super_names = set(a.name for a in super_attrs)\n+        self._attr_names = tuple(a.name for a in attrs)\n+        self._slots = slots\n+        self._frozen = frozen or _has_frozen_superclass(cls)\n+        self._has_post_init = bool(getattr(cls, \"__attrs_post_init__\", False))\n+\n+        self._cls_dict[\"__attrs_attrs__\"] = self._attrs\n+\n+        if frozen:\n+            self._cls_dict[\"__setattr__\"] = _frozen_setattrs\n+            self._cls_dict[\"__delattr__\"] = _frozen_delattrs\n+\n+    def __repr__(self):\n+        return \"<_ClassBuilder(cls={cls})>\".format(cls=self._cls.__name__)\n+\n+    def build_class(self):\n+        \"\"\"\n+        Finalize class based on the accumulated configuration.\n+\n+        Builder cannot be used anymore after calling this method.\n+        \"\"\"\n+        if self._slots is True:\n+            return self._create_slots_class()\n+        else:\n+            return self._patch_original_class()\n+\n+    def _patch_original_class(self):\n+        \"\"\"\n+        Apply accumulated methods and return the class.\n+        \"\"\"\n+        cls = self._cls\n+        super_names = self._super_names\n+\n+        # Clean class of attribute definitions (`attr.ib()`s).\n+        for name in self._attr_names:\n+            if name not in super_names and \\\n+                    getattr(cls, name, None) is not None:\n+                delattr(cls, name)\n+\n+        # Attach our dunder methods.\n+        for name, value in self._cls_dict.items():\n+            setattr(cls, name, value)\n+\n+        return cls\n+\n+    def _create_slots_class(self):\n+        \"\"\"\n+        Build and return a new class with a `__slots__` attribute.\n+        \"\"\"\n+        super_names = self._super_names\n+        cd = {\n+            k: v\n+            for k, v in iteritems(self._cls_dict)\n+            if k not in tuple(self._attr_names) + (\"__dict__\",)\n+        }\n+\n+        # We only add the names of attributes that aren't inherited.\n+        # Settings __slots__ to inherited attributes wastes memory.\n+        cd[\"__slots__\"] = tuple(\n+            name\n+            for name in self._attr_names\n+            if name not in super_names\n+        )\n+\n+        qualname = getattr(self._cls, \"__qualname__\", None)\n+        if qualname is not None:\n+            cd[\"__qualname__\"] = qualname\n+\n+        attr_names = tuple(self._attr_names)\n+\n+        def slots_getstate(self):\n+            \"\"\"\n+            Automatically created by attrs.\n+            \"\"\"\n+            return tuple(getattr(self, name) for name in attr_names)\n+\n+        def slots_setstate(self, state):\n+            \"\"\"\n+            Automatically created by attrs.\n+            \"\"\"\n+            __bound_setattr = _obj_setattr.__get__(self, Attribute)\n+            for name, value in zip(attr_names, state):\n+                __bound_setattr(name, value)\n+\n+        # slots and frozen require __getstate__/__setstate__ to work\n+        cd[\"__getstate__\"] = slots_getstate\n+        cd[\"__setstate__\"] = slots_setstate\n+\n+        # Create new class based on old class and our methods.\n+        cls = type(self._cls)(\n+            self._cls.__name__,\n+            self._cls.__bases__,\n+            cd,\n+        )\n+\n+        # The following is a fix for\n+        # https://github.com/python-attrs/attrs/issues/102.  On Python 3,\n+        # if a method mentions `__class__` or uses the no-arg super(), the\n+        # compiler will bake a reference to the class in the method itself\n+        # as `method.__closure__`.  Since we replace the class with a\n+        # clone, we rewrite these references so it keeps working.\n+        for item in cls.__dict__.values():\n+            if isinstance(item, (classmethod, staticmethod)):\n+                # Class- and staticmethods hide their functions inside.\n+                # These might need to be rewritten as well.\n+                closure_cells = getattr(item.__func__, \"__closure__\", None)\n+            else:\n+                closure_cells = getattr(item, \"__closure__\", None)\n+\n+            if not closure_cells:  # Catch None or the empty list.\n+                continue\n+            for cell in closure_cells:\n+                if cell.cell_contents is self._cls:\n+                    set_closure_cell(cell, cls)\n+\n+        return cls\n+\n+    def add_repr(self, ns):\n+        self._cls_dict[\"__repr__\"] = _make_repr(self._attrs, ns=ns)\n+        return self\n+\n+    def add_str(self):\n+        repr_ = self._cls_dict.get(\"__repr__\")\n+        if repr_ is None:\n+            raise ValueError(\n+                \"__str__ can only be generated if a __repr__ exists.\"\n+            )\n+\n+        self._cls_dict[\"__str__\"] = repr_\n+        return self\n+\n+    def make_unhashable(self):\n+        self._cls_dict[\"__hash__\"] = None\n+        return self\n+\n+    def add_hash(self):\n+        self._cls_dict[\"__hash__\"] = _make_hash(self._attrs)\n+        return self\n+\n+    def add_init(self):\n+        self._cls_dict[\"__init__\"] = _make_init(\n+            self._attrs,\n+            self._has_post_init,\n+            self._frozen,\n+        )\n+        return self\n+\n+    def add_cmp(self):\n+        cd = self._cls_dict\n+\n+        cd[\"__eq__\"], cd[\"__ne__\"], cd[\"__lt__\"], cd[\"__le__\"], cd[\"__gt__\"], \\\n+            cd[\"__ge__\"] = _make_cmp(self._attrs)\n+\n+        return self\n+\n+\n def attrs(maybe_cls=None, these=None, repr_ns=None,\n           repr=True, cmp=True, hash=None, init=True,\n           slots=False, frozen=False, str=False):\n@@ -339,7 +533,7 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,\n                circumvent that limitation by using\n                ``object.__setattr__(self, \"attribute_name\", value)``.\n \n-        ..  _slots: https://docs.python.org/3.5/reference/datamodel.html#slots\n+        ..  _slots: https://docs.python.org/3/reference/datamodel.html#slots\n \n     ..  versionadded:: 16.0.0 *slots*\n     ..  versionadded:: 16.1.0 *frozen*\n@@ -352,70 +546,31 @@ def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n             raise TypeError(\"attrs only works with new-style classes.\")\n \n-        if repr is False and str is True:\n-            raise ValueError(\n-                \"__str__ can only be generated if a __repr__ exists.\"\n-            )\n-\n-        ca_list = _transform_attrs(cls, these)\n+        builder = _ClassBuilder(cls, these, slots, frozen)\n \n-        # Can't just re-use frozen name because Python's scoping. :(\n-        # Can't compare function objects because Python 2 is terrible. :(\n-        effectively_frozen = _has_frozen_superclass(cls) or frozen\n         if repr is True:\n-            cls = _add_repr(cls, ns=repr_ns, str=str)\n+            builder.add_repr(repr_ns)\n+        if str is True:\n+            builder.add_str()\n         if cmp is True:\n-            cls = _add_cmp(cls)\n+            builder.add_cmp()\n \n         if hash is not True and hash is not False and hash is not None:\n+            # Can't use `hash in` because 1 == True for example.\n             raise TypeError(\n                 \"Invalid value for hash.  Must be True, False, or None.\"\n             )\n         elif hash is False or (hash is None and cmp is False):\n             pass\n         elif hash is True or (hash is None and cmp is True and frozen is True):\n-            cls = _add_hash(cls)\n+            builder.add_hash()\n         else:\n-            cls.__hash__ = None\n+            builder.make_unhashable()\n \n         if init is True:\n-            cls = _add_init(cls, effectively_frozen)\n-        if effectively_frozen is True:\n-            cls.__setattr__ = _frozen_setattrs\n-            cls.__delattr__ = _frozen_delattrs\n-            if slots is True:\n-                # slots and frozen require __getstate__/__setstate__ to work\n-                cls = _add_pickle(cls)\n-        if slots is True:\n-            cls_dict = dict(cls.__dict__)\n-            attr_names = tuple(t[0] for t in ca_list)\n-            cls_dict[\"__slots__\"] = attr_names\n-            for ca_name in attr_names:\n-                # It might not actually be in there, e.g. if using 'these'.\n-                cls_dict.pop(ca_name, None)\n-            cls_dict.pop(\"__dict__\", None)\n-            old_cls = cls\n-\n-            qualname = getattr(cls, \"__qualname__\", None)\n-            cls = type(cls)(cls.__name__, cls.__bases__, cls_dict)\n-            if qualname is not None:\n-                cls.__qualname__ = qualname\n-\n-            # The following is a fix for\n-            # https://github.com/python-attrs/attrs/issues/102.  On Python 3,\n-            # if a method mentions `__class__` or uses the no-arg super(), the\n-            # compiler will bake a reference to the class in the method itself\n-            # as `method.__closure__`.  Since we replace the class with a\n-            # clone, we rewrite these references so it keeps working.\n-            for item in cls.__dict__.values():\n-                closure_cells = getattr(item, \"__closure__\", None)\n-                if not closure_cells:  # Catch None or the empty list.\n-                    continue\n-                for cell in closure_cells:\n-                    if cell.cell_contents is old_cls:\n-                        set_closure_cell(cell, cls)\n+            builder.add_init()\n \n-        return cls\n+        return builder.build_class()\n \n     # maybe_cls's type depends on the usage of the decorator.  It's a class\n     # if it's used as `@attrs` but ``None`` if used as `@attrs()`.\n@@ -460,14 +615,12 @@ def _attrs_to_tuple(obj, attrs):\n     return tuple(getattr(obj, a.name) for a in attrs)\n \n \n-def _add_hash(cls, attrs=None):\n-    \"\"\"\n-    Add a hash method to *cls*.\n-    \"\"\"\n-    if attrs is None:\n-        attrs = [a\n-                 for a in cls.__attrs_attrs__\n-                 if a.hash is True or (a.hash is None and a.cmp is True)]\n+def _make_hash(attrs):\n+    attrs = tuple(\n+        a\n+        for a in attrs\n+        if a.hash is True or (a.hash is None and a.cmp is True)\n+    )\n \n     def hash_(self):\n         \"\"\"\n@@ -475,16 +628,19 @@ def hash_(self):\n         \"\"\"\n         return hash(_attrs_to_tuple(self, attrs))\n \n-    cls.__hash__ = hash_\n-    return cls\n+    return hash_\n \n \n-def _add_cmp(cls, attrs=None):\n+def _add_hash(cls, attrs):\n     \"\"\"\n-    Add comparison methods to *cls*.\n+    Add a hash method to *cls*.\n     \"\"\"\n-    if attrs is None:\n-        attrs = [a for a in cls.__attrs_attrs__ if a.cmp]\n+    cls.__hash__ = _make_hash(attrs)\n+    return cls\n+\n+\n+def _make_cmp(attrs):\n+    attrs = [a for a in attrs if a.cmp]\n \n     def attrs_to_tuple(obj):\n         \"\"\"\n@@ -547,22 +703,31 @@ def ge(self, other):\n         else:\n             return NotImplemented\n \n-    cls.__eq__ = eq\n-    cls.__ne__ = ne\n-    cls.__lt__ = lt\n-    cls.__le__ = le\n-    cls.__gt__ = gt\n-    cls.__ge__ = ge\n+    return eq, ne, lt, le, gt, ge\n+\n+\n+def _add_cmp(cls, attrs=None):\n+    \"\"\"\n+    Add comparison methods to *cls*.\n+    \"\"\"\n+    if attrs is None:\n+        attrs = cls.__attrs_attrs__\n+\n+    cls.__eq__, cls.__ne__, cls.__lt__, cls.__le__, cls.__gt__, cls.__ge__ = \\\n+        _make_cmp(attrs)\n \n     return cls\n \n \n-def _add_repr(cls, ns=None, attrs=None, str=False):\n+def _make_repr(attrs, ns):\n     \"\"\"\n-    Add a repr method to *cls*. If *str* is True, also add __str__.\n+    Make a repr method for *attr_names* adding *ns* to the full name.\n     \"\"\"\n-    if attrs is None:\n-        attrs = [a for a in cls.__attrs_attrs__ if a.repr]\n+    attr_names = tuple(\n+        a.name\n+        for a in attrs\n+        if a.repr\n+    )\n \n     def repr_(self):\n         \"\"\"\n@@ -580,21 +745,32 @@ def repr_(self):\n \n         return \"{0}({1})\".format(\n             class_name,\n-            \", \".join(a.name + \"=\" + repr(getattr(self, a.name))\n-                      for a in attrs)\n+            \", \".join(\n+                name + \"=\" + repr(getattr(self, name))\n+                for name in attr_names\n+            )\n         )\n-    cls.__repr__ = repr_\n-    if str is True:\n-        cls.__str__ = repr_\n-    return cls\n+    return repr_\n \n \n-def _add_init(cls, frozen):\n+def _add_repr(cls, ns=None, attrs=None):\n     \"\"\"\n-    Add a __init__ method to *cls*.  If *frozen* is True, make it immutable.\n+    Add a repr method to *cls*.\n     \"\"\"\n-    attrs = [a for a in cls.__attrs_attrs__\n-             if a.init or a.default is not NOTHING]\n+    if attrs is None:\n+        attrs = cls.__attrs_attrs__\n+\n+    repr_ = _make_repr(attrs, ns)\n+    cls.__repr__ = repr_\n+    return cls\n+\n+\n+def _make_init(attrs, post_init, frozen):\n+    attrs = [\n+        a\n+        for a in attrs\n+        if a.init or a.default is not NOTHING\n+    ]\n \n     # We cache the generated init methods for the same kinds of attributes.\n     sha1 = hashlib.sha1()\n@@ -606,7 +782,7 @@ def _add_init(cls, frozen):\n     script, globs = _attrs_to_script(\n         attrs,\n         frozen,\n-        getattr(cls, \"__attrs_post_init__\", False),\n+        post_init,\n     )\n     locs = {}\n     bytecode = compile(script, unique_filename, \"exec\")\n@@ -630,30 +806,19 @@ def _add_init(cls, frozen):\n         script.splitlines(True),\n         unique_filename\n     )\n-    cls.__init__ = init\n-    return cls\n+\n+    return init\n \n \n-def _add_pickle(cls):\n+def _add_init(cls, frozen):\n     \"\"\"\n-    Add pickle helpers, needed for frozen and slotted classes\n+    Add a __init__ method to *cls*.  If *frozen* is True, make it immutable.\n     \"\"\"\n-    def _slots_getstate__(obj):\n-        \"\"\"\n-        Play nice with pickle.\n-        \"\"\"\n-        return tuple(getattr(obj, a.name) for a in fields(obj.__class__))\n-\n-    def _slots_setstate__(obj, state):\n-        \"\"\"\n-        Play nice with pickle.\n-        \"\"\"\n-        __bound_setattr = _obj_setattr.__get__(obj, Attribute)\n-        for a, value in zip(fields(obj.__class__), state):\n-            __bound_setattr(a.name, value)\n-\n-    cls.__getstate__ = _slots_getstate__\n-    cls.__setstate__ = _slots_setstate__\n+    cls.__init__ = _make_init(\n+        cls.__attrs_attrs__,\n+        getattr(cls, \"__attrs_post_init__\", False),\n+        frozen,\n+    )\n     return cls\n \n \n", "test_patch": "diff --git a/tests/test_annotations.py b/tests/test_annotations.py\n--- a/tests/test_annotations.py\n+++ b/tests/test_annotations.py\n@@ -1,13 +1,15 @@\n \"\"\"\n Tests for PEP-526 type annotations.\n+\n+Python 3.6+ only.\n \"\"\"\n \n+import typing\n+\n import pytest\n \n import attr\n \n-import typing\n-\n \n class TestAnnotations:\n     \"\"\"\ndiff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -1,3 +1,7 @@\n+\"\"\"\n+End-to-end tests.\n+\"\"\"\n+\n from __future__ import absolute_import, division, print_function\n \n import pickle\n@@ -283,3 +287,91 @@ class SubOverwrite(Super):\n             x = attr.ib(default=attr.Factory(list))\n \n         assert SubOverwrite([]) == SubOverwrite()\n+\n+    def test_dict_patch_class(self):\n+        \"\"\"\n+        dict-classes are never replaced.\n+        \"\"\"\n+        class C(object):\n+            x = attr.ib()\n+\n+        C_new = attr.s(C)\n+\n+        assert C_new is C\n+\n+    def test_hash_by_id(self):\n+        \"\"\"\n+        With dict classes, hashing by ID is active for hash=False even on\n+        Python 3.  This is incorrect behavior but we have to retain it for\n+        backward compatibility.\n+        \"\"\"\n+        @attr.s(hash=False)\n+        class HashByIDBackwardCompat(object):\n+            x = attr.ib()\n+\n+        assert (\n+            hash(HashByIDBackwardCompat(1)) != hash(HashByIDBackwardCompat(1))\n+        )\n+\n+        @attr.s(hash=False, cmp=False)\n+        class HashByID(object):\n+            x = attr.ib()\n+\n+        assert hash(HashByID(1)) != hash(HashByID(1))\n+\n+        @attr.s(hash=True)\n+        class HashByValues(object):\n+            x = attr.ib()\n+\n+        assert hash(HashByValues(1)) == hash(HashByValues(1))\n+\n+    def test_handles_different_defaults(self):\n+        \"\"\"\n+        Unhashable defaults + subclassing values work.\n+        \"\"\"\n+        @attr.s\n+        class Unhashable(object):\n+            pass\n+\n+        @attr.s\n+        class C(object):\n+            x = attr.ib(default=Unhashable())\n+\n+        @attr.s\n+        class D(C):\n+            pass\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_hash_false_cmp_false(self, slots):\n+        \"\"\"\n+        hash=False and cmp=False make a class hashable by ID.\n+        \"\"\"\n+        @attr.s(hash=False, cmp=False, slots=slots)\n+        class C(object):\n+            pass\n+\n+        assert hash(C()) != hash(C())\n+\n+    def test_overwrite_super(self):\n+        \"\"\"\n+        Super classes can overwrite each other and the attributes are added\n+        in the order they are defined.\n+        \"\"\"\n+        @attr.s\n+        class C(object):\n+            c = attr.ib(default=100)\n+            x = attr.ib(default=1)\n+            b = attr.ib(default=23)\n+\n+        @attr.s\n+        class D(C):\n+            a = attr.ib(default=42)\n+            x = attr.ib(default=2)\n+            d = attr.ib(default=3.14)\n+\n+        @attr.s\n+        class E(D):\n+            y = attr.ib(default=3)\n+            z = attr.ib(default=4)\n+\n+        assert \"E(c=100, b=23, a=42, x=2, d=3.14, y=3, z=4)\" == repr(E())\ndiff --git a/tests/test_init_subclass.py b/tests/test_init_subclass.py\nnew file mode 100644\n--- /dev/null\n+++ b/tests/test_init_subclass.py\n@@ -0,0 +1,44 @@\n+\"\"\"\n+Tests for `__init_subclass__` related tests.\n+\n+Python 3.6+ only.\n+\"\"\"\n+\n+import pytest\n+\n+import attr\n+\n+\n+@pytest.mark.parametrize(\"slots\", [True, False])\n+def test_init_subclass_vanilla(slots):\n+    \"\"\"\n+    `super().__init_subclass__` can be used if the subclass is not an attrs\n+    class both with dict and slots classes.\n+    \"\"\"\n+    @attr.s(slots=slots)\n+    class Base:\n+        def __init_subclass__(cls, param, **kw):\n+            super().__init_subclass__(**kw)\n+            cls.param = param\n+\n+    class Vanilla(Base, param=\"foo\"):\n+        pass\n+\n+    assert \"foo\" == Vanilla().param\n+\n+\n+def test_init_subclass_attrs():\n+    \"\"\"\n+    `__init_subclass__` works with attrs classes as long as slots=False.\n+    \"\"\"\n+    @attr.s(slots=False)\n+    class Base:\n+        def __init_subclass__(cls, param, **kw):\n+            super().__init_subclass__(**kw)\n+            cls.param = param\n+\n+    @attr.s\n+    class Attrs(Base, param=\"foo\"):\n+        pass\n+\n+    assert \"foo\" == Attrs().param\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -21,6 +21,8 @@\n     Attribute,\n     Factory,\n     _AndValidator,\n+    _Attributes,\n+    _ClassBuilder,\n     _CountingAttr,\n     _transform_attrs,\n     and_,\n@@ -136,13 +138,23 @@ class TestTransformAttrs(object):\n     \"\"\"\n     Tests for `_transform_attrs`.\n     \"\"\"\n+    def test_no_modifications(self):\n+        \"\"\"\n+        Doesn't attach __attrs_attrs__ to the class anymore.\n+        \"\"\"\n+        C = make_tc()\n+        _transform_attrs(C, None)\n+\n+        assert None is getattr(C, \"__attrs_attrs__\", None)\n+\n     def test_normal(self):\n         \"\"\"\n         Transforms every `_CountingAttr` and leaves others (a) be.\n         \"\"\"\n         C = make_tc()\n-        _transform_attrs(C, None)\n-        assert [\"z\", \"y\", \"x\"] == [a.name for a in C.__attrs_attrs__]\n+        attrs, _, = _transform_attrs(C, None)\n+\n+        assert [\"z\", \"y\", \"x\"] == [a.name for a in attrs]\n \n     def test_empty(self):\n         \"\"\"\n@@ -152,23 +164,18 @@ def test_empty(self):\n         class C(object):\n             pass\n \n-        _transform_attrs(C, None)\n-\n-        assert () == C.__attrs_attrs__\n+        assert _Attributes(((), [])) == _transform_attrs(C, None)\n \n-    @pytest.mark.parametrize(\"attribute\", [\n-        \"z\",\n-        \"y\",\n-        \"x\",\n-    ])\n-    def test_transforms_to_attribute(self, attribute):\n+    def test_transforms_to_attribute(self):\n         \"\"\"\n         All `_CountingAttr`s are transformed into `Attribute`s.\n         \"\"\"\n         C = make_tc()\n-        _transform_attrs(C, None)\n+        attrs, super_attrs = _transform_attrs(C, None)\n \n-        assert isinstance(getattr(fields(C), attribute), Attribute)\n+        assert [] == super_attrs\n+        assert 3 == len(attrs)\n+        assert all(isinstance(a, Attribute) for a in attrs)\n \n     def test_conflicting_defaults(self):\n         \"\"\"\n@@ -191,50 +198,20 @@ class C(object):\n \n     def test_these(self):\n         \"\"\"\n-        If these is passed, use it and ignore body.\n+        If these is passed, use it and ignore body and super classes.\n         \"\"\"\n-        class C(object):\n-            y = attr.ib()\n-\n-        _transform_attrs(C, {\"x\": attr.ib()})\n-        assert (\n-            simple_attr(\"x\"),\n-        ) == C.__attrs_attrs__\n-        assert isinstance(C.y, _CountingAttr)\n-\n-    def test_recurse(self):\n-        \"\"\"\n-        Collect attributes from all sub-classes.\n-        \"\"\"\n-        class A(object):\n-            a = None\n-\n-        class B(A):\n-            b = attr.ib()\n-\n-        _transform_attrs(B, None)\n-\n-        class C(B):\n-            c = attr.ib()\n-\n-        _transform_attrs(C, None)\n-\n-        class D(C):\n-            d = attr.ib()\n-\n-        _transform_attrs(D, None)\n+        class Base(object):\n+            z = attr.ib()\n \n-        class E(D):\n-            e = attr.ib()\n+        class C(Base):\n+            y = attr.ib()\n \n-        _transform_attrs(E, None)\n+        attrs, super_attrs = _transform_attrs(C, {\"x\": attr.ib()})\n \n+        assert [] == super_attrs\n         assert (\n-            simple_attr(\"b\"),\n-            simple_attr(\"c\"),\n-            simple_attr(\"d\"),\n-            simple_attr(\"e\"),\n-        ) == E.__attrs_attrs__\n+            simple_attr(\"x\"),\n+        ) == attrs\n \n \n class TestAttributes(object):\n@@ -250,6 +227,7 @@ def test_catches_old_style(self):\n             @attr.s\n             class C:\n                 pass\n+\n         assert (\"attrs only works with new-style classes.\",) == e.value.args\n \n     def test_sets_attrs(self):\n@@ -259,6 +237,7 @@ def test_sets_attrs(self):\n         @attr.s\n         class C(object):\n             x = attr.ib()\n+\n         assert \"x\" == C.__attrs_attrs__[0].name\n         assert all(isinstance(a, Attribute) for a in C.__attrs_attrs__)\n \n@@ -269,6 +248,7 @@ def test_empty(self):\n         @attr.s\n         class C3(object):\n             pass\n+\n         assert \"C3()\" == repr(C3())\n         assert C3() == C3()\n \n@@ -798,3 +778,45 @@ def test_empty_metadata_singleton(self, list_of_attrs):\n         C = make_class(\"C\", dict(zip(gen_attr_names(), list_of_attrs)))\n         for a in fields(C)[1:]:\n             assert a.metadata is fields(C)[0].metadata\n+\n+\n+class TestClassBuilder(object):\n+    \"\"\"\n+    Tests for `_ClassBuilder`.\n+    \"\"\"\n+    def test_repr_str(self):\n+        \"\"\"\n+        Trying to add a `__str__` without having a `__repr__` raises a\n+        ValueError.\n+        \"\"\"\n+        with pytest.raises(ValueError) as ei:\n+            make_class(\"C\", {}, repr=False, str=True)\n+\n+        assert (\n+            \"__str__ can only be generated if a __repr__ exists.\",\n+        ) == ei.value.args\n+\n+    def test_repr(self):\n+        \"\"\"\n+        repr of builder itself makes sense.\n+        \"\"\"\n+        class C(object):\n+            pass\n+\n+        b = _ClassBuilder(C, None, True, True)\n+\n+        assert \"<_ClassBuilder(cls=C)>\" == repr(b)\n+\n+    def test_returns_self(self):\n+        \"\"\"\n+        All methods return the builder for chaining.\n+        \"\"\"\n+        class C(object):\n+            x = attr.ib()\n+\n+        b = _ClassBuilder(C, None, True, True)\n+\n+        cls = b.add_cmp().add_hash().add_init().add_repr(\"ns\").add_str() \\\n+            .build_class()\n+\n+        assert \"ns.C(x=1)\" == repr(cls(1))\ndiff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -8,7 +8,7 @@\n try:\n     from pympler.asizeof import asizeof\n     has_pympler = True\n-except:  # Won't be an import error.\n+except BaseException:  # Won't be an import error.\n     has_pympler = False\n \n import attr\n@@ -129,10 +129,13 @@ class C2Slots(C1):\n         z = attr.ib()\n \n     c2 = C2Slots(x=1, y=2, z=\"test\")\n+\n     assert 1 == c2.x\n     assert 2 == c2.y\n     assert \"test\" == c2.z\n+\n     c2.t = \"test\"  # This will work, using the base class.\n+\n     assert \"test\" == c2.t\n \n     assert 1 == c2.method()\n@@ -142,8 +145,11 @@ class C2Slots(C1):\n     assert set([\"z\"]) == set(C2Slots.__slots__)\n \n     c3 = C2Slots(x=1, y=3, z=\"test\")\n+\n     assert c3 > c2\n+\n     c2_ = C2Slots(x=1, y=2, z=\"test\")\n+\n     assert c2 == c2_\n \n     assert \"C2Slots(x=1, y=2, z='test')\" == repr(c2)\n@@ -365,3 +371,30 @@ def my_subclass(self):\n \n     assert non_slot_instance.my_subclass() is C2\n     assert slot_instance.my_subclass() is C2Slots\n+\n+\n+@pytest.mark.skipif(PY2, reason=\"closure cell rewriting is PY3-only.\")\n+@pytest.mark.parametrize(\"slots\", [True, False])\n+def test_closure_cell_rewriting_cls_static(slots):\n+    \"\"\"\n+    Slot classes support proper closure cell rewriting for class- and static\n+    methods.\n+    \"\"\"\n+    # Python can reuse closure cells, so we create new classes just for\n+    # this test.\n+\n+    @attr.s(slots=slots)\n+    class C:\n+        @classmethod\n+        def clsmethod(cls):\n+            return __class__  # noqa: F821\n+\n+    assert C.clsmethod() is C\n+\n+    @attr.s(slots=slots)\n+    class D:\n+        @staticmethod\n+        def statmethod():\n+            return __class__  # noqa: F821\n+\n+    assert D.statmethod() is D\ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -218,8 +218,13 @@ class HypClass:\n         def post_init(self):\n             pass\n         cls_dict[\"__attrs_post_init__\"] = post_init\n-    return make_class(\"HypClass\", cls_dict,\n-                      slots=slots_flag, frozen=frozen_flag)\n+\n+    return make_class(\n+        \"HypClass\",\n+        cls_dict,\n+        slots=slots_flag,\n+        frozen=frozen_flag,\n+    )\n \n \n # st.recursive works by taking a base strategy (in this case, simple_classes)\n", "problem_statement": "slots=True do not play nice with __init_subclass__\nA class annotated with `attr.s(slots=True)` can't call `super().__init__subclass__` within its own `__init_subclass__` method - a `TypeError: super(type, obj): obj must be an instance or subtype of type` is raised.\r\n\r\nReproducible example (tested on 16.3.0, 17.2.0 and f7f53d4) is here: https://repl.it/Mmkb/0\n", "hints_text": "", "created_at": "2017-10-19T14:42:06Z"}
{"repo": "python-attrs/attrs", "pull_number": 229, "instance_id": "python-attrs__attrs-229", "issue_numbers": ["221"], "base_commit": "37a421e559a6330b7ace242698b06b258b979e91", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -181,11 +181,6 @@ def _transform_attrs(cls, these):\n \n     If *these* is passed, use that and don't look for them on the class.\n     \"\"\"\n-    super_cls = []\n-    for c in reversed(cls.__mro__[1:-1]):\n-        sub_attrs = getattr(c, \"__attrs_attrs__\", None)\n-        if sub_attrs is not None:\n-            super_cls.extend(a for a in sub_attrs if a not in super_cls)\n     if these is None:\n         ca_list = [(name, attr)\n                    for name, attr\n@@ -201,6 +196,17 @@ def _transform_attrs(cls, these):\n         for attr_name, ca\n         in sorted(ca_list, key=lambda e: e[1].counter)\n     ]\n+\n+    super_cls = []\n+    non_super_names = set(a.name for a in non_super_attrs)\n+    for c in reversed(cls.__mro__[1:-1]):\n+        sub_attrs = getattr(c, \"__attrs_attrs__\", None)\n+        if sub_attrs is not None:\n+            super_cls.extend(\n+                a for a in sub_attrs\n+                if a not in super_cls and a.name not in non_super_names\n+            )\n+\n     attr_names = [a.name for a in super_cls + non_super_attrs]\n \n     AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -271,3 +271,15 @@ def compute(self):\n                 return self.x + 1\n \n         assert C(1, 2) == C()\n+\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_attrib_overwrite(self, slots, frozen):\n+        \"\"\"\n+        Subclasses can overwrite attributes of their superclass.\n+        \"\"\"\n+        @attr.s(slots=slots, frozen=frozen)\n+        class SubOverwrite(Super):\n+            x = attr.ib(default=attr.Factory(list))\n+\n+        assert SubOverwrite([]) == SubOverwrite()\n", "problem_statement": "Can't overide a __super__'s attrib.\nHi.\r\n\r\nIs it not possible to do this? Let's say I want to change the default for arg 'p' in the inherited Class, B:\r\n```\r\n@attr.s\r\nclass A(object):\r\n    p=attr.ib(default='old')\r\n\r\n@attr.s\r\nclass B(A):\r\n    p=attr.ib(default='new')\r\n\r\nB().p\r\n```\r\n\r\nI get farts:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"E:/D/OneDrive/PyCharm/attrs_test/01.py\", line 44, in <module>\r\n    class B(A):\r\n  File \"E:\\D\\OneDrive\\Miniconda3\\envs\\dev\\lib\\site-packages\\attr\\_make.py\", line 391, in attributes\r\n    return wrap(maybe_cls)\r\n  File \"E:\\D\\OneDrive\\Miniconda3\\envs\\dev\\lib\\site-packages\\attr\\_make.py\", line 364, in wrap\r\n    cls = _add_init(cls, effectively_frozen)\r\n  File \"E:\\D\\OneDrive\\Miniconda3\\envs\\dev\\lib\\site-packages\\attr\\_make.py\", line 569, in _add_init\r\n    bytecode = compile(script, unique_filename, \"exec\")\r\n  File \"<attrs generated init 6e95dcc9478c7a8b8784f6244afbff55f563f7c6>\", line 1\r\nSyntaxError: duplicate argument 'p' in function definition\r\n```\r\n\r\nThanks.\n", "hints_text": "Yes that\u2019s a bug that got mentioned in a different ticket and asked the reporter to file a new bug but he didn\u2019t get around to it so it got lost.", "created_at": "2017-08-12T07:31:40Z"}
{"repo": "python-attrs/attrs", "pull_number": 209, "instance_id": "python-attrs__attrs-209", "issue_numbers": ["208"], "base_commit": "10368b4232849bf65ac35ac06a6aa81254eb261b", "patch": "diff --git a/src/attr/_funcs.py b/src/attr/_funcs.py\n--- a/src/attr/_funcs.py\n+++ b/src/attr/_funcs.py\n@@ -170,7 +170,7 @@ def assoc(inst, **changes):\n     \"\"\"\n     import warnings\n     warnings.warn(\"assoc is deprecated and will be removed after 2018/01.\",\n-                  DeprecationWarning)\n+                  DeprecationWarning, stacklevel=2)\n     new = copy.copy(inst)\n     attrs = fields(inst.__class__)\n     for k, v in iteritems(changes):\n", "test_patch": "diff --git a/tests/test_funcs.py b/tests/test_funcs.py\n--- a/tests/test_funcs.py\n+++ b/tests/test_funcs.py\n@@ -416,6 +416,19 @@ class C(object):\n         with pytest.deprecated_call():\n             assert C(3, 2) == assoc(C(1, 2), x=3)\n \n+    def test_warning(self):\n+        \"\"\"\n+        DeprecationWarning points to the correct file.\n+        \"\"\"\n+        @attributes\n+        class C(object):\n+            x = attr()\n+\n+        with pytest.warns(DeprecationWarning) as wi:\n+            assert C(2) == assoc(C(1), x=2)\n+\n+        assert __file__ == wi.list[0].filename\n+\n \n class TestEvolve(object):\n     \"\"\"\n", "problem_statement": "assoc warning is unhelpful\nCurrently the warning emitted looks something like this:\r\n```\r\n/home/mithrandi/deployment/virtualenvs/txaws/site-packages/attr/_funcs.py:173: DeprecationWarning: assoc is deprecated and will be removed after 2018/01.\r\n```\r\nI think this should pass an appropriate stacklevel so you can see where the calling code actually is.\n", "hints_text": "", "created_at": "2017-06-11T10:16:34Z"}
{"repo": "python-attrs/attrs", "pull_number": 204, "instance_id": "python-attrs__attrs-204", "issue_numbers": ["203"], "base_commit": "303b2f627f0a754ffa329c54f024e6e669ae882a", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -965,7 +965,7 @@ def default(self, meth):\n _CountingAttr = _add_cmp(_add_repr(_CountingAttr))\n \n \n-@attributes(slots=True, init=False)\n+@attributes(slots=True, init=False, hash=True)\n class Factory(object):\n     \"\"\"\n     Stores a factory callable.\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -572,6 +572,12 @@ def test_factory_takes_self(self):\n \n         assert i is i.x\n \n+    def test_factory_hashable(self):\n+        \"\"\"\n+        Factory is hashable.\n+        \"\"\"\n+        assert hash(Factory(None, False)) == hash(Factory(None, False))\n+\n     def test_convert_before_validate(self):\n         \"\"\"\n         Validation happens after conversion.\n", "problem_statement": "filtering.include/exclude throw a TypeError when any class attribute uses a Factory default\nThe `hash_` method added by `_add_hash` in `attr._make` throws `TypeError: unhashable type: 'Factory'` if any of the class's attributes uses an `attr.Factory` default. So for example, below no longer works.\r\n\r\n```python\r\n@attr.s\r\nclass C(object):\r\n    a = attr.ib()\r\n    b = attr.ib(default=attr.Factory(list))\r\n\r\nattr.asdict(C(1), filter=attr.filters.include(attr.fields(C).a))\r\n```\n", "hints_text": "", "created_at": "2017-06-06T10:05:07Z"}
{"repo": "python-attrs/attrs", "pull_number": 199, "instance_id": "python-attrs__attrs-199", "issue_numbers": ["198"], "base_commit": "f8dab9b7ac9306169aee2b740c2e42c96b51c228", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -343,9 +343,7 @@ def wrap(cls):\n         # Can't compare function objects because Python 2 is terrible. :(\n         effectively_frozen = _has_frozen_superclass(cls) or frozen\n         if repr is True:\n-            cls = _add_repr(cls, ns=repr_ns)\n-        if str is True:\n-            cls.__str__ = cls.__repr__\n+            cls = _add_repr(cls, ns=repr_ns, str=str)\n         if cmp is True:\n             cls = _add_cmp(cls)\n \n@@ -516,9 +514,9 @@ def ge(self, other):\n     return cls\n \n \n-def _add_repr(cls, ns=None, attrs=None):\n+def _add_repr(cls, ns=None, attrs=None, str=False):\n     \"\"\"\n-    Add a repr method to *cls*.\n+    Add a repr method to *cls*. If *str* is True, also add __str__.\n     \"\"\"\n     if attrs is None:\n         attrs = [a for a in cls.__attrs_attrs__ if a.repr]\n@@ -543,6 +541,8 @@ def repr_(self):\n                       for a in attrs)\n         )\n     cls.__repr__ = repr_\n+    if str is True:\n+        cls.__str__ = repr_\n     return cls\n \n \n", "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -198,15 +198,15 @@ class C(object):\n \n         assert \"C(_x=42)\" == repr(i)\n \n-    @pytest.mark.parametrize(\"add_str\", [True, False])\n-    def test_str(self, add_str):\n+    @given(add_str=booleans(), slots=booleans())\n+    def test_str(self, add_str, slots):\n         \"\"\"\n         If str is True, it returns the same as repr.\n \n         This only makes sense when subclassing a class with an poor __str__\n         (like Exceptions).\n         \"\"\"\n-        @attributes(str=add_str)\n+        @attributes(str=add_str, slots=slots)\n         class Error(Exception):\n             x = attr()\n \n", "problem_statement": "slots=True is incompatible with str=True\n`slots=True` seems to be incompatible with `str=True`. I discovered this using attrs for exceptions, but it seems true in general:\r\n\r\n```pycon\r\n>>> import attr\r\n>>> @attr.s(str=True, slots=True)\r\n... class Foo(object):\r\n...     x = attr.ib()\r\n...\r\n>>> f = Foo(1)\r\n>>> str(f)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: unbound method repr_() must be called with Foo instance as first argument (got nothing instead)\r\n```\r\n\r\nPython 2.7.13, attrs==17.2.0\n", "hints_text": "FTR this is a Python 2-bug only:\r\n\r\n```pycon\r\nPython 3.6.1 (default, May  4 2017, 15:25:00)\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 6.0.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import attr\r\n\r\nIn [2]: @attr.s(str=True, slots=True)\r\n   ...: class C:\r\n   ...:     x = attr.ib()\r\n   ...:\r\nIn [4]: str(C(1))\r\nOut[4]: 'C(x=1)'\r\n```\r\n\r\n(I was surprised about this bug repost because I use it all the time :))", "created_at": "2017-06-01T06:10:57Z"}
{"repo": "python-attrs/attrs", "pull_number": 189, "instance_id": "python-attrs__attrs-189", "issue_numbers": ["165"], "base_commit": "fbe0bd5967801ecff11bda0918e9ecda66ab75fd", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -7,12 +7,17 @@\n \n from . import _config\n from ._compat import PY2, iteritems, isclass, iterkeys, metadata_proxy\n-from .exceptions import FrozenInstanceError, NotAnAttrsClassError\n+from .exceptions import (\n+    DefaultAlreadySetError,\n+    FrozenInstanceError,\n+    NotAnAttrsClassError,\n+)\n \n \n # This is used at least twice, so cache it here.\n _obj_setattr = object.__setattr__\n _init_convert_pat = \"__attr_convert_{}\"\n+_init_factory_pat = \"__attr_factory_{}\"\n _tuple_property_pat = \"    {attr_name} = property(itemgetter({index}))\"\n _empty_metadata_singleton = metadata_proxy({})\n \n@@ -701,21 +706,26 @@ def fmt_setter_with_converter(attr_name, value_var):\n             attrs_to_validate.append(a)\n         attr_name = a.name\n         arg_name = a.name.lstrip(\"_\")\n+        has_factory = isinstance(a.default, Factory)\n+        if has_factory and a.default.takes_self:\n+            maybe_self = \"self\"\n+        else:\n+            maybe_self = \"\"\n         if a.init is False:\n-            if isinstance(a.default, Factory):\n+            if has_factory:\n+                init_factory_name = _init_factory_pat.format(a.name)\n                 if a.convert is not None:\n                     lines.append(fmt_setter_with_converter(\n                         attr_name,\n-                        \"attr_dict['{attr_name}'].default.factory()\"\n-                        .format(attr_name=attr_name)))\n+                        init_factory_name + \"({0})\".format(maybe_self)))\n                     conv_name = _init_convert_pat.format(a.name)\n                     names_for_globals[conv_name] = a.convert\n                 else:\n                     lines.append(fmt_setter(\n                         attr_name,\n-                        \"attr_dict['{attr_name}'].default.factory()\"\n-                        .format(attr_name=attr_name)\n+                        init_factory_name + \"({0})\".format(maybe_self)\n                     ))\n+                names_for_globals[init_factory_name] = a.default.factory\n             else:\n                 if a.convert is not None:\n                     lines.append(fmt_setter_with_converter(\n@@ -731,7 +741,7 @@ def fmt_setter_with_converter(attr_name, value_var):\n                         \"attr_dict['{attr_name}'].default\"\n                         .format(attr_name=attr_name)\n                     ))\n-        elif a.default is not NOTHING and not isinstance(a.default, Factory):\n+        elif a.default is not NOTHING and not has_factory:\n             args.append(\n                 \"{arg_name}=attr_dict['{attr_name}'].default\".format(\n                     arg_name=arg_name,\n@@ -743,18 +753,18 @@ def fmt_setter_with_converter(attr_name, value_var):\n                 names_for_globals[_init_convert_pat.format(a.name)] = a.convert\n             else:\n                 lines.append(fmt_setter(attr_name, arg_name))\n-        elif a.default is not NOTHING and isinstance(a.default, Factory):\n+        elif has_factory:\n             args.append(\"{arg_name}=NOTHING\".format(arg_name=arg_name))\n             lines.append(\"if {arg_name} is not NOTHING:\"\n                          .format(arg_name=arg_name))\n+            init_factory_name = _init_factory_pat.format(a.name)\n             if a.convert is not None:\n                 lines.append(\"    \" + fmt_setter_with_converter(attr_name,\n                                                                 arg_name))\n                 lines.append(\"else:\")\n                 lines.append(\"    \" + fmt_setter_with_converter(\n                     attr_name,\n-                    \"attr_dict['{attr_name}'].default.factory()\"\n-                    .format(attr_name=attr_name)\n+                    init_factory_name + \"({0})\".format(maybe_self)\n                 ))\n                 names_for_globals[_init_convert_pat.format(a.name)] = a.convert\n             else:\n@@ -762,9 +772,9 @@ def fmt_setter_with_converter(attr_name, value_var):\n                 lines.append(\"else:\")\n                 lines.append(\"    \" + fmt_setter(\n                     attr_name,\n-                    \"attr_dict['{attr_name}'].default.factory()\"\n-                    .format(attr_name=attr_name)\n+                    init_factory_name + \"({0})\".format(maybe_self)\n                 ))\n+            names_for_globals[init_factory_name] = a.default.factory\n         else:\n             args.append(arg_name)\n             if a.convert is not None:\n@@ -808,21 +818,21 @@ class Attribute(object):\n         \"convert\", \"metadata\",\n     )\n \n-    def __init__(self, name, default, _validator, repr, cmp, hash, init,\n+    def __init__(self, name, _default, _validator, repr, cmp, hash, init,\n                  convert=None, metadata=None):\n         # Cache this descriptor here to speed things up later.\n-        __bound_setattr = _obj_setattr.__get__(self, Attribute)\n-\n-        __bound_setattr(\"name\", name)\n-        __bound_setattr(\"default\", default)\n-        __bound_setattr(\"validator\", _validator)\n-        __bound_setattr(\"repr\", repr)\n-        __bound_setattr(\"cmp\", cmp)\n-        __bound_setattr(\"hash\", hash)\n-        __bound_setattr(\"init\", init)\n-        __bound_setattr(\"convert\", convert)\n-        __bound_setattr(\"metadata\", (metadata_proxy(metadata) if metadata\n-                                     else _empty_metadata_singleton))\n+        bound_setattr = _obj_setattr.__get__(self, Attribute)\n+\n+        bound_setattr(\"name\", name)\n+        bound_setattr(\"default\", _default)\n+        bound_setattr(\"validator\", _validator)\n+        bound_setattr(\"repr\", repr)\n+        bound_setattr(\"cmp\", cmp)\n+        bound_setattr(\"hash\", hash)\n+        bound_setattr(\"init\", init)\n+        bound_setattr(\"convert\", convert)\n+        bound_setattr(\"metadata\", (metadata_proxy(metadata) if metadata\n+                                   else _empty_metadata_singleton))\n \n     def __setattr__(self, name, value):\n         raise FrozenInstanceError()\n@@ -832,8 +842,10 @@ def from_counting_attr(cls, name, ca):\n         inst_dict = {\n             k: getattr(ca, k)\n             for k\n-            in Attribute.__slots__ + (\"_validator\",)\n-            if k != \"name\" and k != \"validator\"  # `validator` is a method\n+            in Attribute.__slots__ + (\"_validator\", \"_default\")\n+            if k != \"name\" and k not in (\n+                \"validator\", \"default\",\n+            )  # exclude methods\n         }\n         return cls(name=name, **inst_dict)\n \n@@ -850,16 +862,16 @@ def __setstate__(self, state):\n         \"\"\"\n         Play nice with pickle.\n         \"\"\"\n-        __bound_setattr = _obj_setattr.__get__(self, Attribute)\n+        bound_setattr = _obj_setattr.__get__(self, Attribute)\n         for name, value in zip(self.__slots__, state):\n             if name != \"metadata\":\n-                __bound_setattr(name, value)\n+                bound_setattr(name, value)\n             else:\n-                __bound_setattr(name, metadata_proxy(value) if value else\n-                                _empty_metadata_singleton)\n+                bound_setattr(name, metadata_proxy(value) if value else\n+                              _empty_metadata_singleton)\n \n \n-_a = [Attribute(name=name, default=NOTHING, _validator=None,\n+_a = [Attribute(name=name, _default=NOTHING, _validator=None,\n                 repr=True, cmp=True, hash=(name != \"metadata\"), init=True)\n       for name in Attribute.__slots__]\n \n@@ -877,15 +889,15 @@ class _CountingAttr(object):\n     *Internal* data structure of the attrs library.  Running into is most\n     likely the result of a bug like a forgotten `@attr.s` decorator.\n     \"\"\"\n-    __slots__ = (\"counter\", \"default\", \"repr\", \"cmp\", \"hash\", \"init\",\n+    __slots__ = (\"counter\", \"_default\", \"repr\", \"cmp\", \"hash\", \"init\",\n                  \"metadata\", \"_validator\", \"convert\")\n     __attrs_attrs__ = tuple(\n-        Attribute(name=name, default=NOTHING, _validator=None,\n+        Attribute(name=name, _default=NOTHING, _validator=None,\n                   repr=True, cmp=True, hash=True, init=True)\n         for name\n-        in (\"counter\", \"default\", \"repr\", \"cmp\", \"hash\", \"init\",)\n+        in (\"counter\", \"_default\", \"repr\", \"cmp\", \"hash\", \"init\",)\n     ) + (\n-        Attribute(name=\"metadata\", default=None, _validator=None,\n+        Attribute(name=\"metadata\", _default=None, _validator=None,\n                   repr=True, cmp=True, hash=False, init=True),\n     )\n     cls_counter = 0\n@@ -894,7 +906,7 @@ def __init__(self, default, validator, repr, cmp, hash, init, convert,\n                  metadata):\n         _CountingAttr.cls_counter += 1\n         self.counter = _CountingAttr.cls_counter\n-        self.default = default\n+        self._default = default\n         # If validator is a list/tuple, wrap it using helper validator.\n         if validator and isinstance(validator, (list, tuple)):\n             self._validator = and_(*validator)\n@@ -912,6 +924,8 @@ def validator(self, meth):\n         Decorator that adds *meth* to the list of validators.\n \n         Returns *meth* unchanged.\n+\n+        .. versionadded:: 17.1.0\n         \"\"\"\n         if self._validator is None:\n             self._validator = meth\n@@ -919,19 +933,52 @@ def validator(self, meth):\n             self._validator = and_(self._validator, meth)\n         return meth\n \n+    def default(self, meth):\n+        \"\"\"\n+        Decorator that allows to set the default for an attribute.\n+\n+        Returns *meth* unchanged.\n+\n+        :raises DefaultAlreadySetError: If default has been set before.\n+\n+        .. versionadded:: 17.1.0\n+        \"\"\"\n+        if self._default is not NOTHING:\n+            raise DefaultAlreadySetError()\n+\n+        self._default = Factory(meth, takes_self=True)\n+\n+        return meth\n+\n \n _CountingAttr = _add_cmp(_add_repr(_CountingAttr))\n \n \n-@attributes(slots=True)\n+@attributes(slots=True, init=False)\n class Factory(object):\n     \"\"\"\n     Stores a factory callable.\n \n     If passed as the default value to :func:`attr.ib`, the factory is used to\n     generate a new value.\n+\n+    :param callable factory: A callable that takes either none or exactly one\n+        mandatory positional argument depending on *takes_self*.\n+    :param bool takes_self: Pass the partially initialized instance that is\n+        being initialized as a positional argument.\n+\n+    .. versionadded:: 17.1.0  *takes_self*\n     \"\"\"\n     factory = attr()\n+    takes_self = attr()\n+\n+    def __init__(self, factory, takes_self=False):\n+        \"\"\"\n+        `Factory` is part of the default machinery so if we want a default\n+        value here, we have to implement it ourselves.\n+        \"\"\"\n+        self.factory = factory\n+        self.takes_self = takes_self\n \n \n def make_class(name, attrs, bases=(object,), **attributes_arguments):\ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\n--- a/src/attr/exceptions.py\n+++ b/src/attr/exceptions.py\n@@ -28,3 +28,12 @@ class NotAnAttrsClassError(ValueError):\n \n     .. versionadded:: 16.2.0\n     \"\"\"\n+\n+\n+class DefaultAlreadySetError(RuntimeError):\n+    \"\"\"\n+    A default has been set using ``attr.ib()`` and is attempted to be reset\n+    using the decorator.\n+\n+    .. versionadded:: 17.1.0\n+    \"\"\"\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -109,9 +109,9 @@ def test_fields(self, cls):\n         `attr.fields` works.\n         \"\"\"\n         assert (\n-            Attribute(name=\"x\", default=foo, _validator=None,\n+            Attribute(name=\"x\", _default=foo, _validator=None,\n                       repr=True, cmp=True, hash=None, init=True),\n-            Attribute(name=\"y\", default=attr.Factory(list), _validator=None,\n+            Attribute(name=\"y\", _default=attr.Factory(list), _validator=None,\n                       repr=True, cmp=True, hash=None, init=True),\n         ) == attr.fields(cls)\n \n@@ -158,9 +158,9 @@ def test_programmatic(self, slots, frozen):\n         \"\"\"\n         PC = attr.make_class(\"PC\", [\"a\", \"b\"], slots=slots, frozen=frozen)\n         assert (\n-            Attribute(name=\"a\", default=NOTHING, _validator=None,\n+            Attribute(name=\"a\", _default=NOTHING, _validator=None,\n                       repr=True, cmp=True, hash=None, init=True),\n-            Attribute(name=\"b\", default=NOTHING, _validator=None,\n+            Attribute(name=\"b\", _default=NOTHING, _validator=None,\n                       repr=True, cmp=True, hash=None, init=True),\n         ) == attr.fields(PC)\n \n@@ -251,4 +251,23 @@ def test_subclassing_frozen_gives_frozen(self):\n \n     @pytest.mark.parametrize(\"cls\", [WithMeta, WithMetaSlots])\n     def test_metaclass_preserved(self, cls):\n+        \"\"\"\n+        Metaclass data is preserved.\n+        \"\"\"\n         assert Meta == type(cls)\n+\n+    def test_default_decorator(self):\n+        \"\"\"\n+        Default decorator sets the default and the respective method gets\n+        called.\n+        \"\"\"\n+        @attr.s\n+        class C(object):\n+            x = attr.ib(default=1)\n+            y = attr.ib()\n+\n+            @y.default\n+            def compute(self):\n+                return self.x + 1\n+\n+        assert C(1, 2) == C()\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -28,7 +28,7 @@\n     make_class,\n     validate,\n )\n-from attr.exceptions import NotAnAttrsClassError\n+from attr.exceptions import NotAnAttrsClassError, DefaultAlreadySetError\n \n from .utils import (gen_attr_names, list_of_attrs, simple_attr, simple_attrs,\n                     simple_attrs_without_metadata, simple_classes)\n@@ -105,6 +105,31 @@ def v2(self, _, __):\n \n         assert _AndValidator((v, v2,)) == a._validator\n \n+    def test_default_decorator_already_set(self):\n+        \"\"\"\n+        Raise DefaultAlreadySetError if the decorator is used after a default\n+        has been set.\n+        \"\"\"\n+        a = attr(default=42)\n+\n+        with pytest.raises(DefaultAlreadySetError):\n+            @a.default\n+            def f(self):\n+                pass\n+\n+    def test_default_decorator_sets(self):\n+        \"\"\"\n+        Decorator wraps the method in a Factory with pass_self=True and sets\n+        the default.\n+        \"\"\"\n+        a = attr()\n+\n+        @a.default\n+        def f(self):\n+            pass\n+\n+        assert Factory(f, True) == a._default\n+\n \n def make_tc():\n     class TransformC(object):\n@@ -535,6 +560,18 @@ def test_convert_factory_property(self, val, init):\n         assert c.x == val + 1\n         assert c.y == 2\n \n+    def test_factory_takes_self(self):\n+        \"\"\"\n+        If takes_self on factories is True, self is passed.\n+        \"\"\"\n+        C = make_class(\"C\", {\"x\": attr(default=Factory(\n+            (lambda self: self), takes_self=True\n+        ))})\n+\n+        i = C()\n+\n+        assert i is i.x\n+\n     def test_convert_before_validate(self):\n         \"\"\"\n         Validation happens after conversion.\ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -35,7 +35,7 @@ def simple_attr(name, default=NOTHING, validator=None, repr=True,\n     Return an attribute with a name and no other bells and whistles.\n     \"\"\"\n     return Attribute(\n-        name=name, default=default, _validator=validator, repr=repr,\n+        name=name, _default=default, _validator=validator, repr=repr,\n         cmp=cmp, hash=hash, init=init\n     )\n \n", "problem_statement": "attr default based on other attributes\nHi!\r\n\r\nI have unsucessfully tried to define a default value by referencing other attributes. I'm sure the code below doesnt' work for some obvious or fundamental reason, but I would be grateful for comments on how to do something like it:\r\n\r\n```python\r\nimport attr\r\nfrom attr.validators import instance_of\r\nimport datetime\r\n\r\n@attr.s\r\nclass Something:\r\n    some_date = attr.ib(validator=instance_of(datetime.date))\r\n    some_number = attr.ib(convert=float)\r\n    name = attr.ib(validator=instance_of(str),\r\n                   default=\"Generic Name {0} - {1}%\".format(\r\n                       some_date.strftime(\"%d-%b-%Y\"),\r\n                       some_number * 100)\r\n                   )\r\n\r\ns = Something(some_date=datetime.date.today(), some_number=0.375)\r\n```\r\n\r\nI included the `.strftime()` conversion to highlight that `name` doesn't see a float and a date, but a `_CountingAttr` object, hence I get an AttributeError (and a TypeError for `some_number * 100`). Since I can't reference self either, what would be the correct way to do this?\n", "hints_text": "Hi,\r\n\r\nfor now I suggest using `__attrs_post_init__` (http://attrs.readthedocs.io/en/stable/examples.html?highlight=attrs_post_init#other-goodies). The linked example is basically what you want.\nI have wanted to do this several times. For example, you have a test of a function which takes many inputs. You want to test this function with many different cases. So (of course) you create a quick e.g. `@attr.s class TestInput:...` for that. In many cases you want some attribute to have a default depending on other attributes, but still be able to override it. The existing options are not so good for this:\r\n\r\n- I think you can use `these` for this but it's cumbersome.\r\n- `__attrs_post_init__` is not good because you can't override it.\r\n\r\nWhat I'd want, following the ad-hoc validators example, is something like this:\r\n\r\n```\r\n@attr.s\r\nclass C:\r\n    x = attr.ib()\r\n    y = attr.ib()\r\n    z = attr.ib()\r\n\r\n    @z.default\r\n    def z_default(self, attribute):\r\n        return self.x + self.y\r\n```\r\n\r\nThis is sensitive to the initialization order. However, if you have a stateful factory, the order is already important, so this is not new. And the natural order is the definition order which is intuitive.\r\n\r\nAnother issue is that this makes it possible to specify multiple defaults. I would just raise an error if this is detected.\r\n\r\nFinal issue I can think of is that an occasional user might confuse this with a property, while it does not behave like a property:\r\n\r\n- The value is persisted.\r\n- In mutable objects, the value doesn't change if the dependencies change, unlike a dynamically-computed property.\r\n\r\nBut I think \"default\" is clear on the behavior it has.\nAt first glance I like the proposed API :)\nI guess we could have a lot fun with decorators based on `_CountingAttr`.\nI *think* I want this in 17.1 but it entirely depends on the goodwill of reviewers (most likely @Tinche \u2013 I *gotta* shanghai some innocent souls at PyCon).", "created_at": "2017-05-13T10:49:50Z"}
{"repo": "python-attrs/attrs", "pull_number": 186, "instance_id": "python-attrs__attrs-186", "issue_numbers": ["161"], "base_commit": "fdfd51e249f11483a9f731a4f19282df0f97e1e7", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -897,7 +897,7 @@ def __init__(self, default, validator, repr, cmp, hash, init, convert,\n         self.default = default\n         # If validator is a list/tuple, wrap it using helper validator.\n         if validator and isinstance(validator, (list, tuple)):\n-            self._validator = _AndValidator(tuple(validator))\n+            self._validator = and_(*validator)\n         else:\n             self._validator = validator\n         self.repr = repr\n@@ -911,37 +911,18 @@ def validator(self, meth):\n         \"\"\"\n         Decorator that adds *meth* to the list of validators.\n \n-        Returns meth unchanged.\n+        Returns *meth* unchanged.\n         \"\"\"\n-        if not isinstance(self._validator, _AndValidator):\n-            self._validator = _AndValidator(\n-                (self._validator,) if self._validator else ()\n-            )\n-        self._validator.add(meth)\n+        if self._validator is None:\n+            self._validator = meth\n+        else:\n+            self._validator = and_(self._validator, meth)\n         return meth\n \n \n _CountingAttr = _add_cmp(_add_repr(_CountingAttr))\n \n \n-@attributes(slots=True)\n-class _AndValidator(object):\n-    \"\"\"\n-    Compose many validators to a single one.\n-    \"\"\"\n-    _validators = attr()\n-\n-    def __call__(self, inst, attr, value):\n-        for v in self._validators:\n-            v(inst, attr, value)\n-\n-    def add(self, validator):\n-        \"\"\"\n-        Add *validator*.  Shouldn't be called after the class is done.\n-        \"\"\"\n-        self._validators += (validator,)\n-\n-\n @attributes(slots=True)\n class Factory(object):\n     \"\"\"\n@@ -981,3 +962,40 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):\n         raise TypeError(\"attrs argument must be a dict or a list.\")\n \n     return attributes(**attributes_arguments)(type(name, bases, cls_dict))\n+\n+\n+# These are required by whithin this module so we define them here and merely\n+# import into .validators.\n+\n+\n+@attributes(slots=True)\n+class _AndValidator(object):\n+    \"\"\"\n+    Compose many validators to a single one.\n+    \"\"\"\n+    _validators = attr()\n+\n+    def __call__(self, inst, attr, value):\n+        for v in self._validators:\n+            v(inst, attr, value)\n+\n+\n+def and_(*validators):\n+    \"\"\"\n+    A validator that composes multiple validators into one.\n+\n+    When called on a value, it runs all wrapped validators.\n+\n+    :param validators: Arbitrary number of validators.\n+    :type validators: callables\n+\n+    .. versionadded:: 17.1.0\n+    \"\"\"\n+    vals = []\n+    for validator in validators:\n+        vals.extend(\n+            validator._validators if isinstance(validator, _AndValidator)\n+            else [validator]\n+        )\n+\n+    return _AndValidator(tuple(vals))\ndiff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -4,7 +4,15 @@\n \n from __future__ import absolute_import, division, print_function\n \n-from ._make import attr, attributes\n+from ._make import attr, attributes, and_, _AndValidator\n+\n+\n+__all__ = [\n+    \"and_\",\n+    \"instance_of\",\n+    \"optional\",\n+    \"provides\",\n+]\n \n \n @attributes(repr=False, slots=True)\n@@ -93,12 +101,13 @@ class _OptionalValidator(object):\n     def __call__(self, inst, attr, value):\n         if value is None:\n             return\n-        return self.validator(inst, attr, value)\n+\n+        self.validator(inst, attr, value)\n \n     def __repr__(self):\n         return (\n-            \"<optional validator for {type} or None>\"\n-            .format(type=repr(self.validator))\n+            \"<optional validator for {what} or None>\"\n+            .format(what=repr(self.validator))\n         )\n \n \n@@ -108,6 +117,13 @@ def optional(validator):\n     which can be set to ``None`` in addition to satisfying the requirements of\n     the sub-validator.\n \n-    :param validator: A validator that is used for non-``None`` values.\n+    :param validator: A validator (or a list of validators) that is used for\n+        non-``None`` values.\n+    :type validator: callable or :class:`list` of callables.\n+\n+    .. versionadded:: 15.1.0\n+    .. versionchanged:: 17.1.0 *validator* can be a list of validators.\n     \"\"\"\n+    if isinstance(validator, list):\n+        return _OptionalValidator(_AndValidator(validator))\n     return _OptionalValidator(validator)\n", "test_patch": "diff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -21,6 +21,7 @@\n     _AndValidator,\n     _CountingAttr,\n     _transform_attrs,\n+    and_,\n     attr,\n     attributes,\n     fields,\n@@ -71,6 +72,8 @@ def v2(_, __):\n \n     def test_validator_decorator_single(self):\n         \"\"\"\n+        If _CountingAttr.validator is used as a decorator and there is no\n+        decorator set, the decorated method is used as the validator.\n         \"\"\"\n         a = attr()\n \n@@ -78,17 +81,23 @@ def test_validator_decorator_single(self):\n         def v():\n             pass\n \n-        assert _AndValidator((v,)) == a._validator\n+        assert v == a._validator\n \n-    def test_validator_decorator(self):\n+    @pytest.mark.parametrize(\"wrap\", [\n+        lambda v: v,\n+        lambda v: [v],\n+        lambda v: and_(v)\n+\n+    ])\n+    def test_validator_decorator(self, wrap):\n         \"\"\"\n-        If _CountingAttr.validator is used as a decorator, the decorated method\n-        is added to validators.\n+        If _CountingAttr.validator is used as a decorator and there is already\n+        a decorator set, the decorators are composed using `and_`.\n         \"\"\"\n         def v(_, __):\n             pass\n \n-        a = attr(validator=[v])\n+        a = attr(validator=wrap(v))\n \n         @a.validator\n         def v2(self, _, __):\ndiff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -7,8 +7,9 @@\n import pytest\n import zope.interface\n \n-from attr.validators import instance_of, provides, optional\n+from attr.validators import and_, instance_of, provides, optional\n from attr._compat import TYPE\n+from attr._make import attributes, attr\n \n from .utils import simple_attr\n \n@@ -58,6 +59,53 @@ def test_repr(self):\n         ) == repr(v)\n \n \n+def always_pass(_, __, ___):\n+    \"\"\"\n+    Toy validator that always passses.\n+    \"\"\"\n+\n+\n+def always_fail(_, __, ___):\n+    \"\"\"\n+    Toy validator that always fails.\n+    \"\"\"\n+    0/0\n+\n+\n+class TestAnd(object):\n+    def test_success(self):\n+        \"\"\"\n+        Succeeds if all wrapped validators succeed.\n+        \"\"\"\n+        v = and_(instance_of(int), always_pass)\n+\n+        v(None, simple_attr(\"test\"), 42)\n+\n+    def test_fail(self):\n+        \"\"\"\n+        Fails if any wrapped validator fails.\n+        \"\"\"\n+        v = and_(instance_of(int), always_fail)\n+\n+        with pytest.raises(ZeroDivisionError):\n+            v(None, simple_attr(\"test\"), 42)\n+\n+    def test_sugar(self):\n+        \"\"\"\n+        `and_(v1, v2, v3)` and `[v1, v2, v3]` are equivalent.\n+        \"\"\"\n+        @attributes\n+        class C(object):\n+            a1 = attr(\"a1\", validator=and_(\n+                instance_of(int),\n+            ))\n+            a2 = attr(\"a2\", validator=[\n+                instance_of(int),\n+            ])\n+\n+        assert C.__attrs_attrs__[0].validator == C.__attrs_attrs__[1].validator\n+\n+\n class IFoo(zope.interface.Interface):\n     \"\"\"\n     An interface.\n@@ -111,29 +159,33 @@ def test_repr(self):\n         ) == repr(v)\n \n \n+@pytest.mark.parametrize(\"validator\", [\n+    instance_of(int),\n+    [always_pass, instance_of(int)],\n+])\n class TestOptional(object):\n     \"\"\"\n     Tests for `optional`.\n     \"\"\"\n-    def test_success_with_type(self):\n+    def test_success(self, validator):\n         \"\"\"\n-        Nothing happens if types match.\n+        Nothing happens if validator succeeds.\n         \"\"\"\n-        v = optional(instance_of(int))\n+        v = optional(validator)\n         v(None, simple_attr(\"test\"), 42)\n \n-    def test_success_with_none(self):\n+    def test_success_with_none(self, validator):\n         \"\"\"\n         Nothing happens if None.\n         \"\"\"\n-        v = optional(instance_of(int))\n+        v = optional(validator)\n         v(None, simple_attr(\"test\"), None)\n \n-    def test_fail(self):\n+    def test_fail(self, validator):\n         \"\"\"\n         Raises `TypeError` on wrong types.\n         \"\"\"\n-        v = optional(instance_of(int))\n+        v = optional(validator)\n         a = simple_attr(\"test\")\n         with pytest.raises(TypeError) as e:\n             v(None, a, \"42\")\n@@ -144,13 +196,21 @@ def test_fail(self):\n \n         ) == e.value.args\n \n-    def test_repr(self):\n+    def test_repr(self, validator):\n         \"\"\"\n         Returned validator has a useful `__repr__`.\n         \"\"\"\n-        v = optional(instance_of(int))\n-        assert (\n-            (\"<optional validator for <instance_of validator for type \"\n-             \"<{type} 'int'>> or None>\")\n-            .format(type=TYPE)\n-        ) == repr(v)\n+        v = optional(validator)\n+\n+        if isinstance(validator, list):\n+            assert (\n+                (\"<optional validator for _AndValidator(_validators=[{func}, \"\n+                 \"<instance_of validator for type <{type} 'int'>>]) or None>\")\n+                .format(func=repr(always_pass), type=TYPE)\n+            ) == repr(v)\n+        else:\n+            assert (\n+                (\"<optional validator for <instance_of validator for type \"\n+                 \"<{type} 'int'>> or None>\")\n+                .format(type=TYPE)\n+            ) == repr(v)\n", "problem_statement": "validators.optional should take lists like validator=\nWe\u2019ve added the support for taking a list of validators to validator=, optional() should be able to take lists too otherwise users have to wrap all validators in the list with optional().\n", "hints_text": "", "created_at": "2017-05-10T09:52:56Z"}
{"repo": "python-attrs/attrs", "pull_number": 181, "instance_id": "python-attrs__attrs-181", "issue_numbers": ["165"], "base_commit": "a328e671690be4e6342d50056d121506b64da9d3", "patch": "diff --git a/src/attr/validators.py b/src/attr/validators.py\n--- a/src/attr/validators.py\n+++ b/src/attr/validators.py\n@@ -48,9 +48,9 @@ def instance_of(type):\n     :param type: The type to check for.\n     :type type: type or tuple of types\n \n-    The :exc:`TypeError` is raised with a human readable error message, the\n-    attribute (of type :class:`attr.Attribute`), the expected type, and the\n-    value it got.\n+    :raises TypeError: With a human readable error message, the attribute\n+        (of type :class:`attr.Attribute`), the expected type, and the value it\n+        got.\n     \"\"\"\n     return _InstanceOfValidator(type)\n \n@@ -87,9 +87,9 @@ def provides(interface):\n \n     :param zope.interface.Interface interface: The interface to check for.\n \n-    The :exc:`TypeError` is raised with a human readable error message, the\n-    attribute (of type :class:`attr.Attribute`), the expected interface, and\n-    the value it got.\n+    :raises TypeError: With a human readable error message, the attribute\n+        (of type :class:`attr.Attribute`), the expected interface, and the\n+        value it got.\n     \"\"\"\n     return _ProvidesValidator(interface)\n \n@@ -127,3 +127,39 @@ def optional(validator):\n     if isinstance(validator, list):\n         return _OptionalValidator(_AndValidator(validator))\n     return _OptionalValidator(validator)\n+\n+\n+@attributes(repr=False, slots=True)\n+class _InValidator(object):\n+    options = attr()\n+\n+    def __call__(self, inst, attr, value):\n+        if value not in self.options:\n+            raise ValueError(\n+                \"'{name}' must be in {options!r} (got {value!r})\"\n+                .format(name=attr.name, options=self.options, value=value)\n+            )\n+\n+    def __repr__(self):\n+        return (\n+            \"<in_ validator with options {options!r}>\"\n+            .format(options=self.options)\n+        )\n+\n+\n+def in_(options):\n+    \"\"\"\n+    A validator that raises a :exc:`ValueError` if the initializer is called\n+    with a value that does not belong in the options provided.  The check is\n+    performed using ``value in options``.\n+\n+    :param options: Allowed options.\n+    :type options: list, tuple, :class:`enum.Enum`, ...\n+\n+    :raises ValueError: With a human readable error message, the attribute (of\n+       type :class:`attr.Attribute`), the expected options, and the value it\n+       got.\n+\n+    .. versionadded:: 17.1.0\n+    \"\"\"\n+    return _InValidator(options)\n", "test_patch": "diff --git a/tests/test_validators.py b/tests/test_validators.py\n--- a/tests/test_validators.py\n+++ b/tests/test_validators.py\n@@ -7,7 +7,7 @@\n import pytest\n import zope.interface\n \n-from attr.validators import and_, instance_of, provides, optional\n+from attr.validators import and_, instance_of, provides, optional, in_\n from attr._compat import TYPE\n from attr._make import attributes, attr\n \n@@ -214,3 +214,37 @@ def test_repr(self, validator):\n                  \"<{type} 'int'>> or None>\")\n                 .format(type=TYPE)\n             ) == repr(v)\n+\n+\n+class TestIn_(object):\n+    \"\"\"\n+    Tests for `in_`.\n+    \"\"\"\n+    def test_success_with_value(self):\n+        \"\"\"\n+        If the value is in our options, nothing happens.\n+        \"\"\"\n+        v = in_([1, 2, 3])\n+        a = simple_attr(\"test\")\n+        v(1, a, 3)\n+\n+    def test_fail(self):\n+        \"\"\"\n+        Raise ValueError if the value is outside our options.\n+        \"\"\"\n+        v = in_([1, 2, 3])\n+        a = simple_attr(\"test\")\n+        with pytest.raises(ValueError) as e:\n+            v(None, a, None)\n+        assert (\n+            \"'test' must be in [1, 2, 3] (got None)\",\n+        ) == e.value.args\n+\n+    def test_repr(self):\n+        \"\"\"\n+        Returned validator has a useful `__repr__`.\n+        \"\"\"\n+        v = in_([3, 4, 5])\n+        assert(\n+            (\"<in_ validator with options [3, 4, 5]>\")\n+        ) == repr(v)\n", "problem_statement": "attr default based on other attributes\nHi!\r\n\r\nI have unsucessfully tried to define a default value by referencing other attributes. I'm sure the code below doesnt' work for some obvious or fundamental reason, but I would be grateful for comments on how to do something like it:\r\n\r\n```python\r\nimport attr\r\nfrom attr.validators import instance_of\r\nimport datetime\r\n\r\n@attr.s\r\nclass Something:\r\n    some_date = attr.ib(validator=instance_of(datetime.date))\r\n    some_number = attr.ib(convert=float)\r\n    name = attr.ib(validator=instance_of(str),\r\n                   default=\"Generic Name {0} - {1}%\".format(\r\n                       some_date.strftime(\"%d-%b-%Y\"),\r\n                       some_number * 100)\r\n                   )\r\n\r\ns = Something(some_date=datetime.date.today(), some_number=0.375)\r\n```\r\n\r\nI included the `.strftime()` conversion to highlight that `name` doesn't see a float and a date, but a `_CountingAttr` object, hence I get an AttributeError (and a TypeError for `some_number * 100`). Since I can't reference self either, what would be the correct way to do this?\n", "hints_text": "Hi,\r\n\r\nfor now I suggest using `__attrs_post_init__` (http://attrs.readthedocs.io/en/stable/examples.html?highlight=attrs_post_init#other-goodies). The linked example is basically what you want.\nI have wanted to do this several times. For example, you have a test of a function which takes many inputs. You want to test this function with many different cases. So (of course) you create a quick e.g. `@attr.s class TestInput:...` for that. In many cases you want some attribute to have a default depending on other attributes, but still be able to override it. The existing options are not so good for this:\r\n\r\n- I think you can use `these` for this but it's cumbersome.\r\n- `__attrs_post_init__` is not good because you can't override it.\r\n\r\nWhat I'd want, following the ad-hoc validators example, is something like this:\r\n\r\n```\r\n@attr.s\r\nclass C:\r\n    x = attr.ib()\r\n    y = attr.ib()\r\n    z = attr.ib()\r\n\r\n    @z.default\r\n    def z_default(self, attribute):\r\n        return self.x + self.y\r\n```\r\n\r\nThis is sensitive to the initialization order. However, if you have a stateful factory, the order is already important, so this is not new. And the natural order is the definition order which is intuitive.\r\n\r\nAnother issue is that this makes it possible to specify multiple defaults. I would just raise an error if this is detected.\r\n\r\nFinal issue I can think of is that an occasional user might confuse this with a property, while it does not behave like a property:\r\n\r\n- The value is persisted.\r\n- In mutable objects, the value doesn't change if the dependencies change, unlike a dynamically-computed property.\r\n\r\nBut I think \"default\" is clear on the behavior it has.\nAt first glance I like the proposed API :)\nI guess we could have a lot fun with decorators based on `_CountingAttr`.\nI *think* I want this in 17.1 but it entirely depends on the goodwill of reviewers (most likely @Tinche \u2013 I *gotta* shanghai some innocent souls at PyCon).", "created_at": "2017-05-01T17:45:41Z"}
{"repo": "python-attrs/attrs", "pull_number": 173, "instance_id": "python-attrs__attrs-173", "issue_numbers": ["177"], "base_commit": "d02b1d8b5a4ff401ebf1cda637cc86b03cf789b8", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -23,6 +23,7 @@\n )\n from . import exceptions\n from . import filters\n+from . import converters\n from . import validators\n \n \n@@ -54,6 +55,7 @@\n     \"attrib\",\n     \"attributes\",\n     \"attrs\",\n+    \"converters\",\n     \"evolve\",\n     \"exceptions\",\n     \"fields\",\ndiff --git a/src/attr/converters.py b/src/attr/converters.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attr/converters.py\n@@ -0,0 +1,24 @@\n+\"\"\"\n+Commonly useful converters.\n+\"\"\"\n+\n+from __future__ import absolute_import, division, print_function\n+\n+\n+def optional(converter):\n+    \"\"\"\n+    A converter that allows an attribute to be optional. An optional attribute\n+    is one which can be set to ``None``.\n+\n+    :param callable converter: the converter that is used for non-``None``\n+        values.\n+\n+    ..  versionadded:: 17.1.0\n+    \"\"\"\n+\n+    def optional_converter(val):\n+        if val is None:\n+            return None\n+        return converter(val)\n+\n+    return optional_converter\n", "test_patch": "diff --git a/tests/test_converters.py b/tests/test_converters.py\nnew file mode 100644\n--- /dev/null\n+++ b/tests/test_converters.py\n@@ -0,0 +1,36 @@\n+\"\"\"\n+Tests for `attr.converters`.\n+\"\"\"\n+\n+from __future__ import absolute_import\n+\n+import pytest\n+\n+from attr.converters import optional\n+\n+\n+class TestOptional(object):\n+    \"\"\"\n+    Tests for `optional`.\n+    \"\"\"\n+    def test_success_with_type(self):\n+        \"\"\"\n+        Wrapped converter is used as usual if value is not None.\n+        \"\"\"\n+        c = optional(int)\n+        assert c(\"42\") == 42\n+\n+    def test_success_with_none(self):\n+        \"\"\"\n+        Nothing happens if None.\n+        \"\"\"\n+        c = optional(int)\n+        assert c(None) is None\n+\n+    def test_fail(self):\n+        \"\"\"\n+        Propagates the underlying conversion error when conversion fails.\n+        \"\"\"\n+        c = optional(int)\n+        with pytest.raises(ValueError):\n+            c(\"not_an_int\")\n", "problem_statement": "documentation errors when describing `these`\nFollowing on in the vein of #171:\r\n\r\nThe \"these\" argument is documented as having [something to do with properties](https://github.com/python-attrs/attrs/blame/96fc8cb815e5d544e03f13a966ed54ac9c67645e/docs/examples.rst#L101) in [multiple places](https://github.com/python-attrs/attrs/blob/a48124b9049ab4102b18f2216d690a0d3319e704/src/attr/_make.py#L239).  But, does it?  In what way does `@property` not work with `@attr.s` already?  This program works exactly as I expect it would:\r\n\r\n```python\r\nimport attr\r\n\r\n@attr.s\r\nclass propertized(object):\r\n    _x = attr.ib()\r\n    @property\r\n    def x(self):\r\n        return self.x ** 2\r\n\r\np3 = propertized(3)\r\np3prime = propertized(x=3)\r\nprint(p3 == p3prime)\r\nprint(p3)\r\n```\r\n\r\nIt also describes the class body as being \"ignored\".  This is accurate in the extremely narrow sense of the implementation of what exactly `@attr.s` does - either reading the `attr.ib` objects out of the class namespace or not, which were presumably defined during the class body - but it is somewhat unclear for users who want to know what attr.s's interface is rather than the mechanics of its internals.\r\n\r\nThe passive voice of \"will be ignored\" also suggests that _everything_ will ignore the class body - attrs, python, random passers-by - whereas the docs mean to rather specifically say \"`@attr.s` will ignore the class body\".  I think it should be even more specific: `attr.s` will not transform any `attr.ib` declarations into arguments or parts of the `repr`, leaving them instead as private `_CountingAttr` objects.  I'd even go so far as to say that `attr.s` should emit a warning if any such objects are found, but that's probably a more complex discussion.\r\n\r\nAlso, `properties` is not an identifier and should not be typeset as such; \"`property` objects\" or somesuch would be a better way to express that (if it needs to be expressed).\n", "hints_text": "", "created_at": "2017-03-29T07:06:32Z"}
{"repo": "python-attrs/attrs", "pull_number": 155, "instance_id": "python-attrs__attrs-155", "issue_numbers": ["154", "154"], "base_commit": "2c8bd463399a1439b099d47c73f1f21c8a0bb906", "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -362,7 +362,7 @@ def wrap(cls):\n             cls_dict.pop(\"__dict__\", None)\n \n             qualname = getattr(cls, \"__qualname__\", None)\n-            cls = type(cls.__name__, cls.__bases__, cls_dict)\n+            cls = type(cls)(cls.__name__, cls.__bases__, cls_dict)\n             if qualname is not None:\n                 cls.__qualname__ = qualname\n \n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -3,6 +3,7 @@\n import pickle\n \n import pytest\n+import six\n \n from hypothesis import given\n from hypothesis.strategies import booleans\n@@ -82,6 +83,22 @@ class FrozenNoSlots(object):\n     x = attr.ib()\n \n \n+class Meta(type):\n+    pass\n+\n+\n+@attr.s\n+@six.add_metaclass(Meta)\n+class WithMeta(object):\n+    pass\n+\n+\n+@attr.s(slots=True)\n+@six.add_metaclass(Meta)\n+class WithMetaSlots(object):\n+    pass\n+\n+\n class TestDarkMagic(object):\n     \"\"\"\n     Integration tests.\n@@ -231,3 +248,7 @@ def test_subclassing_frozen_gives_frozen(self):\n \n         assert i.x == \"foo\"\n         assert i.y == \"bar\"\n+\n+    @pytest.mark.parametrize(\"cls\", [WithMeta, WithMetaSlots])\n+    def test_metaclass_preserved(self, cls):\n+        assert Meta == type(cls)\n", "problem_statement": "Metaclass lost with slots=True \nHello.\r\n\r\nUsing a metaclass with slots=True, e.g.\r\n```\r\n@attr.s(slots=True)\r\nclass A(metaclass=abc.ABCMeta):\r\n    @abc.abstractmethod\r\n    def f(self):\r\n        pass\r\n```\r\nWill lead to `A` being instantiable and `type(A)` being `<class 'type'>` (unlike the case with slots=False), as for slots to work the new class is generated in [_make.py](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L365) with:\r\n\r\n`cls = type(cls.__name__, cls.__bases__, cls_dict)` [1]\r\n\r\nThis doesn't happen if this line is changed to:\r\n\r\n`cls = type(cls)(cls.__name__, cls.__bases__, cls_dict)` [2]\r\n\r\nWith this change `type(A)` is `<class 'abc.ABCMeta'>` and A is no longer instantiable.\r\nCan the class generation for slots be changed to something like [2] to avoid losing metaclasses or it is intentionally written as it is now and I am missing something?\r\n\nMetaclass lost with slots=True \nHello.\r\n\r\nUsing a metaclass with slots=True, e.g.\r\n```\r\n@attr.s(slots=True)\r\nclass A(metaclass=abc.ABCMeta):\r\n    @abc.abstractmethod\r\n    def f(self):\r\n        pass\r\n```\r\nWill lead to `A` being instantiable and `type(A)` being `<class 'type'>` (unlike the case with slots=False), as for slots to work the new class is generated in [_make.py](https://github.com/python-attrs/attrs/blob/master/src/attr/_make.py#L365) with:\r\n\r\n`cls = type(cls.__name__, cls.__bases__, cls_dict)` [1]\r\n\r\nThis doesn't happen if this line is changed to:\r\n\r\n`cls = type(cls)(cls.__name__, cls.__bases__, cls_dict)` [2]\r\n\r\nWith this change `type(A)` is `<class 'abc.ABCMeta'>` and A is no longer instantiable.\r\nCan the class generation for slots be changed to something like [2] to avoid losing metaclasses or it is intentionally written as it is now and I am missing something?\r\n\n", "hints_text": "It's not intentional, it just hasn't come up until now. :)\r\n\r\nCould you try applying the change, and if the tests pass contribute a PR? It'd be nice to add a test for this as well.\nIt's not intentional, it just hasn't come up until now. :)\r\n\r\nCould you try applying the change, and if the tests pass contribute a PR? It'd be nice to add a test for this as well.", "created_at": "2017-02-27T15:18:16Z"}
{"repo": "python-attrs/attrs", "pull_number": 142, "instance_id": "python-attrs__attrs-142", "issue_numbers": ["136"], "base_commit": "0563f44b477666143fb81e9c3822de1f87b9a8c5", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -48,8 +48,8 @@\n     \"Factory\",\n     \"NOTHING\",\n     \"asdict\",\n-    \"astuple\",\n     \"assoc\",\n+    \"astuple\",\n     \"attr\",\n     \"attrib\",\n     \"attributes\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -49,7 +49,7 @@ def __hash__(self):\n \n \n def attr(default=NOTHING, validator=None,\n-         repr=True, cmp=True, hash=True, init=True,\n+         repr=True, cmp=True, hash=None, init=True,\n          convert=None, metadata={}):\n     \"\"\"\n     Create a new attribute on a class.\n@@ -92,8 +92,11 @@ def attr(default=NOTHING, validator=None,\n         method.\n     :param bool cmp: Include this attribute in the generated comparison methods\n         (``__eq__`` et al).\n-    :param bool hash: Include this attribute in the generated ``__hash__``\n-        method.\n+    :param hash: Include this attribute in the generated ``__hash__``\n+        method.  If ``None`` (default), mirror *cmp*'s value.  This is the\n+        correct behavior according the Python spec.  Setting this value to\n+        anything else than ``None`` is *discouraged*.\n+    :type hash: ``bool`` or ``None``\n     :param bool init: Include this attribute in the generated ``__init__``\n         method.  It is possible to set this to ``False`` and set a default\n         value.  In that case this attributed is unconditionally initialized\n@@ -104,10 +107,16 @@ def attr(default=NOTHING, validator=None,\n         returned value will be used as the new value of the attribute.  The\n         value is converted before being passed to the validator, if any.\n     :param metadata: An arbitrary mapping, to be used by third-party\n-        components.\n+        components.  See :ref:`extending_metadata`.\n \n     ..  versionchanged:: 17.1.0 *validator* can be a ``list`` now.\n+    ..  versionchanged:: 17.1.0\n+        *hash* is ``None`` and therefore mirrors *cmp* by default .\n     \"\"\"\n+    if hash is not None and hash is not True and hash is not False:\n+        raise TypeError(\n+            \"Invalid value for hash.  Must be True, False, or None.\"\n+        )\n     return _CountingAttr(\n         default=default,\n         validator=validator,\n@@ -216,7 +225,7 @@ def _frozen_delattrs(self, name):\n \n \n def attributes(maybe_cls=None, these=None, repr_ns=None,\n-               repr=True, cmp=True, hash=True, init=True,\n+               repr=True, cmp=True, hash=None, init=True,\n                slots=False, frozen=False, str=False):\n     r\"\"\"\n     A class decorator that adds `dunder\n@@ -245,8 +254,26 @@ def attributes(maybe_cls=None, these=None, repr_ns=None,\n         ``__gt__``, and ``__ge__`` methods that compare the class as if it were\n         a tuple of its ``attrs`` attributes.  But the attributes are *only*\n         compared, if the type of both classes is *identical*!\n-    :param bool hash: Create a ``__hash__`` method that returns the\n-        :func:`hash` of a tuple of all ``attrs`` attribute values.\n+    :param hash: If ``None`` (default), the ``__hash__`` method is generated\n+        according how *cmp* and *frozen* are set.\n+\n+        1. If *both* are True, ``attrs`` will generate a ``__hash__`` for you.\n+        2. If *cmp* is True and *frozen* is False, ``__hash__`` will be set to\n+           None, marking it unhashable (which it is).\n+        3. If *cmp* is False, ``__hash__`` will be left untouched meaning the\n+           ``__hash__`` method of the superclass will be used (if superclass is\n+           ``object``, this means it will fall back to id-based hashing.).\n+\n+        Although not recommended, you can decide for yourself and force\n+        ``attrs`` to create one (e.g. if the class is immutable even though you\n+        didn't freeze it programmatically) by passing ``True`` or not.  Both of\n+        these cases are rather special and should be used carefully.\n+\n+        See the `Python documentation \\\n+        <https://docs.python.org/3/reference/datamodel.html#object.__hash__>`_\n+        and the `GitHub issue that led to the default behavior \\\n+        <https://github.com/hynek/attrs/issues/136>`_ for more details.\n+    :type hash: ``bool`` or ``None``\n     :param bool init: Create a ``__init__`` method that initialiazes the\n         ``attrs`` attributes.  Leading underscores are stripped for the\n         argument name.  If a ``__attrs_post_init__`` method exists on the\n@@ -273,6 +300,9 @@ def attributes(maybe_cls=None, these=None, repr_ns=None,\n     ..  versionadded:: 16.0.0 *slots*\n     ..  versionadded:: 16.1.0 *frozen*\n     ..  versionadded:: 16.3.0 *str*, and support for ``__attrs_post_init__``.\n+    ..  versionchanged::\n+            17.1.0 *hash* supports ``None`` as value which is also the default\n+            now.\n     \"\"\"\n     def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n@@ -303,8 +333,18 @@ def wrap(cls):\n             cls.__str__ = cls.__repr__\n         if cmp is True:\n             cls = _add_cmp(cls)\n-        if hash is True:\n+\n+        if hash is not True and hash is not False and hash is not None:\n+            raise TypeError(\n+                \"Invalid value for hash.  Must be True, False, or None.\"\n+            )\n+        elif hash is False or (hash is None and cmp is False):\n+            pass\n+        elif hash is True or (hash is None and cmp is True and frozen is True):\n             cls = _add_hash(cls)\n+        else:\n+            cls.__hash__ = None\n+\n         if init is True:\n             cls = _add_init(cls, effectively_frozen)\n         if effectively_frozen is True:\n@@ -369,7 +409,9 @@ def _add_hash(cls, attrs=None):\n     Add a hash method to *cls*.\n     \"\"\"\n     if attrs is None:\n-        attrs = [a for a in cls.__attrs_attrs__ if a.hash]\n+        attrs = [a\n+                 for a in cls.__attrs_attrs__\n+                 if a.hash is True or (a.hash is None and a.cmp is True)]\n \n     def hash_(self):\n         \"\"\"\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -1,7 +1,9 @@\n from __future__ import absolute_import, division, print_function\n+\n import pickle\n \n import pytest\n+\n from hypothesis import given\n from hypothesis.strategies import booleans\n \n@@ -91,9 +93,9 @@ def test_fields(self, cls):\n         \"\"\"\n         assert (\n             Attribute(name=\"x\", default=foo, _validator=None,\n-                      repr=True, cmp=True, hash=True, init=True),\n+                      repr=True, cmp=True, hash=None, init=True),\n             Attribute(name=\"y\", default=attr.Factory(list), _validator=None,\n-                      repr=True, cmp=True, hash=True, init=True),\n+                      repr=True, cmp=True, hash=None, init=True),\n         ) == attr.fields(cls)\n \n     @pytest.mark.parametrize(\"cls\", [C1, C1Slots])\n@@ -140,9 +142,9 @@ def test_programmatic(self, slots, frozen):\n         PC = attr.make_class(\"PC\", [\"a\", \"b\"], slots=slots, frozen=frozen)\n         assert (\n             Attribute(name=\"a\", default=NOTHING, _validator=None,\n-                      repr=True, cmp=True, hash=True, init=True),\n+                      repr=True, cmp=True, hash=None, init=True),\n             Attribute(name=\"b\", default=NOTHING, _validator=None,\n-                      repr=True, cmp=True, hash=True, init=True),\n+                      repr=True, cmp=True, hash=None, init=True),\n         ) == attr.fields(PC)\n \n     @pytest.mark.parametrize(\"cls\", [Sub, SubSlots])\ndiff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -29,8 +29,11 @@\n CmpCSlots = simple_class(cmp=True, slots=True)\n ReprC = simple_class(repr=True)\n ReprCSlots = simple_class(repr=True, slots=True)\n+\n+# HashC is hashable by explicit definition while HashCSlots is hashable\n+# implicitly.\n HashC = simple_class(hash=True)\n-HashCSlots = simple_class(hash=True, slots=True)\n+HashCSlots = simple_class(hash=None, cmp=True, frozen=True, slots=True)\n \n \n class InitC(object):\n@@ -227,15 +230,67 @@ class TestAddHash(object):\n     \"\"\"\n     Tests for `_add_hash`.\n     \"\"\"\n+    def test_enforces_type(self):\n+        \"\"\"\n+        The `hash` argument to both attrs and attrib must be None, True, or\n+        False.\n+        \"\"\"\n+        exc_args = (\"Invalid value for hash.  Must be True, False, or None.\",)\n+\n+        with pytest.raises(TypeError) as e:\n+            make_class(\"C\", {}, hash=1),\n+\n+        assert exc_args == e.value.args\n+\n+        with pytest.raises(TypeError) as e:\n+            make_class(\"C\", {\"a\": attr(hash=1)}),\n+\n+        assert exc_args == e.value.args\n+\n     @given(booleans())\n-    def test_hash(self, slots):\n+    def test_hash_attribute(self, slots):\n         \"\"\"\n-        If `hash` is False, ignore that attribute.\n+        If `hash` is False on an attribute, ignore that attribute.\n         \"\"\"\n-        C = make_class(\"C\", {\"a\": attr(hash=False), \"b\": attr()}, slots=slots)\n+        C = make_class(\"C\", {\"a\": attr(hash=False), \"b\": attr()},\n+                       slots=slots, hash=True)\n \n         assert hash(C(1, 2)) == hash(C(2, 2))\n \n+    @given(booleans())\n+    def test_hash_attribute_mirrors_cmp(self, cmp):\n+        \"\"\"\n+        If `hash` is None, the hash generation mirrors `cmp`.\n+        \"\"\"\n+        C = make_class(\"C\", {\"a\": attr(cmp=cmp)}, cmp=True, frozen=True)\n+\n+        if cmp:\n+            assert C(1) != C(2)\n+            assert hash(C(1)) != hash(C(2))\n+            assert hash(C(1)) == hash(C(1))\n+        else:\n+            assert C(1) == C(2)\n+            assert hash(C(1)) == hash(C(2))\n+\n+    @given(booleans())\n+    def test_hash_mirrors_cmp(self, cmp):\n+        \"\"\"\n+        If `hash` is None, the hash generation mirrors `cmp`.\n+        \"\"\"\n+        C = make_class(\"C\", {\"a\": attr()}, cmp=cmp, frozen=True)\n+\n+        i = C(1)\n+\n+        assert i == i\n+        assert hash(i) == hash(i)\n+\n+        if cmp:\n+            assert C(1) == C(1)\n+            assert hash(C(1)) == hash(C(1))\n+        else:\n+            assert C(1) != C(1)\n+            assert hash(C(1)) != hash(C(1))\n+\n     @pytest.mark.parametrize(\"cls\", [HashC, HashCSlots])\n     def test_hash_works(self, cls):\n         \"\"\"\n@@ -243,6 +298,20 @@ def test_hash_works(self, cls):\n         \"\"\"\n         assert hash(cls(1, 2)) != hash(cls(1, 1))\n \n+    def test_hash_default(self):\n+        \"\"\"\n+        Classes are not hashable by default.\n+        \"\"\"\n+        C = make_class(\"C\", {})\n+\n+        with pytest.raises(TypeError) as e:\n+            hash(C())\n+\n+        assert e.value.args[0] in (\n+            \"'C' objects are unhashable\",  # PyPy\n+            \"unhashable type: 'C'\",  # CPython\n+        )\n+\n \n class TestAddInit(object):\n     \"\"\"\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -159,7 +159,7 @@ class C(object):\n             \"No mandatory attributes allowed after an attribute with a \"\n             \"default value or factory.  Attribute in question: Attribute\"\n             \"(name='y', default=NOTHING, validator=None, repr=True, \"\n-            \"cmp=True, hash=True, init=True, convert=None, \"\n+            \"cmp=True, hash=None, init=True, convert=None, \"\n             \"metadata=mappingproxy({}))\",\n         ) == e.value.args\n \n@@ -213,7 +213,7 @@ class E(D):\n \n class TestAttributes(object):\n     \"\"\"\n-    Tests for the `attributes` class decorator.\n+    Tests for the `attrs`/`attr.s` class decorator.\n     \"\"\"\n     @pytest.mark.skipif(not PY2, reason=\"No old-style classes in Py3\")\n     def test_catches_old_style(self):\n@@ -262,29 +262,24 @@ def test_immutable(self, attr, attr_name):\n     ])\n     def test_adds_all_by_default(self, method_name):\n         \"\"\"\n-        If no further arguments are supplied, all add_XXX functions are\n-        applied.\n+        If no further arguments are supplied, all add_XXX functions except\n+        add_hash are applied.  __hash__ is set to None.\n         \"\"\"\n         # Set the method name to a sentinel and check whether it has been\n         # overwritten afterwards.\n         sentinel = object()\n \n-        class C1(object):\n-            x = attr()\n-\n-        setattr(C1, method_name, sentinel)\n-\n-        C1 = attributes(C1)\n-\n-        class C2(object):\n+        class C(object):\n             x = attr()\n \n-        setattr(C2, method_name, sentinel)\n+        setattr(C, method_name, sentinel)\n \n-        C2 = attributes(C2)\n+        C = attributes(C)\n+        meth = getattr(C, method_name)\n \n-        assert sentinel != getattr(C1, method_name)\n-        assert sentinel != getattr(C2, method_name)\n+        assert sentinel != meth\n+        if method_name == \"__hash__\":\n+            assert meth is None\n \n     @pytest.mark.parametrize(\"arg_name, method_name\", [\n         (\"repr\", \"__repr__\"),\n@@ -294,7 +289,7 @@ class C2(object):\n     ])\n     def test_respects_add_arguments(self, arg_name, method_name):\n         \"\"\"\n-        If a certain `add_XXX` is `True`, XXX is not added to the class.\n+        If a certain `add_XXX` is `False`, `__XXX__` is not added to the class.\n         \"\"\"\n         # Set the method name to a sentinel and check whether it has been\n         # overwritten afterwards.\n@@ -635,7 +630,6 @@ class TestMetadata(object):\n     \"\"\"\n     Tests for metadata handling.\n     \"\"\"\n-\n     @given(sorted_lists_of_attrs)\n     def test_metadata_present(self, list_of_attrs):\n         \"\"\"\ndiff --git a/tests/test_slots.py b/tests/test_slots.py\n--- a/tests/test_slots.py\n+++ b/tests/test_slots.py\n@@ -31,7 +31,7 @@ def staticmethod():\n         return \"staticmethod\"\n \n \n-@attr.s(slots=True)\n+@attr.s(slots=True, hash=True)\n class C1Slots(object):\n     x = attr.ib(validator=attr.validators.instance_of(int))\n     y = attr.ib()\n@@ -106,7 +106,7 @@ def test_inheritance_from_nonslots():\n     Note that a slots class inheriting from an ordinary class loses most of the\n     benefits of slots classes, but it should still work.\n     \"\"\"\n-    @attr.s(slots=True)\n+    @attr.s(slots=True, hash=True)\n     class C2Slots(C1):\n         z = attr.ib()\n \n@@ -159,7 +159,7 @@ def staticmethod():\n             return \"staticmethod\"\n \n     C2Slots = attr.s(these={\"x\": attr.ib(), \"y\": attr.ib(), \"z\": attr.ib()},\n-                     init=False, slots=True)(SimpleOrdinaryClass)\n+                     init=False, slots=True, hash=True)(SimpleOrdinaryClass)\n \n     c2 = C2Slots(x=1, y=2, z=\"test\")\n     assert 1 == c2.x\n@@ -190,11 +190,11 @@ def test_inheritance_from_slots():\n     \"\"\"\n     Inheriting from an attr slot class works.\n     \"\"\"\n-    @attr.s(slots=True)\n+    @attr.s(slots=True, hash=True)\n     class C2Slots(C1Slots):\n         z = attr.ib()\n \n-    @attr.s(slots=True)\n+    @attr.s(slots=True, hash=True)\n     class C2(C1):\n         z = attr.ib()\n \n@@ -264,11 +264,11 @@ def classmethod(cls):\n         def staticmethod():\n             return \"staticmethod\"\n \n-    @attr.s(slots=True)\n+    @attr.s(slots=True, hash=True)\n     class C2Slots(C1BareSlots):\n         z = attr.ib()\n \n-    @attr.s(slots=True)\n+    @attr.s(slots=True, hash=True)\n     class C2(C1Bare):\n         z = attr.ib()\n \ndiff --git a/tests/utils.py b/tests/utils.py\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -17,18 +17,20 @@\n from attr._make import NOTHING, make_class\n \n \n-def simple_class(cmp=False, repr=False, hash=False, str=False, slots=False):\n+def simple_class(cmp=False, repr=False, hash=False, str=False, slots=False,\n+                 frozen=False):\n     \"\"\"\n     Return a new simple class.\n     \"\"\"\n     return make_class(\n         \"C\", [\"a\", \"b\"],\n         cmp=cmp, repr=repr, hash=hash, init=True, slots=slots, str=str,\n+        frozen=frozen,\n     )\n \n \n def simple_attr(name, default=NOTHING, validator=None, repr=True,\n-                cmp=True, hash=True, init=True):\n+                cmp=True, hash=None, init=True):\n     \"\"\"\n     Return an attribute with a name and no other bells and whistles.\n     \"\"\"\n", "problem_statement": "It doesn't make sense that cmp and hash are set independently, does it?\nRight now, `cmp=` and `hash=` are treated as independent options, both in `attr.s()` and `attr.ib()`. This does't make much sense to me.\r\n\r\nIf you do `attr.s(cmp=True, hash=False)` then you get a broken class that violates Python's invariant that objects which compare equal must hash equal (if they are hashable at all).\r\n\r\nIf you do `attr.s(cmp=False, hash=True)` then you get a class with a really weird `hash` that has lots of collisions (`Foo(x=1)` and `Foo(x=1)` are different objects so they compare non-equal, but their hashes are the same.) Also, it is broken if the object is mutable, because the hash can change over time. ...and now that I think about it, objects that have `cmp=True` also have the same problem with mutability. Actually I guess all of my `attrs` classes are currently illegal, because the defaults are to generate illegal classes. I guess I should go fix that.\r\n\r\nAnyway, I think the only plausible configurations are:\r\n* `cmp=True`, `frozen=True`, `hash=True`\r\n* `cmp=True`, `frozen=True`, hash undefined (attrs doesn't have a nice way to do this right now I think?)\r\n* `cmp=False`, `hash=False` (use `object.__hash__`)\r\n* `cmp=False`, hash undefined\r\n\r\nAnd then for `attr.ib`, why are `cmp` and `hash` separate arguments? Wouldn't it make more sense to drop the `hash` argument, and just use the logic that if `attr.ib(cmp=True)` and we're generating a hash method at all, then we should include this attrib?\r\n\n", "hints_text": "There\u2019s exactly one reason: unhashable attributes.  Sometimes you want an attribute contain a dictionary and still be comparable.\nOh and sometimes you want to implement `__hash__` yourself.\nSure, the \"contain a dictionary and still be comparable\" case is `cmp=True`, hash raises an error, and the implement-`__hash__`-yourself case is `cmp=False`. Once `__eq__` is defined, though, there are exactly two correct ways to implement `__hash__`: either it hashes exactly the same things that `__eq__` cares about *and* those things are immutable, or it else raises an exception.\r\n\r\nCurrently there are 2^3 = 8 possible settings for cmp/hash/frozen when calling `attr.s`, but:\r\n\r\n* if `frozen=False`, then `hash=True` is just broken (I guess modulo some edge cases around classes where some attributes are immutable in practice, and those are the only ones that participate in comparison; because of missing #133 then the only way to express this to attrs is by telling it that the whole class is mutable and then just carefully not touching the immutable subset)\r\n* if `cmp=False`, then `hash=True` is just broken\r\n* if `cmp=True`, then `hash=False` is just broken, unless the user also adds `__hash__ = None` to the body of their class\r\n\r\nAnd when calling `attr.ib`, there's literally never any options about how to set `hash`, right? Either it doesn't matter (if you used `attr.s(hash=False)`, or else it must be set to match `cmp`.\r\n\r\nMy main concern is that plain `@attr.s` by default generates broken classes, and the obvious fix of using `@attr.s(cmp=False)` doesn't fix it. So the minimal correct ways of calling `@attr.s` are either `@attr.s(frozen=True)` or `@attr.s(cmp=False, hash=False)`, right?\r\n\r\nI think in a perfect world the API I'd prefer is: `attr.s` takes two arguments, `cmp=` and `frozen=` (well and other ones that aren't relevant here, but not `hash=`). The defaults are `frozen=True`, and `cmp=<whatever frozen is set to>`. (Rationale: 99% of the time you want `frozen == cmp`, and immutable is a better default than mutable.) If `cmp=True` and `frozen=True`, then the default is to generate a `__hash__`. If `cmp=True` and `frozen=False`, then the default is to set `__hash__ = None`. If `cmp=False`, then the default is not to generate a `__hash__` at all. In all cases if the user defined `__hash__` then we leave it alone. (This covers the weird cases like if you to explicitly mark an immutable comparable object as being non-hashable, it's written:\r\n```python\r\n@attr.s(cmp=True, frozen=True)\r\nclass Foo:\r\n    __hash__ = None\r\n```\r\n)\r\n\r\nOf course backwards-compatibility is a problem...\nUgh, this is a complicated issue.\r\n\r\nI think #3 is relevant here. Some of the ideas from #3 were having `attr.value` and `attr.object` as higher-level, more opinionated wrappers for `attr.s` that made sure the affected classes made sense according to certain internal rules. Maybe defining these could be used to get around backwards compatibility problems.\r\n\r\nI agree we're maybe too trigger happy with defining hashes for classes. Making your class hashable is a complex thing. Basically the only reason to make your class hashable is to use it as a key in a dict, or to put it in a set, which introduces additional constraints, which makes this even more complex.\r\n\r\n```\r\n@attr.s(hash=False)\r\nclass A:\r\n    pass\r\n\r\nhash(A())\r\n-9223372036575954421\r\n```\r\nThis is probably a bug. (Interestingly, it will work properly and raise an exception if `slots=True`, because that will recreate the class.)\r\n\r\nI think an easy case could be made for the following change: if the class is `slots=False`, `cmp=True`, `hash=False` and `Cls.__hash__ is object.__hash__`, set `Cls.__hash__` to None (to make the class unhashable).\nThere\u2019s a lot of issues raised here and honestly I can\u2019t follow all of them.  Just as a preamble/excuse:  the reason you can set all these things is that attrs started out with a different scope.  More of a class construction kit so the users was supposed to know what they did and invariants weren\u2019t caught.  The reality changed though (which makes me happy of course) and this dark little corner is just something nobody really cared about (which is also why I\u2019m OK with being a bit more aggressive about fixing it).\r\n\r\n# What I understand:\r\n- If `hash=False` is set for the whole class, we shouldn\u2019t just not set a hash, we should set `__hash__` to None (instead of falling though to `object`\u2019s).  I agree this is a bug and I\u2019d be willing allow this change.  If anyone was relying on this behavior it's most likely a bug and it will explode loudly as it should.  Maybe it\u2019s necessary to allow the use to signal they *want* to inherit the `__hash__` because they do (god forbid) subclass something else than `object`)?  That makes me think that it would be best to use `hash=False` for current behavior and `hash=None` for the correct one (and document it properly).\r\n- We have a related issue for `cmp=False` because  `Foo(x=1) == Foo(x=1)` is `False` but `hash(Foo(x=1)) == hash(Foo(x=1))` is `True`.   `hash=None` would take care of it.\r\n- I was coming up with examples for `attr.ib(hash=False)` but the answer is always \u201cyep, but then they can also carry `cmp=False`\u201d). :)\r\n- I never really thought about it, but yeah mutable objects shouldn\u2019t have a `__hash__` at all. \u2192 `If a class defines mutable objects and implements an __eq__() method, it should not implement __hash__(), since the implementation of hashable collections requires that a key\u2019s hash value is immutable (if the object\u2019s hash value changes, it will be in the wrong hash bucket).`\r\n\r\n# What I don\u2019t understand\r\nWhat\u2019s wrong with `cmp=True, hash=None, frozen=False` because I\u2019d tend to make that the new default.  I know y\u2019all love immutable data, but let\u2019s think of the 99,999% of developers out there that don\u2019t want to slow down their software. :) \r\n\r\nThis is in line with what the Python docs say, and if people want to have it hashed, they have to put extra effort into it.  But it\u2019s still comparable.\r\n\r\n# What Should Be Done\r\n1. Add the case of `hash=None` and promote it. \r\n2. Maybe even make it default because it might be masking bugs and is currently in violation with the Python spec.\r\n3. Let\u2019s assume `hash`, `cmp`, `slots`, and `frozen` are more of internal knobs.  You list four plausible configurations, I think there\u2019s a fifth.  We should give them names and add them as high-level, opinionated templates.  Which is basically #3.  It just makes me sad, that it breaks the naming.  `@attr.s` should not become an implementation detail.  Going that way is even more fodder for #131.\r\n4. I\u2019m not sure what to do about `attr.ib()`.  With the new thinking, *un*hashable is the default.  It seems weird to add something like `hashable=True` to all attributes.  But maybe this is the lowest priority of them all.\r\n\r\nI think 1+2 is something we should tackle before the new release.\r\n\r\n***\r\n\r\nIn any case thank you for being patient with me.  It took me two coffees, to write this down and honestly I don\u2019t think anyone really thought this completely though.\r\n\r\nI\u2019d also welcome input from @glyph as usual :)\nAFAICT the cases that make sense are:\r\n\r\n* mutable object, inherit `__eq__` from superclass, inherit `__hash__` from superclass (= the default behavior if defining a class without using attrs at all)\r\n* mutable object, attrs-generated `__eq__`, `__hash__ = None`\r\n* immutable object, inherit `__eq__` from superclass, inherit `__hash__` from superclass\r\n* immutable object, attrs-generated `__eq__`, attrs-generated `__hash__`\r\n\r\nMy proposal above was that we map these 4 cases to the 4 argument patterns, respectively:\r\n\r\n* `frozen=False, cmp=False`\r\n* `frozen=False, cmp=True`\r\n* `frozen=True, cmp=False`\r\n* `frozen=True, cmp=True`\r\n\r\nSo I don't see any use for a `hash=` argument at all really... it's always implied by the other arguments. And this nicely avoids the issue you mention about having a split between high-level \"templates\" and the actual `attr.s` arguments.\r\n\r\nThe one additional wrinkle is that in *principle* someone might want something really odd, like, \"this is an immutable class with an attrs-defined `__eq__`, so it totally could be hashable, but for some reason I have decided that I never want to use it as a dictionary key, and I want to get an error if that happens\". My suggestion to cover that case is to say that if the user explicitly defines a `__hash__` in the class body, then that we always leave it alone. (So this would be written like:\r\n```python\r\n@attr.s(frozen=True, cmp=True)\r\nclass Foo:\r\n    __hash__ = None\r\n```\r\n)\r\n\r\nDoes this cover all of your 5 cases? I'm not quite clear on what they are, since the 5th one you added is already on my list of 4 :-).\r\n\r\nAnd yeah of these four cases probably the best default is `frozen=False, cmp=True`.\nMy fifth is `frozen=False, cmp=True, hash=None` which isn\u2019t in your original list.  The use of the hash argument might be debatable but it\u2019s here to stay so we have to take it into account when modeling the cases. :)\r\n\r\nMy understanding is the following:\r\n\r\n`hash=False` doesn\u2019t make sense, except when subclassing:\r\n\r\n```python\r\nclass Base:\r\n    def __hash__(self):\r\n        return something_something_very_smart_that_we_cannot_anticipate\r\n\r\n@attr.s(hash=False)\r\nclass C(Base):\r\n    ...\r\n```\r\n\r\nMain cases:\r\n\r\n- `frozen=False, cmp=True, hash=None`: normal Python class.\r\n- `frozen=False, cmp=False, hash=None`: immutable container that may contain mutable/unhashable attributes\r\n- `frozen=True, cmp=True, hash=True`: immutable container with only hashable contents\r\n\r\nValid but kind of pointless:\r\n\r\n- `frozen=False, cmp=False, hash=None`\r\n\r\n***\r\n\r\nAfter we\u2019ve added `hash=None` (and made it default), the only deficiency seems to be that there should be a nicer/more idiomatic way to define immutable containers (\u2192 #3).  People can still manually break their classes but that\u2019s their problem if they really want to, I\u2019m not their nanny.\r\n\r\nAm I missing something?\r\n\r\n***\r\n\r\nOne final thought: in attrs, True/False for hash etc always meant \u201cattrs won\u2019t attach one\u201d not \u201cclass won\u2019t have one\u201d.  Which seems fine except for `hash`.  Again, when attrs started, I had a different scope in mind\u2026\n> `hash=False` doesn\u2019t make sense, except when subclassing:\r\n\r\nI use `frozen=False, cmp=False, hash=False` all the time, for when I want `object`-style compare-and-hash-by-identity but still want to take advantage of attrs' other conveniences. (I know this is kind of an abuse of attrs compared to how you were imagining it would be used, but those conveniences are pretty convenient! :-)) I just checked and in my current code-base I have 26 uses of `@attr.s`, and they're split exactly 50/50 between ones that use `frozen=True, cmp=True, hash=True` and ones that use `frozen=False, cmp=False, hash=False`.\r\n\r\n> but it\u2019s here to stay so we have to take it into account when modeling the cases. :)\r\n\r\nWhy does it have to stay? The only case you've come up with where it's meaningful is `hash=None`, which would be a new feature anyway -- all the existing cases are either broken or redundant, no?\n> Why does it have to stay? The only case you've come up with where it's meaningful is hash=None, which would be a new feature anyway -- all the existing cases are either broken or redundant, no?\r\n\r\nThe subclassing use-case is still existent.   I want to discourage it\u2019s use but I\u2019m not comfortable to take away the knob altogether. \r\n\r\nThe only thing you\u2019re arguing against is `hash=False`, not `hash` itself, isn\u2019t it?  You said yourself, that you use it sometimes?\r\n\r\nSorry if I\u2019m too dumb to follow. :|\r\n\r\n***\r\n\r\nAnyhow:  can we agree, that adding `hash=None`, making it default, (and attending PyCon under a pseudonym) would fix the actual *bug* in attrs?\r\n\r\nThere\u2019s two additional feature requests that should be handled in separate issues:\r\n\r\n1. better way to define a class, where `hash=True` makes sense.\r\n2. do something about `attr.ib(cmp/hash)`.\r\n\r\nOr is there something I\u2019m missing?\n> The subclassing use-case is still existent. I want to discourage it\u2019s use but I\u2019m not comfortable to take away the knob altogether.\r\n\r\nsubclassing is `cmp=False, hash=False` in your proposal, and `cmp=False` in my proposal, no?\r\n\r\n> Anyhow: can we agree, that adding `hash=None`, making it default, (and attending PyCon under a pseudonym) would fix the actual *bug* in attrs?\r\n\r\nYes, this would make it so that attrs never generates classes that break Python's rules without being explicitly asked to, because it's always legal to have `__hash__ = None`. The reason I prefer my proposal is that mine does that and also avoids boilerplate in the common cases, and also removes a bunch of options that don't make any sense (e.g. `cmp=False, hash=True`).\r\n\r\nConcretely, for the project I mentioned that has 26 calls to `@attr.s`:\r\n\r\nRight now, I have:\r\n\r\n* 13 `frozen=True`\r\n* 13 `cmp=False, hash=False`\r\n\r\nWith the `hash=None`-by-default approach, I'd have to change it to:\r\n* 13 `frozen=True, hash=True`\r\n* 13 `cmp=False, hash=False`\r\n\r\nWith my proposal, it becomes:\r\n* 13 `frozen=True`\r\n* 13 `cmp=False`\r\n\r\nI.e. on this codebase then the `hash=None`-by-default approach actually increases the necessary boilerplate, while my proposal removes it.\r\n\nYour proposal is pretty much my point 1 from above.\r\n\r\nTo my maintainer eyes things look like this:\r\n\r\n1. attrs does something wrong by default.  Nobody really cares about this stuff so I\u2019m gonna take the risk and fix it to do the right thing.\r\n2. It\u2019s annoying to create certain types of classes.  I\u2019m *very* much opposed to add implicit effects by setting one or another.  But I understand where you\u2018re coming from (and @glyph basically complained about the same thing).\r\n\r\nNow, I really want to tackle those things separately because they\u2019re separate to me.  One bug and one feature.  I\u2019ll open a PR later for 1 unless you convince me it\u2019s wrong but let\u2019s talk about 2 to give your mind some peace. :)\r\n\r\n***\r\n\r\nI\u2019m thinking to talk about \u201carchetypes\u201d (code name?)?\r\n\r\nHow does this look to you:\r\n\r\n```python\r\nfrom attr.archetypes import hashable\r\n\r\n@hashable\r\nclass Item:\r\n    \"\"\"Implies frozen=True, cmp=True, hash=True.\"\"\"\r\n```\r\n\r\nThe intent would be apparent from the name, not by squinting at the combination of parameters and figuring out side-effects that would vary by attrs release.\r\n\r\nI\u2019m open to other ways to achieve that.  Adding more arguments to `@attr.s` seams like the wrong way tho?  It\u2019s pretty crowded already.", "created_at": "2017-02-04T12:22:14Z"}
{"repo": "python-attrs/attrs", "pull_number": 60, "instance_id": "python-attrs__attrs-60", "issue_numbers": ["3"], "base_commit": "5a1814f8d07e00d47d7d81274e4b4ee10dd83d41", "patch": "diff --git a/src/attr/__init__.py b/src/attr/__init__.py\n--- a/src/attr/__init__.py\n+++ b/src/attr/__init__.py\n@@ -19,6 +19,7 @@\n     get_run_validators,\n     set_run_validators,\n )\n+from . import exceptions\n from . import filters\n from . import validators\n \n@@ -49,6 +50,7 @@\n     \"attrib\",\n     \"attributes\",\n     \"attrs\",\n+    \"exceptions\",\n     \"fields\",\n     \"filters\",\n     \"get_run_validators\",\ndiff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -3,8 +3,9 @@\n import hashlib\n import linecache\n \n-from ._compat import exec_, iteritems, isclass, iterkeys\n from . import _config\n+from ._compat import exec_, iteritems, isclass, iterkeys\n+from .exceptions import FrozenInstanceError\n \n \n class _Nothing(object):\n@@ -145,8 +146,16 @@ def _transform_attrs(cls, these):\n             had_default = True\n \n \n+def _frozen_setattrs(self, name, value):\n+    \"\"\"\n+    Attached to frozen classes as __setattr__.\n+    \"\"\"\n+    raise FrozenInstanceError()\n+\n+\n def attributes(maybe_cls=None, these=None, repr_ns=None,\n-               repr=True, cmp=True, hash=True, init=True, slots=False):\n+               repr=True, cmp=True, hash=True, init=True,\n+               slots=False, frozen=False):\n     \"\"\"\n     A class decorator that adds `dunder\n     <https://wiki.python.org/moin/DunderAlias>`_\\ -methods according to the\n@@ -161,33 +170,42 @@ def attributes(maybe_cls=None, these=None, repr_ns=None,\n         If *these* is not `None`, the class body is *ignored*.\n     :type these: :class:`dict` of :class:`str` to :func:`attr.ib`\n \n-    :param repr_ns: When using nested classes, there's no way in Python 2 to\n-        automatically detect that.  Therefore it's possible to set the\n+    :param str repr_ns: When using nested classes, there's no way in Python 2\n+        to automatically detect that.  Therefore it's possible to set the\n         namespace explicitly for a more meaningful ``repr`` output.\n-\n-    :param repr: Create a ``__repr__`` method with a human readable\n+    :param bool repr: Create a ``__repr__`` method with a human readable\n         represantation of ``attrs`` attributes..\n-    :type repr: bool\n-\n-    :param cmp: Create ``__eq__``, ``__ne__``, ``__lt__``, ``__le__``,\n+    :param bool cmp: Create ``__eq__``, ``__ne__``, ``__lt__``, ``__le__``,\n         ``__gt__``, and ``__ge__`` methods that compare the class as if it were\n         a tuple of its ``attrs`` attributes.  But the attributes are *only*\n         compared, if the type of both classes is *identical*!\n-    :type cmp: bool\n+    :param bool hash: Create a ``__hash__`` method that returns the\n+        :func:`hash` of a tuple of all ``attrs`` attribute values.\n+    :param bool init: Create a ``__init__`` method that initialiazes the\n+        ``attrs`` attributes.  Leading underscores are stripped for the\n+        argument name.\n+    :param bool slots: Create a slots_-style class that's more\n+        memory-efficient.  See :ref:`slots` for further ramifications.\n+    :param bool frozen: Make instances immutable after initialization.  If\n+        someone attempts to modify a frozen instance,\n+        :exc:`attr.exceptions.FrozenInstanceError` is raised.\n+\n+        Please note:\n \n-    :param hash: Create a ``__hash__`` method that returns the :func:`hash` of\n-        a tuple of all ``attrs`` attribute values.\n-    :type hash: bool\n+            1. This is achieved by installing a custom ``__setattr__`` method\n+               on your class so you can't implement an own one.\n \n-    :param init: Create a ``__init__`` method that initialiazes the ``attrs``\n-        attributes.  Leading underscores are stripped for the argument name.\n-    :type init: bool\n+            2. True immutability is impossible in Python.\n \n-    :param slots: Create a slots_-style class that's more memory-efficient.\n-        See :ref:`slots` for further ramifications.\n-    :type slots: bool\n+            3. This *does* have a minor a runtime performance impact when\n+               initializing new instances.  In other words: ``__init__`` is\n+               slightly slower with ``frozen=True``.\n \n-    .. _slots: https://docs.python.org/3.5/reference/datamodel.html#slots\n+        ..  _slots: https://docs.python.org/3.5/reference/datamodel.html#slots\n+\n+        ..  versionadded:: 16.0.0 *slots*\n+\n+        ..  versionadded:: 16.1.0 *frozen*\n     \"\"\"\n     def wrap(cls):\n         if getattr(cls, \"__class__\", None) is None:\n@@ -209,8 +227,10 @@ def wrap(cls):\n         if hash is True:\n             cls = _add_hash(cls)\n         if init is True:\n-            cls = _add_init(cls)\n-        if slots:\n+            cls = _add_init(cls, frozen)\n+        if frozen is True:\n+            cls.__setattr__ = _frozen_setattrs\n+        if slots is True:\n             cls_dict = dict(cls.__dict__)\n             cls_dict[\"__slots__\"] = tuple(ca_list)\n             for ca_name in ca_list:\n@@ -367,7 +387,10 @@ def repr_(self):\n     return cls\n \n \n-def _add_init(cls):\n+def _add_init(cls, frozen):\n+    \"\"\"\n+    Add a __init__ method to *cls*.  If *frozen* is True, make it immutable.\n+    \"\"\"\n     attrs = [a for a in cls.__attrs_attrs__\n              if a.init or a.default is not NOTHING]\n \n@@ -378,14 +401,21 @@ def _add_init(cls):\n         sha1.hexdigest()\n     )\n \n-    script = _attrs_to_script(attrs)\n+    script = _attrs_to_script(attrs, frozen)\n     locs = {}\n     bytecode = compile(script, unique_filename, \"exec\")\n     attr_dict = dict((a.name, a) for a in attrs)\n-    exec_(bytecode, {\"NOTHING\": NOTHING,\n-                     \"attr_dict\": attr_dict,\n-                     \"validate\": validate,\n-                     \"_convert\": _convert}, locs)\n+    globs = {\n+        \"NOTHING\": NOTHING,\n+        \"attr_dict\": attr_dict,\n+        \"validate\": validate,\n+        \"_convert\": _convert\n+    }\n+    if frozen is True:\n+        # Save the lookup overhead in __init__ if we need to circumvent\n+        # immutability.\n+        globs[\"_cached_setattr\"] = object.__setattr__\n+    exec_(bytecode, globs, locs)\n     init = locs[\"__init__\"]\n \n     # In order of debuggers like PDB being able to step through the code,\n@@ -450,11 +480,31 @@ def _convert(inst):\n             setattr(inst, a.name, a.convert(getattr(inst, a.name)))\n \n \n-def _attrs_to_script(attrs):\n+def _attrs_to_script(attrs, frozen):\n     \"\"\"\n     Return a valid Python script of an initializer for *attrs*.\n+\n+    If *frozen* is True, we cannot set the attributes directly so we use\n+    a cached ``object.__setattr__``.\n     \"\"\"\n     lines = []\n+    if frozen is True:\n+        lines.append(\n+            \"_setattr = _cached_setattr.__get__(self, self.__class__)\"\n+        )\n+\n+        def fmt_setter(attr_name, value):\n+            return \"_setattr('%(attr_name)s', %(value)s)\" % {\n+                \"attr_name\": attr_name,\n+                \"value\": value,\n+            }\n+    else:\n+        def fmt_setter(attr_name, value):\n+            return \"self.%(attr_name)s = %(value)s\" % {\n+                \"attr_name\": attr_name,\n+                \"value\": value,\n+            }\n+\n     args = []\n     has_validator = False\n     has_convert = False\n@@ -467,14 +517,16 @@ def _attrs_to_script(attrs):\n         arg_name = a.name.lstrip(\"_\")\n         if a.init is False:\n             if isinstance(a.default, Factory):\n-                lines.append(\"\"\"\\\n-self.{attr_name} = attr_dict[\"{attr_name}\"].default.factory()\"\"\".format(\n-                    attr_name=attr_name,\n+                lines.append(fmt_setter(\n+                    attr_name,\n+                    \"attr_dict['{attr_name}'].default.factory()\"\n+                    .format(attr_name=attr_name)\n                 ))\n             else:\n-                lines.append(\"\"\"\\\n-self.{attr_name} = attr_dict[\"{attr_name}\"].default\"\"\".format(\n-                    attr_name=attr_name,\n+                lines.append(fmt_setter(\n+                    attr_name,\n+                    \"attr_dict['{attr_name}'].default\"\n+                    .format(attr_name=attr_name)\n                 ))\n         elif a.default is not NOTHING and not isinstance(a.default, Factory):\n             args.append(\n@@ -483,26 +535,21 @@ def _attrs_to_script(attrs):\n                     attr_name=attr_name,\n                 )\n             )\n-            lines.append(\"self.{attr_name} = {arg_name}\".format(\n-                arg_name=arg_name,\n-                attr_name=attr_name,\n-            ))\n+            lines.append(fmt_setter(attr_name, arg_name))\n         elif a.default is not NOTHING and isinstance(a.default, Factory):\n             args.append(\"{arg_name}=NOTHING\".format(arg_name=arg_name))\n-            lines.extend(\"\"\"\\\n-if {arg_name} is not NOTHING:\n-    self.{attr_name} = {arg_name}\n-else:\n-    self.{attr_name} = attr_dict[\"{attr_name}\"].default.factory()\"\"\"\n-                         .format(attr_name=attr_name,\n-                                 arg_name=arg_name)\n-                         .split(\"\\n\"))\n+            lines.append(\"if {arg_name} is not NOTHING:\"\n+                         .format(arg_name=arg_name))\n+            lines.append(\"    \" + fmt_setter(attr_name, arg_name))\n+            lines.append(\"else:\")\n+            lines.append(\"    \" + fmt_setter(\n+                attr_name,\n+                \"attr_dict['{attr_name}'].default.factory()\"\n+                .format(attr_name=attr_name)\n+            ))\n         else:\n             args.append(arg_name)\n-            lines.append(\"self.{attr_name} = {arg_name}\".format(\n-                attr_name=attr_name,\n-                arg_name=arg_name,\n-            ))\n+            lines.append(fmt_setter(attr_name, arg_name))\n \n     if has_convert:\n         lines.append(\"_convert(self)\")\n@@ -511,10 +558,10 @@ def _attrs_to_script(attrs):\n \n     return \"\"\"\\\n def __init__(self, {args}):\n-    {setters}\n+    {lines}\n \"\"\".format(\n         args=\", \".join(args),\n-        setters=\"\\n    \".join(lines) if lines else \"pass\",\n+        lines=\"\\n    \".join(lines) if lines else \"pass\",\n     )\n \n \n@@ -544,7 +591,7 @@ def __init__(self, **kw):\n                     raise TypeError(\"Missing argument '{arg}'.\".format(arg=a))\n \n     def __setattr__(self, name, value):\n-        raise AttributeError(\"can't set attribute\")  # To mirror namedtuple.\n+        raise FrozenInstanceError()\n \n     @classmethod\n     def from_counting_attr(cls, name, ca):\ndiff --git a/src/attr/exceptions.py b/src/attr/exceptions.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/attr/exceptions.py\n@@ -0,0 +1,12 @@\n+from __future__ import absolute_import, division, print_function\n+\n+\n+class FrozenInstanceError(AttributeError):\n+    \"\"\"\n+    A frozen/immutable instance has been attempted to be modified.\n+\n+    It mirrors the behavior of ``namedtuples`` by using the same error message\n+    and subclassing :exc:`AttributeError``.\n+    \"\"\"\n+    msg = \"can't set attribute\"\n+    args = [msg]\n", "test_patch": "diff --git a/tests/test_dark_magic.py b/tests/test_dark_magic.py\n--- a/tests/test_dark_magic.py\n+++ b/tests/test_dark_magic.py\n@@ -8,6 +8,7 @@\n \n from attr._compat import TYPE\n from attr._make import Attribute, NOTHING\n+from attr.exceptions import FrozenInstanceError\n \n \n @attr.s\n@@ -62,6 +63,11 @@ class SubSlots(SuperSlots):\n     y = attr.ib()\n \n \n+@attr.s(frozen=True, slots=True)\n+class Frozen(object):\n+    x = attr.ib()\n+\n+\n class TestDarkMagic(object):\n     \"\"\"\n     Integration tests.\n@@ -114,12 +120,12 @@ class C3(object):\n \n         assert \"C3(_x=1)\" == repr(C3(x=1))\n \n-    @given(booleans())\n-    def test_programmatic(self, slots):\n+    @given(booleans(), booleans())\n+    def test_programmatic(self, slots, frozen):\n         \"\"\"\n         `attr.make_class` works.\n         \"\"\"\n-        PC = attr.make_class(\"PC\", [\"a\", \"b\"], slots=slots)\n+        PC = attr.make_class(\"PC\", [\"a\", \"b\"], slots=slots, frozen=frozen)\n         assert (\n             Attribute(name=\"a\", default=NOTHING, validator=None,\n                       repr=True, cmp=True, hash=True, init=True),\n@@ -155,3 +161,19 @@ class Sub2(base):\n         i = Sub2(x=obj)\n         assert i.x is i.meth() is obj\n         assert \"Sub2(x={obj})\".format(obj=obj) == repr(i)\n+\n+    @pytest.mark.parametrize(\"frozen_class\", [\n+        Frozen,  # has slots=True\n+        attr.make_class(\"FrozenToo\", [\"x\"], slots=False, frozen=True),\n+    ])\n+    def test_frozen_instance(self, frozen_class):\n+        \"\"\"\n+        Frozen instances can't be modified (easily).\n+        \"\"\"\n+        frozen = frozen_class(1)\n+\n+        with pytest.raises(FrozenInstanceError) as e:\n+            frozen.x = 2\n+\n+        assert e.value.args[0] == \"can't set attribute\"\n+        assert 1 == frozen.x\ndiff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -35,7 +35,7 @@\n class InitC(object):\n     __attrs_attrs__ = [simple_attr(\"a\"), simple_attr(\"b\")]\n \n-InitC = _add_init(InitC)\n+InitC = _add_init(InitC, False)\n \n \n class TestAddCmp(object):\n@@ -219,12 +219,13 @@ class TestAddInit(object):\n     \"\"\"\n     Tests for `_add_init`.\n     \"\"\"\n-    @given(booleans())\n-    def test_init(self, slots):\n+    @given(booleans(), booleans())\n+    def test_init(self, slots, frozen):\n         \"\"\"\n         If `init` is False, ignore that attribute.\n         \"\"\"\n-        C = make_class(\"C\", {\"a\": attr(init=False), \"b\": attr()}, slots=slots)\n+        C = make_class(\"C\", {\"a\": attr(init=False), \"b\": attr()},\n+                       slots=slots, frozen=frozen)\n         with pytest.raises(TypeError) as e:\n             C(a=1, b=2)\n \n@@ -233,8 +234,8 @@ def test_init(self, slots):\n             e.value.args[0]\n         )\n \n-    @given(booleans())\n-    def test_no_init_default(self, slots):\n+    @given(booleans(), booleans())\n+    def test_no_init_default(self, slots, frozen):\n         \"\"\"\n         If `init` is False but a Factory is specified, don't allow passing that\n         argument but initialize it anyway.\n@@ -243,7 +244,7 @@ def test_no_init_default(self, slots):\n             \"_a\": attr(init=False, default=42),\n             \"_b\": attr(init=False, default=Factory(list)),\n             \"c\": attr()\n-        }, slots=slots)\n+        }, slots=slots, frozen=frozen)\n         with pytest.raises(TypeError):\n             C(a=1, c=2)\n         with pytest.raises(TypeError):\n@@ -252,8 +253,8 @@ def test_no_init_default(self, slots):\n         i = C(23)\n         assert (42, [], 23) == (i._a, i._b, i.c)\n \n-    @given(booleans())\n-    def test_no_init_order(self, slots):\n+    @given(booleans(), booleans())\n+    def test_no_init_order(self, slots, frozen):\n         \"\"\"\n         If an attribute is `init=False`, it's legal to come after a mandatory\n         attribute.\n@@ -261,7 +262,7 @@ def test_no_init_order(self, slots):\n         make_class(\"C\", {\n             \"a\": attr(default=Factory(list)),\n             \"b\": attr(init=False),\n-        }, slots=slots)\n+        }, slots=slots, frozen=frozen)\n \n     def test_sets_attributes(self):\n         \"\"\"\n@@ -282,7 +283,7 @@ class C(object):\n                 simple_attr(name=\"c\", default=None),\n             ]\n \n-        C = _add_init(C)\n+        C = _add_init(C, False)\n         i = C()\n         assert 2 == i.a\n         assert \"hallo\" == i.b\n@@ -300,7 +301,7 @@ class C(object):\n                 simple_attr(name=\"a\", default=Factory(list)),\n                 simple_attr(name=\"b\", default=Factory(D)),\n             ]\n-        C = _add_init(C)\n+        C = _add_init(C, False)\n         i = C()\n         assert [] == i.a\n         assert isinstance(i.b, D)\n@@ -363,7 +364,7 @@ def test_underscores(self):\n         class C(object):\n             __attrs_attrs__ = [simple_attr(\"_private\")]\n \n-        C = _add_init(C)\n+        C = _add_init(C, False)\n         i = C(private=42)\n         assert 42 == i._private\n \n", "problem_statement": "clean division between \"value\" and \"object\"\nObjects, as in object-oriented programming, are side-effecty, mutable state, whose methods ought to represent I/O.\n\nValues, as in functional programming, are immutable data, whose methods ought to represent computation.\n\nPython does not have as good a division between these very different sorts of beasts as it should, but it does have one critical distinction: the `__hash__` method.\n\n`characteristic` has this issue which crops up occasionally where you end up with objects that you can't put into a dictionary as a key, because one of its attributes is a dictionary.  Sometimes people expect to be able to do this because `characteristic` makes so many other things easy, and just expect dictionaries to suddenly be immutable; sometimes people expect hash-by-identity.\n\nI propose that attr provide a way to specifically create two types of objects with a distinct interface; one that creates a \"value\" and one that creates an \"object\", so that users can see issues around mutability far earlier in the process.\n\nSo, for example, the \"object\" type would:\n- not provide `__hash__` by default, provide an `__eq__` that does structural equality, and `__gt__`/`__lt__` that just raise exceptions\n- if asked, provide an identity-based `__hash__`, but then also switch to an identity-based `__eq__`\n\nand the 'value\" type would\n- call `hash()` on all of its arguments at construction time so it would fail immediately if it contained a mutable type\n- fail immediately at class-definition time if any validator is mutable\n- provide immutable descriptors for all its attributes\n\n", "hints_text": "How would that look API-wise?  Would something like `@attr.object` or `@attr.value` be presets for `@attr.s`?\n\nI'm not sure.  I'm trying to decide what I think the default for `attr.s` is; there's a strong case in my mind for both default-to-mutable or default-to-immutable.  `attr.s(mutable=True)`?\n\nThe default should be what most people (and I!) would expect it to do.  We\u2019re still on Python and don\u2019t have free COW structures etc.  Therefore any immutability gimmickry ought to be opt-in (but in place and simple to use).\n\nI think you're right; Python programmers are going to expect mutability by default, trying to turn that off would just be an ideological statement, not useful functionality.  So how about just having a `__hash__` that raises an exception which points you at `attr.value`, and `attr.s` is `object`?\n\nHi, I found this ticket because I was looking for an `immutable` argument to `@attr.s` like there was with characteristic :)\n\nALSO: on the subject of \"value types\", I would like to point out my new library [sumtypes](https://pypi.python.org/pypi/sumtypes) (honestly I didn't come here looking for a place to advertise, but it seems relevant). `immutable` would be great to have for it too (and I probably _would_ make it the default in that library).\n\nI\u2019m reluctant to implement immutable myself because it adds another method I have to highly invasively muck with (`__setattr__`).\n\n_But_ `attrs` [is extensible](https://attrs.readthedocs.org/en/stable/extending.html), so feel free to implement it yourself!\n\n@hynek I guess there's two separate aspects of immutability: making sure declared attributes are immutable, and making sure new attributes can't be dynamically assigned to. \n\nNeither of these actually require defining `__setattr__`. The former can be accomplished with the descriptor protocol, and the latter can be accomplished with `__slots__`. \n\nI assumed Attribute must have already implemented the descriptor protocol, but I see now I'm wrong, and, for example, mutating an attribute post-instantiation will allow setting it to a value that a validator wouldn't accept, because validators are not run on mutation. So maybe it would be best if Attribute instances do provide the descriptor protocol, both to support validating mutation as well as implementing immutability if it's requested?\n\nI kinda want to recommend setting up a performance test suite at this point, because while it seems to me like using the descriptor protocol _ought_ to be zero-cost on PyPy and \"fast enough\" on CPython, it also seems like it would be worth knowing that for sure.\n\n(Although I also assumed that attrs would validate on mutation and this is a slightly unpleasant surprise.  Hmm.)\n\nattrs had validation on mutation once but there were so many loopholes that I decided to take it out because the performance hit for _everyone_ simply wasn\u2019t worth it.\n\nI\u2019m pretty sure that using descriptors is measurably slower.  I\u2019ll happily be proven wrong with a benchmark. :)\n\nWhat do you mean \"so many loopholes\"?  Other than `__dict__.__setitem__` and `object.__setattr__` what else is there?\n\n@glyph well, there's also other methods on `__dict__` than `__setitem__`, so generalize that to \"`__dict__` mutation\"\n\nPersonally I think it's worth doing validation with the descriptor protocol even though someone could bypass with `__dict__` mutation. However! It would also be possible to make naive dict mutation ineffective, since Python always consults a descriptor before a `__dict__` entry. It might have other downsides, but you could have the descriptors store their actual data under a different name in the instance dict, so at least someone would really know they're bypassing validation when they're assigning something to `__dict__['__attrs_x']`.\n\nBut... yeah, that might be a bit too surprising/weird for people who do want to dig down into the representation. I mean, Pickling would still work just fine, but maybe there are some useful things that would break?\n\nAlso, as a follow-up to my previous mention of `__slots__`, I've hit a snag there: apparently the way `__slots__` works is by creating descriptors on the class. Which means you can't use your _own_ descriptors (or even non-descriptors -- you can't even use class variables to declare defaults for instances, for example). The result of trying to add `__slots__` to a `@attrib.s`-using class is this:\n\n```\n>>> @attr.s\n... class Foo(object):\n...  __slots__ = ('x', 'y')\n...  x = attr.ib()\n...  y = attr.ib()\n...\n>>> Foo(1, 2)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<attrs generated init a7439b12cdcdd2d603c04767f9a798adb8a0d944>\", line 2, in __init__\nAttributeError: 'Foo' object attribute 'x' is read-only\n```\n\nThere may be some clever trick I'm missing to still use `__slots__` (which actually would be nice to use on CPython if we could...), but I'm thinking @hynek is right and the only way to implement immutability would be by defining a `__setattr__` :-(\n\nOh, never mind. There is a way to use both slots and descriptors:\n\nhttp://stackoverflow.com/questions/4912499/using-python-descriptors-with-slots\n\nIt's just a matter of having the user's descriptor be named different from the slot.\n\nmost obvious loophole:  `instance.attribute.do_something_that_mutates_instance()`.\n\nI don\u2019t want to sound like an ass but adding features that are invasive but only interesting to a small fraction of people made `characteristic` what it is so I\u2019m much more conservative this time and rather made it extensible than implementing everything ppl shout at me.\n\nI\u2019m open to descriptor-based solutions that have no negative impact on performance though.\n\nMutability doesn't seem like a particularly obscure or minority concern :).\n\nThat said, I'm not sure what you're objecting to.  Doing validation on attributes by default?  Doing validation on attributes at all?  Or the actual topic of this bug, `@attr.value`, which would not be on by default anyway?\n\nEcho chamber. :)\n\nI\u2019m objecting the tangent of validating on assignment.  I don\u2019t object immutability but I feel it should be a separate decorator.  Maybe `@attr.value`? :)\n\nOK good. Let's have another issue to discuss that.\n\nFor the case of `@attr.value` specifically, we could just override `__setattr__` to raise `AttributeError` after initialization. Does that seem sufficient?\n\nYou mentioned not wanting to do it yourself, but nothing _except_ `value` would need to mess with it.\n\nJust to be clear: my main issue is not being lazy but wanting to keep attrs clean. :)  Moving settattr magic into a separate decorator seems a fair compromise to me.\n\nCool, thank you, I asked the question very awkwardly but that was exactly the form of answer I wanted :).\n\nSee also #50 ?\n", "created_at": "2016-08-16T14:35:17Z"}
