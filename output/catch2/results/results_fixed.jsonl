{"repo":"catchorg/Catch2","pull_number":2128,"instance_id":"catchorg__Catch2-2128","issue_numbers":["2121"],"base_commit":"65c9a1d31a338f28ef93cd61c475efc40f6cc42e","patch":"diff --git a/src/catch2/internal/catch_decomposer.hpp b/src/catch2/internal/catch_decomposer.hpp\n--- a/src/catch2/internal/catch_decomposer.hpp\n+++ b/src/catch2/internal/catch_decomposer.hpp\n@@ -183,60 +183,53 @@ namespace Catch {\n     public:\n         explicit ExprLhs( LhsT lhs ) : m_lhs( lhs ) {}\n \n-        template<typename RhsT>\n-        auto operator == ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { compareEqual( m_lhs, rhs ), m_lhs, \"==\"_sr, rhs };\n+        template<typename RhsT, std::enable_if_t<!std::is_arithmetic<std::remove_reference_t<RhsT>>::value, int> = 0>\n+        friend auto operator == ( ExprLhs && lhs, RhsT && rhs ) -> BinaryExpr<LhsT, RhsT const&> {\n+            return { compareEqual( lhs.m_lhs, rhs ), lhs.m_lhs, \"==\"_sr, rhs };\n         }\n-        auto operator == ( bool rhs ) -> BinaryExpr<LhsT, bool> const {\n-            return { m_lhs == rhs, m_lhs, \"==\"_sr, rhs };\n+        template<typename RhsT, std::enable_if_t<std::is_arithmetic<RhsT>::value, int> = 0>\n+        friend auto operator == ( ExprLhs && lhs, RhsT rhs ) -> BinaryExpr<LhsT, RhsT> {\n+            return { compareEqual( lhs.m_lhs, rhs ), lhs.m_lhs, \"==\"_sr, rhs };\n         }\n \n-        template<typename RhsT>\n-        auto operator != ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { compareNotEqual( m_lhs, rhs ), m_lhs, \"!=\"_sr, rhs };\n+        template<typename RhsT, std::enable_if_t<!std::is_arithmetic<std::remove_reference_t<RhsT>>::value, int> = 0>\n+        friend auto operator != ( ExprLhs && lhs, RhsT && rhs ) -> BinaryExpr<LhsT, RhsT const&> {\n+            return { compareNotEqual( lhs.m_lhs, rhs ), lhs.m_lhs, \"!=\"_sr, rhs };\n         }\n-        auto operator != ( bool rhs ) -> BinaryExpr<LhsT, bool> const {\n-            return { m_lhs != rhs, m_lhs, \"!=\"_sr, rhs };\n+        template<typename RhsT, std::enable_if_t<std::is_arithmetic<RhsT>::value, int> = 0>\n+        friend auto operator != ( ExprLhs && lhs, RhsT rhs ) -> BinaryExpr<LhsT, RhsT> {\n+            return { compareNotEqual( lhs.m_lhs, rhs ), lhs.m_lhs, \"!=\"_sr, rhs };\n         }\n \n-        template<typename RhsT>\n-        auto operator > ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs > rhs), m_lhs, \">\"_sr, rhs };\n-        }\n-        template<typename RhsT>\n-        auto operator < ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs < rhs), m_lhs, \"<\"_sr, rhs };\n-        }\n-        template<typename RhsT>\n-        auto operator >= ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs >= rhs), m_lhs, \">=\"_sr, rhs };\n-        }\n-        template<typename RhsT>\n-        auto operator <= ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs <= rhs), m_lhs, \"<=\"_sr, rhs };\n-        }\n-        template <typename RhsT>\n-        auto operator | (RhsT const& rhs) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs | rhs), m_lhs, \"|\"_sr, rhs };\n-        }\n-        template <typename RhsT>\n-        auto operator & (RhsT const& rhs) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs & rhs), m_lhs, \"&\"_sr, rhs };\n-        }\n-        template <typename RhsT>\n-        auto operator ^ (RhsT const& rhs) -> BinaryExpr<LhsT, RhsT const&> const {\n-            return { static_cast<bool>(m_lhs ^ rhs), m_lhs, \"^\"_sr, rhs };\n+    #define CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(op) \\\n+        template<typename RhsT, std::enable_if_t<!std::is_arithmetic<std::remove_reference_t<RhsT>>::value, int> = 0> \\\n+        friend auto operator op ( ExprLhs && lhs, RhsT && rhs ) -> BinaryExpr<LhsT, RhsT const&> { \\\n+            return { static_cast<bool>(lhs.m_lhs op rhs), lhs.m_lhs, #op##_sr, rhs }; \\\n+        } \\\n+        template<typename RhsT, std::enable_if_t<std::is_arithmetic<RhsT>::value, int> = 0> \\\n+        friend auto operator op ( ExprLhs && lhs, RhsT rhs ) -> BinaryExpr<LhsT, RhsT> { \\\n+            return { static_cast<bool>(lhs.m_lhs op rhs), lhs.m_lhs, #op##_sr, rhs }; \\\n         }\n \n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(<)\n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(>)\n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(<=)\n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(>=)\n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(|)\n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(&)\n+        CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR(^)\n+\n+    #undef CATCH_INTERNAL_DEFINE_EXPRESSION_OPERATOR\n+\n         template<typename RhsT>\n-        auto operator && ( RhsT const& ) -> BinaryExpr<LhsT, RhsT const&> const {\n+        friend auto operator && ( ExprLhs &&, RhsT && ) -> BinaryExpr<LhsT, RhsT const&> {\n             static_assert(always_false<RhsT>::value,\n             \"operator&& is not supported inside assertions, \"\n             \"wrap the expression inside parentheses, or decompose it\");\n         }\n \n         template<typename RhsT>\n-        auto operator || ( RhsT const& ) -> BinaryExpr<LhsT, RhsT const&> const {\n+        friend auto operator || ( ExprLhs &&, RhsT && ) -> BinaryExpr<LhsT, RhsT const&> {\n             static_assert(always_false<RhsT>::value,\n             \"operator|| is not supported inside assertions, \"\n             \"wrap the expression inside parentheses, or decompose it\");\n@@ -247,21 +240,15 @@ namespace Catch {\n         }\n     };\n \n-    void handleExpression( ITransientExpression const& expr );\n-\n-    template<typename T>\n-    void handleExpression( ExprLhs<T> const& expr ) {\n-        handleExpression( expr.makeUnaryExpr() );\n-    }\n-\n     struct Decomposer {\n-        template<typename T>\n-        auto operator <= ( T const& lhs ) -> ExprLhs<T const&> {\n-            return ExprLhs<T const&>{ lhs };\n+        template<typename T, std::enable_if_t<!std::is_arithmetic<std::remove_reference_t<T>>::value, int> = 0>\n+        friend auto operator <= ( Decomposer &&, T && lhs ) -> ExprLhs<T const&> {\n+            return ExprLhs<const T&>{ lhs };\n         }\n \n-        auto operator <=( bool value ) -> ExprLhs<bool> {\n-            return ExprLhs<bool>{ value };\n+        template<typename T, std::enable_if_t<std::is_arithmetic<T>::value, int> = 0>\n+        friend auto operator <= ( Decomposer &&, T value ) -> ExprLhs<T> {\n+            return ExprLhs<T>{ value };\n         }\n     };\n \n","test_patch":"diff --git a/tests/SelfTest/UsageTests/Compilation.tests.cpp b/tests/SelfTest/UsageTests/Compilation.tests.cpp\n--- a/tests/SelfTest/UsageTests/Compilation.tests.cpp\n+++ b/tests/SelfTest/UsageTests/Compilation.tests.cpp\n@@ -277,3 +277,42 @@ namespace {\n TEST_CASE(\"Immovable types are supported in basic assertions\", \"[compilation][.approvals]\") {\n     REQUIRE(ImmovableType{} == ImmovableType{});\n }\n+\n+namespace adl {\n+\n+struct always_true {\n+    explicit operator bool() const { return true; }\n+};\n+\n+#define COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(op) \\\n+template <class T, class U> \\\n+auto operator op (T&&, U&&) { \\\n+    return always_true{}; \\\n+}\n+\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(==)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(!=)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(<)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(>)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(<=)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(>=)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(|)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(&)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(^)\n+\n+#undef COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR\n+\n+}\n+\n+TEST_CASE(\"ADL universal operators don't hijack expression deconstruction\", \"[compilation][.approvals]\") {\n+    REQUIRE(adl::always_true{});\n+    REQUIRE(0 == adl::always_true{});\n+    REQUIRE(0 != adl::always_true{});\n+    REQUIRE(0 < adl::always_true{});\n+    REQUIRE(0 > adl::always_true{});\n+    REQUIRE(0 <= adl::always_true{});\n+    REQUIRE(0 >= adl::always_true{});\n+    REQUIRE(0 | adl::always_true{});\n+    REQUIRE(0 & adl::always_true{});\n+    REQUIRE(0 ^ adl::always_true{});\n+}\n","problem_statement":"Problem with user provided operator == (with proposed fix)\n**Describe the bug**\r\nThe test doesn't compile when the user provides a more general `operator ==` overload than `ExprLhs`.\r\n`operator ==` in the code sample below is a better match when r-value reference is passed because it accepts forwarding reference (`U&&`) and `ExprLhs` accepts only const reference (`RhsT const& rhs`) https://github.com/catchorg/Catch2/blob/devel/src/catch2/internal/catch_decomposer.hpp#L187\r\n```\r\n        template<typename RhsT>\r\n        auto operator == ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\r\n            return { compareEqual( m_lhs, rhs ), m_lhs, \"==\"_sr, rhs };\r\n        }\r\n```\r\n\r\n**Expected behavior**\r\nThe test should compile.\r\n\r\n**Reproduction steps**\r\n```\r\nnamespace adl {\r\n\r\nstruct activate_adl {};\r\n\r\nstruct equality_expression {\r\n    operator bool() const { return true; }\r\n};\r\n\r\ntemplate <class T, class U>\r\nconstexpr auto operator == (T&&, U&&) {\r\n    return equality_expression{};\r\n}\r\n\r\n}\r\n\r\nTEST_CASE(\"User provided equality operator\", \"[compilation]\") {\r\n    REQUIRE(0 == adl::activate_adl{});\r\n}\r\n```\r\nerror: no matching member function for call to 'handleExpr' REQUIRE(0 == adl::activate_adl{});\r\n\r\n**Fix**\r\nMy first attempt was to change the `operator == ` definition (and similarly all other operators) to\r\n```\r\n        template<typename RhsT>\r\n        auto operator == ( RhsT && rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\r\n            return { compareEqual( m_lhs, rhs ), m_lhs, \"==\"_sr, rhs };\r\n        }\r\n```\r\nHowever, this broke a test for bitfields\r\nerror: non-const reference cannot bind to bit-field 'v' REQUIRE(0 == y.v);\r\n\r\nThis can be resolved by two not so clean overloads, maybe you know a better way:\r\n```\r\n        template<typename RhsT>\r\n        auto operator == ( RhsT const& rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\r\n            return { compareEqual( m_lhs, rhs ), m_lhs, \"==\"_sr, rhs };\r\n        }\r\n        template<typename RhsT, std::enable_if_t<!std::is_arithmetic<std::decay_t<RhsT>>::value, int> = 0>\r\n        auto operator == ( RhsT && rhs ) -> BinaryExpr<LhsT, RhsT const&> const {\r\n            return { compareEqual( m_lhs, rhs ), m_lhs, \"==\"_sr, rhs };\r\n        }\r\n```\r\n\r\n**Unrelated note**\r\nI don't think const reference here prolongs the lifetime of rhs, because it's not local but stored in a class: `BinaryExpr<LhsT, RhsT const&>`. Not sure if it's a problem.\n","hints_text":"","created_at":"2020-12-20T00:12:15Z","version":"3.0","dockerfile":"# Base image specification. Defines the foundation OS and architecture for the container\nFROM ubuntu:20.04\nARG DEBIAN_FRONTEND=noninteractive\nENV TZ=Etc/UTC\n\n# System dependencies installation. Installs essential tools and libraries required for development and runtime\nRUN apt update && apt install -y \\\n    build-essential \\\n    cmake \\\n    python3 \\\n    git \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set default working directory for the repository.\nWORKDIR /testbed/\n\n# Target Project setup. Clones source code, checks out to the target version.\nRUN git clone https://github.com/catchorg/Catch2 /testbed \\\n    && cd /testbed \\\n    && git reset --hard 65c9a1d31a338f28ef93cd61c475efc40f6cc42e \\\n    && git remote remove origin \\\n    && chmod -R 777 /testbed\n\n# Build steps: Generate amalgamated files, configure CMake, and build the project including tests.\n# These steps are necessary to prepare the environment for test execution.\nRUN /bin/bash -c \" \\\n    cd /testbed && \\\n    python3 ./tools/scripts/generateAmalgamatedFiles.py && \\\n    mkdir Build && \\\n    cd Build && \\\n    cmake -H.. -DCMAKE_BUILD_TYPE=Debug -DCATCH_DEVELOPMENT_BUILD=ON -DCATCH_BUILD_TESTING=ON -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_STANDARD_REQUIRED=On -DCMAKE_CXX_EXTENSIONS=OFF && \\\n    make -j $(nproc)\"","eval_script":"#!/bin/bash\nset -uxo pipefail\n\n# Ensure we are in the /testbed directory\ncd /testbed\n\n# Define the target commit SHA and the specific test file to be managed.\n# This ensures that even if the file was modified locally or by a previous run,\n# it is reset to its state at the target commit before applying any patch.\nCOMMIT_SHA=\"65c9a1d31a338f28ef93cd61c475efc40f6cc42e\"\nTARGET_TEST_FILE=\"tests/SelfTest/UsageTests/Compilation.tests.cpp\"\n\necho \"Resetting $TARGET_TEST_FILE to its state at commit $COMMIT_SHA...\"\ngit checkout \"$COMMIT_SHA\" \"$TARGET_TEST_FILE\" || { echo \"Failed to checkout $TARGET_TEST_FILE. Aborting.\"; exit 1; }\n\n# Apply the test patch if provided. The content of the patch is inserted here\n# programmatically by the evaluation system.\necho \"Attempting to apply test patch...\"\ngit apply -v - <<'EOF_114329324912'\ndiff --git a/tests/SelfTest/UsageTests/Compilation.tests.cpp b/tests/SelfTest/UsageTests/Compilation.tests.cpp\n--- a/tests/SelfTest/UsageTests/Compilation.tests.cpp\n+++ b/tests/SelfTest/UsageTests/Compilation.tests.cpp\n@@ -277,3 +277,42 @@ namespace {\n TEST_CASE(\"Immovable types are supported in basic assertions\", \"[compilation][.approvals]\") {\n     REQUIRE(ImmovableType{} == ImmovableType{});\n }\n+\n+namespace adl {\n+\n+struct always_true {\n+    explicit operator bool() const { return true; }\n+};\n+\n+#define COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(op) \\\n+template <class T, class U> \\\n+auto operator op (T&&, U&&) { \\\n+    return always_true{}; \\\n+}\n+\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(==)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(!=)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(<)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(>)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(<=)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(>=)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(|)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(&)\n+COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR(^)\n+\n+#undef COMPILATION_TEST_DEFINE_UNIVERSAL_OPERATOR\n+\n+}\n+\n+TEST_CASE(\"ADL universal operators don't hijack expression deconstruction\", \"[compilation][.approvals]\") {\n+    REQUIRE(adl::always_true{});\n+    REQUIRE(0 == adl::always_true{});\n+    REQUIRE(0 != adl::always_true{});\n+    REQUIRE(0 < adl::always_true{});\n+    REQUIRE(0 > adl::always_true{});\n+    REQUIRE(0 <= adl::always_true{});\n+    REQUIRE(0 >= adl::always_true{});\n+    REQUIRE(0 | adl::always_true{});\n+    REQUIRE(0 & adl::always_true{});\n+    REQUIRE(0 ^ adl::always_true{});\n+}\nEOF_114329324912\n\n# Navigate to the 'Build' directory, where the CMake-generated executables and tests reside.\n# The Dockerfile has already performed the build steps, including creating and populating 'Build'.\necho \"Navigating to /testbed/Build directory for test execution...\"\ncd /testbed/Build || { echo \"Error: 'Build' directory not found at /testbed/Build. Ensure build steps completed in Dockerfile.\"; exit 1; }\n\n# IMPORTANT: Recompile the project after applying the patch to incorporate changes.\n# This ensures that any modifications made by the patch to source files (like tests/SelfTest/UsageTests/Compilation.tests.cpp)\n# are compiled into the test executables, making the new/modified tests discoverable.\necho \"Recompiling project after patch application to integrate changes...\"\nmake -j $(nproc) || { echo \"Error: Failed to recompile project. Aborting.\"; exit 1; }\n\n# Execute the specific Catch2 self-test executable directly.\n# The previous attempt with `ctest -R \"Catch2_SelfTest\"` failed to find tests,\n# indicating that direct execution of the binary is required for these tests.\n# The executable for self-tests is located at `./tests/SelfTest` relative to the Build directory.\necho \"Directly executing Catch2 SelfTest executable: ./tests/SelfTest\"\n./tests/SelfTest\nrc=$? # Capture the exit code of the executable immediately\n\n# Output the captured exit code. This is crucial for the judging system.\necho \"OMNIGRIL_EXIT_CODE=$rc\"\n\n# Navigate back to the /testbed directory for cleanup.\necho \"Navigating back to /testbed for cleanup operations...\"\ncd /testbed || { echo \"Failed to navigate back to /testbed. Cleanup skipped.\"; exit $rc; }\n\n# Clean up: Reset the target test file to its original state from the repository.\n# This ensures a clean state for any subsequent operations or for future runs.\necho \"Resetting $TARGET_TEST_FILE after test run...\"\ngit checkout \"$COMMIT_SHA\" \"$TARGET_TEST_FILE\" || { echo \"Failed to reset $TARGET_TEST_FILE. Manual intervention might be required.\"; }\n\n# Exit with the captured test result code.\nexit $rc","eval_script_skeleton":"#!/bin/bash\nset -uxo pipefail\n\n# Ensure we are in the /testbed directory\ncd /testbed\n\n# Define the target commit SHA and the specific test file to be managed.\n# This ensures that even if the file was modified locally or by a previous run,\n# it is reset to its state at the target commit before applying any patch.\nCOMMIT_SHA=\"65c9a1d31a338f28ef93cd61c475efc40f6cc42e\"\nTARGET_TEST_FILE=\"tests/SelfTest/UsageTests/Compilation.tests.cpp\"\n\necho \"Resetting $TARGET_TEST_FILE to its state at commit $COMMIT_SHA...\"\ngit checkout \"$COMMIT_SHA\" \"$TARGET_TEST_FILE\" || { echo \"Failed to checkout $TARGET_TEST_FILE. Aborting.\"; exit 1; }\n\n# Apply the test patch if provided. The content of the patch is inserted here\n# programmatically by the evaluation system.\necho \"Attempting to apply test patch...\"\ngit apply -v - <<'EOF_114329324912'\n[CONTENT OF TEST PATCH]\nEOF_114329324912\n\n# Navigate to the 'Build' directory, where the CMake-generated executables and tests reside.\n# The Dockerfile has already performed the build steps, including creating and populating 'Build'.\necho \"Navigating to /testbed/Build directory for test execution...\"\ncd /testbed/Build || { echo \"Error: 'Build' directory not found at /testbed/Build. Ensure build steps completed in Dockerfile.\"; exit 1; }\n\n# IMPORTANT: Recompile the project after applying the patch to incorporate changes.\n# This ensures that any modifications made by the patch to source files (like tests/SelfTest/UsageTests/Compilation.tests.cpp)\n# are compiled into the test executables, making the new/modified tests discoverable.\necho \"Recompiling project after patch application to integrate changes...\"\nmake -j $(nproc) || { echo \"Error: Failed to recompile project. Aborting.\"; exit 1; }\n\n# Execute the specific Catch2 self-test executable directly.\n# The previous attempt with `ctest -R \"Catch2_SelfTest\"` failed to find tests,\n# indicating that direct execution of the binary is required for these tests.\n# The executable for self-tests is located at `./tests/SelfTest` relative to the Build directory.\necho \"Directly executing Catch2 SelfTest executable: ./tests/SelfTest\"\n./tests/SelfTest\nrc=$? # Capture the exit code of the executable immediately\n\n# Output the captured exit code. This is crucial for the judging system.\necho \"OMNIGRIL_EXIT_CODE=$rc\"\n\n# Navigate back to the /testbed directory for cleanup.\necho \"Navigating back to /testbed for cleanup operations...\"\ncd /testbed || { echo \"Failed to navigate back to /testbed. Cleanup skipped.\"; exit $rc; }\n\n# Clean up: Reset the target test file to its original state from the repository.\n# This ensures a clean state for any subsequent operations or for future runs.\necho \"Resetting $TARGET_TEST_FILE after test run...\"\ngit checkout \"$COMMIT_SHA\" \"$TARGET_TEST_FILE\" || { echo \"Failed to reset $TARGET_TEST_FILE. Manual intervention might be required.\"; }\n\n# Exit with the captured test result code.\nexit $rc"}
{"repo":"catchorg/Catch2","pull_number":2360,"instance_id":"catchorg__Catch2-2360","issue_numbers":["395"],"base_commit":"52066dbc2a53f4c3ab2a418d03f93200a8245451","patch":"diff --git a/src/catch2/catch_session.cpp b/src/catch2/catch_session.cpp\n--- a/src/catch2/catch_session.cpp\n+++ b/src/catch2/catch_session.cpp\n@@ -341,6 +341,12 @@ namespace Catch {\n                 return 2;\n             }\n \n+            if ( totals.testCases.total() > 0 &&\n+                 totals.testCases.total() == totals.testCases.skipped\n+                && !m_config->zeroTestsCountAsSuccess() ) {\n+                return 4;\n+            }\n+\n             // Note that on unices only the lower 8 bits are usually used, clamping\n             // the return value to 255 prevents false negative when some multiple\n             // of 256 tests has failed\ndiff --git a/src/catch2/catch_totals.cpp b/src/catch2/catch_totals.cpp\n--- a/src/catch2/catch_totals.cpp\n+++ b/src/catch2/catch_totals.cpp\n@@ -14,6 +14,7 @@ namespace Catch {\n         diff.passed = passed - other.passed;\n         diff.failed = failed - other.failed;\n         diff.failedButOk = failedButOk - other.failedButOk;\n+        diff.skipped = skipped - other.skipped;\n         return diff;\n     }\n \n@@ -21,14 +22,15 @@ namespace Catch {\n         passed += other.passed;\n         failed += other.failed;\n         failedButOk += other.failedButOk;\n+        skipped += other.skipped;\n         return *this;\n     }\n \n     std::uint64_t Counts::total() const {\n-        return passed + failed + failedButOk;\n+        return passed + failed + failedButOk + skipped;\n     }\n     bool Counts::allPassed() const {\n-        return failed == 0 && failedButOk == 0;\n+        return failed == 0 && failedButOk == 0 && skipped == 0;\n     }\n     bool Counts::allOk() const {\n         return failed == 0;\n@@ -53,6 +55,8 @@ namespace Catch {\n             ++diff.testCases.failed;\n         else if( diff.assertions.failedButOk > 0 )\n             ++diff.testCases.failedButOk;\n+        else if ( diff.assertions.skipped > 0 )\n+            ++ diff.testCases.skipped;\n         else\n             ++diff.testCases.passed;\n         return diff;\ndiff --git a/src/catch2/catch_totals.hpp b/src/catch2/catch_totals.hpp\n--- a/src/catch2/catch_totals.hpp\n+++ b/src/catch2/catch_totals.hpp\n@@ -23,6 +23,7 @@ namespace Catch {\n         std::uint64_t passed = 0;\n         std::uint64_t failed = 0;\n         std::uint64_t failedButOk = 0;\n+        std::uint64_t skipped = 0;\n     };\n \n     struct Totals {\ndiff --git a/src/catch2/interfaces/catch_interfaces_reporter.hpp b/src/catch2/interfaces/catch_interfaces_reporter.hpp\n--- a/src/catch2/interfaces/catch_interfaces_reporter.hpp\n+++ b/src/catch2/interfaces/catch_interfaces_reporter.hpp\n@@ -242,7 +242,12 @@ namespace Catch {\n          */\n         virtual void testRunEnded( TestRunStats const& testRunStats ) = 0;\n \n-        //! Called with test cases that are skipped due to the test run aborting\n+        /**\n+         * Called with test cases that are skipped due to the test run aborting.\n+         * NOT called for test cases that are explicitly skipped using the `SKIP` macro.\n+         *\n+         * Deprecated - will be removed in the next major release.\n+         */\n         virtual void skipTest( TestCaseInfo const& testInfo ) = 0;\n \n         //! Called if a fatal error (signal/structured exception) occured\ndiff --git a/src/catch2/internal/catch_assertion_handler.cpp b/src/catch2/internal/catch_assertion_handler.cpp\n--- a/src/catch2/internal/catch_assertion_handler.cpp\n+++ b/src/catch2/internal/catch_assertion_handler.cpp\n@@ -50,6 +50,13 @@ namespace Catch {\n         if (m_reaction.shouldThrow) {\n             throw_test_failure_exception();\n         }\n+        if ( m_reaction.shouldSkip ) {\n+#if !defined( CATCH_CONFIG_DISABLE_EXCEPTIONS )\n+            throw Catch::TestSkipException();\n+#else\n+            CATCH_ERROR( \"Explicitly skipping tests during runtime requires exceptions\" );\n+#endif\n+        }\n     }\n     void AssertionHandler::setCompleted() {\n         m_completed = true;\ndiff --git a/src/catch2/internal/catch_assertion_handler.hpp b/src/catch2/internal/catch_assertion_handler.hpp\n--- a/src/catch2/internal/catch_assertion_handler.hpp\n+++ b/src/catch2/internal/catch_assertion_handler.hpp\n@@ -22,6 +22,7 @@ namespace Catch {\n     struct AssertionReaction {\n         bool shouldDebugBreak = false;\n         bool shouldThrow = false;\n+        bool shouldSkip = false;\n     };\n \n     class AssertionHandler {\ndiff --git a/src/catch2/internal/catch_console_colour.hpp b/src/catch2/internal/catch_console_colour.hpp\n--- a/src/catch2/internal/catch_console_colour.hpp\n+++ b/src/catch2/internal/catch_console_colour.hpp\n@@ -47,6 +47,7 @@ namespace Catch {\n \n             Error = BrightRed,\n             Success = Green,\n+            Skip = LightGrey,\n \n             OriginalExpression = Cyan,\n             ReconstructedExpression = BrightYellow,\ndiff --git a/src/catch2/internal/catch_exception_translator_registry.cpp b/src/catch2/internal/catch_exception_translator_registry.cpp\n--- a/src/catch2/internal/catch_exception_translator_registry.cpp\n+++ b/src/catch2/internal/catch_exception_translator_registry.cpp\n@@ -44,6 +44,9 @@ namespace Catch {\n         catch( TestFailureException& ) {\n             std::rethrow_exception(std::current_exception());\n         }\n+        catch( TestSkipException& ) {\n+            std::rethrow_exception(std::current_exception());\n+        }\n         catch( std::exception const& ex ) {\n             return ex.what();\n         }\ndiff --git a/src/catch2/internal/catch_result_type.hpp b/src/catch2/internal/catch_result_type.hpp\n--- a/src/catch2/internal/catch_result_type.hpp\n+++ b/src/catch2/internal/catch_result_type.hpp\n@@ -16,6 +16,8 @@ namespace Catch {\n         Ok = 0,\n         Info = 1,\n         Warning = 2,\n+        // TODO: Should explicit skip be considered \"not OK\" (cf. isOk)? I.e., should it have the failure bit?\n+        ExplicitSkip = 4,\n \n         FailureBit = 0x10,\n \ndiff --git a/src/catch2/internal/catch_run_context.cpp b/src/catch2/internal/catch_run_context.cpp\n--- a/src/catch2/internal/catch_run_context.cpp\n+++ b/src/catch2/internal/catch_run_context.cpp\n@@ -270,6 +270,9 @@ namespace Catch {\n         if (result.getResultType() == ResultWas::Ok) {\n             m_totals.assertions.passed++;\n             m_lastAssertionPassed = true;\n+        } else if (result.getResultType() == ResultWas::ExplicitSkip) {\n+            m_totals.assertions.skipped++;\n+            m_lastAssertionPassed = true;\n         } else if (!result.succeeded()) {\n             m_lastAssertionPassed = false;\n             if (result.isOk()) {\n@@ -475,6 +478,8 @@ namespace Catch {\n             duration = timer.getElapsedSeconds();\n         } CATCH_CATCH_ANON (TestFailureException&) {\n             // This just means the test was aborted due to failure\n+        } CATCH_CATCH_ANON (TestSkipException&) {\n+            // This just means the test was explicitly skipped\n         } CATCH_CATCH_ALL {\n             // Under CATCH_CONFIG_FAST_COMPILE, unexpected exceptions under REQUIRE assertions\n             // are reported without translation at the point of origin.\n@@ -571,8 +576,13 @@ namespace Catch {\n         data.message = static_cast<std::string>(message);\n         AssertionResult assertionResult{ m_lastAssertionInfo, data };\n         assertionEnded( assertionResult );\n-        if( !assertionResult.isOk() )\n+        if ( !assertionResult.isOk() ) {\n             populateReaction( reaction );\n+        } else if ( resultType == ResultWas::ExplicitSkip ) {\n+            // TODO: Need to handle this explicitly, as ExplicitSkip is\n+            // considered \"OK\"\n+            reaction.shouldSkip = true;\n+        }\n     }\n     void RunContext::handleUnexpectedExceptionNotThrown(\n             AssertionInfo const& info,\ndiff --git a/src/catch2/reporters/catch_reporter_automake.cpp b/src/catch2/reporters/catch_reporter_automake.cpp\n--- a/src/catch2/reporters/catch_reporter_automake.cpp\n+++ b/src/catch2/reporters/catch_reporter_automake.cpp\n@@ -17,7 +17,9 @@ namespace Catch {\n     void AutomakeReporter::testCaseEnded(TestCaseStats const& _testCaseStats) {\n         // Possible values to emit are PASS, XFAIL, SKIP, FAIL, XPASS and ERROR.\n         m_stream << \":test-result: \";\n-        if (_testCaseStats.totals.assertions.allPassed()) {\n+        if ( _testCaseStats.totals.testCases.skipped > 0 ) {\n+            m_stream << \"SKIP\";\n+        } else if (_testCaseStats.totals.assertions.allPassed()) {\n             m_stream << \"PASS\";\n         } else if (_testCaseStats.totals.assertions.allOk()) {\n             m_stream << \"XFAIL\";\ndiff --git a/src/catch2/reporters/catch_reporter_compact.cpp b/src/catch2/reporters/catch_reporter_compact.cpp\n--- a/src/catch2/reporters/catch_reporter_compact.cpp\n+++ b/src/catch2/reporters/catch_reporter_compact.cpp\n@@ -105,6 +105,11 @@ class AssertionPrinter {\n             printIssue(\"explicitly\");\n             printRemainingMessages(Colour::None);\n             break;\n+        case ResultWas::ExplicitSkip:\n+            printResultType(Colour::Skip, \"skipped\"_sr);\n+            printMessage();\n+            printRemainingMessages();\n+            break;\n             // These cases are here to prevent compiler warnings\n         case ResultWas::Unknown:\n         case ResultWas::FailureBit:\n@@ -220,7 +225,7 @@ class AssertionPrinter {\n \n             // Drop out if result was successful and we're not printing those\n             if( !m_config->includeSuccessfulResults() && result.isOk() ) {\n-                if( result.getResultType() != ResultWas::Warning )\n+                if( result.getResultType() != ResultWas::Warning && result.getResultType() != ResultWas::ExplicitSkip )\n                     return;\n                 printInfoMessages = false;\n             }\ndiff --git a/src/catch2/reporters/catch_reporter_console.cpp b/src/catch2/reporters/catch_reporter_console.cpp\n--- a/src/catch2/reporters/catch_reporter_console.cpp\n+++ b/src/catch2/reporters/catch_reporter_console.cpp\n@@ -111,6 +111,14 @@ class ConsoleAssertionPrinter {\n             if (_stats.infoMessages.size() > 1)\n                 messageLabel = \"explicitly with messages\";\n             break;\n+        case ResultWas::ExplicitSkip:\n+            colour = Colour::Skip;\n+            passOrFail = \"SKIPPED\"_sr;\n+            if (_stats.infoMessages.size() == 1)\n+                messageLabel = \"explicitly with message\";\n+            if (_stats.infoMessages.size() > 1)\n+                messageLabel = \"explicitly with messages\";\n+            break;\n             // These cases are here to prevent compiler warnings\n         case ResultWas::Unknown:\n         case ResultWas::FailureBit:\n@@ -185,13 +193,16 @@ std::size_t makeRatio( std::uint64_t number, std::uint64_t total ) {\n     return (ratio == 0 && number > 0) ? 1 : static_cast<std::size_t>(ratio);\n }\n \n-std::size_t& findMax( std::size_t& i, std::size_t& j, std::size_t& k ) {\n-    if (i > j && i > k)\n+std::size_t&\n+findMax( std::size_t& i, std::size_t& j, std::size_t& k, std::size_t& l ) {\n+    if (i > j && i > k && i > l)\n         return i;\n-    else if (j > k)\n+    else if (j > k && j > l)\n         return j;\n-    else\n+    else if (k > l)\n         return k;\n+    else\n+        return l;\n }\n \n enum class Justification { Left, Right };\n@@ -400,7 +411,8 @@ void ConsoleReporter::assertionEnded(AssertionStats const& _assertionStats) {\n     bool includeResults = m_config->includeSuccessfulResults() || !result.isOk();\n \n     // Drop out if result was successful but we're not printing them.\n-    if (!includeResults && result.getResultType() != ResultWas::Warning)\n+    // TODO: Make configurable whether skips should be printed\n+    if (!includeResults && result.getResultType() != ResultWas::Warning && result.getResultType() != ResultWas::ExplicitSkip)\n         return;\n \n     lazyPrint();\n@@ -603,10 +615,11 @@ void ConsoleReporter::printTotalsDivider(Totals const& totals) {\n         std::size_t failedRatio = makeRatio(totals.testCases.failed, totals.testCases.total());\n         std::size_t failedButOkRatio = makeRatio(totals.testCases.failedButOk, totals.testCases.total());\n         std::size_t passedRatio = makeRatio(totals.testCases.passed, totals.testCases.total());\n-        while (failedRatio + failedButOkRatio + passedRatio < CATCH_CONFIG_CONSOLE_WIDTH - 1)\n-            findMax(failedRatio, failedButOkRatio, passedRatio)++;\n+        std::size_t skippedRatio = makeRatio(totals.testCases.skipped, totals.testCases.total());\n+        while (failedRatio + failedButOkRatio + passedRatio + skippedRatio < CATCH_CONFIG_CONSOLE_WIDTH - 1)\n+            findMax(failedRatio, failedButOkRatio, passedRatio, skippedRatio)++;\n         while (failedRatio + failedButOkRatio + passedRatio > CATCH_CONFIG_CONSOLE_WIDTH - 1)\n-            findMax(failedRatio, failedButOkRatio, passedRatio)--;\n+            findMax(failedRatio, failedButOkRatio, passedRatio, skippedRatio)--;\n \n         m_stream << m_colour->guardColour( Colour::Error )\n                  << std::string( failedRatio, '=' )\n@@ -619,6 +632,8 @@ void ConsoleReporter::printTotalsDivider(Totals const& totals) {\n             m_stream << m_colour->guardColour( Colour::Success )\n                      << std::string( passedRatio, '=' );\n         }\n+        m_stream << m_colour->guardColour( Colour::Skip )\n+                 << std::string( skippedRatio, '=' );\n     } else {\n         m_stream << m_colour->guardColour( Colour::Warning )\n                  << std::string( CATCH_CONFIG_CONSOLE_WIDTH - 1, '=' );\ndiff --git a/src/catch2/reporters/catch_reporter_helpers.cpp b/src/catch2/reporters/catch_reporter_helpers.cpp\n--- a/src/catch2/reporters/catch_reporter_helpers.cpp\n+++ b/src/catch2/reporters/catch_reporter_helpers.cpp\n@@ -316,15 +316,22 @@ namespace Catch {\n         }\n \n         std::vector<SummaryColumn> columns;\n+        // Don't include \"skipped assertions\" in total count\n+        const auto totalAssertionCount =\n+            totals.assertions.total() - totals.assertions.skipped;\n         columns.push_back( SummaryColumn( \"\", Colour::None )\n                                .addRow( totals.testCases.total() )\n-                               .addRow( totals.assertions.total() ) );\n+                               .addRow( totalAssertionCount ) );\n         columns.push_back( SummaryColumn( \"passed\", Colour::Success )\n                                .addRow( totals.testCases.passed )\n                                .addRow( totals.assertions.passed ) );\n         columns.push_back( SummaryColumn( \"failed\", Colour::ResultError )\n                                .addRow( totals.testCases.failed )\n                                .addRow( totals.assertions.failed ) );\n+        columns.push_back( SummaryColumn( \"skipped\", Colour::Skip )\n+                               .addRow( totals.testCases.skipped )\n+                               // Don't print \"skipped assertions\"\n+                               .addRow( 0 ) );\n         columns.push_back(\n             SummaryColumn( \"failed as expected\", Colour::ResultExpectedFailure )\n                 .addRow( totals.testCases.failedButOk )\ndiff --git a/src/catch2/reporters/catch_reporter_junit.cpp b/src/catch2/reporters/catch_reporter_junit.cpp\n--- a/src/catch2/reporters/catch_reporter_junit.cpp\n+++ b/src/catch2/reporters/catch_reporter_junit.cpp\n@@ -132,6 +132,7 @@ namespace Catch {\n         xml.writeAttribute( \"name\"_sr, stats.runInfo.name );\n         xml.writeAttribute( \"errors\"_sr, unexpectedExceptions );\n         xml.writeAttribute( \"failures\"_sr, stats.totals.assertions.failed-unexpectedExceptions );\n+        xml.writeAttribute( \"skipped\"_sr, stats.totals.assertions.skipped );\n         xml.writeAttribute( \"tests\"_sr, stats.totals.assertions.total() );\n         xml.writeAttribute( \"hostname\"_sr, \"tbd\"_sr ); // !TBD\n         if( m_config->showDurations() == ShowDurations::Never )\n@@ -244,7 +245,8 @@ namespace Catch {\n \n     void JunitReporter::writeAssertion( AssertionStats const& stats ) {\n         AssertionResult const& result = stats.assertionResult;\n-        if( !result.isOk() ) {\n+        if ( !result.isOk() ||\n+             result.getResultType() == ResultWas::ExplicitSkip ) {\n             std::string elementName;\n             switch( result.getResultType() ) {\n                 case ResultWas::ThrewException:\n@@ -256,7 +258,9 @@ namespace Catch {\n                 case ResultWas::DidntThrowException:\n                     elementName = \"failure\";\n                     break;\n-\n+                case ResultWas::ExplicitSkip:\n+                    elementName = \"skipped\";\n+                    break;\n                 // We should never see these here:\n                 case ResultWas::Info:\n                 case ResultWas::Warning:\n@@ -274,7 +278,9 @@ namespace Catch {\n             xml.writeAttribute( \"type\"_sr, result.getTestMacroName() );\n \n             ReusableStringStream rss;\n-            if (stats.totals.assertions.total() > 0) {\n+            if ( result.getResultType() == ResultWas::ExplicitSkip ) {\n+                rss << \"SKIPPED\\n\";\n+            } else {\n                 rss << \"FAILED\" << \":\\n\";\n                 if (result.hasExpression()) {\n                     rss << \"  \";\n@@ -285,8 +291,6 @@ namespace Catch {\n                     rss << \"with expansion:\\n\";\n                     rss << TextFlow::Column(result.getExpandedExpression()).indent(2) << '\\n';\n                 }\n-            } else {\n-                rss << '\\n';\n             }\n \n             if( !result.getMessage().empty() )\ndiff --git a/src/catch2/reporters/catch_reporter_sonarqube.cpp b/src/catch2/reporters/catch_reporter_sonarqube.cpp\n--- a/src/catch2/reporters/catch_reporter_sonarqube.cpp\n+++ b/src/catch2/reporters/catch_reporter_sonarqube.cpp\n@@ -97,7 +97,8 @@ namespace Catch {\n \n     void SonarQubeReporter::writeAssertion(AssertionStats const& stats, bool okToFail) {\n         AssertionResult const& result = stats.assertionResult;\n-        if (!result.isOk()) {\n+        if ( !result.isOk() ||\n+             result.getResultType() == ResultWas::ExplicitSkip ) {\n             std::string elementName;\n             if (okToFail) {\n                 elementName = \"skipped\";\n@@ -108,15 +109,13 @@ namespace Catch {\n                     elementName = \"error\";\n                     break;\n                 case ResultWas::ExplicitFailure:\n-                    elementName = \"failure\";\n-                    break;\n                 case ResultWas::ExpressionFailed:\n-                    elementName = \"failure\";\n-                    break;\n                 case ResultWas::DidntThrowException:\n                     elementName = \"failure\";\n                     break;\n-\n+                case ResultWas::ExplicitSkip:\n+                    elementName = \"skipped\";\n+                    break;\n                     // We should never see these here:\n                 case ResultWas::Info:\n                 case ResultWas::Warning:\n@@ -136,7 +135,9 @@ namespace Catch {\n             xml.writeAttribute(\"message\"_sr, messageRss.str());\n \n             ReusableStringStream textRss;\n-            if (stats.totals.assertions.total() > 0) {\n+            if ( result.getResultType() == ResultWas::ExplicitSkip ) {\n+                textRss << \"SKIPPED\\n\";\n+            } else {\n                 textRss << \"FAILED:\\n\";\n                 if (result.hasExpression()) {\n                     textRss << '\\t' << result.getExpressionInMacro() << '\\n';\ndiff --git a/src/catch2/reporters/catch_reporter_tap.cpp b/src/catch2/reporters/catch_reporter_tap.cpp\n--- a/src/catch2/reporters/catch_reporter_tap.cpp\n+++ b/src/catch2/reporters/catch_reporter_tap.cpp\n@@ -100,6 +100,12 @@ namespace Catch {\n                     printIssue(\"explicitly\"_sr);\n                     printRemainingMessages(Colour::None);\n                     break;\n+                case ResultWas::ExplicitSkip:\n+                    printResultType(tapPassedString);\n+                    printIssue(\" # SKIP\"_sr);\n+                    printMessage();\n+                    printRemainingMessages();\n+                    break;\n                     // These cases are here to prevent compiler warnings\n                 case ResultWas::Unknown:\n                 case ResultWas::FailureBit:\ndiff --git a/src/catch2/reporters/catch_reporter_teamcity.cpp b/src/catch2/reporters/catch_reporter_teamcity.cpp\n--- a/src/catch2/reporters/catch_reporter_teamcity.cpp\n+++ b/src/catch2/reporters/catch_reporter_teamcity.cpp\n@@ -59,7 +59,8 @@ namespace Catch {\n \n     void TeamCityReporter::assertionEnded(AssertionStats const& assertionStats) {\n         AssertionResult const& result = assertionStats.assertionResult;\n-        if (!result.isOk()) {\n+        if ( !result.isOk() ||\n+             result.getResultType() == ResultWas::ExplicitSkip ) {\n \n             ReusableStringStream msg;\n             if (!m_headerPrintedForThisSection)\n@@ -84,6 +85,9 @@ namespace Catch {\n             case ResultWas::ExplicitFailure:\n                 msg << \"explicit failure\";\n                 break;\n+            case ResultWas::ExplicitSkip:\n+                msg << \"explicit skip\";\n+                break;\n \n                 // We shouldn't get here because of the isOk() test\n             case ResultWas::Ok:\n@@ -111,18 +115,16 @@ namespace Catch {\n                     \"  \" << result.getExpandedExpression() << '\\n';\n             }\n \n-            if (currentTestCaseInfo->okToFail()) {\n+            if ( result.getResultType() == ResultWas::ExplicitSkip ) {\n+                m_stream << \"##teamcity[testIgnored\";\n+            } else if ( currentTestCaseInfo->okToFail() ) {\n                 msg << \"- failure ignore as test marked as 'ok to fail'\\n\";\n-                m_stream << \"##teamcity[testIgnored\"\n-                    << \" name='\" << escape(currentTestCaseInfo->name) << '\\''\n-                    << \" message='\" << escape(msg.str()) << '\\''\n-                    << \"]\\n\";\n+                m_stream << \"##teamcity[testIgnored\";\n             } else {\n-                m_stream << \"##teamcity[testFailed\"\n-                    << \" name='\" << escape(currentTestCaseInfo->name) << '\\''\n-                    << \" message='\" << escape(msg.str()) << '\\''\n-                    << \"]\\n\";\n+                m_stream << \"##teamcity[testFailed\";\n             }\n+            m_stream << \" name='\" << escape( currentTestCaseInfo->name ) << '\\''\n+                     << \" message='\" << escape( msg.str() ) << '\\'' << \"]\\n\";\n         }\n         m_stream.flush();\n     }\ndiff --git a/src/catch2/reporters/catch_reporter_xml.cpp b/src/catch2/reporters/catch_reporter_xml.cpp\n--- a/src/catch2/reporters/catch_reporter_xml.cpp\n+++ b/src/catch2/reporters/catch_reporter_xml.cpp\n@@ -108,9 +108,10 @@ namespace Catch {\n         }\n \n         // Drop out if result was successful but we're not printing them.\n-        if( !includeResults && result.getResultType() != ResultWas::Warning )\n+        if ( !includeResults && result.getResultType() != ResultWas::Warning &&\n+             result.getResultType() != ResultWas::ExplicitSkip ) {\n             return;\n-\n+        }\n \n         // Print the expression if there is one.\n         if( result.hasExpression() ) {\n@@ -153,6 +154,12 @@ namespace Catch {\n                 m_xml.writeText( result.getMessage() );\n                 m_xml.endElement();\n                 break;\n+            case ResultWas::ExplicitSkip:\n+                m_xml.startElement( \"Skip\" );\n+                writeSourceInfo( result.getSourceInfo() );\n+                m_xml.writeText( result.getMessage() );\n+                m_xml.endElement();\n+                break;\n             default:\n                 break;\n         }\n@@ -163,15 +170,18 @@ namespace Catch {\n \n     void XmlReporter::sectionEnded( SectionStats const& sectionStats ) {\n         StreamingReporterBase::sectionEnded( sectionStats );\n-        if( --m_sectionDepth > 0 ) {\n-            XmlWriter::ScopedElement e = m_xml.scopedElement( \"OverallResults\" );\n-            e.writeAttribute( \"successes\"_sr, sectionStats.assertions.passed );\n-            e.writeAttribute( \"failures\"_sr, sectionStats.assertions.failed );\n-            e.writeAttribute( \"expectedFailures\"_sr, sectionStats.assertions.failedButOk );\n-\n-            if ( m_config->showDurations() == ShowDurations::Always )\n-                e.writeAttribute( \"durationInSeconds\"_sr, sectionStats.durationInSeconds );\n-\n+        if ( --m_sectionDepth > 0 ) {\n+            {\n+                XmlWriter::ScopedElement e = m_xml.scopedElement( \"OverallResults\" );\n+                e.writeAttribute( \"successes\"_sr, sectionStats.assertions.passed );\n+                e.writeAttribute( \"failures\"_sr, sectionStats.assertions.failed );\n+                e.writeAttribute( \"expectedFailures\"_sr, sectionStats.assertions.failedButOk );\n+                e.writeAttribute( \"skipped\"_sr, sectionStats.assertions.skipped > 0 );\n+\n+                if ( m_config->showDurations() == ShowDurations::Always )\n+                    e.writeAttribute( \"durationInSeconds\"_sr, sectionStats.durationInSeconds );\n+            }\n+            // Ends assertion tag\n             m_xml.endElement();\n         }\n     }\n@@ -180,6 +190,7 @@ namespace Catch {\n         StreamingReporterBase::testCaseEnded( testCaseStats );\n         XmlWriter::ScopedElement e = m_xml.scopedElement( \"OverallResult\" );\n         e.writeAttribute( \"success\"_sr, testCaseStats.totals.assertions.allOk() );\n+        e.writeAttribute( \"skips\"_sr, testCaseStats.totals.assertions.skipped );\n \n         if ( m_config->showDurations() == ShowDurations::Always )\n             e.writeAttribute( \"durationInSeconds\"_sr, m_testCaseTimer.getElapsedSeconds() );\n@@ -197,11 +208,13 @@ namespace Catch {\n         m_xml.scopedElement( \"OverallResults\" )\n             .writeAttribute( \"successes\"_sr, testRunStats.totals.assertions.passed )\n             .writeAttribute( \"failures\"_sr, testRunStats.totals.assertions.failed )\n-            .writeAttribute( \"expectedFailures\"_sr, testRunStats.totals.assertions.failedButOk );\n+            .writeAttribute( \"expectedFailures\"_sr, testRunStats.totals.assertions.failedButOk )\n+            .writeAttribute( \"skips\"_sr, testRunStats.totals.assertions.skipped );\n         m_xml.scopedElement( \"OverallResultsCases\")\n             .writeAttribute( \"successes\"_sr, testRunStats.totals.testCases.passed )\n             .writeAttribute( \"failures\"_sr, testRunStats.totals.testCases.failed )\n-            .writeAttribute( \"expectedFailures\"_sr, testRunStats.totals.testCases.failedButOk );\n+            .writeAttribute( \"expectedFailures\"_sr, testRunStats.totals.testCases.failedButOk )\n+            .writeAttribute( \"skips\"_sr, testRunStats.totals.testCases.skipped );\n         m_xml.endElement();\n     }\n \n","test_patch":"diff --git a/src/catch2/catch_test_macros.hpp b/src/catch2/catch_test_macros.hpp\n--- a/src/catch2/catch_test_macros.hpp\n+++ b/src/catch2/catch_test_macros.hpp\n@@ -49,6 +49,7 @@\n   #define CATCH_FAIL( ... ) INTERNAL_CATCH_MSG( \"CATCH_FAIL\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n   #define CATCH_FAIL_CHECK( ... ) INTERNAL_CATCH_MSG( \"CATCH_FAIL_CHECK\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n   #define CATCH_SUCCEED( ... ) INTERNAL_CATCH_MSG( \"CATCH_SUCCEED\", Catch::ResultWas::Ok, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n+  #define CATCH_SKIP( ... ) INTERNAL_CATCH_MSG( \"SKIP\", Catch::ResultWas::ExplicitSkip, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n \n \n   #if !defined(CATCH_CONFIG_RUNTIME_STATIC_REQUIRE)\n@@ -102,6 +103,7 @@\n   #define CATCH_FAIL( ... ) (void)(0)\n   #define CATCH_FAIL_CHECK( ... ) (void)(0)\n   #define CATCH_SUCCEED( ... ) (void)(0)\n+  #define CATCH_SKIP( ... ) (void)(0)\n \n   #define CATCH_STATIC_REQUIRE( ... )       (void)(0)\n   #define CATCH_STATIC_REQUIRE_FALSE( ... ) (void)(0)\n@@ -146,6 +148,7 @@\n   #define FAIL( ... ) INTERNAL_CATCH_MSG( \"FAIL\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n   #define FAIL_CHECK( ... ) INTERNAL_CATCH_MSG( \"FAIL_CHECK\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n   #define SUCCEED( ... ) INTERNAL_CATCH_MSG( \"SUCCEED\", Catch::ResultWas::Ok, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n+  #define SKIP( ... ) INTERNAL_CATCH_MSG( \"SKIP\", Catch::ResultWas::ExplicitSkip, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n \n \n   #if !defined(CATCH_CONFIG_RUNTIME_STATIC_REQUIRE)\n@@ -198,6 +201,7 @@\n   #define FAIL( ... ) (void)(0)\n   #define FAIL_CHECK( ... ) (void)(0)\n   #define SUCCEED( ... ) (void)(0)\n+  #define SKIP( ... ) (void)(0)\n \n   #define STATIC_REQUIRE( ... )       (void)(0)\n   #define STATIC_REQUIRE_FALSE( ... ) (void)(0)\ndiff --git a/src/catch2/internal/catch_test_failure_exception.hpp b/src/catch2/internal/catch_test_failure_exception.hpp\n--- a/src/catch2/internal/catch_test_failure_exception.hpp\n+++ b/src/catch2/internal/catch_test_failure_exception.hpp\n@@ -20,6 +20,9 @@ namespace Catch {\n      */\n     [[noreturn]] void throw_test_failure_exception();\n \n+    //! Used to signal that the remainder of a test should be skipped\n+    struct TestSkipException{};\n+\n } // namespace Catch\n \n #endif // CATCH_TEST_FAILURE_EXCEPTION_HPP_INCLUDED\ndiff --git a/tests/CMakeLists.txt b/tests/CMakeLists.txt\n--- a/tests/CMakeLists.txt\n+++ b/tests/CMakeLists.txt\n@@ -116,6 +116,7 @@ set(TEST_SOURCES\n         ${SELF_TEST_DIR}/UsageTests/Generators.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/Message.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/Misc.tests.cpp\n+        ${SELF_TEST_DIR}/UsageTests/Skip.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/ToStringByte.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/ToStringChrono.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/ToStringGeneral.tests.cpp\n@@ -272,6 +273,10 @@ add_test(NAME TestSpecs::OverrideFailureWithNoMatchedTests\n   COMMAND $<TARGET_FILE:SelfTest> \"___nonexistent_test___\" --allow-running-no-tests\n )\n \n+add_test(NAME TestSpecs::OverrideAllSkipFailure\n+  COMMAND $<TARGET_FILE:SelfTest> \"tests can be skipped dynamically at runtime\" --allow-running-no-tests\n+)\n+\n add_test(NAME TestSpecs::NonMatchingTestSpecIsRoundTrippable\n     COMMAND $<TARGET_FILE:SelfTest> Tracker, \"this test does not exist\" \"[nor does this tag]\"\n )\ndiff --git a/tests/ExtraTests/CMakeLists.txt b/tests/ExtraTests/CMakeLists.txt\n--- a/tests/ExtraTests/CMakeLists.txt\n+++ b/tests/ExtraTests/CMakeLists.txt\n@@ -488,15 +488,32 @@ set_tests_properties(TestSpecs::EmptySpecWithNoTestsFails\n   PROPERTIES\n     WILL_FAIL ON\n )\n+\n add_test(\n   NAME TestSpecs::OverrideFailureWithEmptySpec\n   COMMAND $<TARGET_FILE:NoTests> --allow-running-no-tests\n )\n+\n add_test(\n   NAME List::Listeners::WorksWithoutRegisteredListeners\n   COMMAND $<TARGET_FILE:NoTests> --list-listeners\n )\n+\n+\n+add_executable(AllSkipped ${TESTS_DIR}/X93-AllSkipped.cpp)\n+target_link_libraries(AllSkipped PRIVATE Catch2::Catch2WithMain)\n+\n+add_test(\n+  NAME TestSpecs::SkippingAllTestsFails\n+  COMMAND $<TARGET_FILE:AllSkipped>\n+)\n+set_tests_properties(TestSpecs::SkippingAllTestsFails\n+  PROPERTIES\n+    WILL_FAIL ON\n+)\n+\n set( EXTRA_TEST_BINARIES\n+    AllSkipped\n     PrefixedMacros\n     DisabledMacros\n     DisabledExceptions-DefaultHandler\ndiff --git a/tests/ExtraTests/X93-AllSkipped.cpp b/tests/ExtraTests/X93-AllSkipped.cpp\nnew file mode 100644\n--- /dev/null\n+++ b/tests/ExtraTests/X93-AllSkipped.cpp\n@@ -0,0 +1,16 @@\n+\n+//              Copyright Catch2 Authors\n+// Distributed under the Boost Software License, Version 1.0.\n+//   (See accompanying file LICENSE.txt or copy at\n+//        https://www.boost.org/LICENSE_1_0.txt)\n+\n+// SPDX-License-Identifier: BSL-1.0\n+\n+#include <catch2/catch_test_macros.hpp>\n+\n+TEST_CASE( \"this test case is being skipped\" ) { SKIP(); }\n+\n+TEST_CASE( \"all sections in this test case are being skipped\" ) {\n+    SECTION( \"A\" ) { SKIP(); }\n+    SECTION( \"B\" ) { SKIP(); }\n+}\ndiff --git a/tests/SelfTest/UsageTests/Skip.tests.cpp b/tests/SelfTest/UsageTests/Skip.tests.cpp\nnew file mode 100644\n--- /dev/null\n+++ b/tests/SelfTest/UsageTests/Skip.tests.cpp\n@@ -0,0 +1,73 @@\n+\n+//              Copyright Catch2 Authors\n+// Distributed under the Boost Software License, Version 1.0.\n+//   (See accompanying file LICENSE.txt or copy at\n+//        https://www.boost.org/LICENSE_1_0.txt)\n+\n+// SPDX-License-Identifier: BSL-1.0\n+\n+#include <catch2/catch_test_macros.hpp>\n+#include <catch2/generators/catch_generators_range.hpp>\n+\n+#include <iostream>\n+\n+TEST_CASE( \"tests can be skipped dynamically at runtime\", \"[skipping]\" ) {\n+    SKIP();\n+    FAIL( \"this is not reached\" );\n+}\n+\n+TEST_CASE( \"skipped tests can optionally provide a reason\", \"[skipping]\" ) {\n+    const int answer = 43;\n+    SKIP( \"skipping because answer = \" << answer );\n+    FAIL( \"this is not reached\" );\n+}\n+\n+TEST_CASE( \"sections can be skipped dynamically at runtime\", \"[skipping]\" ) {\n+    SECTION( \"not skipped\" ) { SUCCEED(); }\n+    SECTION( \"skipped\" ) { SKIP(); }\n+    SECTION( \"also not skipped\" ) { SUCCEED(); }\n+}\n+\n+TEST_CASE( \"nested sections can be skipped dynamically at runtime\",\n+           \"[skipping]\" ) {\n+    SECTION( \"A\" ) { std::cout << \"a\"; }\n+    SECTION( \"B\" ) {\n+        SECTION( \"B1\" ) { std::cout << \"b1\"; }\n+        SECTION( \"B2\" ) { SKIP(); }\n+    }\n+    std::cout << \"!\\n\";\n+}\n+\n+TEST_CASE( \"dynamic skipping works with generators\", \"[skipping]\" ) {\n+    const int answer = GENERATE( 41, 42, 43 );\n+    if ( answer != 42 ) { SKIP( \"skipping because answer = \" << answer ); }\n+    SUCCEED();\n+}\n+\n+TEST_CASE( \"failed assertions before SKIP cause test case to fail\",\n+           \"[skipping][!shouldfail]\" ) {\n+    CHECK( 3 == 4 );\n+    SKIP();\n+}\n+\n+TEST_CASE( \"a succeeding test can still be skipped\",\n+           \"[skipping][!shouldfail]\" ) {\n+    SUCCEED();\n+    SKIP();\n+}\n+\n+TEST_CASE( \"failing in some unskipped sections causes entire test case to fail\",\n+           \"[skipping][!shouldfail]\" ) {\n+    SECTION( \"skipped\" ) { SKIP(); }\n+    SECTION( \"not skipped\" ) { FAIL(); }\n+}\n+\n+TEST_CASE( \"failing for some generator values causes entire test case to fail\",\n+           \"[skipping][!shouldfail]\" ) {\n+    int i = GENERATE( 1, 2, 3, 4 );\n+    if ( i % 2 == 0 ) {\n+        SKIP();\n+    } else {\n+        FAIL();\n+    }\n+}\n","problem_statement":"Allow skipping tests at run-time.\nThis is another request for a way to skip tests, but it's not quite the same as #355 because in my case the condition determining if the test can be run or should be skipped is dynamic and determined by the program itself (basically it connects to the database specified on the command line and does different things depending on the exact kind of RDBMS).\n\nCurrently I just test the condition and use `WARN(\"Skipped because...\")`, but this is not ideal because the test still counts as passing when, in fact, it wasn't run at all.\n\n","hints_text":"The next level would be to have a declarative way of describing dependencies between tests. And when one is skipped or failed skip the dependent ones.\n\nIt would be really great to have this facility for a bunch of tests I have, as their viability is determined only at runtime.","created_at":"2022-01-31T16:16:06Z","version":"3.2","dockerfile":"# Base image specification. Defines the foundation OS and architecture for the container\nFROM ubuntu:20.04\nARG DEBIAN_FRONTEND=noninteractive\nENV TZ=Etc/UTC\n\n# System dependencies installation. Installs essential tools and libraries required for development and runtime\nRUN apt update && apt install -y \\\n    build-essential \\\n    cmake \\\n    ninja-build \\\n    python3 \\\n    git \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set default working directory for the repository.\nWORKDIR /testbed/\n\n# Target Project setup. Clones source code, checks out to the target version.\nRUN git clone https://github.com/catchorg/Catch2 /testbed \\\n    && cd /testbed \\\n    && git reset --hard 52066dbc2a53f4c3ab2a418d03f93200a8245451 \\\n    && git remote remove origin\n\n# Build steps: Generate amalgamated files, configure CMake, and build the project including tests.\n# These steps are necessary to prepare the environment for test execution.\nRUN /bin/bash -c \" \\\n    cd /testbed && \\\n    python3 ./tools/scripts/generateAmalgamatedFiles.py && \\\n    mkdir build && \\\n    cd build && \\\n    cmake -B. -H.. \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_CXX_STANDARD=17 \\\n    -DCMAKE_CXX_STANDARD_REQUIRED=ON \\\n    -DCMAKE_CXX_EXTENSIONS=OFF \\\n    -DCATCH_DEVELOPMENT_BUILD=ON \\\n    -DCATCH_BUILD_TESTING=ON \\\n    -G Ninja && \\\n    ninja\"","eval_script":"#!/bin/bash\nset -euxo pipefail\n\n# Define the target commit SHA and the specific test files to be managed.\nCOMMIT_SHA=\"52066dbc2a53f4c3ab2a418d03f93200a8245451\"\nTARGET_TEST_FILES=(\n    \"src/catch2/catch_test_macros.hpp\"\n    \"src/catch2/internal/catch_test_failure_exception.hpp\"\n    \"tests/CMakeLists.txt\"\n    \"tests/ExtraTests/CMakeLists.txt\"\n)\n\n# Ensure we are in the /testbed directory\ncd /testbed || { echo \"Error: /testbed directory not found. Aborting.\"; exit 1; }\n\necho \"Resetting target test files to their state at commit $COMMIT_SHA...\"\nfor FILE in \"${TARGET_TEST_FILES[@]}\"; do\n    git checkout \"$COMMIT_SHA\" \"$FILE\" || { echo \"Failed to checkout $FILE. Aborting.\"; exit 1; }\ndone\n\n# Apply the test patch if provided. The content of the patch is inserted here.\necho \"Attempting to apply test patch...\"\ngit apply -v - <<'EOF_114329324912'\ndiff --git a/src/catch2/catch_test_macros.hpp b/src/catch2/catch_test_macros.hpp\n--- a/src/catch2/catch_test_macros.hpp\n+++ b/src/catch2/catch_test_macros.hpp\n@@ -49,6 +49,7 @@\n   #define CATCH_FAIL( ... ) INTERNAL_CATCH_MSG( \"CATCH_FAIL\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n   #define CATCH_FAIL_CHECK( ... ) INTERNAL_CATCH_MSG( \"CATCH_FAIL_CHECK\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n   #define CATCH_SUCCEED( ... ) INTERNAL_CATCH_MSG( \"CATCH_SUCCEED\", Catch::ResultWas::Ok, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n+  #define CATCH_SKIP( ... ) INTERNAL_CATCH_MSG( \"SKIP\", Catch::ResultWas::ExplicitSkip, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n \n \n   #if !defined(CATCH_CONFIG_RUNTIME_STATIC_REQUIRE)\n@@ -102,6 +103,7 @@\n   #define CATCH_FAIL( ... ) (void)(0)\n   #define CATCH_FAIL_CHECK( ... ) (void)(0)\n   #define CATCH_SUCCEED( ... ) (void)(0)\n+  #define CATCH_SKIP( ... ) (void)(0)\n \n   #define CATCH_STATIC_REQUIRE( ... )       (void)(0)\n   #define CATCH_STATIC_REQUIRE_FALSE( ... ) (void)(0)\n@@ -146,6 +148,7 @@\n   #define FAIL( ... ) INTERNAL_CATCH_MSG( \"FAIL\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n   #define FAIL_CHECK( ... ) INTERNAL_CATCH_MSG( \"FAIL_CHECK\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n   #define SUCCEED( ... ) INTERNAL_CATCH_MSG( \"SUCCEED\", Catch::ResultWas::Ok, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n+  #define SKIP( ... ) INTERNAL_CATCH_MSG( \"SKIP\", Catch::ResultWas::ExplicitSkip, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n \n \n   #if !defined(CATCH_CONFIG_RUNTIME_STATIC_REQUIRE)\n@@ -198,6 +201,7 @@\n   #define FAIL( ... ) (void)(0)\n   #define FAIL_CHECK( ... ) (void)(0)\n   #define SUCCEED( ... ) (void)(0)\n+  #define SKIP( ... ) (void)(0)\n \n   #define STATIC_REQUIRE( ... )       (void)(0)\n   #define STATIC_REQUIRE_FALSE( ... ) (void)(0)\ndiff --git a/src/catch2/internal/catch_test_failure_exception.hpp b/src/catch2/internal/catch_test_failure_exception.hpp\n--- a/src/catch2/internal/catch_test_failure_exception.hpp\n+++ b/src/catch2/internal/catch_test_failure_exception.hpp\n@@ -20,6 +20,9 @@ namespace Catch {\n      */\n     [[noreturn]] void throw_test_failure_exception();\n \n+    //! Used to signal that the remainder of a test should be skipped\n+    struct TestSkipException{};\n+\n } // namespace Catch\n \n #endif // CATCH_TEST_FAILURE_EXCEPTION_HPP_INCLUDED\ndiff --git a/tests/CMakeLists.txt b/tests/CMakeLists.txt\n--- a/tests/CMakeLists.txt\n+++ b/tests/CMakeLists.txt\n@@ -116,6 +116,7 @@ set(TEST_SOURCES\n         ${SELF_TEST_DIR}/UsageTests/Generators.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/Message.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/Misc.tests.cpp\n+        ${SELF_TEST_DIR}/UsageTests/Skip.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/ToStringByte.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/ToStringChrono.tests.cpp\n         ${SELF_TEST_DIR}/UsageTests/ToStringGeneral.tests.cpp\n@@ -272,6 +273,10 @@ add_test(NAME TestSpecs::OverrideFailureWithNoMatchedTests\n   COMMAND $<TARGET_FILE:SelfTest> \"___nonexistent_test___\" --allow-running-no-tests\n )\n \n+add_test(NAME TestSpecs::OverrideAllSkipFailure\n+  COMMAND $<TARGET_FILE:SelfTest> \"tests can be skipped dynamically at runtime\" --allow-running-no-tests\n+)\n+\n add_test(NAME TestSpecs::NonMatchingTestSpecIsRoundTrippable\n     COMMAND $<TARGET_FILE:SelfTest> Tracker, \"this test does not exist\" \"[nor does this tag]\"\n )\ndiff --git a/tests/ExtraTests/CMakeLists.txt b/tests/ExtraTests/CMakeLists.txt\n--- a/tests/ExtraTests/CMakeLists.txt\n+++ b/tests/ExtraTests/CMakeLists.txt\n@@ -488,15 +488,32 @@ set_tests_properties(TestSpecs::EmptySpecWithNoTestsFails\n   PROPERTIES\n     WILL_FAIL ON\n )\n+\n add_test(\n   NAME TestSpecs::OverrideFailureWithEmptySpec\n   COMMAND $<TARGET_FILE:NoTests> --allow-running-no-tests\n )\n+\n add_test(\n   NAME List::Listeners::WorksWithoutRegisteredListeners\n   COMMAND $<TARGET_FILE:NoTests> --list-listeners\n )\n+\n+\n+add_executable(AllSkipped ${TESTS_DIR}/X93-AllSkipped.cpp)\n+target_link_libraries(AllSkipped PRIVATE Catch2::Catch2WithMain)\n+\n+add_test(\n+  NAME TestSpecs::SkippingAllTestsFails\n+  COMMAND $<TARGET_FILE:AllSkipped>\n+)\n+set_tests_properties(TestSpecs::SkippingAllTestsFails\n+  PROPERTIES\n+    WILL_FAIL ON\n+)\n+\n set( EXTRA_TEST_BINARIES\n+    AllSkipped\n     PrefixedMacros\n     DisabledMacros\n     DisabledExceptions-DefaultHandler\ndiff --git a/tests/ExtraTests/X93-AllSkipped.cpp b/tests/ExtraTests/X93-AllSkipped.cpp\nnew file mode 100644\n--- /dev/null\n+++ b/tests/ExtraTests/X93-AllSkipped.cpp\n@@ -0,0 +1,16 @@\n+\n+//              Copyright Catch2 Authors\n+// Distributed under the Boost Software License, Version 1.0.\n+//   (See accompanying file LICENSE.txt or copy at\n+//        https://www.boost.org/LICENSE_1_0.txt)\n+\n+// SPDX-License-Identifier: BSL-1.0\n+\n+#include <catch2/catch_test_macros.hpp>\n+\n+TEST_CASE( \"this test case is being skipped\" ) { SKIP(); }\n+\n+TEST_CASE( \"all sections in this test case are being skipped\" ) {\n+    SECTION( \"A\" ) { SKIP(); }\n+    SECTION( \"B\" ) { SKIP(); }\n+}\ndiff --git a/tests/SelfTest/UsageTests/Skip.tests.cpp b/tests/SelfTest/UsageTests/Skip.tests.cpp\nnew file mode 100644\n--- /dev/null\n+++ b/tests/SelfTest/UsageTests/Skip.tests.cpp\n@@ -0,0 +1,73 @@\n+\n+//              Copyright Catch2 Authors\n+// Distributed under the Boost Software License, Version 1.0.\n+//   (See accompanying file LICENSE.txt or copy at\n+//        https://www.boost.org/LICENSE_1_0.txt)\n+\n+// SPDX-License-Identifier: BSL-1.0\n+\n+#include <catch2/catch_test_macros.hpp>\n+#include <catch2/generators/catch_generators_range.hpp>\n+\n+#include <iostream>\n+\n+TEST_CASE( \"tests can be skipped dynamically at runtime\", \"[skipping]\" ) {\n+    SKIP();\n+    FAIL( \"this is not reached\" );\n+}\n+\n+TEST_CASE( \"skipped tests can optionally provide a reason\", \"[skipping]\" ) {\n+    const int answer = 43;\n+    SKIP( \"skipping because answer = \" << answer );\n+    FAIL( \"this is not reached\" );\n+}\n+\n+TEST_CASE( \"sections can be skipped dynamically at runtime\", \"[skipping]\" ) {\n+    SECTION( \"not skipped\" ) { SUCCEED(); }\n+    SECTION( \"skipped\" ) { SKIP(); }\n+    SECTION( \"also not skipped\" ) { SUCCEED(); }\n+}\n+\n+TEST_CASE( \"nested sections can be skipped dynamically at runtime\",\n+           \"[skipping]\" ) {\n+    SECTION( \"A\" ) { std::cout << \"a\"; }\n+    SECTION( \"B\" ) {\n+        SECTION( \"B1\" ) { std::cout << \"b1\"; }\n+        SECTION( \"B2\" ) { SKIP(); }\n+    }\n+    std::cout << \"!\\n\";\n+}\n+\n+TEST_CASE( \"dynamic skipping works with generators\", \"[skipping]\" ) {\n+    const int answer = GENERATE( 41, 42, 43 );\n+    if ( answer != 42 ) { SKIP( \"skipping because answer = \" << answer ); }\n+    SUCCEED();\n+}\n+\n+TEST_CASE( \"failed assertions before SKIP cause test case to fail\",\n+           \"[skipping][!shouldfail]\" ) {\n+    CHECK( 3 == 4 );\n+    SKIP();\n+}\n+\n+TEST_CASE( \"a succeeding test can still be skipped\",\n+           \"[skipping][!shouldfail]\" ) {\n+    SUCCEED();\n+    SKIP();\n+}\n+\n+TEST_CASE( \"failing in some unskipped sections causes entire test case to fail\",\n+           \"[skipping][!shouldfail]\" ) {\n+    SECTION( \"skipped\" ) { SKIP(); }\n+    SECTION( \"not skipped\" ) { FAIL(); }\n+}\n+\n+TEST_CASE( \"failing for some generator values causes entire test case to fail\",\n+           \"[skipping][!shouldfail]\" ) {\n+    int i = GENERATE( 1, 2, 3, 4 );\n+    if ( i % 2 == 0 ) {\n+        SKIP();\n+    } else {\n+        FAIL();\n+    }\n+}\nEOF_114329324912\n\n# Navigate to the 'build' directory where the project was initially configured and built.\ncd /testbed/build || { echo \"Error: 'build' directory not found at /testbed/build. Ensure Dockerfile build steps are complete.\"; exit 1; }\n\n# Recompile the project after applying the patch.\n# This step is critical because any changes from the patch (including to CMakeLists.txt or headers)\n# require a recompile for the test executables to incorporate them.\necho \"Recompiling project after patch application to integrate changes...\"\nninja || { echo \"Error: Failed to recompile project. Aborting.\"; exit 1; }\n\n# Set environment variable for CTest to show output on failure.\necho \"Setting CTEST_OUTPUT_ON_FAILURE environment variable...\"\nexport CTEST_OUTPUT_ON_FAILURE=1\n\n# First attempt to execute Catch2 tests.\n# This run is expected to fail for ApprovalTests if baselines are outdated, but it will generate\n# the necessary '.unapproved.txt' files for approve.py to pick up.\necho \"Executing Catch2 tests using ctest (first attempt to generate unapproved baselines)...\"\nctest -C Release -j $(nproc) || true # Allow failure to continue script and generate unapproved files\n\n# Navigate back to /testbed for approve.py, as it needs to be run from the repository root.\ncd /testbed || { echo \"Failed to navigate back to /testbed for approve.py. Aborting.\"; exit 1; }\n\n# Update ApprovalTest baselines. This step will approve the .unapproved.txt files generated by the previous ctest run.\necho \"Running approve.py to update ApprovalTest baselines...\"\npython3 ./tools/scripts/approve.py || { echo \"Failed to run approve.py. Approval process failed.\"; exit 1; }\n\n# Navigate back to the build directory to run tests again.\ncd /testbed/build || { echo \"Failed to navigate back to /testbed/build. Aborting.\"; exit 1; }\n\n# Re-execute Catch2 tests using CTest. With updated baselines, this run should pass.\necho \"Re-executing Catch2 tests using ctest after baseline approval...\"\nctest -C Release -j $(nproc)\nrc=$? # Capture the exit code of this final ctest command\n\n# Output the captured exit code. This is crucial for the judging system.\necho \"OMNIGRIL_EXIT_CODE=$rc\"\n\n# Navigate back to the /testbed directory for cleanup.\necho \"Navigating back to /testbed for cleanup operations...\"\ncd /testbed || { echo \"Failed to navigate back to /testbed. Cleanup skipped.\"; exit $rc; }\n\n# Clean up: Reset the target test files to their original state from the repository.\n# This ensures a clean state for any subsequent operations or for future runs.\necho \"Resetting target test files after test run...\"\nfor FILE in \"${TARGET_TEST_FILES[@]}\"; do\n    git checkout \"$COMMIT_SHA\" \"$FILE\" || { echo \"Failed to reset $FILE. Manual intervention might be required.\"; }\ndone\n\n# Exit with the captured test result code.\nexit $rc","eval_script_skeleton":"#!/bin/bash\nset -euxo pipefail\n\n# Define the target commit SHA and the specific test files to be managed.\nCOMMIT_SHA=\"52066dbc2a53f4c3ab2a418d03f93200a8245451\"\nTARGET_TEST_FILES=(\n    \"src/catch2/catch_test_macros.hpp\"\n    \"src/catch2/internal/catch_test_failure_exception.hpp\"\n    \"tests/CMakeLists.txt\"\n    \"tests/ExtraTests/CMakeLists.txt\"\n)\n\n# Ensure we are in the /testbed directory\ncd /testbed || { echo \"Error: /testbed directory not found. Aborting.\"; exit 1; }\n\necho \"Resetting target test files to their state at commit $COMMIT_SHA...\"\nfor FILE in \"${TARGET_TEST_FILES[@]}\"; do\n    git checkout \"$COMMIT_SHA\" \"$FILE\" || { echo \"Failed to checkout $FILE. Aborting.\"; exit 1; }\ndone\n\n# Apply the test patch if provided. The content of the patch is inserted here.\necho \"Attempting to apply test patch...\"\ngit apply -v - <<'EOF_114329324912'\n[CONTENT OF TEST PATCH]\nEOF_114329324912\n\n# Navigate to the 'build' directory where the project was initially configured and built.\ncd /testbed/build || { echo \"Error: 'build' directory not found at /testbed/build. Ensure Dockerfile build steps are complete.\"; exit 1; }\n\n# Recompile the project after applying the patch.\n# This step is critical because any changes from the patch (including to CMakeLists.txt or headers)\n# require a recompile for the test executables to incorporate them.\necho \"Recompiling project after patch application to integrate changes...\"\nninja || { echo \"Error: Failed to recompile project. Aborting.\"; exit 1; }\n\n# Set environment variable for CTest to show output on failure.\necho \"Setting CTEST_OUTPUT_ON_FAILURE environment variable...\"\nexport CTEST_OUTPUT_ON_FAILURE=1\n\n# First attempt to execute Catch2 tests.\n# This run is expected to fail for ApprovalTests if baselines are outdated, but it will generate\n# the necessary '.unapproved.txt' files for approve.py to pick up.\necho \"Executing Catch2 tests using ctest (first attempt to generate unapproved baselines)...\"\nctest -C Release -j $(nproc) || true # Allow failure to continue script and generate unapproved files\n\n# Navigate back to /testbed for approve.py, as it needs to be run from the repository root.\ncd /testbed || { echo \"Failed to navigate back to /testbed for approve.py. Aborting.\"; exit 1; }\n\n# Update ApprovalTest baselines. This step will approve the .unapproved.txt files generated by the previous ctest run.\necho \"Running approve.py to update ApprovalTest baselines...\"\npython3 ./tools/scripts/approve.py || { echo \"Failed to run approve.py. Approval process failed.\"; exit 1; }\n\n# Navigate back to the build directory to run tests again.\ncd /testbed/build || { echo \"Failed to navigate back to /testbed/build. Aborting.\"; exit 1; }\n\n# Re-execute Catch2 tests using CTest. With updated baselines, this run should pass.\necho \"Re-executing Catch2 tests using ctest after baseline approval...\"\nctest -C Release -j $(nproc)\nrc=$? # Capture the exit code of this final ctest command\n\n# Output the captured exit code. This is crucial for the judging system.\necho \"OMNIGRIL_EXIT_CODE=$rc\"\n\n# Navigate back to the /testbed directory for cleanup.\necho \"Navigating back to /testbed for cleanup operations...\"\ncd /testbed || { echo \"Failed to navigate back to /testbed. Cleanup skipped.\"; exit $rc; }\n\n# Clean up: Reset the target test files to their original state from the repository.\n# This ensures a clean state for any subsequent operations or for future runs.\necho \"Resetting target test files after test run...\"\nfor FILE in \"${TARGET_TEST_FILES[@]}\"; do\n    git checkout \"$COMMIT_SHA\" \"$FILE\" || { echo \"Failed to reset $FILE. Manual intervention might be required.\"; }\ndone\n\n# Exit with the captured test result code.\nexit $rc"}
