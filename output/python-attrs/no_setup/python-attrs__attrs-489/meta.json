{
    "task_id": "python-attrs__attrs-489",
    "setup_info": {
        "repo_path": "testbed/python-attrs__attrs-489_2025-07-03_17-42-35",
        "repo_cache_path": "testbed/python-attrs/attrs_cache"
    },
    "task_info": {
        "repo": "python-attrs/attrs",
        "pull_number": 489,
        "instance_id": "python-attrs__attrs-489",
        "issue_numbers": [
            "482"
        ],
        "base_commit": "1a90857109794f27e4cf5914bb9ae4617993e880",
        "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -529,6 +529,26 @@ def _patch_original_class(self):\n         for name, value in self._cls_dict.items():\n             setattr(cls, name, value)\n \n+        # Attach __setstate__. This is necessary to clear the hash code\n+        # cache on deserialization. See issue\n+        # https://github.com/python-attrs/attrs/issues/482 .\n+        # Note that this code only handles setstate for dict classes.\n+        # For slotted classes, see similar code in _create_slots_class .\n+        if self._cache_hash:\n+            existing_set_state_method = getattr(cls, \"__setstate__\", None)\n+            if existing_set_state_method:\n+                raise NotImplementedError(\n+                    \"Currently you cannot use hash caching if \"\n+                    \"you specify your own __setstate__ method.\"\n+                    \"See https://github.com/python-attrs/attrs/issues/494 .\"\n+                )\n+\n+            def cache_hash_set_state(chss_self, _):\n+                # clear hash code cache\n+                setattr(chss_self, _hash_cache_field, None)\n+\n+            setattr(cls, \"__setstate__\", cache_hash_set_state)\n+\n         return cls\n \n     def _create_slots_class(self):\n@@ -581,6 +601,8 @@ def slots_getstate(self):\n             \"\"\"\n             return tuple(getattr(self, name) for name in state_attr_names)\n \n+        hash_caching_enabled = self._cache_hash\n+\n         def slots_setstate(self, state):\n             \"\"\"\n             Automatically created by attrs.\n@@ -588,6 +610,13 @@ def slots_setstate(self, state):\n             __bound_setattr = _obj_setattr.__get__(self, Attribute)\n             for name, value in zip(state_attr_names, state):\n                 __bound_setattr(name, value)\n+            # Clearing the hash code cache on deserialization is needed\n+            # because hash codes can change from run to run. See issue\n+            # https://github.com/python-attrs/attrs/issues/482 .\n+            # Note that this code only handles setstate for slotted classes.\n+            # For dict classes, see similar code in _patch_original_class .\n+            if hash_caching_enabled:\n+                __bound_setattr(_hash_cache_field, None)\n \n         # slots and frozen require __getstate__/__setstate__ to work\n         cd[\"__getstate__\"] = slots_getstate\n",
        "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -5,6 +5,7 @@\n from __future__ import absolute_import, division, print_function\n \n import copy\n+import pickle\n \n import pytest\n \n@@ -453,6 +454,83 @@ def __hash__(self):\n         assert 2 == uncached_instance.hash_counter.times_hash_called\n         assert 1 == cached_instance.hash_counter.times_hash_called\n \n+    def test_cache_hash_serialization(self):\n+        \"\"\"\n+        Tests that the hash cache is cleared on deserialization to fix\n+        https://github.com/python-attrs/attrs/issues/482 .\n+        \"\"\"\n+\n+        # First, check that our fix didn't break serialization without\n+        # hash caching.\n+        # We don't care about the result of this; we just want to make sure we\n+        # can do it without exceptions.\n+        hash(pickle.loads(pickle.dumps(HashCacheSerializationTestUncached)))\n+\n+        def assert_hash_code_not_cached_across_serialization(original):\n+            # Now check our fix for #482 for when hash caching is enabled.\n+            original_hash = hash(original)\n+            round_tripped = pickle.loads(pickle.dumps(original))\n+            # What we want to guard against is having a stale hash code\n+            # when a field's hash code differs in a new interpreter after\n+            # deserialization.  This is tricky to test because we are,\n+            # of course, still running in the same interpreter.  So\n+            # after deserialization we reach in and change the value of\n+            # a field to simulate the field changing its hash code. We then\n+            # check that the object's hash code changes, indicating that we\n+            # don't have a stale hash code.\n+            # This could fail in two ways: (1) pickle.loads could get the hash\n+            # code of the deserialized value (triggering it to cache) before\n+            # we alter the field value.  This doesn't happen in our tested\n+            # Python versions.  (2) \"foo\" and \"something different\" could\n+            # have a hash collision on this interpreter run.   But this is\n+            # extremely improbable and would just result in one buggy test run.\n+            round_tripped.foo_string = \"something different\"\n+            assert original_hash != hash(round_tripped)\n+\n+        # Slots and non-slots classes implement __setstate__ differently,\n+        # so we need to test both cases.\n+        assert_hash_code_not_cached_across_serialization(\n+            HashCacheSerializationTestCached()\n+        )\n+        assert_hash_code_not_cached_across_serialization(\n+            HashCacheSerializationTestCachedSlots()\n+        )\n+\n+        # Test that a custom __setstate__ is disallowed on a\n+        # cache_hash=True object.\n+        # This is needed because we handle clearing the cache after\n+        # deserialization with a custom __setstate__. It is possible\n+        # to make both work, but it requires some thought about how to go\n+        # about it, so it has not yet been implemented.\n+        with pytest.raises(\n+            NotImplementedError,\n+            message=\"Currently you cannot use hash caching if you \"\n+            \"specify your own __setstate__ method.  This is tracked\"\n+            \"by https://github.com/python-attrs/attrs/issues/494\",\n+        ):\n+\n+            @attr.attrs(hash=True, cache_hash=True)\n+            class NoCacheHashAndCustomSetState(object):\n+                def __setstate__(self, state):\n+                    pass\n+\n+\n+# these are for use in TestAddHash.test_cache_hash_serialization\n+# they need to be out here so they can be un-pickled\n+@attr.attrs(hash=True, cache_hash=False)\n+class HashCacheSerializationTestUncached(object):\n+    foo_string = attr.ib(default=\"foo\")\n+\n+\n+@attr.attrs(hash=True, cache_hash=True)\n+class HashCacheSerializationTestCached(object):\n+    foo_string = attr.ib(default=\"foo\")\n+\n+\n+@attr.attrs(slots=True, hash=True, cache_hash=True)\n+class HashCacheSerializationTestCachedSlots(object):\n+    foo_string = attr.ib(default=\"foo\")\n+\n \n class TestAddInit(object):\n     \"\"\"\n",
        "problem_statement": "cache_hash can give the wrong hash code for deserialized objects\nI just realized a bug in the code I wrote for hash code caching (#426).  Because the hash code cache field gets serialized and deserialized by Pickle, when you deserialize a `cache_hash=True` `attrs` object, the hashcode will be the hashcode the object had at serialization-time. However, if your object has fields with hash codes which are not deterministic between interpreter runs, then on a new interpreter run your deserialized object will have a hash code which differs from a newly created identical object.\r\n\r\nWe can fix this for `pickle` by recomputing the hash code in `__setstate__`.  Other serialization libraries which don't respect `__setstate__` will still have a problem, but I don't think we can do anything about that.  If the `__setstate__` solution sounds acceptable I will implement it next week.\n",
        "hints_text": "",
        "created_at": "2019-01-22T20:01:01Z",
        "version": "18.2"
    }
}