{
    "task_id": "python-attrs__attrs-620",
    "setup_info": {
        "repo_path": "testbed/python-attrs__attrs-620_2025-07-03_17-42-35",
        "repo_cache_path": "testbed/python-attrs/attrs_cache"
    },
    "task_info": {
        "repo": "python-attrs/attrs",
        "pull_number": 620,
        "instance_id": "python-attrs__attrs-620",
        "issue_numbers": [
            "494"
        ],
        "base_commit": "8c00f755f9d91c06fbdd9a20e24d2c4663e6339d",
        "patch": "diff --git a/src/attr/_make.py b/src/attr/_make.py\n--- a/src/attr/_make.py\n+++ b/src/attr/_make.py\n@@ -70,6 +70,31 @@ def __repr__(self):\n \"\"\"\n \n \n+class _CacheHashWrapper(int):\n+    \"\"\"\n+    An integer subclass that pickles / copies as None\n+\n+    This is used for non-slots classes with ``cache_hash=True``, to avoid\n+    serializing a potentially (even likely) invalid hash value. Since ``None``\n+    is the default value for uncalculated hashes, whenever this is copied,\n+    the copy's value for the hash should automatically reset.\n+\n+    See GH #613 for more details.\n+    \"\"\"\n+\n+    if PY2:\n+        # For some reason `type(None)` isn't callable in Python 2, but we don't\n+        # actually need a constructor for None objects, we just need any\n+        # available function that returns None.\n+        def __reduce__(self, _none_constructor=getattr, _args=(0, \"\", None)):\n+            return _none_constructor, _args\n+\n+    else:\n+\n+        def __reduce__(self, _none_constructor=type(None), _args=()):\n+            return _none_constructor, _args\n+\n+\n def attrib(\n     default=NOTHING,\n     validator=None,\n@@ -523,34 +548,6 @@ def _patch_original_class(self):\n         for name, value in self._cls_dict.items():\n             setattr(cls, name, value)\n \n-        # Attach __setstate__. This is necessary to clear the hash code\n-        # cache on deserialization. See issue\n-        # https://github.com/python-attrs/attrs/issues/482 .\n-        # Note that this code only handles setstate for dict classes.\n-        # For slotted classes, see similar code in _create_slots_class .\n-        if self._cache_hash:\n-            existing_set_state_method = getattr(cls, \"__setstate__\", None)\n-            if existing_set_state_method:\n-                raise NotImplementedError(\n-                    \"Currently you cannot use hash caching if \"\n-                    \"you specify your own __setstate__ method.\"\n-                    \"See https://github.com/python-attrs/attrs/issues/494 .\"\n-                )\n-\n-            # Clears the cached hash state on serialization; for frozen\n-            # classes we need to bypass the class's setattr method.\n-            if self._frozen:\n-\n-                def cache_hash_set_state(chss_self, _):\n-                    object.__setattr__(chss_self, _hash_cache_field, None)\n-\n-            else:\n-\n-                def cache_hash_set_state(chss_self, _):\n-                    setattr(chss_self, _hash_cache_field, None)\n-\n-            cls.__setstate__ = cache_hash_set_state\n-\n         return cls\n \n     def _create_slots_class(self):\n@@ -612,11 +609,10 @@ def slots_setstate(self, state):\n             __bound_setattr = _obj_setattr.__get__(self, Attribute)\n             for name, value in zip(state_attr_names, state):\n                 __bound_setattr(name, value)\n-            # Clearing the hash code cache on deserialization is needed\n-            # because hash codes can change from run to run. See issue\n-            # https://github.com/python-attrs/attrs/issues/482 .\n-            # Note that this code only handles setstate for slotted classes.\n-            # For dict classes, see similar code in _patch_original_class .\n+\n+            # The hash code cache is not included when the object is\n+            # serialized, but it still needs to be initialized to None to\n+            # indicate that the first call to __hash__ should be a cache miss.\n             if hash_caching_enabled:\n                 __bound_setattr(_hash_cache_field, None)\n \n@@ -1103,7 +1099,23 @@ def _make_hash(cls, attrs, frozen, cache_hash):\n     unique_filename = _generate_unique_filename(cls, \"hash\")\n     type_hash = hash(unique_filename)\n \n-    method_lines = [\"def __hash__(self):\"]\n+    hash_def = \"def __hash__(self\"\n+    hash_func = \"hash((\"\n+    closing_braces = \"))\"\n+    if not cache_hash:\n+        hash_def += \"):\"\n+    else:\n+        if not PY2:\n+            hash_def += \", *\"\n+\n+        hash_def += (\n+            \", _cache_wrapper=\"\n+            + \"__import__('attr._make')._make._CacheHashWrapper):\"\n+        )\n+        hash_func = \"_cache_wrapper(\" + hash_func\n+        closing_braces += \")\"\n+\n+    method_lines = [hash_def]\n \n     def append_hash_computation_lines(prefix, indent):\n         \"\"\"\n@@ -1111,14 +1123,18 @@ def append_hash_computation_lines(prefix, indent):\n         Below this will either be returned directly or used to compute\n         a value which is then cached, depending on the value of cache_hash\n         \"\"\"\n+\n         method_lines.extend(\n-            [indent + prefix + \"hash((\", indent + \"        %d,\" % (type_hash,)]\n+            [\n+                indent + prefix + hash_func,\n+                indent + \"        %d,\" % (type_hash,),\n+            ]\n         )\n \n         for a in attrs:\n             method_lines.append(indent + \"        self.%s,\" % a.name)\n \n-        method_lines.append(indent + \"    ))\")\n+        method_lines.append(indent + \"    \" + closing_braces)\n \n     if cache_hash:\n         method_lines.append(tab + \"if self.%s is None:\" % _hash_cache_field)\n",
        "test_patch": "diff --git a/tests/test_dunders.py b/tests/test_dunders.py\n--- a/tests/test_dunders.py\n+++ b/tests/test_dunders.py\n@@ -310,6 +310,33 @@ def test_str_no_repr(self):\n         ) == e.value.args[0]\n \n \n+# these are for use in TestAddHash.test_cache_hash_serialization\n+# they need to be out here so they can be un-pickled\n+@attr.attrs(hash=True, cache_hash=False)\n+class HashCacheSerializationTestUncached(object):\n+    foo_value = attr.ib()\n+\n+\n+@attr.attrs(hash=True, cache_hash=True)\n+class HashCacheSerializationTestCached(object):\n+    foo_value = attr.ib()\n+\n+\n+@attr.attrs(slots=True, hash=True, cache_hash=True)\n+class HashCacheSerializationTestCachedSlots(object):\n+    foo_value = attr.ib()\n+\n+\n+class IncrementingHasher(object):\n+    def __init__(self):\n+        self.hash_value = 100\n+\n+    def __hash__(self):\n+        rv = self.hash_value\n+        self.hash_value += 1\n+        return rv\n+\n+\n class TestAddHash(object):\n     \"\"\"\n     Tests for `_add_hash`.\n@@ -492,85 +519,87 @@ def __hash__(self):\n         assert 2 == uncached_instance.hash_counter.times_hash_called\n         assert 1 == cached_instance.hash_counter.times_hash_called\n \n-    def test_cache_hash_serialization(self):\n+    @pytest.mark.parametrize(\"cache_hash\", [True, False])\n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    @pytest.mark.parametrize(\"slots\", [True, False])\n+    def test_copy_hash_cleared(self, cache_hash, frozen, slots):\n         \"\"\"\n-        Tests that the hash cache is cleared on deserialization to fix\n-        https://github.com/python-attrs/attrs/issues/482 .\n+        Test that the default hash is recalculated after a copy operation.\n         \"\"\"\n \n-        # First, check that our fix didn't break serialization without\n-        # hash caching.\n-        # We don't care about the result of this; we just want to make sure we\n-        # can do it without exceptions.\n-        hash(pickle.loads(pickle.dumps(HashCacheSerializationTestUncached)))\n-\n-        def assert_hash_code_not_cached_across_serialization(original):\n-            # Now check our fix for #482 for when hash caching is enabled.\n-            original_hash = hash(original)\n-            round_tripped = pickle.loads(pickle.dumps(original))\n-            # What we want to guard against is having a stale hash code\n-            # when a field's hash code differs in a new interpreter after\n-            # deserialization.  This is tricky to test because we are,\n-            # of course, still running in the same interpreter.  So\n-            # after deserialization we reach in and change the value of\n-            # a field to simulate the field changing its hash code. We then\n-            # check that the object's hash code changes, indicating that we\n-            # don't have a stale hash code.\n-            # This could fail in two ways: (1) pickle.loads could get the hash\n-            # code of the deserialized value (triggering it to cache) before\n-            # we alter the field value.  This doesn't happen in our tested\n-            # Python versions.  (2) \"foo\" and \"something different\" could\n-            # have a hash collision on this interpreter run.   But this is\n-            # extremely improbable and would just result in one buggy test run.\n-            round_tripped.foo_string = \"something different\"\n-            assert original_hash != hash(round_tripped)\n-\n-        # Slotted and dict classes implement __setstate__ differently,\n-        # so we need to test both cases.\n-        assert_hash_code_not_cached_across_serialization(\n-            HashCacheSerializationTestCached()\n-        )\n-        assert_hash_code_not_cached_across_serialization(\n-            HashCacheSerializationTestCachedSlots()\n-        )\n+        kwargs = dict(frozen=frozen, slots=slots, cache_hash=cache_hash,)\n+\n+        # Give it an explicit hash if we don't have an implicit one\n+        if not frozen:\n+            kwargs[\"hash\"] = True\n+\n+        @attr.s(**kwargs)\n+        class C(object):\n+            x = attr.ib()\n+\n+        a = C(IncrementingHasher())\n+        # Ensure that any hash cache would be calculated before copy\n+        orig_hash = hash(a)\n+        b = copy.deepcopy(a)\n \n-    def test_caching_and_custom_setstate(self):\n+        if kwargs[\"cache_hash\"]:\n+            # For cache_hash classes, this call is cached\n+            assert orig_hash == hash(a)\n+\n+        assert orig_hash != hash(b)\n+\n+    @pytest.mark.parametrize(\n+        \"klass,cached\",\n+        [\n+            (HashCacheSerializationTestUncached, False),\n+            (HashCacheSerializationTestCached, True),\n+            (HashCacheSerializationTestCachedSlots, True),\n+        ],\n+    )\n+    def test_cache_hash_serialization_hash_cleared(self, klass, cached):\n         \"\"\"\n-        The combination of a custom __setstate__ and cache_hash=True is caught\n-        with a helpful message.\n+        Tests that the hash cache is cleared on deserialization to fix\n+        https://github.com/python-attrs/attrs/issues/482 .\n \n-        This is needed because we handle clearing the cache after\n-        deserialization with a custom __setstate__. It is possible to make both\n-        work, but it requires some thought about how to go about it, so it has\n-        not yet been implemented.\n+        This test is intended to guard against a stale hash code surviving\n+        across serialization (which may cause problems when the hash value\n+        is different in different interpreters).\n         \"\"\"\n-        with pytest.raises(\n-            NotImplementedError,\n-            match=\"Currently you cannot use hash caching if you \"\n-            \"specify your own __setstate__ method.\",\n-        ):\n \n-            @attr.attrs(hash=True, cache_hash=True)\n-            class NoCacheHashAndCustomSetState(object):\n-                def __setstate__(self, state):\n-                    pass\n+        obj = klass(IncrementingHasher())\n+        original_hash = hash(obj)\n+        obj_rt = self._roundtrip_pickle(obj)\n \n+        if cached:\n+            assert original_hash == hash(obj)\n \n-# these are for use in TestAddHash.test_cache_hash_serialization\n-# they need to be out here so they can be un-pickled\n-@attr.attrs(hash=True, cache_hash=False)\n-class HashCacheSerializationTestUncached(object):\n-    foo_string = attr.ib(default=\"foo\")\n+        assert original_hash != hash(obj_rt)\n \n+    @pytest.mark.parametrize(\"frozen\", [True, False])\n+    def test_copy_two_arg_reduce(self, frozen):\n+        \"\"\"\n+        If __getstate__ returns None, the tuple returned by object.__reduce__\n+        won't contain the state dictionary; this test ensures that the custom\n+        __reduce__ generated when cache_hash=True works in that case.\n+        \"\"\"\n \n-@attr.attrs(hash=True, cache_hash=True)\n-class HashCacheSerializationTestCached(object):\n-    foo_string = attr.ib(default=\"foo\")\n+        @attr.s(frozen=frozen, cache_hash=True, hash=True)\n+        class C(object):\n+            x = attr.ib()\n \n+            def __getstate__(self):\n+                return None\n \n-@attr.attrs(slots=True, hash=True, cache_hash=True)\n-class HashCacheSerializationTestCachedSlots(object):\n-    foo_string = attr.ib(default=\"foo\")\n+        # By the nature of this test it doesn't really create an object that's\n+        # in a valid state - it basically does the equivalent of\n+        # `object.__new__(C)`, so it doesn't make much sense to assert anything\n+        # about the result of the copy. This test will just check that it\n+        # doesn't raise an *error*.\n+        copy.deepcopy(C(1))\n+\n+    def _roundtrip_pickle(self, obj):\n+        pickle_str = pickle.dumps(obj)\n+        return pickle.loads(pickle_str)\n \n \n class TestAddInit(object):\ndiff --git a/tests/test_make.py b/tests/test_make.py\n--- a/tests/test_make.py\n+++ b/tests/test_make.py\n@@ -1466,16 +1466,66 @@ class C2(C):\n \n         assert [C2] == C.__subclasses__()\n \n-    def test_cache_hash_with_frozen_serializes(self):\n+    def _get_copy_kwargs(include_slots=True):\n         \"\"\"\n-        Frozen classes with cache_hash should be serializable.\n+        Generate a list of compatible attr.s arguments for the `copy` tests.\n         \"\"\"\n+        options = [\"frozen\", \"hash\", \"cache_hash\"]\n \n-        @attr.s(cache_hash=True, frozen=True)\n+        if include_slots:\n+            options.extend([\"slots\", \"weakref_slot\"])\n+\n+        out_kwargs = []\n+        for args in itertools.product([True, False], repeat=len(options)):\n+            kwargs = dict(zip(options, args))\n+\n+            kwargs[\"hash\"] = kwargs[\"hash\"] or None\n+\n+            if kwargs[\"cache_hash\"] and not (\n+                kwargs[\"frozen\"] or kwargs[\"hash\"]\n+            ):\n+                continue\n+\n+            out_kwargs.append(kwargs)\n+\n+        return out_kwargs\n+\n+    @pytest.mark.parametrize(\"kwargs\", _get_copy_kwargs())\n+    def test_copy(self, kwargs):\n+        \"\"\"\n+        Ensure that an attrs class can be copied successfully.\n+        \"\"\"\n+\n+        @attr.s(eq=True, **kwargs)\n         class C(object):\n-            pass\n+            x = attr.ib()\n+\n+        a = C(1)\n+        b = copy.deepcopy(a)\n+\n+        assert a == b\n+\n+    @pytest.mark.parametrize(\"kwargs\", _get_copy_kwargs(include_slots=False))\n+    def test_copy_custom_setstate(self, kwargs):\n+        \"\"\"\n+        Ensure that non-slots classes respect a custom __setstate__.\n+        \"\"\"\n+\n+        @attr.s(eq=True, **kwargs)\n+        class C(object):\n+            x = attr.ib()\n+\n+            def __getstate__(self):\n+                return self.__dict__\n+\n+            def __setstate__(self, state):\n+                state[\"x\"] *= 5\n+                self.__dict__.update(state)\n+\n+        expected = C(25)\n+        actual = copy.copy(C(5))\n \n-        copy.deepcopy(C())\n+        assert actual == expected\n \n \n class TestMakeOrder:\n",
        "problem_statement": "Allow cache_hash=True to be used when a custom __setstate__ is present\nThis is not currently possible (as of the merge of #489 ) because when `cache_hash=True`, we solve #482 by adding a `__setstate__`  to all classes which clears the cached hash code.\r\n\r\nThis is a somewhat unusual combination of needs, so I imagine this is very low priority. This issue is just here as a marker for anyone who runs into this problem in the future.\n",
        "hints_text": "How about solving this (albeit mostly theoretical) issue by clearing the hash cache after invoking the custom `__setstate__`, like so (not including changes from #612 for simplicity, and there are lots of variations on how to implement this):\r\n\r\n```python\r\noriginal_setstate = getattr(cls, __setstate__, lambda s, _: None)\r\ndef cache_hash_set_state(chss_self, _):\r\n    original_setstate(chss_self, _)\r\n    setattr(chss_self, _hash_cache_field, None)\r\n```\r\n\r\nIf you consider the hash cache field to be an implementation detail owned by attrs, I think that likely the custom `__setstate__` shouldn't be touching it *anyway*, so this seems pretty safe. If you want a custom `__setstate__` that also has custom behavior involving the hash caching, you can implement a custom `__hash__` instead of using `cache_hash=True`.\n@pganssle : It has been a long time since I've touched this code, so I could be mistaken, but I believe your solution should work fine.  ",
        "created_at": "2020-01-27T18:44:43Z",
        "version": "19.3"
    }
}